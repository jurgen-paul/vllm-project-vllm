[33mcommit 46039703d19aabad486fe8a72f5bc586b4a1fb11[m[33m ([m[1;36mHEAD[m[33m)[m
Author: wwl2755 <wangwenlong2755@gmail.com>
Date:   Sun Mar 23 23:05:40 2025 +0000

    sucessfully save and load sharded state using V1
    
    Signed-off-by: wwl2755 <wangwenlong2755@gmail.com>

[33mcommit a4283e478da7a3df3dc90ddf62d6e2b65f29e0b5[m
Author: wwl2755 <wangwenlong2755@gmail.com>
Date:   Sun Mar 23 05:35:40 2025 +0000

    fix V1 engine core
    
    Signed-off-by: wwl2755 <wangwenlong2755@gmail.com>

[33mcommit e92694b6fe264a85371317295bca6643508034ef[m
Author: Lingfan Yu <lingfany@amazon.com>
Date:   Tue Feb 11 21:12:37 2025 -0800

    [Neuron][Kernel] Support Longer Sequences in NKI-based Flash PagedAttention and Improve Efficiency (#12921)
    
    Signed-off-by: Lingfan Yu <lingfany@amazon.com>

[33mcommit 842b0fd402574f49f8828fcff1b8dacc3bcab5fa[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Feb 11 20:38:10 2025 -0800

    [ci] Add more source file dependencies for some tests (#13123)
    
    Signed-off-by: <>
    Co-authored-by: EC2 Default User <ec2-user@ip-172-31-20-117.us-west-2.compute.internal>

[33mcommit 974dfd497149e871e59e35b677a85cca66ec3bae[m
Author: Christian Pinto <chrpinto@gmail.com>
Date:   Wed Feb 12 04:34:30 2025 +0000

    [Model] IBM/NASA Prithvi Geospatial model  (#12830)

[33mcommit 3ee696a63dd0c2acee44809a3bedec33ea27dfa0[m
Author: Keyun Tong <tongkeyun@gmail.com>
Date:   Tue Feb 11 20:25:58 2025 -0800

    [RFC][vllm-API] Support tokenizer registry for customized tokenizer in vLLM (#12518)
    
    Signed-off-by: Keyun Tong <tongkeyun@gmail.com>

[33mcommit 72c2b68dc9d4fb20eb135c22ee8c86caca48d28b[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Feb 11 17:34:16 2025 -0500

    [Misc] Move pre-commit suggestion back to the end (#13114)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 14ecab5be21b2af4ab1bbc6309d558ec620badc6[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Tue Feb 11 13:17:44 2025 -0500

    [Bugfix] Guided decoding falls back to outlines when fails to import xgrammar (#12976)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit deb6c1c6b4469984eb2a032099081f7f9e4ec8a8[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Tue Feb 11 18:02:46 2025 +0000

    [Doc] Improve OpenVINO installation doc (#13102)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit 565c1efa65358f43a78a52296d658651dd2b8f36[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Wed Feb 12 00:55:56 2025 +0800

    [CI/Build][Bugfix] Fix CPU backend default threads num (#13077)

[33mcommit 2b25b7d2e1bd915dde2890e7a923958c8d1eb8e2[m
Author: Szymon O≈º√≥g <58388001+SzymonOzog@users.noreply.github.com>
Date:   Tue Feb 11 17:38:48 2025 +0100

    Fix initializing GGUF weights for ColumnParallelLinear when using tensor parallel > 1 (#13023)

[33mcommit 6c4dbe23eb85e5d1da00ccaf4923a275d8769a7f[m
Author: ‚Ñçùï†ùïùùïùùï†ùï® ùïÑùïíùïü <hollowman@opensuse.org>
Date:   Tue Feb 11 18:21:50 2025 +0200

    [BugFix] Pop instead of del CUDA_VISIBLE_DEVICES (#12962)
    
    Signed-off-by: Hollow Man <hollowman@opensuse.org>

[33mcommit 21f5d50fa557f431e9c76d432771337f5399c420[m
Author: MoonRide303 <130458190+MoonRide303@users.noreply.github.com>
Date:   Tue Feb 11 17:21:18 2025 +0100

    [Bugfix] Do not use resource module on Windows (#12858) (#13029)

[33mcommit bf3e05215c7f20baf9fcd82d8877d8453dcebf6e[m
Author: Jewon Lee <105219284+je1lee@users.noreply.github.com>
Date:   Wed Feb 12 01:20:37 2025 +0900

    [Misc] Fix typo at comments at metrics.py (#13024)

[33mcommit ad9776353e6b00d019415e94fd17c78ad4575ff7[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Tue Feb 11 15:51:19 2025 +0000

    Set `torch_dtype` in `TransformersModel` (#13088)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit 75e6e145164c8e47a97b6e29654fe81b2fbc1ff5[m
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Tue Feb 11 15:14:00 2025 +0000

    [V1][Metrics] Add several request timing histograms (#12644)
    
    Signed-off-by: Mark McLoughlin <markmc@redhat.com>

[33mcommit 110f59a33e22aaa16a1d0278bb19f76e4fe5f5a3[m
Author: ‡ÆÆ‡Æ©‡Øã‡Æú‡Øç‡Æï‡ØÅ‡ÆÆ‡Ææ‡Æ∞‡Øç ‡Æ™‡Æ¥‡Æ©‡Æø‡Æö‡Øç‡Æö‡Ææ‡ÆÆ‡Æø <smartmanoj42857@gmail.com>
Date:   Tue Feb 11 20:11:20 2025 +0530

    [Bugfix] fix flaky test (#13089)
    
    Signed-off-by: ‡ÆÆ‡Æ©‡Øã‡Æú‡Øç‡Æï‡ØÅ‡ÆÆ‡Ææ‡Æ∞‡Øç ‡Æ™‡Æ¥‡Æ©‡Æø‡Æö‡Øç‡Æö‡Ææ‡ÆÆ‡Æø <smartmanoj42857@gmail.com>

[33mcommit 2e3b969ec0d46e2cfff041a07f29a2ca4bb82bbd[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Tue Feb 11 22:06:46 2025 +0800

    [Platform] add pre_register_and_update function (#12432)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit da317197dd9352a7718d9bf697c2a5aeb9d42b41[m
Author: Yuhong Guo <yuhong.gyh@antgroup.com>
Date:   Tue Feb 11 21:55:57 2025 +0800

    [Build] Fix cuda link target of cumem_allocator in CPU env (#12863)
    
    Signed-off-by: YuhongGuo <yuhong.gyh@antgroup.com>
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 7539bbc6a6715dc8e5e71730e2377219b0e69e21[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Tue Feb 11 08:47:10 2025 -0500

    [ROCm] Using a more precise memory profiling (#12624)
    
    Signed-off-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>

[33mcommit 9cf4759493919580011f03812abf16387eafe18c[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Tue Feb 11 21:20:53 2025 +0800

    [executor] init `local_rank` as device index (#13027)
    
    Signed-off-by: Mengqing Cao <cmq0113@163.com>

[33mcommit 41c5dd45b98d5a6facad328a1ce534b9a94763a2[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Tue Feb 11 00:27:25 2025 -0800

    [V1][Metrics] Add GPU prefix cache hit rate % gauge (#12592)

[33mcommit fc6485d27750076642e99a1ef2df0e6375958bb4[m
Author: Ce Gao <cegao@tensorchord.ai>
Date:   Tue Feb 11 15:49:03 2025 +0800

    [Bugfix]: Reasoning output bug according to the chat template change (#13025)
    
    Signed-off-by: Ce Gao <cegao@tensorchord.ai>

[33mcommit 78a141d768a18edc8c598a57d992e6aa56a33259[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Tue Feb 11 12:56:03 2025 +0530

    [Misc] LoRA - Refactor Punica ops tests (#12970)
    
    Signed-off-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit c320ca8edd5c4c19e7581703e428dd566b068756[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Feb 11 02:25:25 2025 -0500

    [Core] Don't do platform detection at import time (#12933)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 58047c6f0410fc7a86b64c88c092a246984b2342[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 10 21:25:30 2025 -0800

    [Benchmark] Add BurstGPT to benchmark_serving (#13063)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit cb080f32e38e87beda897d0602bf6a0d0c79d00f[m
Author: Florian Greinacher <florian.greinacher@siemens.com>
Date:   Tue Feb 11 04:33:33 2025 +0100

    [Bugfix] Support missing tool parameters in mistral tokenizer (#12884)
    
    Signed-off-by: Florian Greinacher <florian.greinacher@siemens.com>

[33mcommit 2c0f58203c111bcc331f931664400acfc94cb9bc[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Feb 10 18:24:29 2025 -0800

    [Docs] Annouce Meta Meetup (#13065)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit 2ff4857678044407a959398178a7a04a9530919a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 10 18:10:06 2025 -0800

    [V1][Minor] Move scheduler outputs to a separate file (#13062)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 91e876750eace8e899ab25cd5d93fc365906c07b[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Feb 10 18:06:16 2025 -0800

    [misc] Fix setup.py condition to avoid AMD from being mistaken with CPU (#13022)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 08b2d845d6261309bfdb46933f872eebe4e2bb31[m
Author: Farzad Abdolhosseini <farzad.abdolhosseini@gmail.com>
Date:   Mon Feb 10 14:02:48 2025 -0800

    [Model] Ultravox Model: Support v0.5 Release (#12912)
    
    Signed-off-by: Farzad Abdolhosseini <farzad@fixie.ai>

[33mcommit 2ae889052c6d0205ca677052ddb41db96a2a2620[m
Author: ‡ÆÆ‡Æ©‡Øã‡Æú‡Øç‡Æï‡ØÅ‡ÆÆ‡Ææ‡Æ∞‡Øç ‡Æ™‡Æ¥‡Æ©‡Æø‡Æö‡Øç‡Æö‡Ææ‡ÆÆ‡Æø <smartmanoj42857@gmail.com>
Date:   Mon Feb 10 20:56:50 2025 +0530

    Fix seed parameter behavior in vLLM (#13007)
    
    Signed-off-by: ‡ÆÆ‡Æ©‡Øã‡Æú‡Øç‡Æï‡ØÅ‡ÆÆ‡Ææ‡Æ∞‡Øç ‡Æ™‡Æ¥‡Æ©‡Æø‡Æö‡Øç‡Æö‡Ææ‡ÆÆ‡Æø <smartmanoj42857@gmail.com>

[33mcommit 51f0b5f7f6ec4aa8199f12bb7df08c9cb5e025db[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Feb 10 18:45:21 2025 +0800

    [Bugfix] Clean up and fix multi-modal processors (#13012)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit fde71262e0c235fa5ad80677b3ba65df7f5110de[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Feb 10 01:15:02 2025 -0800

    [misc] Add retries with exponential backoff for HF file existence check (#13008)

[33mcommit 243137143c81f738db17cfcd93d991f6dd842e27[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Mon Feb 10 01:09:33 2025 -0500

    [Doc] Add link to tool_choice tracking issue in tool_calling.md (#13003)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit b2496bb07fdf9318e7d9a8065356941fef380bac[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Feb 10 13:03:43 2025 +0800

    [core] fix sleep mode and pytorch checkpoint compatibility (#13001)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 44607e07d3baf297efe56d77b3b1ddfbf16dad88[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Sun Feb 9 22:45:07 2025 -0500

    Check if selected backend is None in get_attn_backend_cls() (#12975)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit 67c4637ccfd1f1b4e4aa2b645a5635096cf6d1fe[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sun Feb 9 19:35:56 2025 -0800

    [V1] Use msgpack for core request serialization (#12918)
    
    Signed-off-by: Nick Hill <nhill@redhat.com>

[33mcommit aa0ca5ebb7936587b4acde66cc466495b358be04[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Feb 10 10:28:59 2025 +0800

    [core][rlhf] add colocate example for RLHF (#12984)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 59fff4a01ae0f5c887cc547af6b49a9b028b4c70[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Feb 10 09:38:57 2025 +0800

    [core] improve error handling when wake up from sleep mode (#12981)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 29f1d47e73de3764c944a0af0ff10bbc8ce244f4[m
Author: Lu Fang <30275821+houseroad@users.noreply.github.com>
Date:   Sun Feb 9 02:56:40 2025 -0800

    [MISC] Always import version library first in the vllm package (#12979)
    
    Signed-off-by: Lu Fang <lufang@fb.com>

[33mcommit cf797aa856995a474eec310884f2a71a3826c0f3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Feb 9 15:00:00 2025 +0800

    [core] port pynvml into vllm codebase (#12963)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 24700c346bee5760f015bf41cdc6fd9ffb5d6aaf[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Feb 8 15:32:32 2025 -0800

    [V1] Cache `uses_mrope` in GPUModelRunner (#12969)

[33mcommit d366ccc4e391ab772711f0832e8ea61d90d5def3[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Sat Feb 8 22:12:53 2025 +0100

    [RFC] [Mistral] FP8 format (#10130)
    
    Signed-off-by: mgoin <mgoin64@gmail.com>
    Co-authored-by: mgoin <mgoin64@gmail.com>

[33mcommit 870c37481e4d9dbcd548344e1eee6bd83993388a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Feb 8 12:48:30 2025 -0800

    [V1][Minor] Remove outdated comment (#12968)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 86222a3dab50b66bb0bff17a94b629aa59c3ed57[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Feb 9 04:32:16 2025 +0800

    [VLM] Merged multi-modal processor for GLM4V (#12449)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit fe743b798dfa56aea3e2cb7182365ba3495489ee[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Feb 9 00:06:56 2025 +0800

    [bugfix] fix early import of flash attention (#12959)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 913df14da3014d9432bfd8a5114f845ab567b1c6[m
Author: shangmingc <caishangming@linux.alibaba.com>
Date:   Sat Feb 8 22:46:19 2025 +0800

    [Bugfix] Remove unused seq_group_metadata_list from ModelInputForGPU (#12935)
    
    Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com>

[33mcommit 8a69e0e20e72d429aaf379ae7647f0434a0e9c9e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Feb 8 20:25:15 2025 +0800

    [CI/Build] Auto-fix Markdown files (#12941)

[33mcommit 4c8dd12ef3474e43c614a229dabe85cc47432cf8[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sat Feb 8 20:24:47 2025 +0800

    [Misc] Add qwen2.5-vl BNB support (#12944)

[33mcommit 256a2d29dc2358d7c0a5d38c0faf152095335929[m
Author: Jun Duan <jun.duan.phd@outlook.com>
Date:   Sat Feb 8 04:42:15 2025 -0500

    [Doc] Correct HF repository for TeleChat2 models (#12949)

[33mcommit c45d398e6f0e1c78b958d2e0346b860c23444af9[m
Author: Liangfu Chen <liangfc@amazon.com>
Date:   Sat Feb 8 01:41:35 2025 -0800

    [CI] Resolve transformers-neuronx version conflict (#12925)

[33mcommit 011e612d92c25cb1a3cbfa1536cb8edd871d7715[m
Author: Jun Duan <jun.duan.phd@outlook.com>
Date:   Sat Feb 8 04:16:42 2025 -0500

    [Misc] Log time consumption on weight downloading (#12926)

[33mcommit 7e1837676a3230b1b392d7699771cdb3f3407242[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Sat Feb 8 14:45:44 2025 +0530

    [misc]  Add LoRA to benchmark_serving (#12898)
    
    Signed-off-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 2880e21e3d2513c89bd63ac05b718e0c0a50e4e4[m
Author: Sanju C Sudhakaran <scsudhakaran@habana.ai>
Date:   Sat Feb 8 14:45:30 2025 +0530

    [Hardware][Intel-Gaudi] Enable long-contexts + LoRA support for Intel Gaudi (#12812)
    
    Signed-off-by: Sanju C Sudhakaran <scsudhakaran@habana.ai>

[33mcommit 407b5537db02da122abf863673fc6cb76795e8bd[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Sat Feb 8 17:15:15 2025 +0800

    [Build] Make pypi install work on CPU platform (#12874)

[33mcommit 4ea48fb35cf67d61a1c3f18e3981c362e1d8e26f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Feb 8 00:39:09 2025 -0800

    [V1][Minor] Move cascade attn logic outside _prepare_inputs (#12943)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit e31498bdcbd70f91786fd2f23f4afabdd4256f1c[m
Author: Shaoting <shaotingf@uchicago.edu>
Date:   Sat Feb 8 02:38:20 2025 -0600

    [Misc] Add offline test for disaggregated prefill (#12418)

[33mcommit 91dd8f7aa63a1923cc17868c7646d1277d64ed53[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Feb 8 16:17:08 2025 +0800

    [bugfix] respect distributed_executor_backend in world_size=1 (#12934)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d01f66b0394e62a11429c8f0afd9a56b7b2b7f0c[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Fri Feb 7 23:04:34 2025 -0800

    [Bugfix] Fix multi-round chat error when mistral tokenizer is used (#12859)
    
    Signed-off-by: Zifei Tong <zifeitong@gmail.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit cc01223f3ba0434487a0179a2ccd2107bf3c93cb[m
Author: Ke Zhao <yingxiongraomingzk@gmail.com>
Date:   Sat Feb 8 14:56:43 2025 +0800

    [Misc] Fix typo in the example file (#12896)
    
    Signed-off-by: Zhao Ke <yingxiongraomingzk@gmail.com>

[33mcommit 306923da82535593bc508cc4e039bdec55159e9f[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sat Feb 8 13:02:53 2025 +0800

    [Bugfix] Fix Qwen2_5_VLForConditionalGeneration packed_modules_mapping (#12905)

[33mcommit 3243158336d377c8aced151722b5f8bbff2f905d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 7 19:14:10 2025 -0800

    [V1] Move KV block hashes from Request to KVCacheManager (#12922)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit b21f0f9d173e5094791815380cb213f9eed44bad[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 7 19:07:37 2025 -0800

    [V1][Minor] Remove outdated comment (#12928)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 45cbc4991dcf405c959f774d07e66e7e9ac71f0c[m
Author: Lu Fang <30275821+houseroad@users.noreply.github.com>
Date:   Fri Feb 7 16:39:50 2025 -0800

    [Bugfix] Fix disagg hang caused by the prefill and decode communication issues (#12723)
    
    Signed-off-by: Lu Fang <lufang@fb.com>

[33mcommit 932c6b74616d25199e87c96707e8cfea3ab045c0[m
Author: Robert Shaw <114415538+robertgshaw2-redhat@users.noreply.github.com>
Date:   Fri Feb 7 18:07:03 2025 -0500

    [V1] LM Eval With Streaming Integration Tests (#11590)

[33mcommit eaa92d443743830f9efd35320cf6d440e49283e3[m
Author: TJian <tunjian.tan@embeddedllm.com>
Date:   Sat Feb 8 00:13:43 2025 +0800

    [ROCm] [Feature] [Doc] [Dockerfile] [BugFix] Support Per-Token-Activation Per-Channel-Weight FP8 Quantization Inferencing (#12501)

[33mcommit 0630d4537a5fbab80cb1109a26170101cffb7f84[m
Author: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
Date:   Fri Feb 7 10:26:20 2025 -0500

    [V1] Logprobs and prompt logprobs support (#9880)
    
    This PR is adding support for sample logprobs & prompt logprobs to vLLM v1.
    
    New behavior:
    
    - During model execution, model runner computes sample logprobs (if user-provided logprobs setting is not None) and prompt logprobs (if user-provided prompt_logprobs setting is not None). For both sample and prompt logprobs, the engine core returns 3 vectors: token ids, token logprob values, token ranks. Ranks reflect tokens' 1-indexed positions in the vocabulary vector after sorting the vocabulary by log probability in descending order.
    - In scheduler.update_from_output(), sample and prompt logprobs are incorporated into the EngineCoreOutput data structure which is transferred to the engine client. If multiprocessing is enabled, then sample and prompt logprobs will be (de)serialized when the EngineCoreOutput data structure is (de)serialized.
    - During output processing, the LogprobsProcessor transforms the triplet of token ids, token logprobs values, and token ranks into the OpenAI-compatible List[Dict[token id,Logprob]] format (for sample and prompt logprobs respectively.)
    - Each Logprob instance (whether sample- or prompt-) consists of a token's log-probability, rank, and detokenized string representation. Note that logprob detokenization is handled by the LogprobsProcessor not the detokenizer.
    
    Signed-off-by: Andrew Feldman <afeldman@neuralmagic.com>
    Signed-off-by: Nick Hill <nhill@redhat.com>
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>
    
    
    Co-authored-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>
    Co-authored-by: Nick Hill <nhill@redhat.com>

[33mcommit 538fab93cdd36e965ea1888143dab0df57c8ba84[m
Author: Amit Garg <mitgarg17495@gmail.com>
Date:   Fri Feb 7 06:22:37 2025 -0800

    PR #12718 (#12718)

[33mcommit ce26b16268ef8d7db5c1346c482b899f49dcd3cd[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Feb 7 22:21:17 2025 +0800

    [Misc] Remove unnecessary detokenization in multimodal processing (#12868)

[33mcommit 1918aa1b8010c00443b71f8bb976d4db4acf3c18[m
Author: Lu Fang <30275821+houseroad@users.noreply.github.com>
Date:   Fri Feb 7 05:04:39 2025 -0800

    [MISC][EASY] Break check file names into entry and args in the pre-commit hooks (#12880)
    
    Signed-off-by: Lu Fang <lufang@fb.com>

[33mcommit 6e1fc61f0fb90c37f0d4a1a8f76235a6e4e1103c[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Fri Feb 7 02:37:41 2025 -0300

    Prevent unecessary requests to huggingface hub (#12837)

[33mcommit aa375dca9fbeff03904cd7b7dcc5014bfa19b0fb[m
Author: Szymon O≈º√≥g <58388001+SzymonOzog@users.noreply.github.com>
Date:   Fri Feb 7 06:35:09 2025 +0100

    [Bugfix] Missing quant_config in deepseek embedding layer (#12836)

[33mcommit 433c4a49230a470f13657f06e7612cde86e4fb40[m
Author: ZSL98 <36250440+ZSL98@users.noreply.github.com>
Date:   Fri Feb 7 11:54:20 2025 +0800

    Make vllm compatible with verl (#12824)
    
    Co-authored-by: zhangshulai <zhangshulai@bytedance.com>

[33mcommit ef533d25fba4b5ef8b4da9369de718c0773b9bce[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Feb 6 22:54:07 2025 -0500

    [Bugfix] FA2 illegal memory access (#12848)

[33mcommit b26078235722a434d92fe90dcea2023a5ae7294a[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Feb 6 16:29:12 2025 -0800

    [misc] Revert # 12833 (#12857)
    
    Signed-off-by: <>
    Co-authored-by: EC2 Default User <ec2-user@ip-172-31-20-117.us-west-2.compute.internal>

[33mcommit 741429a4cd4443001264a2c89c0150c12c2bd750[m
Author: Lu Fang <30275821+houseroad@users.noreply.github.com>
Date:   Thu Feb 6 15:36:21 2025 -0800

    [MISC] Check space in the file names in the pre commit checks (#12804)
    
    Signed-off-by: Lu Fang <lufang@fb.com>

[33mcommit aff404571b0d5aba342c46fdf5d7f8a251da9383[m
Author: Yu Chin Fabian Lim <fabianlim@users.noreply.github.com>
Date:   Fri Feb 7 07:22:42 2025 +0800

    Add Bamba Model (#10909)
    
    Signed-off-by: Yu Chin Fabian Lim <flim@sg.ibm.com>
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 467a96a5415dc896170cecc0bb83d9c49c2f3c5e[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Thu Feb 6 23:02:51 2025 +0530

    [V1] LoRA Support (#10957)
    
    Signed-off-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 8108ac841d66515b58252edc26ba63da6cf980e5[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Feb 7 01:18:22 2025 +0800

    [Bugfix] Fix unsupported FA version check for Turing GPU (#12828)

[33mcommit afe74f7a969132ec17589e51edb645b894439c0a[m
Author: Jitse Klomp <jitse@jitseklomp.nl>
Date:   Thu Feb 6 18:17:55 2025 +0100

    [Doc] double quote cmake package in build.inc.md (#12840)

[33mcommit 09b95e36abbce747b52b9c3e7ae4cceaf40076ad[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Feb 7 01:09:07 2025 +0800

    [torch.compile] PyTorch 2.6 and nightly compatibility (#12393)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 85ac82d228ef6af4e8fc6332d918133e783a0fdb[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Feb 7 00:46:13 2025 +0800

    [Kernel] Make rotary_embedding ops more flexible with input shape (#12777)

[33mcommit 1e57b1ee6312325a9dab99918422693c38f2b203[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Feb 7 00:45:44 2025 +0800

    [Misc] Remove unnecessary decode call (#12833)

[33mcommit e152f295020ea2a7ca37be9cabadfaef78464274[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Feb 6 06:59:18 2025 -0800

    [misc] Reduce number of config file requests to HuggingFace (#12797)
    
    Signed-off-by: EC2 Default User <ec2-user@ip-172-31-20-117.us-west-2.compute.internal>
    Signed-off-by: <>
    Co-authored-by: EC2 Default User <ec2-user@ip-172-31-20-117.us-west-2.compute.internal>

[33mcommit c786e757fae4519256e4ef88a7d4f56c3339d14d[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Feb 6 06:43:12 2025 -0500

    [Attention] Use FA3 for MLA on Hopper (#12807)
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit cefd56ee354b915e2fff6b2b5eb1f8b55721fe7e[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Feb 6 01:02:38 2025 -0800

    [Docs] Add Google Cloud Slides (#12814)

[33mcommit 7ca9934fe773edf8680aed287b0a05cb195bd8e4[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Thu Feb 6 04:02:14 2025 -0500

    [Misc] Update w2 scale loading for GPTQMarlinMoE (#12757)

[33mcommit 0408efc6d0c17fba17b2be38d0d0f02e96d2bf9d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Feb 6 15:23:50 2025 +0800

    [Misc] Improve error message for incorrect pynvml (#12809)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 449d1bce029f87e0d1cf3f30483687ff659268f2[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Feb 6 02:16:20 2025 -0500

    [Misc] Remove duplicated DeepSeek V2/V3 model definition (#12793)

[33mcommit 1a6fcad4c933c89b4060a37d807a7f9e5a680cf3[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Thu Feb 6 06:24:57 2025 +0000

    Improve `TransformersModel` UX (#12785)

[33mcommit 56534cd577211c563b2c5b74098929b949fc4063[m
Author: Lu Fang <30275821+houseroad@users.noreply.github.com>
Date:   Wed Feb 5 21:25:54 2025 -0800

    [Bugfix] Fix the test_ultravox.py's license (#12806)
    
    Signed-off-by: Lu Fang <lufang@fb.com>

[33mcommit d88506dda45f69cf1f56c4325282c2a881eaaaf7[m
Author: Sumit Vij <sumitvij11+github@gmail.com>
Date:   Wed Feb 5 19:54:13 2025 -0800

    [Model] LoRA Support for Ultravox model (#11253)

[33mcommit 9cdea30b4fe0ebd23847371f51ea0a48b9615847[m
Author: Lu Fang <30275821+houseroad@users.noreply.github.com>
Date:   Wed Feb 5 19:23:35 2025 -0800

    [Misc][Easy] Remove the space from the file name

[33mcommit 76abd0c88143419826bfc13d2cd29669d0fdfa1b[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Wed Feb 5 22:22:19 2025 -0500

    [Bugfix] Better FP8 supported defaults

[33mcommit 5b19b93082fc5ad0ce33752d8467337cbe93de21[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Wed Feb 5 22:15:08 2025 -0500

    [ROCm][Kernel] Using the correct warp_size value

[33mcommit 75404d041be0d6e656b59cbbea23520d47d37b66[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Feb 6 11:09:45 2025 +0800

    [VLM] Update compatibility with transformers 4.49

[33mcommit bf3b79efb82676219a3275764d8fcf4c70097ce5[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Feb 5 13:31:38 2025 -0800

    [VLM] Qwen2.5-VL

[33mcommit 9a5b1554b4f049aad6398bb29d3064138ac9a039[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Feb 5 16:30:50 2025 -0500

    [Docs] Drop duplicate [source] links

[33mcommit a4ce74c14a469b178c446a34ce48f158909a8e74[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Feb 6 05:30:46 2025 +0800

    [VLM] Use shared field to pass token ids to model

[33mcommit 3b2005e1db79efe2ea4587035eb2e7ced6e258cb[m
Author: Rahul Tuli <rahul@neuralmagic.com>
Date:   Wed Feb 5 15:30:43 2025 -0600

    Add: Support for Sparse24Bitmask Compressed Models

[33mcommit af8486de49a200a980f71fddc6d1eb4d8f9f1bca[m
Author: Sanju C Sudhakaran <scsudhakaran@habana.ai>
Date:   Thu Feb 6 02:59:45 2025 +0530

    [Hardware][Intel-Gaudi] Enable FusedSDPA support for Intel Gaudi (HPU)

[33mcommit 4c3aac51e14214880a3205b45c26aa16535992b5[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Thu Feb 6 05:24:26 2025 +0800

    Merging PR #12536
    
    Merged via CLI script

[33mcommit bc1bdecebf76cca0dfafe4924d529b30c8a24795[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Feb 6 02:03:19 2025 +0800

    [core][distributed] exact ray placement control (#12732)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 022bcc701a948f96e68af678eee686837f393d07[m
Author: Akash kaothalkar <61960177+Akashcodes732@users.noreply.github.com>
Date:   Wed Feb 5 12:41:02 2025 +0530

    [Bugfix] Fix 'ModuleNotFoundError: No module named 'intel_extension_for_pytorch'' for --tensor-parallel-size more than 1  (#12546)

[33mcommit c53dc466b1b802d45d0b61cce36908334ea7a23e[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Feb 5 01:43:11 2025 -0500

    [Doc] Remove performance warning for auto_awq.md (#12743)

[33mcommit 3d09e592a860982acef0edef858078d28d393e84[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Feb 4 22:43:02 2025 -0800

    [V1][Misc] Shorten `FinishReason` enum and use constant strings (#12760)

[33mcommit fcf2e3d7fcc9898b7a1b26bacea22753ab76f3a6[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Wed Feb 5 06:42:46 2025 +0000

    [Bugfix] Fix OpenVINO model runner (#12750)

[33mcommit 58b218d7ae91340a70a2a961d03f6e49315c2cfa[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Feb 5 01:42:09 2025 -0500

    [Doc] Update PR Reminder with link to Developer Slack (#12748)

[33mcommit 7ff7a638b66fdeca71257f245369bd7337e55d32[m
Author: Kyle Sayers <kylesayrs@gmail.com>
Date:   Wed Feb 5 00:32:06 2025 -0500

    [Model][Quant] Fix GLM, Fix fused module mappings for quantization (#12634)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Signed-off-by: Kyle Sayers <kylesayrs@gmail.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit 686006a22020c80fcaab2d12064302505188f577[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Feb 4 23:44:48 2025 -0500

    [Misc] Bump the compressed-tensors version (#12736)

[33mcommit 98fd089fc974313ac13370f79f4c02a3839baf4a[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Wed Feb 5 12:44:26 2025 +0800

    [VLM] Add MLA with pure RoPE support for deepseek-vl2 models (#12729)

[33mcommit 249824c3bfef6b9c03dd087569ef1e1072b2a4b0[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Wed Feb 5 04:31:12 2025 +0000

    Refactor `Linear` handling in `TransformersModel` (#12727)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit 64862d106efa78032702f5fa5c110ccd6d654e9a[m
Author: Aleksandr Malyshev <164964928+maleksan85@users.noreply.github.com>
Date:   Tue Feb 4 19:58:22 2025 -0800

    [ROCM][AMD][TRITON] Halving warps number for fw_prefill to reduce spilling (#12713)
    
    Signed-off-by: Aleksandr Malyshev <maleksan@amd.com>
    Co-authored-by: Aleksandr Malyshev <maleksan@amd.com>

[33mcommit b3a0d01e4551118c735ee905c4ddc800ec603f24[m
Author: Aviv Keshet <akeshet@gmail.com>
Date:   Tue Feb 4 18:46:26 2025 -0800

    [Core] add and implement `VLLM_LOGITS_PROCESSOR_THREADS` (#12368)
    
    Signed-off-by: Aviv Keshet <akeshet@scaledcognition.com>

[33mcommit 75e94309e8d8919e0daea041f6cd81a4b8c09060[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Tue Feb 4 21:22:24 2025 -0500

    [Perf] Mem align KV caches for CUDA devices (MLA perf improvement) (#12676)
    
    Signed-off-by: simon-mo <xmo@berkeley.edu>
    Signed-off-by: Lucas Wilkinson <lcwilkins@redhat.com>
    Signed-off-by: Lucas Wilkinson <lwilkins@redhat.com>
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>
    Co-authored-by: simon-mo <xmo@berkeley.edu>

[33mcommit 233df6f5c4520ae57e4a24acfbaedcc9ce166074[m
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Wed Feb 5 00:46:54 2025 +0000

    [V1][Metrics] Add request_success_total counter, labelled with finish reason (#12579)
    
    Signed-off-by: Mark McLoughlin <markmc@redhat.com>

[33mcommit 18016a5e627d2a4b69af599272a5aa8ce71b98c8[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Feb 4 23:54:23 2025 +0800

    [Bugfix] Fix CI failures for InternVL and Mantis models (#12728)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 649550f27e4ad35e7e3352800438991fdaf150a4[m
Author: Sophie du Cou√©dic <sophie.du.couedic.de.kergoualer@ibm.com>
Date:   Tue Feb 4 14:19:12 2025 +0100

    [Build] update requirements of no-device for plugin usage (#12630)
    
    Signed-off-by: Sophie du Cou√©dic <sop@zurich.ibm.com>

[33mcommit 62467a834a94566e2d81a276817a20174b474151[m
Author: Kero Liang <kerorek@outlook.com>
Date:   Tue Feb 4 21:03:19 2025 +0800

    Avoid unnecessary multi-modal input data copy when len(batch) == 1 (#12722)
    
    Signed-off-by: imkero <kerorek@outlook.com>

[33mcommit 6469038b149425e25b77c1ef93adf0e7712fd100[m
Author: Michael Greenbaum <48786769+mgtk77@users.noreply.github.com>
Date:   Tue Feb 4 14:58:48 2025 +0200

    [Bugfix] Fix loading of fine-tuned models based on Phi-3-Small (#12689)
    
    Signed-off-by: Michael Greenbaum <mgreenbaum@microsoft.com>
    Co-authored-by: Michael Greenbaum <mgreenbaum@microsoft.com>

[33mcommit 815079de8e9dd984d474f7046412d5aedf4350ff[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Tue Feb 4 20:00:51 2025 +0800

    [VLM] merged multimodal processor and V1 support for idefics3 (#12660)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 18a88fcccce73261d51a18aba17368236ceb2f8b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 4 02:43:58 2025 -0800

    [V1] Remove scheduling constraint on partial requests (#12674)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit d1ca7df84d9f8853001bdf1c2900321d9cb5d64e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Feb 4 16:44:52 2025 +0800

    [VLM] Merged multi-modal processor for InternVL-based models (#12553)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 96b23621c16d4e3b65380c6af3a7d7bac79cfa5b[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Feb 4 16:27:36 2025 +0800

    [Misc] Add BNB quantization for Whisper (#12381)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit c36ac98d0118537ec5f3f405a68311a10f9b59a5[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Tue Feb 4 03:24:11 2025 -0500

    [AMD][ROCm] Enable DeepSeek model on ROCm (#12662)
    
    Signed-off-by: Hongxia Yang <hongxia.yang@amd.com>
    Co-authored-by: Matthew Wong <Matthew.Wong2@amd.com>

[33mcommit 4896d0c2dd367efbdf8387028322bf5f74359930[m
Author: Kyle Sayers <kylesayrs@gmail.com>
Date:   Tue Feb 4 02:27:11 2025 -0500

    [Quant] Fix use_mla TypeError and support loading pure-sparsity Compressed Tensors configs (#12711)

[33mcommit bb392af434a49b3f8655f0e78737ced6524056b7[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Tue Feb 4 02:05:04 2025 -0500

    [Doc] Replace ibm-fms with ibm-ai-platform (#12709)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 5d98d56089426555d303d82bdf29b9ffc825ec20[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Feb 3 22:55:46 2025 -0500

    Support Pixtral-Large HF by using llava multimodal_projector_bias config (#12710)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 73b35cca7f3745d07d439c197768b25d88b6ab7f[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Mon Feb 3 19:28:20 2025 -0500

    [Core] Improve hash collision avoidance in prefix caching (#12621)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 5095e966069b9e65b7c4c63427e06cebacaad0a0[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Mon Feb 3 15:04:53 2025 -0800

    [V1] Revert `uncache_blocks` and support recaching full blocks (#12415)
    
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit cf58b9c4cab7a90e56a45d30edfc43912b9a0a56[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Mon Feb 3 13:34:16 2025 -0800

    [MISC] Remove model input dumping when exception (#12582)
    
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 4797dad3ec48c2b1fa8a1e4cc53c7854675b6b8d[m
Author: kushanam <42385577+kushanam@users.noreply.github.com>
Date:   Mon Feb 3 13:30:39 2025 -0800

    [Model] Add Deepseek V3 fp8_w8a8 configs for B200 (#12707)

[33mcommit 6dd5e52823cc0ca8ddc9c4377d29ead37cc09a95[m
Author: Kyle Sayers <kylesayrs@gmail.com>
Date:   Mon Feb 3 16:29:56 2025 -0500

    Squelch MLA warning for Compressed-Tensors Models (#12704)
    
    Signed-off-by: Kyle Sayers <kylesayrs@gmail.com>

[33mcommit c11de33dad217bca79225128059b6fac7e1b2519[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Feb 3 16:04:59 2025 -0500

    [Bugfix][Kernel] Fix per-token/per-channel quantization for Hopper scaled mm (#12696)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 33e0602e59cfb37ab0bfdff5ea6802aeb3a3ecc9[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Mon Feb 3 14:16:59 2025 -0500

    [Misc] Fix improper placement of SPDX header in scripts (#12694)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit a1a2aaadb9122f05667140e39cf67e5736c8b6d6[m
Author: Arthur <48595927+ArthurZucker@users.noreply.github.com>
Date:   Mon Feb 3 14:30:38 2025 +0100

    [Model]: Add `transformers` backend support (#11330)
    
    # Adds support for `transformers` as a backend
    
    Following https://github.com/huggingface/transformers/pull/35235, a
    bunch of models should already be supported, we are ramping up support
    for more models.
    
    Thanks @Isotr0py for the TP support, and @hmellor for his help as well!
    This includes:
    - `trust_remote_code=True` support: any model on the hub, if it
    implements attention the correct way can be natively supported!!
    - tensor parallel support
    
    ---------
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Isotr0py <41363108+Isotr0py@users.noreply.github.com>
    Co-authored-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: Michael Goin <mgoin64@gmail.com>
    Co-authored-by: Isotr0py <mozf@mail2.sysu.edu.cn>

[33mcommit 1298a400e8e8496b6e9ce3847ada5ec9f6e6cb48[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Feb 3 15:59:49 2025 +0800

    [ci/build] fix gh200 test (#12681)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit ad4a9dc817f00c266d1ca210342d1865aa69db27[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Feb 3 15:58:21 2025 +0800

    [cuda] manually import the correct pynvml module (#12679)
    
    fixes problems like https://github.com/vllm-project/vllm/pull/12635 and
    https://github.com/vllm-project/vllm/pull/12636 and
    https://github.com/vllm-project/vllm/pull/12565
    
    ---------
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit b9986454fe8ba80e2a109d069397b6b59aae658b[m
Author: Srikanth Srinivas <srikanth@astrum.ai>
Date:   Sun Feb 2 21:46:19 2025 -0800

    Fix for attention layers to remain unquantized during moe_wn16 quant (#12570)
    
    Fix to AWQ quant loading of the new R1 model
    
    The new optimized MoE kernels for a large number of experts `moe_wn16`
    uses AWQ quant which requires the attention layers to be in 16bit
    
    The current merge has broken this, and the `get_quant_method` must
    return None for it to work correctly again
    
    ---------
    
    Signed-off-by: Srikanth Srinivas <srikanth@astrum.ai>
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>
    Signed-off-by: Beim <beim2015@outlook.com>
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Signed-off-by: npanpaliya <nishidha.panpaliya@partner.ibm.com>
    Signed-off-by: Aleksandr Malyshev <maleksan@amd.com>
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>
    Signed-off-by: simon-mo <xmo@berkeley.edu>
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>
    Signed-off-by: Ryan N <ryan.nguyen@centml.ai>
    Signed-off-by: Brian Dellabetta <bdellabe@redhat.com>
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Signed-off-by: Rahul Tuli <rahul@neuralmagic.com>
    Signed-off-by: Russell Bryant <rbryant@redhat.com>
    Signed-off-by: simon-mo <simon.mo@hey.com>
    Signed-off-by: Vicente Herrera <vicenteherrera@vicenteherrera.com>
    Signed-off-by: Jinzhen Lin <linjinzhen@hotmail.com>
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Signed-off-by: Shawn Du <shawnd200@outlook.com>
    Signed-off-by: Kunshang Ji <kunshang.ji@intel.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>
    Co-authored-by: Beim <805908499@qq.com>
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-redhat@users.noreply.github.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: simon-mo <xmo@berkeley.edu>
    Co-authored-by: Nishidha <nishidha.panpaliya@partner.ibm.com>
    Co-authored-by: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
    Co-authored-by: Aleksandr Malyshev <164964928+maleksan85@users.noreply.github.com>
    Co-authored-by: Aleksandr Malyshev <maleksan@amd.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: simon-mo <simon.mo@hey.com>
    Co-authored-by: Michael Goin <mgoin64@gmail.com>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>
    Co-authored-by: Tyler Michael Smith <tysmith@redhat.com>
    Co-authored-by: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>
    Co-authored-by: Chen Zhang <zhangch99@outlook.com>
    Co-authored-by: Kevin H. Luu <kevin@anyscale.com>
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>
    Co-authored-by: Ryan Nguyen <96593302+xpbowler@users.noreply.github.com>
    Co-authored-by: Brian Dellabetta <brian-dellabetta@users.noreply.github.com>
    Co-authored-by: fade_away <1028552010@qq.com>
    Co-authored-by: weilong.yu <weilong.yu@shopee.com>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: Eldar Kurtic <eldarkurtic314@gmail.com>
    Co-authored-by: Rahul Tuli <rahul@neuralmagic.com>
    Co-authored-by: Russell Bryant <rbryant@redhat.com>
    Co-authored-by: Vicente Herrera <vicenteherrera@vicenteherrera.com>
    Co-authored-by: Jinzhen Lin <linjinzhen@hotmail.com>
    Co-authored-by: Shawn Du <shawnd200@outlook.com>
    Co-authored-by: Kunshang Ji <kunshang.ji@intel.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit c5932e5daceba8a5eefece98f1a769ddf84a864b[m
Author: Eldar Kurtic <eldarkurtic314@gmail.com>
Date:   Mon Feb 3 06:42:18 2025 +0100

    Properly check if all fused layers are in the list of targets (#12666)
    
    Thanks @kylesayrs for catching this!

[33mcommit 20579c0fae1757c9da9fc35a69960563186f3036[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Feb 3 13:40:25 2025 +0800

    make sure mistral_common not imported for non-mistral models (#12669)
    
    When people use deepseek models, they find that they need to solve cv2
    version conflict, see https://zhuanlan.zhihu.com/p/21064432691 .
    
    I added the check, and make all imports of `cv2` lazy.
    
    ---------
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 95460fc51318702a33226b87152afe810187e01e[m
Author: Yang Chen <yangchen.utah@gmail.com>
Date:   Sun Feb 2 21:09:50 2025 -0800

    [Kernel] port sgl moe_align_block_size kernels (#12574)
    
    sgl_moe_align_block_size is based on:
    
    
    https://github.com/sgl-project/sglang/commit/ded9fcd09a43d5e7d5bb31a2bc3e9fc21bf65d2a
    
    moe_align_block_size is based on:
    
    
    https://github.com/sgl-project/sglang/commit/ba5112ff691d791a9e38c6c71f59324a5fcb49d0
    
    Signed-off-by: Yang Chen <yangche@fb.com>

[33mcommit 326fcc8b9f1d75a9f194581c98a7994d220c5255[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Feb 2 19:19:56 2025 -0800

    [Doc] Deprecate Discord (#12668)

[33mcommit e64330910b4e503e1a672a73c2bfbfc9b7305b86[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Feb 3 09:32:18 2025 +0800

    [doc][misc] clarify VLLM_HOST_IP for multi-node inference (#12667)
    
    As more and more people are trying deepseek models with multi-node
    inference, https://github.com/vllm-project/vllm/issues/7815 becomes more
    frequent. Let's give clear message to users.
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit e489ad7a210f4234db696d1f2749d5f3662fa65b[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Sun Feb 2 14:58:18 2025 -0500

    [Misc] Add SPDX-License-Identifier headers to python source files (#12628)
    
    - **Add SPDX license headers to python source files**
    - **Check for SPDX headers using pre-commit**
    
    commit 9d7ef44c3cfb72ca4c32e1c677d99259d10d4745
    Author: Russell Bryant <rbryant@redhat.com>
    Date:   Fri Jan 31 14:18:24 2025 -0500
    
        Add SPDX license headers to python source files
    
    This commit adds SPDX license headers to python source files as
    recommended to
    the project by the Linux Foundation. These headers provide a concise way
    that is
    both human and machine readable for communicating license information
    for each
    source file. It helps avoid any ambiguity about the license of the code
    and can
        also be easily used by tools to help manage license compliance.
    
    The Linux Foundation runs license scans against the codebase to help
    ensure
        we are in compliance with the licenses of the code we use, including
    dependencies. Having these headers in place helps that tool do its job.
    
        More information can be found on the SPDX site:
    
        - https://spdx.dev/learn/handling-license-info/
    
        Signed-off-by: Russell Bryant <rbryant@redhat.com>
    
    commit 5a1cf1cb3b80759131c73f6a9dddebccac039dea
    Author: Russell Bryant <rbryant@redhat.com>
    Date:   Fri Jan 31 14:36:32 2025 -0500
    
        Check for SPDX headers using pre-commit
    
        Signed-off-by: Russell Bryant <rbryant@redhat.com>
    
    ---------
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit f256ebe4df6757d76f1f1642d7e110268a2f8190[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Sun Feb 2 18:17:26 2025 +0800

    [Hardware][Intel GPU] add XPU bf16 support (#12392)
    
    Signed-off-by: Kunshang Ji <kunshang.ji@intel.com>

[33mcommit f8ece6e17fbf4ff3a98d6d53cb3a03c50c02828c[m
Author: Shawn Du <shawnd200@outlook.com>
Date:   Sun Feb 2 16:40:58 2025 +0800

    [Core][v1] Unify allocating slots in prefill and decode in KV cache manager (#12608)
    
    As mentioned in RFC https://github.com/vllm-project/vllm/issues/12254,
    this PR achieves the task: combine allocate_slots and append_slots.
    
    There should be no functionality change, except that in decode, also
    raise exception when num_tokens is zero (like prefill), and change the
    unit test case accordingly.
    
    @comaniac @rickyyx @WoosukKwon @youkaichao @heheda12345 @simon-mo
    
    ---------
    
    Signed-off-by: Shawn Du <shawnd200@outlook.com>

[33mcommit abfcdcdf27eb54d2a2104b4bf5091a24ea4ff928[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Feb 1 23:43:20 2025 -0800

    [V1][Minor] Avoid frequently creating ConstantList (#12653)
    
    A small optimization to avoid creating a new `ConstantList` every time `request.kv_block_hashes` is used.
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit e497f33491671abbf94a3e563d55ca2818ee09db[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Sun Feb 2 02:35:50 2025 -0500

    [Core] Silence unnecessary deprecation warnings (#12620)
    
    I noticed during testing that I was getting a lot of these deprecation
    warnings about `local_lora_path`:
    
    ```
    DeprecationWarning: The 'lora_local_path' attribute is deprecated
         and will be removed in a future version.
         Please use 'lora_path' instead.
    ```
    
    The check used for emitting this warning was always True, even when the
    parameter was not actually specified. It will always be in
    `__struct_fields__`. We should be checking for a non-None value,
    instead.
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit baaa2b24da86d63965dbffc34c97c7c4b50288db[m
Author: Jinzhen Lin <linjinzhen@hotmail.com>
Date:   Sun Feb 2 15:29:56 2025 +0800

    [Bugfix] fix moe_wna16 get_quant_method (#12648)
    
    Fix https://github.com/vllm-project/vllm/issues/12647
    The `get_quant_method` of `moe_wna16` always return moe method,
    GPTQ-based linear method or AWQ-based linear method, even when the
    target module is attention layer.
    
    
    https://github.com/vllm-project/vllm/blob/baeded25699f9f4851843306f27f685c4d4ee7c5/vllm/attention/layer.py#L86-L92
    
    Signed-off-by: Jinzhen Lin <linjinzhen@hotmail.com>

[33mcommit b4e5c03306ebdf58bce503c73b4f3dc5592df114[m
Author: Vicente Herrera <vicenteherrera@vicenteherrera.com>
Date:   Sat Feb 1 18:17:29 2025 +0100

    doc: fixing minor typo in readme.md (#12643)
    
    Word "evolved" was mistyped
    
    Signed-off-by: Vicente Herrera <vicenteherrera@vicenteherrera.com>
    
    ---------
    
    Signed-off-by: Vicente Herrera <vicenteherrera@vicenteherrera.com>

[33mcommit 3194039c0ee82685af434c9f8023304b4a45124b[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sat Feb 1 11:16:19 2025 -0500

    Apply torch.compile to fused_moe/grouped_topk (#12637)

[33mcommit 4f4d427ac2cee0f8ff7f79103001f6617fa8989c[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jan 31 23:46:57 2025 -0800

    Disable chunked prefill and/or prefix caching when MLA is enabled  (#12642)
    
    From @mgoin in https://github.com/vllm-project/vllm/pull/12638
    
    I cannot push to that branch, therefore a new PR to unblock release.
    
    ---------
    
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Signed-off-by: simon-mo <simon.mo@hey.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit 1e3698393fca22c70dc03539cf534181466d1d25[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Sat Feb 1 02:13:10 2025 -0500

    [CI/Build] Add label automation for structured-output, speculative-decoding, v1 (#12280)
    
    We have `v1`, `structured-output`, and `speculative-decoding` labels on
    github. This adds automation for applying these labels based on the
    files touched by a PR.
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>
    
    ---------
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit baeded25699f9f4851843306f27f685c4d4ee7c5[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Sat Feb 1 00:52:51 2025 -0500

    [Attention] Deepseek v3 MLA support with FP8 compute (#12601)
    
    This PR implements the Deepseek V3 support by performing matrix absorption the fp8 weights
    
    ---------
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: simon-mo <simon.mo@hey.com>
    Co-authored-by: Michael Goin <mgoin64@gmail.com>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>
    Co-authored-by: Tyler Michael Smith <tysmith@redhat.com>
    Co-authored-by: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>

[33mcommit 3e1c76cf3a87854396d9e86a56a335e7d750c85f[m
Author: Rahul Tuli <rahul@neuralmagic.com>
Date:   Fri Jan 31 23:41:59 2025 -0600

    Fix: Respect `sparsity_config.ignore` in Cutlass Integration (#12517)
    
    This PR addresses a bug in the Cutlass integration where the
    `sparsity_config.ignore` list was not being respected. When only a
    subset of modules were configured as Sparse24, the system incorrectly
    selected Cutlass for non-sparse modules as well. This update ensures the
    correct scheme is selected for non-sparse modules, fixing this behavior.
    
    ---
    
    ### Changes
    
    - Updated logic to correctly respect `sparsity_config.ignore`.
    - Ensured non-sparse modules use the appropriate scheme instead of
    defaulting to Cutlass.
    
    ---
    
    <details>
    <summary>Testing Setup</summary>
    
    The fix has been tested on top of [this
    diff](https://github.com/vllm-project/vllm/pull/12097).
    
    #### Steps to Test:
    ```bash
    git checkout -b my-test-branch origin/rahul-bitmask-additions # compressed Cutlass support
    git revert --no-edit aa2cd2c # revert Tyler's commit to turn off Cutlass for W16A16
    git cherry-pick ca624cddb # this branch
    ```
    
    #### Additional Patch Required:
    ```diff
    diff --git a/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py b/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py
    index a54177c1c..f916dd0c9 100644
    --- a/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py
    +++ b/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py
    @@ -9,7 +9,7 @@ from compressed_tensors.quantization import (QuantizationArgs,
                                                  QuantizationStrategy,
                                                  QuantizationType)
     from pydantic import BaseModel
    -
    +from vllm.logger import init_logger
     from vllm.model_executor.layers.fused_moe import FusedMoE
     from vllm.model_executor.layers.linear import (LinearBase, LinearMethodBase,
                                                    UnquantizedLinearMethod)
    @@ -27,7 +27,7 @@ from vllm.model_executor.layers.quantization.compressed_tensors.utils import (
         should_ignore_layer)
     from vllm.model_executor.layers.quantization.kv_cache import BaseKVCacheMethod
     from vllm.platforms import current_platform
    -
    +logger = init_logger(__name__)
     __all__ = ["CompressedTensorsLinearMethod"]
    
     SPARSITY_CONFIG_NAME: Literal["sparsity_config"] = "sparsity_config"
    ```
    
    Apply using:
    ```bash
    git apply logging-patch.patch
    ```
    
    </details>
    
    ---
    
    <details>
    <summary>Models Tested</summary>
    
    - `nm-testing/TinyLlama-1.1B-Chat-v1.0-gsm8k-partial-24`
    - `nm-testing/TinyLlama-1.1B-Chat-v1.0-gsm8k-full-sparse24`
    -
    `nm-testing/TinyLlama-1.1B-Chat-v1.0-gsm8k-partial-24-entire-fp8-compressed`
    -
    `nm-testing/TinyLlama-1.1B-Chat-v1.0-gsm8k-partial-24-remaining-fp8-compressed`
    
    </details>
    
    ---
    
    
    <details>
    <summary>Example Output</summary>
    
    #### Layers 0-5 (Sparse24)
    ```
    Using scheme: CompressedTensors24 for model.layers.0.self_attn.qkv_proj
    Using scheme: CompressedTensors24 for model.layers.0.self_attn.o_proj
    Using scheme: CompressedTensors24 for model.layers.0.mlp.gate_up_proj
    Using scheme: CompressedTensors24 for model.layers.0.mlp.down_proj
    ...
    ```
    
    #### Layers 6+ (Non-Sparse, FP8)
    ```
    Using scheme: CompressedTensorsW8A8Fp8 for model.layers.6.self_attn.qkv_proj
    Using scheme: CompressedTensorsW8A8Fp8 for model.layers.6.self_attn.o_proj
    Using scheme: CompressedTensorsW8A8Fp8 for model.layers.6.mlp.gate_up_proj
    Using scheme: CompressedTensorsW8A8Fp8 for model.layers.6.mlp.down_proj
    ...
    ```
    
    </details>
    
    **Note:** Assumed all modules in fused layers such as `QKV_proj` and
    `Gate_up_proj` follow the same quantization/pruning scheme.
    
    ---
    
    For related tasks using the Asana app for GitHub, refer to [[this
    link](https://app.asana.com/0/0/1209227810815160)](https://app.asana.com/0/0/1209227810815160).
    
    Signed-off-by: Rahul Tuli <rahul@neuralmagic.com>

[33mcommit cfa134d2475096eae47a58d14a6dec4c3fba9294[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sat Feb 1 00:41:35 2025 -0500

    [Bugfix/CI] Fixup benchmark_moe.py (#12562)
    
    Fixes `is_marlin` not being passed into `get_default_config`
    
    Also allow `--tensor-parallel-size` in addition to `-tp` and `--tp-size`
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 35b7a05507e32f6cc60aec7148d3df0c788f7373[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Fri Jan 31 21:22:23 2025 -0800

    [ci] Upgrade transformers to 4.48.2 in CI dependencies (#12599)

[33mcommit 1867c258bda3bc6adb07090c508fd85e3ceed547[m
Author: Eldar Kurtic <eldarkurtic314@gmail.com>
Date:   Sat Feb 1 06:07:46 2025 +0100

    Fix target matching for fused layers with compressed-tensors (#12617)
    
    Without this PR
    ---------------
    Quantizing models with llm-compressor and a recipe that explicitly lists
    names of layers produces a model that is not loadable by vLLM (i.e.
    `vllm serve <model>` fails with `raise ValueError(f"Unable to find
    matching target for {module} in the ...`).
    
    Example recipe:
    ```
    recipe = """
    quantization_stage:
      run_type: oneshot
      quantization_modifiers:
        GPTQModifier:
          ignore: ["lm_head"]
          config_groups:
            group_0:
              weights:
                num_bits: 4
                type: "int"
                symmetric: true
                strategy: "group"
                group_size: 128
              targets: [
                "model.layers.0.mlp.down_proj",
                "model.layers.2.mlp.down_proj",
                "model.layers.3.mlp.down_proj",
                "model.layers.4.mlp.down_proj",
                "model.layers.5.mlp.down_proj",
                "model.layers.6.mlp.down_proj",
                "model.layers.7.mlp.down_proj",
                "model.layers.8.mlp.down_proj",
                "model.layers.9.mlp.down_proj",
                "model.layers.10.mlp.down_proj",
                "model.layers.11.mlp.down_proj",
                "model.layers.12.mlp.down_proj",
                "model.layers.13.mlp.down_proj",
                "model.layers.14.mlp.down_proj",
                "model.layers.15.mlp.down_proj",
                "model.layers.16.mlp.down_proj",
                "model.layers.17.mlp.down_proj",
                "model.layers.19.mlp.down_proj",
                "model.layers.21.mlp.down_proj",
                "model.layers.22.mlp.down_proj",
                .
                .
                .
              ]
    """
    ```
    
    To reproduce the vLLM error:
    ```bash
    vllm serve nm-testing/eldar-test
    ```
    
    With this PR
    ------------
    Models are loaded correctly without any errors.

[33mcommit cb3e73e4c8142b5ce8ac34efc2fa04d90f142dc5[m
Author: fade_away <1028552010@qq.com>
Date:   Sat Feb 1 12:52:07 2025 +0800

    [BugFix] fix wrong output when using lora and num_scheduler_steps=8 (#11161)
    
    FIX issue https://github.com/vllm-project/vllm/issues/9688
    https://github.com/vllm-project/vllm/issues/11086 #12487
    
    ---------
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: weilong.yu <weilong.yu@shopee.com>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit b1340f9d55cd36a92aff713213e95f354a1bd1b4[m
Author: Robert Shaw <114415538+robertgshaw2-redhat@users.noreply.github.com>
Date:   Fri Jan 31 21:32:04 2025 -0500

    [V1] Bugfix: Validate Model Input Length (#12600)
    
    SUMMARY:
    * avoid crashing the engine when we get an input longer than
    max_model_len
    
    FIX #12567(*link existing issues this PR will resolve*)

[33mcommit 44bbca78d71330909dbfdde232debdc73a4d5a81[m
Author: Brian Dellabetta <brian-dellabetta@users.noreply.github.com>
Date:   Fri Jan 31 17:38:48 2025 -0600

    [Doc] int4 w4a16 example (#12585)
    
    Based on a request by @mgoin , with @kylesayrs we have added an example
    doc for int4 w4a16 quantization, following the pre-existing int8 w8a8
    quantization example and the example available in
    [`llm-compressor`](https://github.com/vllm-project/llm-compressor/blob/main/examples/quantization_w4a16/llama3_example.py)
    
    FIX #n/a (no issue created)
    
    @kylesayrs and I have discussed a couple additional improvements for the
    quantization docs. We will revisit at a later date, possibly including:
    - A section for "choosing the correct quantization scheme/ compression
    technique"
    - Additional vision or audio calibration datasets
    
    ---------
    
    Signed-off-by: Brian Dellabetta <bdellabe@redhat.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 60808bd4c7a27b6d28f82657e38a5b303f7534a9[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Fri Jan 31 23:38:35 2025 +0000

    [Doc] Improve installation signposting (#12575)
    
    - Make device tab names more explicit
    - Add comprehensive list of devices to
    https://docs.vllm.ai/en/latest/getting_started/installation/index.html
    - Add `attention` blocks to the intro of all devices that don't have
    pre-built wheels/images
    
    ---------
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit fc542144c4477ffec1d3de6fa43e54f8fb5351e8[m
Author: Ryan Nguyen <96593302+xpbowler@users.noreply.github.com>
Date:   Fri Jan 31 18:37:30 2025 -0500

    [Feature] Fix guided decoding blocking bitmask memcpy (#12563)
    
    **[Guided decoding performance optimization]** Sending the guided
    decoding bitmask in xgrammar to the GPU
    (`self.token_bitmask.to(scores.device)`) is a blocking operation that
    prevents the CPU from pre-launching the sampler kernels. The CPU waits
    until decode is complete, then copies the bitmask over. This PR changes
    the operation to async via setting `non-blocking=True`.
    
    (Current) The CPU is blocked on a `cudaStreamSynchronize` and only
    pre-empts the sampling kernels after bitmask application. Below is the
    Nsys profile for one decode phase from Llama 3.1 8B.
    
    ![image](https://github.com/user-attachments/assets/8997eae1-b822-4f52-beb8-ef19a7c6b824)
    
    With the optimization, this is no longer the case:
    
    ![image](https://github.com/user-attachments/assets/6d5ea83f-f169-4f98-a8c1-41c719b3e1e7)
    
    ---------
    
    Signed-off-by: Ryan N <ryan.nguyen@centml.ai>

[33mcommit eb5741ad422f04d0bac60c9b6c07183e0431ce8c[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Jan 31 18:29:11 2025 -0500

    [Kernel][Quantization] Integrate block-quantized CUTLASS kernels for DeepSeekV3 (#12587)
    
    Integrates the block-quantized kernels introduced in
    https://github.com/vllm-project/vllm/pull/11868 for use in linear
    layers.
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 145c2ff648ad0a300f880ac38811d0d8a2eb3e79[m
Author: Robert Shaw <114415538+robertgshaw2-redhat@users.noreply.github.com>
Date:   Fri Jan 31 18:28:47 2025 -0500

    [Bugfix] Revert MoE Triton Config Default (#12629)
    
    SUMMARY:
    * previous PR for pulling in block configs also changed defaults
    (https://github.com/vllm-project/vllm/pull/11589/files) for FP8
    * this broke L4 MoE since there was not enough SHM for the default
    configuration
    * this reverts the non-block example to the default
    
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>

[33mcommit 415f19474dedc69934cab79cfb8f5bdc19e2ae0d[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Fri Jan 31 13:39:36 2025 -0800

    [release] Add input step to ask for Release version (#12631)
    
    Instead of having to create a new build with release version put in as
    env var.

[33mcommit 89003c4082db880e103e84f5015424e79f9aa762[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Sat Feb 1 05:13:04 2025 +0800

    [v1][Bugfix] Add extra_keys to block_hash for prefix caching (#12603)
    
    This pr adds extra key to block hash, to generate different hash value
    for two blocks with the same token string but different extra_keys in
    their parent blocks. For example, it can generate different hash value
    for the second block of the following two requests:
    ```python
    request1 = make_request(
            request_id=0,
            prompt_token_ids=[_ for _ in range(6)],
            mm_positions=[{
                "offset": 0,
                "length": 3
            }, {
                "offset": 3,
                "length": 3
            }],
            mm_hashes=["hash1", "hash2"],
        )
        request2 = make_request(
            request_id=1,
            prompt_token_ids=[_ for _ in range(6)],
            mm_positions=[{
                "offset": 0,
                "length": 3
            }, {
                "offset": 3,
                "length": 3
            }],
            mm_hashes=["hash3", "hash2"],
        )
    ```
    
    ---------
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit 60bcef000ebcfaf120edc1972a8136344d9bfa0d[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Jan 31 12:30:46 2025 -0800

    [Docs][V1] Prefix caching design (#12598)
    
    - Create v1 design document section in docs.
    - Add prefix caching design doc.
    
    @WoosukKwon @ywang96
    
    ---------
    
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 847f883232cedef583775d6f4e13baa2446ba1c7[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Jan 31 12:30:33 2025 -0800

    [Git] Automatically sign-off commits (#12595)
    
    It's very annoying when I forgot to add `-s` in `git commit` to
    sign-off, because I then need to `git rebase HEAD~1 --signoff` and `git
    push -f` to fix the DCO. This PR adds a hook to sign off commits
    automatically when `-s` is missing to solve this problem. The only
    change from the user side is now users have to install 2 hooks, so
    instead of just
    
    ```
    pre-commit install
    ```
    
    Now we need to
    
    ```
    pre-commit install --hook-type pre-commit --hook-type commit-msg
    ```
    
    Note that even if users still only install the pre-commit hook, they
    won't get any error in `git commit`. Just the sign-off hook won't run.
    
    cc @hmellor @youkaichao
    
    ---------
    
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 325f679f324c1044cfaa0c594bf0d817eeda4451[m
Author: Robert Shaw <114415538+robertgshaw2-redhat@users.noreply.github.com>
Date:   Fri Jan 31 15:06:39 2025 -0500

    [BugFix] Fix Torch.Compile For DeepSeek (#12594)
    
    Co-authored-by: simon-mo <xmo@berkeley.edu>

[33mcommit e3f7ff65e7a6c08cd354f7f333bce543a4f0607e[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Fri Jan 31 17:20:34 2025 +0000

    Add favicon to docs (#12611)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit 7a8987dac5f0ed0c798a73e8b4ec8f5e640bc63a[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Jan 31 00:19:35 2025 -0800

    [Bugfix] Gracefully handle huggingface hub http error (#12571)

[33mcommit cabaf4eff3c7df30d785769d5a0a1fa1a1c48a8a[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Fri Jan 31 02:49:37 2025 -0500

    [Attention] MLA decode optimizations (#12528)
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>
    Signed-off-by: simon-mo <xmo@berkeley.edu>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: simon-mo <simon.mo@hey.com>
    Co-authored-by: Michael Goin <mgoin64@gmail.com>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>
    Co-authored-by: Tyler Michael Smith <tysmith@redhat.com>
    Co-authored-by: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
    Co-authored-by: simon-mo <xmo@berkeley.edu>

[33mcommit a1fc18c030e4d0466f2b23cb7dd4d11ce4b85603[m
Author: Aleksandr Malyshev <164964928+maleksan85@users.noreply.github.com>
Date:   Thu Jan 30 20:24:28 2025 -0800

    [ROCm][AMD][Model] llama 3.2 support upstreaming (#12421)
    
    Signed-off-by: Aleksandr Malyshev <maleksan@amd.com>
    Co-authored-by: Aleksandr Malyshev <maleksan@amd.com>

[33mcommit 9798b2fb0052092a6420172e41c0c8a307eedfa6[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Jan 30 21:33:00 2025 -0500

    [Kernel] Update `cutlass_scaled_mm` to support 2d group (blockwise) scaling (#11868)

[33mcommit 4078052f09f42f898b542e18d60d15a43db67a8b[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Jan 30 18:07:19 2025 -0500

    [V1][Log] Add max request concurrency log to V1 (#12569)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit bd2107e30a258a5bcaa94e678a3890ec083a60a0[m
Author: Nishidha <nishidha.panpaliya@partner.ibm.com>
Date:   Fri Jan 31 02:59:39 2025 +0530

    [CPU][PPC] Updated torch, torchvision, torchaudio dependencies (#12555)
    
    Signed-off-by: npanpaliya <nishidha.panpaliya@partner.ibm.com>

[33mcommit 9b0c4bab36c8f355f562d58521650ee8d5b6095d[m
Author: Robert Shaw <114415538+robertgshaw2-redhat@users.noreply.github.com>
Date:   Thu Jan 30 14:53:22 2025 -0500

    [Kernel] Triton Configs for Fp8 Block Quantization (#11589)
    
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: simon-mo <xmo@berkeley.edu>

[33mcommit 41bf5612f590dd13fa5e5dec083849ab6cde2f70[m
Author: Beim <805908499@qq.com>
Date:   Fri Jan 31 04:39:22 2025 +1300

    [Misc] fix typo: add missing space in lora adapter error message (#12564)
    
    Signed-off-by: Beim <beim2015@outlook.com>

[33mcommit a2769032ca78108e58abc45e2eb0ade8b47a6515[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Thu Jan 30 08:05:42 2025 +0000

    Set `?device={device}` when changing tab in installation guides (#12560)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit f17f1d46086692a2973fad94860a95799fbd8582[m
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Thu Jan 30 02:31:01 2025 +0000

    [V1][Metrics] Add GPU cache usage % gauge (#12561)
    
    Signed-off-by: Mark McLoughlin <markmc@redhat.com>

[33mcommit 1c1bb0bbf20955d346f66bb25d349c1bd9fe6ea2[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Wed Jan 29 18:47:30 2025 -0600

    [Misc][MoE] add Deepseek-V3 moe tuning support (#12558)
    
    Signed-off-by: Divakar Verma <divakar.verma@amd.com>

[33mcommit e0cc5f259a8bec0d66ed0bc3e25ca245377679a1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jan 29 13:47:33 2025 -0800

    [V1][BugFix] Free encoder cache for aborted requests (#12545)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 73aa6cfdf789ddc67a3d2924ef52fd791554fe2a[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Jan 29 16:12:24 2025 -0500

    Revert "[Build/CI] Fix libcuda.so linkage" (#12552)

[33mcommit 27b78c73cad00f5c7bb3b2431f02dc680f7034bc[m
Author: Jinzhen Lin <linjinzhen@hotmail.com>
Date:   Wed Jan 29 22:07:09 2025 +0800

    [Kernel] add triton fused moe kernel for gptq/awq (#12185)

[33mcommit b02fd288b28f0bfa2d7ac8958fe0d71ec22ffc1b[m
Author: Pavani Majety <pmajety@nvidia.com>
Date:   Wed Jan 29 01:46:12 2025 -0800

    [Hardware][NV] Fix Modelopt model loading for k-v-scales for Llama models. (#11787)
    
    Signed-off-by: Pavani Majety <pmajety@nvidia.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit ff7424f491935a1b4737bcc1570de0d616fc22f3[m
Author: Yanyi Liu <wolfsonliu@163.com>
Date:   Wed Jan 29 17:41:01 2025 +0800

    [Frontend] Support override generation config in args (#12409)
    
    Signed-off-by: liuyanyi <wolfsonliu@163.com>

[33mcommit d93bf4da855a0c5e8d3c875def6b37c5e9d77763[m
Author: Alphi <52458637+HwwwwwwwH@users.noreply.github.com>
Date:   Wed Jan 29 17:24:59 2025 +0800

    [Model] Refactoring of MiniCPM-V and add MiniCPM-o-2.6 support for vLLM (#12069)
    
    Signed-off-by: hzh <hezhihui_thu@163.com>
    Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com>
    Signed-off-by: shaochangxu.scx <shaochangxu.scx@antgroup.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Signed-off-by: NickLucche <nlucches@redhat.com>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>
    Signed-off-by: Akshat Tripathi <akshat@krai.ai>
    Signed-off-by: Oleg Mosalov <oleg@krai.ai>
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>
    Signed-off-by: Yida Wu <yidawu@alumni.cmu.edu>
    Signed-off-by: Chenguang Li <757486878@qq.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Signed-off-by: Alex-Brooks <Alex.brooks@ibm.com>
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>
    Signed-off-by: Shanshan Shen <467638484@qq.com>
    Signed-off-by: elijah <f1renze.142857@gmail.com>
    Signed-off-by: Yikun <yikunkero@gmail.com>
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Signed-off-by: Konrad Zawora <kzawora@habana.ai>
    Signed-off-by: tjtanaa <tunjian.tan@embeddedllm.com>
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>
    Co-authored-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com>
    Co-authored-by: shaochangxu <85155497+shaochangxu@users.noreply.github.com>
    Co-authored-by: shaochangxu.scx <shaochangxu.scx@antgroup.com>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>
    Co-authored-by: Nicol√≤ Lucchesi <nlucches@redhat.com>
    Co-authored-by: sixgod <evethwillbeok@outlook.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>
    Co-authored-by: Rafael Vasquez <rafvasq21@gmail.com>
    Co-authored-by: Isotr0py <mozf@mail2.sysu.edu.cn>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: Akshat Tripathi <Akshat.tripathi6568@gmail.com>
    Co-authored-by: Oleg Mosalov <oleg@krai.ai>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: Avshalom Manevich <12231371+avshalomman@users.noreply.github.com>
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
    Co-authored-by: Yangcheng Li <liyangcheng.lyc@alibaba-inc.com>
    Co-authored-by: Siyuan Li <94890248+liaoyanqing666@users.noreply.github.com>
    Co-authored-by: Concurrensee <yida.wu@amd.com>
    Co-authored-by: Chenguang Li <757486878@qq.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Alex Brooks <alex.brooks@ibm.com>
    Co-authored-by: Chen Zhang <zhangch99@outlook.com>
    Co-authored-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>
    Co-authored-by: Shanshan Shen <467638484@qq.com>
    Co-authored-by: elijah <30852919+e1ijah1@users.noreply.github.com>
    Co-authored-by: Yikun Jiang <yikunkero@gmail.com>
    Co-authored-by: Steve Luo <36296769+SunflowerAries@users.noreply.github.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: Konrad Zawora <kzawora@habana.ai>
    Co-authored-by: TJian <tunjian1996@gmail.com>
    Co-authored-by: tjtanaa <tunjian.tan@embeddedllm.com>
    Co-authored-by: wangxiyuan <wangxiyuan1007@gmail.com>
    Co-authored-by: maang-h <55082429+maang-h@users.noreply.github.com>
    Co-authored-by: Elfie Guo <164945471+elfiegg@users.noreply.github.com>
    Co-authored-by: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 036ca94c25fa07391016aa1b4f93a8ac5d74f296[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed Jan 29 01:54:35 2025 -0700

    [Bugfix] handle alignment of arguments in convert_sparse_cross_attention_mask_to_dense (#12347)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>
    Signed-off-by: Wallas Santos <wallashss@ibm.com>
    Co-authored-by: Wallas Santos <wallashss@ibm.com>

[33mcommit ef001d98ef36166ebacb48eab2e32eb738407b53[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Wed Jan 29 04:53:13 2025 -0300

    Fix the pydantic logging validator (#12420)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>

[33mcommit 5f671cb4c3145194e94ffb393ee459432f7fa2b8[m
Author: Robert Shaw <114415538+robertgshaw2-redhat@users.noreply.github.com>
Date:   Tue Jan 28 23:56:56 2025 -0500

    [V1] Improve Error Message for Unsupported Config (#12535)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit bd02164cf9eeed8436b26d62c37c1d792e97f9e8[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Jan 28 23:49:03 2025 -0500

    Bugfix for whisper quantization due to fake k_proj bias (#12524)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 46fb056749b7d9f5e4ea7a060207ed2eb3ad75e0[m
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Wed Jan 29 04:11:16 2025 +0000

    [V1][Metrics] Add TTFT and TPOT histograms (#12530)
    
    Signed-off-by: Mark McLoughlin <markmc@redhat.com>

[33mcommit dd6a3a02cb3bf2a7bc6cb84c85dcd57c6eaf2bf9[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Wed Jan 29 03:38:29 2025 +0000

    [Doc] Convert docs to use colon fences (#12471)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit a7e3eba66fff82f7e12bb2354c4b26635f0f7761[m
Author: Ce Gao <gaocegege@hotmail.com>
Date:   Wed Jan 29 11:38:08 2025 +0800

    [Frontend] Support reasoning content for deepseek r1 (#12473)
    
    Signed-off-by: Ce Gao <cegao@tensorchord.ai>
    Co-authored-by: Rafael Vasquez <rafvasq21@gmail.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: Michael Goin <mgoin@redhat.com>

[33mcommit fbb5bd4cefd62e3e389e2b873d5859eb8e07cbfa[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Jan 28 22:16:47 2025 -0500

    [TPU] Add example for profiling TPU inference (#12531)
    
    Signed-off-by: mgoin <mgoin@redhat.com>

[33mcommit 80fcc3ed1c940ea43e1b495bbdf8b9765f837128[m
Author: fenghuizhang <159459388+fenghuizhang@users.noreply.github.com>
Date:   Tue Jan 28 14:36:44 2025 -0800

    [Kernel] Pipe attn_logits_soft_cap through paged attention TPU kernels (#12482)
    
    Signed-off-by: Fenghui Zhang <fhzhang@google.com>

[33mcommit c386c43ca3a7156a953e0ca4d8f2c2f36ccf1423[m
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Tue Jan 28 22:07:22 2025 +0000

    [V1][Metrics] Add per-request prompt/generation_tokens histograms (#12516)
    
    Signed-off-by: Mark McLoughlin <markmc@redhat.com>

[33mcommit f26d790718b8e50a11a366f3301b6a9300377797[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Tue Jan 28 20:05:27 2025 +0000

    Do not run `suggestion` `pre-commit` hook multiple times (#12521)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit 0f657bdc52d4ad1d079beddf8e7556c419aca7b4[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Jan 28 14:06:32 2025 -0500

    Replace missed warning_once for rerank API (#12472)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 3fd1fb63efb6c96f30237b12e2816b4f2c5323d0[m
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Tue Jan 28 16:38:38 2025 +0000

    [V1][Metrics] Hook up IterationStats for Prometheus metrics (#12478)
    
    Signed-off-by: Mark McLoughlin <markmc@redhat.com>

[33mcommit 925d2f19089b50736ce5e0f2ba0c9b7f3da6fb15[m
Author: Jun Duan <jun.duan.phd@outlook.com>
Date:   Tue Jan 28 11:37:10 2025 -0500

    [Doc] Fix typo for x86 CPU installation (#12514)
    
    Signed-off-by: Jun Duan <jun.duan.phd@outlook.com>

[33mcommit 8f58a5135874770ac8429f4772d7f92fe33094e5[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 29 00:25:05 2025 +0800

    [VLM] Merged multi-modal processor and V1 support for Qwen-VL (#12504)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 2079e43beecc486a607c9d79ab691e0e4563aa11[m
Author: Sebastian Schoennenbeck <sebastian.schoennenbeck@comma-soft.com>
Date:   Tue Jan 28 11:56:45 2025 +0100

    [Core] Make raw_request optional in ServingCompletion (#12503)
    
    Signed-off-by: Sebastian Sch√∂nnenbeck <sebastian.schoennenbeck@comma-soft.com>

[33mcommit e29d4358ef054163b80dfb7e53ce3eb0e08d1328[m
Author: Robert Shaw <114415538+robertgshaw2-redhat@users.noreply.github.com>
Date:   Tue Jan 28 03:27:41 2025 -0500

    [V1] Include Engine Version in Logs (#12496)
    
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>

[33mcommit 8cbc4249758d399c0606ef4a1241e01176d0160b[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jan 28 00:22:41 2025 -0800

    Update README.md with V1 alpha release (#12495)

[33mcommit dd66fd2b01e1195b7ccc8ffcd4b5d49ff1946a56[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Tue Jan 28 14:11:05 2025 +0800

    [CI] fix pre-commit error (#12494)
    
    Signed-off-by: Mengqing Cao <cmq0113@163.com>

[33mcommit 0f465ab53303fbd3c8ad32163db161cdb0cf8dad[m
Author: Gabriel Marinho <104592062+gmarinho2@users.noreply.github.com>
Date:   Tue Jan 28 00:30:13 2025 -0300

    [FEATURE] Enables offline /score for embedding models (#12021)
    
    Signed-off-by: Gabriel Marinho <gmarinho@ibm.com>

[33mcommit 23a7cbc88b5a17499766d1cbc0de283c9f980509[m
Author: Hossein Sarshar <hossein.sarshar@gmail.com>
Date:   Mon Jan 27 22:18:07 2025 -0500

    [CI/Build] Fixed the xla nightly issue report in #12451 (#12453)

[33mcommit 426a5c362557c6df4604ed084660b8915fbca30c[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Jan 27 20:56:31 2025 -0500

    Fix bad path in prometheus example (#12481)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit ddee88d0ff2757bdef98a83a9c78af1ea4559758[m
Author: Liangfu Chen <liangfc@amazon.com>
Date:   Mon Jan 27 17:31:16 2025 -0800

    [Neuron][Kernel] NKI-based flash-attention kernel with paged KV cache (#11277)
    
    Signed-off-by: Liangfu Chen <liangfc@amazon.com>
    Co-authored-by: Jiangfei Duan <jfduan@outlook.com>

[33mcommit 823ab796330825f4052d771e2c462ad3b55236eb[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Tue Jan 28 00:23:08 2025 +0000

    Update `pre-commit` hooks (#12475)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit 6116ca8cd79b642c64f4ae6f050a6bc12b96d037[m
Author: Nicol√≤ Lucchesi <nicolo.lucchesi@gmail.com>
Date:   Mon Jan 27 22:38:35 2025 +0100

    [Feature] [Spec decode]: Enable MLPSpeculator/Medusa and `prompt_logprobs` with ChunkedPrefill (#10132)
    
    Signed-off-by: NickLucche <nlucches@redhat.com>
    Signed-off-by: wallashss <wallashss@ibm.com>
    Co-authored-by: wallashss <wallashss@ibm.com>

[33mcommit 2bc3fbba0cf5b07fabb798d41b153b895d30c7b4[m
Author: Bowen Wang <abmfy@icloud.com>
Date:   Tue Jan 28 02:19:24 2025 +0800

    [FlashInfer] Upgrade to 0.2.0 (#11194)
    
    Signed-off-by: Bowen Wang <abmfy@icloud.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 3f1fc7425a7db4d9722941075e43bb2ebfb90613[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jan 27 09:40:04 2025 -0800

    [V1][CI/Test] Do basic test for top-p & top-k sampling (#12469)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 01ba927040d0b6f7d8daf6bfbf32fde562d2f8a6[m
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Mon Jan 27 17:26:28 2025 +0000

    [V1][Metrics] Add initial Prometheus logger (#12416)
    
    Signed-off-by: Mark McLoughlin <markmc@redhat.com>

[33mcommit 103bd17ac585b44372a47f365d80f13446cf362d[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Mon Jan 27 10:40:00 2025 -0500

    [Build] Only build 9.0a for scaled_mm and sparse kernels (#12339)
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit ce69f7f7542bdb8b6e6302d112fb9fad212c1460[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Mon Jan 27 18:31:49 2025 +0800

    [Bugfix] Fix gpt2 GGUF inference (#12467)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 624a1e4711cb9cfdd7e336980668e64744a84863[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jan 27 01:09:27 2025 -0800

    [V1][Minor] Minor optimizations for update_from_output (#12454)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 372bf0890b19cc3c2992ce5c16eca3647e2a9e13[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Mon Jan 27 15:25:30 2025 +0800

    [Bugfix] Fix missing seq_start_loc in xformers prefill metadata (#12464)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 5204ff5c3feeb96e8a6eea65dfcb78395f90d4d8[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jan 27 13:26:44 2025 +0800

    [Bugfix] Fix Granite 3.0 MoE model loading (#12446)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 0cc6b383d73eb662dfeec671d3b47cda301b2f47[m
Author: Pooya Davoodi <pooya.davoodi@parasail.io>
Date:   Sun Jan 26 20:30:17 2025 -0800

    [Frontend] Support scores endpoint in run_batch (#12430)
    
    Signed-off-by: Pooya Davoodi <pooya.davoodi@parasail.io>

[33mcommit 28e0750847ded93158a66efdcbc869d87463b38f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Jan 26 19:57:56 2025 -0800

    [V1] Avoid list creation in input preparation (#12457)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 582cf78798a6fef9b69d0471df73d81e09a7d3d8[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Sun Jan 26 21:46:19 2025 -0600

    [DOC] Add link to vLLM blog (#12460)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit 0034b09ceb7f578f2d097c7fb8c7042d17367c35[m
Author: Kyle Mistele <kyle@mistele.com>
Date:   Sun Jan 26 20:58:45 2025 -0600

    [Frontend] Rerank API (Jina- and Cohere-compatible API)  (#12376)
    
    Signed-off-by: Kyle Mistele <kyle@mistele.com>

[33mcommit 72bac7306796b01c202d846da041f62ded3a26a9[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sun Jan 26 16:18:19 2025 -0500

    [Build/CI] Fix libcuda.so linkage (#12424)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 68f11149d845a164c9bbf122ab3bee8c94290169[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Sun Jan 26 14:09:34 2025 -0500

    [Bugfix][Kernel] Fix perf regression caused by PR #12405 (#12434)
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit 72f4880425edf06f105863b2389f9c46025e08ee[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sun Jan 26 13:39:03 2025 -0500

    [Bugfix/CI] Fix broken kernels/test_mha.py (#12450)

[33mcommit aa2cd2c43d1d19ece0f3b36ad716c3a9b8a2def0[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sun Jan 26 06:59:58 2025 -0500

    [Bugfix] Disable w16a16 2of4 sparse CompressedTensors24 (#12417)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit 9ddc35220bee793eb445d9592a40bc4d3c081519[m
Author: Matthew Hendrey <matthew.hendrey@gmail.com>
Date:   Sun Jan 26 06:59:25 2025 -0500

    [Frontend] generation_config.json for  maximum tokens(#12242)
    
    Signed-off-by: Matthew Hendrey <matthew.hendrey@gmail.com>
    Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>
    Co-authored-by: shangmingc <caishangming@linux.alibaba.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>
    Co-authored-by: Yuan Tang <terrytangyuan@gmail.com>
    Co-authored-by: Isotr0py <mozf@mail2.sysu.edu.cn>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>
    Co-authored-by: Chen Zhang <zhangch99@outlook.com>
    Co-authored-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit a5255270c3ad492b5def19fe38beb9b2df30e74f[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Jan 26 03:56:34 2025 -0800

    [Misc] Revert FA on ViT #12355 and #12435 (#12445)

[33mcommit 0ee349b5534e3d02b499b1126f2abde73b798fe9[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Jan 26 00:47:42 2025 -0800

    [V1][Bugfix] Fix assertion when mm hashing is turned off (#12439)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit fa63e710c7fbaae3a445f669d3b5ba6b9a4ef412[m
Author: Keyun Tong <tongkeyun@gmail.com>
Date:   Sun Jan 26 00:42:37 2025 -0800

    [V1][Perf] Reduce scheduling overhead in model runner after cuda sync (#12094)
    
    Signed-off-by: Keyun Tong <tongkeyun@gmail.com>

[33mcommit 2a0309a646b1ed83a0c40974e08c8dc628726d3c[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Jan 25 21:00:31 2025 -0800

    [Misc][Bugfix] FA3 support to ViT MHA layer (#12435)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 324960a95c00112ce6b9b858d9311da1597cfb8b[m
Author: Siyuan Liu <lsiyuan@google.com>
Date:   Fri Jan 24 23:23:03 2025 -0800

    [TPU][CI] Update torchxla version in requirement-tpu.txt (#12422)
    
    Signed-off-by: Siyuan Liu <lsiyuan@google.com>

[33mcommit f1fc0510dfbb11c98f41d02a44e092785c626314[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sat Jan 25 15:07:35 2025 +0800

    [Misc] Add FA2 support to ViT MHA layer (#12355)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit bf21481ddef2fa9bb96c13ba1f80072abdae3eb7[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Fri Jan 24 22:17:19 2025 -0600

    [ROCm][MoE] MI300 tuned configs Mixtral-8x(7B,22B) | fp16, fp8 (#12408)
    
    Signed-off-by: Divakar Verma <divakar.verma@amd.com>

[33mcommit fb30ee92eefec7eacc0d7483f9d07daa1206530f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jan 25 11:42:42 2025 +0800

    [Bugfix] Fix BLIP-2 processing (#12412)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 221d388cc5a836fa189305785ed7e887cea8b510[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Fri Jan 24 20:49:28 2025 -0500

    [Bugfix][Kernel] Fix moe align block issue for mixtral (#12413)

[33mcommit 3132a933b65d8ed3383e082264c682940d92d803[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Fri Jan 24 15:20:59 2025 -0500

    [Bugfix][Kernel] FA3 Fix - RuntimeError: This flash attention build only supports pack_gqa (for build size reasons). (#12405)
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit df5dafaa5ba611f7179720958ba63e49615c927f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jan 25 03:45:20 2025 +0800

    [Misc] Remove deprecated code (#12383)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit ab5bbf5ae32bc438803ced4c2a021bb161e00050[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Fri Jan 24 10:27:59 2025 -0500

    [Bugfix][Kernel] Fix CUDA 11.8 being broken by FA3 build (#12375)
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit 3bb8e2c9a2a2dadfe61f35bcde15f72c43f4635f[m
Author: Junichi Sato <junichi.sato@sbintuitions.co.jp>
Date:   Fri Jan 24 23:58:26 2025 +0900

    [Misc] Enable proxy support in benchmark script (#12356)
    
    Signed-off-by: Junichi Sato <junichi.sato@sbintuitions.co.jp>

[33mcommit e784c6b9984e8f8116f74000b863d941495acb0b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jan 24 17:54:29 2025 +0800

    [ci/build] sync default value for wheel size (#12398)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 9a0f3bdbe530f4d90e27cf9c6f5cc506e2b44c03[m
Author: Mohit Deopujari <mdeopujari@habana.ai>
Date:   Fri Jan 24 01:43:49 2025 -0800

    [Hardware][Gaudi][Doc] Add missing step in setup instructions (#12382)

[33mcommit c7c98510360693be668b654c7b1c168d1e656f2c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jan 24 17:31:25 2025 +0800

    [ci/build] fix wheel size check (#12396)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 3c818bdb42f2b0ed1250568abbabf45909ff308e[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Jan 24 00:22:04 2025 -0800

    [Misc] Use VisionArena Dataset for VLM Benchmarking (#12389)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 6dd94dbe94c1820a1e224cba65efcf0befa97995[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jan 24 11:34:27 2025 +0800

    [perf] fix perf regression from #12253 (#12380)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 0e74d797ce8618fdb685126e0ff8576fb966e6ad[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jan 23 19:19:55 2025 -0800

    [V1] Increase default batch size for H100/H200 (#12369)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 55ef66edf48a15468a96cb34985319c57e3840ce[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Thu Jan 23 22:19:42 2025 -0500

    Update compressed-tensors version (#12367)

[33mcommit 5e5630a478fe75bc99e4ceea304f9ea68de5aaa6[m
Author: omer-dayan <omer@run.ai>
Date:   Fri Jan 24 05:06:07 2025 +0200

    [Bugfix] Path join when building local path for S3 clone (#12353)
    
    Signed-off-by: Omer Dayan (SW-GPU) <omer@run.ai>

[33mcommit d3d6bb13fb62da3234addf6574922a4ec0513d04[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Thu Jan 23 21:17:30 2025 -0500

    Set weights_only=True when using torch.load() (#12366)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 24b0205f58c28e05ac060ec6f0e4defe8e9c32eb[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Jan 23 17:17:41 2025 -0800

    [V1][Frontend] Coalesce bunched `RequestOutput`s (#12298)
    
    Signed-off-by: Nick Hill <nhill@redhat.com>
    Co-authored-by: Robert Shaw <rshaw@neuralmagic.com>

[33mcommit c5cffcd0cdbba9273954b4fd1317137208ce564c[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Thu Jan 23 20:15:52 2025 -0500

    [Docs] Update spec decode + structured output in compat matrix (#12373)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 682b55bc0734a5b02ef572c361c66dade71bd44d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jan 23 14:10:03 2025 -0800

    [Docs] Add meetup slides (#12345)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 9726ad676d04d4b424d266212ac85000efdcd64d[m
Author: Junichi Sato <junichi.sato@sbintuitions.co.jp>
Date:   Fri Jan 24 07:02:13 2025 +0900

    [Misc] Fix OpenAI API Compatibility Issues in Benchmark Script (#12357)
    
    Signed-off-by: Junichi Sato <junichi.sato@sbintuitions.co.jp>

[33mcommit eb5cb5e5280c83226408c3d1e30928364c6258db[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Thu Jan 23 16:40:33 2025 -0500

    [BugFix] Fix parameter names and `process_after_weight_loading` for W4A16 MoE Group Act Order  (#11528)
    
    Signed-off-by: ElizaWszola <eliza@neuralmagic.com>
    Co-authored-by: ElizaWszola <eliza@neuralmagic.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 2cbeedad09157d9438bfe26a3ae06f1fe070118b[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Jan 24 03:18:51 2025 +0800

    [Docs] Document Phi-4 support (#12362)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 2c85529bfc7bd0068f2395188bbf54c9adb01422[m
Author: Siyuan Liu <lsiyuan@google.com>
Date:   Thu Jan 23 10:50:16 2025 -0800

    [TPU] Update TPU CI to use torchxla nightly on 20250122 (#12334)
    
    Signed-off-by: Siyuan Liu <lsiyuan@google.com>

[33mcommit e97f802b2d74861af77997691a7d1c36498f6dca[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Thu Jan 23 13:04:03 2025 -0500

    [FP8][Kernel] Dynamic kv cache scaling factors computation (#11906)
    
    Signed-off-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>
    Co-authored-by: Micah Williamson <micah.williamson@amd.com>

[33mcommit 6e650f56a16618db87147d97f699fa407ed1205d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jan 24 02:01:30 2025 +0800

    [torch.compile] decouple compile sizes and cudagraph sizes (#12243)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 3f50c148fd6476fc9099c04add39e873d9972663[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jan 24 02:00:50 2025 +0800

    [core] add wake_up doc and some sanity check (#12361)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 8c01b8022c78d583394509f8cfa2af4e7ca79279[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Jan 24 01:20:33 2025 +0800

    [Bugfix] Fix broken internvl2 inference with v1 (#12360)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 99d01a5e3d5278284bad359ac8b87ee7a551afda[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Jan 23 07:13:23 2025 -0800

    [V1] Simplify M-RoPE (#12352)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: imkero <kerorek@outlook.com>

[33mcommit d07efb31c5efdb16eb386493b326cf3e90047978[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jan 23 22:46:58 2025 +0800

    [Doc] Troubleshooting errors during model inspection (#12351)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 978b45f39970f81d2857fbb8aada5b44619d258c[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Jan 23 09:45:48 2025 -0500

    [Kernel] Flash Attention 3 Support (#12093)
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit c5b4b11d7f4b69160d6a0d99771cb5c04e923a8d[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Thu Jan 23 18:15:33 2025 +0800

    [Bugfix] Fix k_proj's bias for whisper self attention (#12342)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 8ae5ff20093f74671bcdf2c9d4e078839c7a7732[m
Author: liuzhenwei <zhenweiliu@habana.ai>
Date:   Thu Jan 23 16:35:46 2025 +0800

    [Hardware][Gaudi][BugFix] Fix dataclass error due to triton package update (#12338)
    
    Signed-off-by: zhenwei <zhenweiliu@habana.ai>

[33mcommit 511627445e819169ded3aaead54062cddfd37a5d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jan 23 14:56:02 2025 +0800

    [doc] explain common errors around torch.compile (#12340)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit f0ef37233ea0ba5251edaea7362984110411e7eb[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Jan 22 20:19:21 2025 -0800

    [V1] Add `uncache_blocks` (#12333)

[33mcommit 7551a340328dec66d5905b01d0113e251c3afb3b[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Jan 22 22:44:09 2025 -0500

    [Docs] Document vulnerability disclosure process (#12326)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 01a55941f5443c16a88889995f8149edcee2eec3[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jan 22 22:18:09 2025 -0500

    [Docs] Update FP8 KV Cache documentation (#12238)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 8d7aa9de718d55dd5e17846c6a88f3cd11c138d4[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Wed Jan 22 20:53:02 2025 -0600

    [Bugfix] Fixing  AMD LoRA CI test. (#12329)
    
    Signed-off-by: Alexei V. Ivanov <alexei.ivanov@amd.com>

[33mcommit 68c4421b6d898c8cfde9da6ef03b4262f7195fce[m
Author: rasmith <Randall.Smith@amd.com>
Date:   Wed Jan 22 18:10:37 2025 -0600

    [AMD][Quantization] Add TritonScaledMMLinearKernel since int8 is broken for AMD (#12282)
    
    Signed-off-by: Randall Smith <Randall.Smith@amd.com>

[33mcommit aea94362c9bdd08ed2b346701bdc09d278e85f66[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Jan 22 14:22:12 2025 -0800

    [Frontend][V1] Online serving performance improvements (#12287)

[33mcommit 7206ce4ce112ed117796a59045c968a6d353f691[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Jan 22 10:52:27 2025 -0800

    [Core] Support `reset_prefix_cache` (#12284)

[33mcommit 96f6a7596fed0a8a8b5a13ce1ca2a7e06b1e5adf[m
Author: Konrad Zawora <kzawora@habana.ai>
Date:   Wed Jan 22 19:07:07 2025 +0100

    [Bugfix] Fix HPU multiprocessing executor (#12167)
    
    Signed-off-by: Konrad Zawora <kzawora@habana.ai>

[33mcommit 84bee4bd5c41896d626186c9265f30824b928f7a[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Jan 23 00:56:54 2025 +0800

    [Misc]  Improve the readability of BNB error messages  (#12320)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit fc66dee76d9957eab8fdb9d138d1ebaa0fad4649[m
Author: Robin <863579016@qq.com>
Date:   Thu Jan 23 00:48:41 2025 +0800

    [Misc] Fix the error in the tip for the --lora-modules parameter (#12319)
    
    Signed-off-by: wangerxiao <863579016@qq.com>

[33mcommit 6609cdf0195480f3d3bf1352a96acd6fd6ab89d8[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 22 22:56:29 2025 +0800

    [Doc] Add docs for prompt replacement (#12318)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 16366ee8bbdc30aad9776b74121cfc4d8f8c897d[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Jan 22 05:06:36 2025 -0800

    [Bugfix][VLM] Fix mixed-modality inference backward compatibility for V0 (#12313)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 528dbcac7d042d84b5541a1fba968087b7dc2866[m
Author: zhou fan <1247714429@qq.com>
Date:   Wed Jan 22 19:39:19 2025 +0800

    [Model][Bugfix]: correct Aria model output (#12309)
    
    Signed-off-by: xffxff <1247714429@qq.com>

[33mcommit cd7b6f0857c6622d6b98eae6d6526dfe8dfdec70[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 22 19:08:31 2025 +0800

    [VLM] Avoid unnecessary tokenization (#12310)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 68ad4e3a8d8a66fb2a43be57471ee13a8bec4ec0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jan 22 14:39:32 2025 +0800

    [Core] Support fully transparent sleep mode (#11743)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 4004f144f370f9d42c92e2edce5e5db1b453d57a[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Wed Jan 22 14:29:31 2025 +0800

    [Build] update requirements of no-device (#12299)
    
    Signed-off-by: Mengqing Cao <cmq0113@163.com>

[33mcommit 66818e5b63818a286756653816772faa8622ad89[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jan 22 14:13:52 2025 +0800

    [core] separate builder init and builder prepare for each batch (#12253)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 222a9dc350d99e111ba09b29576113c9278e6a3e[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Jan 21 21:46:14 2025 -0800

    [Benchmark] More accurate TPOT calc in `benchmark_serving.py` (#12288)
    
    Signed-off-by: Nick Hill <nhill@redhat.com>

[33mcommit cbdc4ad5a502f38270650a375931db439304094c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 22 12:06:54 2025 +0800

    [Ci/Build] Fix mypy errors on main (#12296)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 016e3676e7eab58b177f92e579ba20173defee01[m
Author: Liangfu Chen <liangfc@amazon.com>
Date:   Tue Jan 21 18:47:49 2025 -0800

    [CI] add docker volume prune to neuron CI (#12291)
    
    Signed-off-by: Liangfu Chen <liangfc@amazon.com>

[33mcommit 64ea24d0b3ca794faabc5f1570a921a7b44118b7[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Jan 21 17:15:27 2025 -0800

    [ci/lint] Add back default arg for pre-commit (#12279)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit df76e5af2635dee68bbace85da6c0257f6ee74bb[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 22 08:48:13 2025 +0800

    [VLM] Simplify post-processing of replacement info (#12269)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 09ccc9c8f7943220f0b211639cee0655527e857d[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Tue Jan 21 18:49:22 2025 -0500

    [Documentation][AMD] Add information about prebuilt ROCm vLLM docker for perf validation purpose (#12281)
    
    Signed-off-by: Hongxia Yang <hongxyan@amd.com>

[33mcommit 69196a9bc7aefcd132c68a2184f1092ee3377ba9[m
Author: Aleksandr Malyshev <164964928+maleksan85@users.noreply.github.com>
Date:   Tue Jan 21 15:30:46 2025 -0800

    [BUGFIX] When skip_tokenize_init and multistep are set, execution crashes (#12277)
    
    Signed-off-by: maleksan85 <maleksan@amd.com>
    Co-authored-by: maleksan85 <maleksan@amd.com>

[33mcommit 2acba47d9bf97135d33355eff303d61a2c8d3d8a[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Tue Jan 21 16:47:32 2025 -0600

    [bugfix] moe tuning. rm is_navi() (#12273)
    
    Signed-off-by: Divakar Verma <divakar.verma@amd.com>

[33mcommit 9c485d9e252a8834ed15656838d5fbe0dc3a8f2f[m
Author: Jani Monoses <jani.monoses@gmail.com>
Date:   Tue Jan 21 21:56:41 2025 +0200

    [Core] Free CPU pinned memory on environment cleanup (#10477)

[33mcommit fa9ee08121d1d0ffb19c64f4b72ee653589e983b[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Wed Jan 22 03:52:11 2025 +0800

    [Misc] Set default backend to SDPA for get_vit_attn_backend (#12235)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit 347eeebe3bd84c1fb59af72be753ec42cc74b799[m
Author: Adrian Cole <64215+codefromthecrypt@users.noreply.github.com>
Date:   Tue Jan 21 11:51:55 2025 -0800

    [Misc] Remove experimental dep from tracing.py (#12007)
    
    Signed-off-by: Adrian Cole <adrian.cole@elastic.co>

[33mcommit 18fd4a83316868747def6e7e1e2a6caebf8b8ace[m
Author: Andy Lo <andylolu24@gmail.com>
Date:   Tue Jan 21 19:51:35 2025 +0000

    [Bugfix] Multi-sequence broken (#11898)
    
    Signed-off-by: Andy Lo <andy@mistral.ai>

[33mcommit 132a1321004bb994e2260fcc02a3c312bd3b1fe0[m
Author: Ricky Xu <xuchen727@hotmail.com>
Date:   Tue Jan 21 11:51:13 2025 -0800

    [v1][stats][1/n] Add RequestStatsUpdate and RequestStats types  (#10907)
    
    Signed-off-by: rickyx <rickyx@anyscale.com>

[33mcommit 1e60f87bb37bc28410e6cf6e9030e9a28ad49d12[m
Author: Jinzhen Lin <linjinzhen@hotmail.com>
Date:   Wed Jan 22 02:30:28 2025 +0800

    [Kernel] fix moe_align_block_size error condition (#12239)
    
    Signed-off-by: Jinzhen Lin <linjinzhen@hotmail.com>

[33mcommit 9705b90bcf66ba6316e70bef442074df7ee6cebf[m
Author: Jannis Sch√∂nleber <joennlae@gmail.com>
Date:   Tue Jan 21 18:47:04 2025 +0100

    [Bugfix] fix race condition that leads to wrong order of token returned (#10802)
    
    Signed-off-by: Jannis Sch√∂nleber <joennlae@gmail.com>

[33mcommit 3aec49e56f60c8ccafe108a8922c731e235a8fcc[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jan 21 23:03:17 2025 +0800

    [ci/build] update nightly torch for gh200 test (#12270)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit c64612802b72f1e015b98e0c569367e12391f579[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Tue Jan 21 22:42:41 2025 +0800

    [Platform] improve platforms getattr (#12264)
    
    Signed-off-by: Mengqing Cao <cmq0113@163.com>

[33mcommit 9a7c3a0042bb7f44b6c2784220cc3d99391eb4c2[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Tue Jan 21 14:49:08 2025 +0100

    Remove pytorch comments for outlines + compressed-tensors (#12260)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit b197a5ccfdaa46b6750feb5efa4c5d8bf4030d44[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jan 21 05:18:43 2025 -0800

    [V1][Bugfix] Fix data item ordering in mixed-modality inference (#12259)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit c81081fece240736e30e0f9a5ed82bb5b483c561[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jan 21 19:32:55 2025 +0800

    [torch.compile] transparent compilation with more logging (#12246)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit a94eee4456b05458bafacc17377de4701ac598a0[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jan 21 18:09:39 2025 +0800

    [Bugfix] Fix mm_limits access for merged multi-modal processor (#12252)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit f2e9f2a3be6f1dce5a6f01b2263488c6533862ac[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jan 21 16:40:39 2025 +0800

    [Misc] Remove redundant TypeVar from base model (#12248)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 1f1542afa915e0975d2b63559424403e5e8aae2c[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Jan 21 15:49:08 2025 +0800

    [Misc]Add BNB quantization for PaliGemmaForConditionalGeneration  (#12237)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 96912550c8399af2632f3f6830f7c3fa9e10a75a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jan 21 15:31:19 2025 +0800

    [Misc] Rename `MultiModalInputsV2 -> MultiModalInputs` (#12244)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 2fc6944c5e69d5d0ce15d09a855452c795d75c3c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jan 21 13:25:03 2025 +0800

    [ci/build] disable failed and flaky tests (#12240)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 5fe6bf29d657518eb4251981ada9f8c4f34dbbde[m
Author: Nicol√≤ Lucchesi <nlucches@redhat.com>
Date:   Tue Jan 21 05:23:14 2025 +0100

    [BugFix] Fix GGUF tp>1 when vocab_size is not divisible by 64 (#12230)
    
    Signed-off-by: NickLucche <nlucches@redhat.com>

[33mcommit d4b62d4641377c104baa2de7807f2c61d091cfe2[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Mon Jan 20 23:22:23 2025 -0500

    [AMD][Build] Porting dockerfiles from the ROCm/vllm fork (#11777)
    
    Signed-off-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>

[33mcommit ecf67814f1a9e31e9802d93e8bd8b11a1c2810e7[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Jan 20 20:23:40 2025 -0500

    Add quantization and guided decoding CODEOWNERS (#12228)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 750f4cabfac4bfed679d95074d9550b043e3f8d5[m
Author: Jinzhen Lin <linjinzhen@hotmail.com>
Date:   Tue Jan 21 08:42:16 2025 +0800

    [Kernel] optimize moe_align_block_size for cuda graph and large num_experts (e.g. DeepSeek-V3) (#12222)
    
    Signed-off-by: Jinzhen Lin <linjinzhen@hotmail.com>
    Co-authored-by: Michael Goin <mgoin@redhat.com>
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 06a760d6e8bcd60dc98775678b5b12eef01d82bb[m
Author: Cheng Kuan Yong Jason <jasoncky96@gmail.com>
Date:   Tue Jan 21 08:42:02 2025 +0800

    [bugfix] catch xgrammar unsupported array constraints (#12210)
    
    Signed-off-by: Jason Cheng <jasoncky96@gmail.com>

[33mcommit da7512215f0b5c589c2747303b171357940c0614[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jan 21 08:31:01 2025 +0800

    [misc] add cuda runtime version to usage data (#12190)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit af69a6aded526343db8d4a199cdfd1bb84134201[m
Author: I≈üƒ±k <41375111+isikhi@users.noreply.github.com>
Date:   Mon Jan 20 22:23:28 2025 +0000

    fix: update platform detection for M-series arm based MacBook processors (#12227)
    
    Signed-off-by: isikhi <huseyin.isik000@gmail.com>

[33mcommit 7bd36300679a0876c16a905e2baea41dd59a60a2[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jan 20 14:19:09 2025 -0800

    [Misc] Update CODEOWNERS (#12229)

[33mcommit 96663699b2f78eecd44d1d1de9d93c7e054aabc2[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Mon Jan 20 23:49:18 2025 +0800

    [CI] Pass local python version explicitly to pre-commit mypy.sh (#12224)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit 18572e3384a6f55a7589dd81e1f3f70f7dd73e3a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jan 20 23:35:36 2025 +0800

    [Bugfix] Fix `HfExampleModels.find_hf_info` (#12223)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 86bfb6dba7c6e0650e7d7498cbd46b49155b2a42[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Mon Jan 20 23:25:28 2025 +0800

    [Misc] Pass `attention` to impl backend (#12218)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit 5f0ec3935a0118fee8cf2764728f765c8cc53d2a[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Mon Jan 20 21:54:16 2025 +0800

    [V1] Remove `_get_cache_block_size` (#12214)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit c222f47992ce0bbcd3ccbce24736e045d8689be8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jan 20 19:35:59 2025 +0800

    [core][bugfix] configure env var during import vllm (#12209)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 170eb350793a04ceb18ae86be4ccf97d02ad199f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jan 20 18:06:24 2025 +0800

    [misc] print a message to suggest how to bypass commit hooks (#12217)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit b37d82791e3c9f7d492db81493d920004de59a26[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jan 20 17:58:48 2025 +0800

    [Model] Upgrade Aria to transformers 4.48 (#12203)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 3127e975fb9417d10513e25b80820870f594c627[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jan 20 17:36:24 2025 +0800

    [CI/Build] Make pre-commit faster (#12212)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 4001ea126692d9c4e6872936a791a1999c826156[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jan 20 16:41:57 2025 +0800

    [CI/Build] Remove dummy CI steps (#12208)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 5c89a29c22471a0ad5bb05dea9cb891ff97f9623[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jan 20 16:04:49 2025 +0800

    [misc] add placeholder format.sh (#12206)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 59a0192fb9bef026086d0a2ed32705d870a9466a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jan 20 15:00:59 2025 +0800

    [Core] Interface for accessing model from `VllmRunner` (#10353)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 83609791d2ceeb628e0d1f5ea60a64c132eb083c[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Mon Jan 20 14:59:46 2025 +0800

    [Model] Add Qwen2 PRM model support (#12202)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 0974c9bc5c0252ecb25f440139936529657452ab[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Mon Jan 20 01:59:20 2025 -0500

    [Bugfix] Fix incorrect types in LayerwiseProfileResults (#12196)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit d2643128f7741b937435b00fecde7d6b2e351d0c[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Mon Jan 20 01:59:00 2025 -0500

    [DOC] Add missing docstring in LLMEngine.add_request() (#12195)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit c5c06209ec1d90146dd12095d7bff3326aa6dd15[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Mon Jan 20 01:58:29 2025 -0500

    [DOC] Fix typo in docstring and assert message (#12194)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit 3ea7b94523f748faf464293ca5fdc4c94e3a3a89[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Mon Jan 20 06:58:01 2025 +0000

    Move linting to `pre-commit` (#11975)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit 51ef828f10acddbe941c38255c5de7f61738abad[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jan 20 11:37:50 2025 +0800

    [torch.compile] fix sym_tensor_indices (#12191)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit df450aa5671bd3a48929686eb14d8a4324afd91a[m
Author: shangmingc <caishangming@linux.alibaba.com>
Date:   Mon Jan 20 10:56:43 2025 +0800

    [Bugfix] Fix num_heads value for simple connector when tp enabled (#12074)
    
    Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com>

[33mcommit bbe5f9de7dab1fa905807577faa185d85040213a[m
Author: Martin Gleize <mgleize@meta.com>
Date:   Sun Jan 19 19:40:40 2025 +0100

    [Model] Support for fairseq2 Llama (#11442)
    
    Signed-off-by: Martin Gleize <mgleize@meta.com>
    Co-authored-by: mgleize user <mgleize@a100-st-p4de24xlarge-4.fair-a100.hpcaas>

[33mcommit 81763c58a01eda9205f3750177358acc79613e65[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Jan 19 03:52:13 2025 -0800

    [V1] Add V1 support of Qwen2-VL (#12128)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: imkero <kerorek@outlook.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit edaae198e72d36e22a10e9e76198fac32f670b49[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sun Jan 19 19:49:22 2025 +0800

    [Misc] Add BNB support to GLM4-V model (#12184)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 936db119ed390fadc7de448261226358e153e46c[m
Author: gujing <925973396@qq.com>
Date:   Sun Jan 19 17:59:56 2025 +0800

    benchmark_serving support --served-model-name param (#12109)
    
    Signed-off-by: zibai <zibai.gj@alibaba-inc.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit e66faf4809cebf0b2169887151f782fd99bf208f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Jan 19 16:27:26 2025 +0800

    [torch.compile] store inductor compiled Python file (#12182)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 630eb5b5ce6ea59b6480440b7f6064be5ca71ae1[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Jan 19 11:16:34 2025 +0800

    [Bugfix] Fix multi-modal processors for transformers 4.48 (#12187)

[33mcommit 4e94951bb16282c36de6d12ef14a1500f25a3bdf[m
Author: Michal Adamczyk <madamczyk@habana.ai>
Date:   Sun Jan 19 04:12:05 2025 +0100

    [BUGFIX] Move scores to float32 in case of running xgrammar on cpu (#12152)
    
    Signed-off-by: Michal Adamczyk <madamczyk@habana.ai>

[33mcommit 7a8a48d51e51554645b233f870b71ef43bc70177[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat Jan 18 19:07:15 2025 -0800

    [V1] Collect env var for usage stats (#12115)

[33mcommit 32eb0da808ea162a2d6758ff0bd9bdd0934b5fd5[m
Author: yancong <32220263+ice-tong@users.noreply.github.com>
Date:   Sun Jan 19 08:13:16 2025 +0800

    [Misc] Support register quantization method out-of-tree (#11969)

[33mcommit 6d0e3d372446cde48b387d4d3530e25fc6e06320[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Jan 18 14:35:15 2025 +0800

    [core] clean up executor class hierarchy between v1 and v0 (#12171)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 02798ecabed36f4c255f5a12ad6c271f95cd8c4e[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sat Jan 18 13:59:39 2025 +0800

    [Model] Port deepseek-vl2 processor, remove dependency (#12169)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 813f249f022a44aded2a843f0c7108ea0b7d1f6b[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Jan 17 23:35:21 2025 -0500

    [Docs] Fix broken link in SECURITY.md (#12175)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit da02cb4b274ab8bcebb8b8e677ff4b43440bc499[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Jan 18 12:25:08 2025 +0800

    [core] further polish memory profiling (#12126)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit c09503ddd657850c66548b5bb28e58bac1c4afb7[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Fri Jan 17 22:15:53 2025 -0500

    [AMD][CI/Build][Bugfix] use pytorch stale wheel (#12172)
    
    Signed-off-by: hongxyan <hongxyan@amd.com>

[33mcommit 2b835032275622d70b19b8cd834740336dc26138[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Jan 18 10:53:27 2025 +0800

    [misc] fix cross-node TP (#12166)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 7b98a65ae6f011fb31fefa1f563b7d6e554df434[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Jan 18 04:29:31 2025 +0800

    [torch.compile] disable logging when cache is disabled (#12043)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit b5b57e301e7bce3a90af7a3ed206414c46eb64e0[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Fri Jan 17 12:12:26 2025 -0500

    [AMD][FP8] Using MI300 FP8 format on ROCm for block_quant (#12134)
    
    Signed-off-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>

[33mcommit 54cacf008f00d35d46273fed4d538cf5740d0965[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Sat Jan 18 00:47:53 2025 +0800

    [Bugfix] Mistral tokenizer encode accept list of str (#12149)
    
    Signed-off-by: Kunshang Ji <kunshang.ji@intel.com>

[33mcommit 58fd57ff1d6d4ed56bed40aaaf9fe133b93b2efa[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Fri Jan 17 13:24:22 2025 -0300

    [Bugfix] Fix score api for missing max_model_len validation (#12119)
    
    Signed-off-by: Wallas Santos <wallashss@ibm.com>

[33mcommit 87a0c076afafb93dd082ff3876bea08adca56c56[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jan 17 20:47:01 2025 +0800

    [core] allow callable in collective_rpc (#12151)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d4e619457075c0dd917b84644f467f7f8aae10f0[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Fri Jan 17 19:39:52 2025 +0800

    [CI/Build][CPU][Bugfix] Fix CPU CI (#12150)
    
    Signed-off-by: jiang1.li <jiang1.li@intel.com>

[33mcommit 07934cc237d16427d705e5abc3c83e4eb0f9b7f4[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Fri Jan 17 19:32:28 2025 +0800

    [Misc][LoRA] Improve the readability of LoRA error messages (#12102)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 69d765f5a5bbbe1ea9843be19b9480660fc5bc8b[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Fri Jan 17 15:39:35 2025 +0800

    [V1] Move more control of kv cache initialization from model_executor to EngineCore (#11960)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 8027a724611353d2ff3a504f91c5607e94f635b0[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Fri Jan 17 00:49:16 2025 -0600

    [ROCm][MoE] moe tuning support for rocm (#12049)
    
    Signed-off-by: Divakar Verma <divakar.verma@amd.com>

[33mcommit d75ab55f1035309c96814af46da1c5166209854b[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Jan 17 14:34:48 2025 +0800

    [Misc] Add deepseek_vl2 chat template (#12143)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit d1adb9b4032dd430bb28b8e91feb8164c3a1ca9c[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Fri Jan 17 13:33:22 2025 +0800

    [BugFix] add more `is not None` check in VllmConfig.__post_init__ (#12138)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit b8bfa46a18abe0bf9f48a29e1e8dd2bc1a79af98[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Thu Jan 16 23:54:01 2025 -0500

    [Bugfix] Fix issues in CPU build Dockerfile (#12135)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit 1475847a14e3693128fcc4f8740493d12074ed93[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Thu Jan 16 23:45:36 2025 -0500

    [Doc] Add instructions on using Podman when SELinux is active (#12136)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit fead53ba78dbcdd4da616308f1ef1b4a312f8897[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Fri Jan 17 12:15:09 2025 +0800

    [CI]add genai-perf benchmark in nightly benchmark (#10704)
    
    Signed-off-by: Kunshang Ji <kunshang.ji@intel.com>

[33mcommit ebc73f2828df48f0ffbb99e52f0e4b394a23dbd3[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Fri Jan 17 11:12:41 2025 +0800

    [Bugfix] Fix a path bug in disaggregated prefill example script. (#12121)
    
    Signed-off-by: Kuntai Du <kuntai@uchicago.edu>

[33mcommit d06e824006d1ba4b92871347738ce1b89f658499[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Fri Jan 17 04:30:08 2025 +0800

    [Bugfix] Set enforce_eager automatically for mllama (#12127)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit 62b06ba23deaca5a0e7602cd2e3a85aeec57f306[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Jan 17 01:14:48 2025 +0800

    [Model] Add support for deepseek-vl2-tiny model (#12068)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 5fd24ec02e0365f96301ac73a31ef06976c256e8[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Thu Jan 16 21:21:40 2025 +0530

    [misc] Add LoRA kernel micro benchmarks (#11579)

[33mcommit 874f7c292a4f4f5dbb89b12426187e5a70f006d6[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Jan 16 06:54:06 2025 -0800

    [Bugfix] Fix max image feature size for Llava-one-vision (#12104)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 92e793d91a1a4e982662ecca0096e5edcafd21c6[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jan 16 20:19:52 2025 +0800

    [core] LLM.collective_rpc interface and RLHF example (#12084)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit bf53e0c70b0fe17087914cc770fd801e0bf02137[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jan 16 19:58:53 2025 +0800

    Support torchrun and SPMD-style offline inference (#12071)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit dd7c9ad87074b68d201208a196e0a4b2b5ecc27a[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Thu Jan 16 18:11:54 2025 +0800

    [Bugfix] Remove hardcoded `head_size=256` for Deepseek v2 and v3 (#12067)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 9aa1519f089e8dc2c2bd1b4c74a8ce47d386f0a9[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Jan 16 04:59:06 2025 -0500

    Various cosmetic/comment fixes (#12089)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit f8ef146f03da8993fb3bf5638b28bef6e931fc51[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jan 16 15:53:43 2025 +0800

    [Doc] Add documentation for specifying model architecture (#12105)

[33mcommit fa0050db08660535368ec5ea41d313bdeb69909d[m
Author: Elfie Guo <164945471+elfiegg@users.noreply.github.com>
Date:   Wed Jan 15 20:31:27 2025 -0800

    [Core] Default to using per_token quantization for fp8 when cutlass is supported. (#8651)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: Michael Goin <mgoin@redhat.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit cd9d06fb8d1f89fc1bcc9305bc20d57c6d8b73d8[m
Author: tvirolai-amd <teemu.virolainen@amd.com>
Date:   Wed Jan 15 23:46:03 2025 +0200

    Allow hip sources to be directly included when compiling for rocm. (#12087)

[33mcommit ebd8c669efa54a218eb83735fd7ba40922f5f3ad[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Thu Jan 16 01:29:42 2025 +0530

    [Bugfix] Fix _get_lora_device for HQQ marlin (#12090)
    
    Signed-off-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 70755e819e0ae5d963dab7d81321bdfaef6d955a[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Jan 15 11:29:00 2025 -0800

    [V1][Core] Autotune encoder cache budget (#11895)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit edce722eaa5e9f0b97bea611531e3341ec2e2e71[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Wed Jan 15 09:31:01 2025 -0700

    [Bugfix] use right truncation for non-generative tasks (#12050)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 57e729e87478d734e8d0075e35aeb4c9bd440e77[m
Author: maang-h <55082429+maang-h@users.noreply.github.com>
Date:   Thu Jan 16 00:07:45 2025 +0800

    [Doc]: Update `OpenAI-Compatible Server` documents (#12082)

[33mcommit de0526f668d6918c1884fd3b201308e9049e6be9[m
Author: kewang-xlnx <73578509+kewang-xlnx@users.noreply.github.com>
Date:   Thu Jan 16 00:05:15 2025 +0800

    [Misc][Quark] Upstream Quark format to VLLM (#10765)
    
    Signed-off-by: kewang-xlnx <kewang@xilinx.com>
    Signed-off-by: kewang2 <kewang2@amd.com>
    Co-authored-by: kewang2 <kewang2@amd.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 5ecf3e0aafc3ae0e2923e0635adc6b26788429a3[m
Author: Yuan <yuan.zhou@intel.com>
Date:   Wed Jan 15 21:16:40 2025 +0800

    Misc: allow to use proxy in `HTTPConnection` (#12042)
    
    Signed-off-by: Yuan Zhou <yuan.zhou@intel.com>

[33mcommit 97eb97b5a4fd64c3cbc97bb9d71a9bfd98348799[m
Author: RunningLeon <maningsheng@sensetime.com>
Date:   Wed Jan 15 19:35:17 2025 +0800

    [Model]: Support internlm3 (#12037)

[33mcommit 3adf0ffda8de31ff32f294324e53b6cfbf16f187[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Wed Jan 15 18:14:15 2025 +0800

    [Platform] Do not raise error if _Backend is not found (#12023)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>
    Signed-off-by: Mengqing Cao <cmq0113@163.com>
    Co-authored-by: Mengqing Cao <cmq0113@163.com>

[33mcommit ad388d25a8e668545ef91c3634b67a241155e2ea[m
Author: Keyun Tong <tongkeyun@gmail.com>
Date:   Wed Jan 15 01:44:56 2025 -0800

    Type-fix: make execute_model output type optional (#12020)

[33mcommit cbe94391eb04aa9ae1be15711fec4eb453c1e053[m
Author: Rahul Tuli <rahul@neuralmagic.com>
Date:   Wed Jan 15 04:41:24 2025 -0500

    Fix: cases with empty sparsity config (#12057)
    
    Signed-off-by: Rahul Tuli <rahul@neuralmagic.com>

[33mcommit 994fc655b71f59f61b82cc44e868091dae493a84[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Wed Jan 15 15:55:30 2025 +0800

    [V1][Prefix Cache] Move the logic of num_computed_tokens into KVCacheManager (#12003)

[33mcommit 3f9b7ab9f59f83ab0551a6a2f1894e30bc0cb41c[m
Author: Kyle Sayers <kylesayrs@gmail.com>
Date:   Wed Jan 15 01:36:01 2025 -0500

    [Doc] Update examples to remove SparseAutoModelForCausalLM (#12062)
    
    Signed-off-by: Kyle Sayers <kylesayrs@gmail.com>

[33mcommit ad34c0df0f1b26b303a590133685b29e3daad20e[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jan 15 13:45:21 2025 +0800

    [core] platform agnostic executor via collective_rpc (#11256)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit f218f9c24d224800e0ea4488aa71bd8215c8bdcd[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Tue Jan 14 21:19:55 2025 -0800

    [core] Turn off GPU communication overlap for Ray executor (#12051)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit 0794e7446efca1fd7b8ea1cde96777897660cdea[m
Author: Elfie Guo <164945471+elfiegg@users.noreply.github.com>
Date:   Tue Jan 14 20:47:49 2025 -0800

    [Misc] Add multipstep chunked-prefill support for FlashInfer (#10467)

[33mcommit b7ee940a828de9d339345e28eee8b13d60d97f26[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jan 14 20:21:28 2025 -0800

    [V1][BugFix] Fix edge case in VLM scheduling (#12065)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 9ddac56311b28f08e40a941296eb66fbb1be0a7a[m
Author: Shanshan Shen <467638484@qq.com>
Date:   Wed Jan 15 11:38:25 2025 +0800

    [Platform] move current_memory_usage() into platform (#11369)
    
    Signed-off-by: Shanshan Shen <467638484@qq.com>

[33mcommit 1a51b9f87226b2290c78c65c1de0f585d31f17ce[m
Author: Konrad Zawora <kzawora@habana.ai>
Date:   Wed Jan 15 03:59:18 2025 +0100

    [HPU][Bugfix] Don't use /dev/accel/accel0 for HPU autodetection in setup.py (#12046)
    
    Signed-off-by: Konrad Zawora <kzawora@habana.ai>

[33mcommit 42f5e7c52a5852e20937001332572c8cb8115af0[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Jan 15 10:29:53 2025 +0800

    [Kernel] Support MulAndSilu (#11624)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit a3a3ee4e6febe8c270fdec0765c844186a728079[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Jan 15 07:49:49 2025 +0800

    [Misc]  Merge bitsandbytes_stacked_params_mapping and packed_modules_mapping (#11924)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 87054a57ab39bad6c7fe8999e7d93566ded713e3[m
Author: maang-h <55082429+maang-h@users.noreply.github.com>
Date:   Wed Jan 15 01:03:04 2025 +0800

    [Doc]: Update the Json Example of the `Engine Arguments` document (#12045)

[33mcommit c9d6ff530b32c526bedda3105dcbab3d2f6ce992[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Tue Jan 14 16:05:50 2025 +0000

    Explain where the engine args go when using Docker (#12041)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit a2d2acb4c8d240b1e5946afe2736e497ce5b71a2[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Tue Jan 14 23:45:05 2025 +0800

    [Bugfix][Kernel] Give unique name to BlockSparseFlashAttention (#12040)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit 2e0e0176104965c9c8c090609f331f9b70e492f3[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Tue Jan 14 21:27:04 2025 +0800

    [Platform] Add output for Attention Backend (#11981)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit 1f18adb2451e9b45048d17023169bd8cbb39747e[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Tue Jan 14 20:59:32 2025 +0800

    [Kernel] Revert the API change of Attention.forward (#12038)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit bb354e6b2dd4f8154c39c33b7eee77fa452b7703[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jan 14 20:16:11 2025 +0800

    [Bugfix] Fix various bugs in multi-modal processor (#12031)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit ff39141a49928540c3975cc8e2a6e9bfa51f0bef[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jan 14 19:24:06 2025 +0800

    [HPU][misc] add comments for explanation (#12034)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 8a1f938e6f02052df0f4953c149410605a2d56d8[m
Author: TJian <tunjian1996@gmail.com>
Date:   Tue Jan 14 12:37:52 2025 +0800

    [Doc] Update Quantization Hardware Support Documentation (#12025)
    
    Signed-off-by: tjtanaa <tunjian.tan@embeddedllm.com>
    Co-authored-by: tjtanaa <tunjian.tan@embeddedllm.com>

[33mcommit 078da319033a32304bb3297092c9ec34c52d598b[m
Author: Konrad Zawora <kzawora@habana.ai>
Date:   Tue Jan 14 04:04:18 2025 +0100

    [HPU][Bugfix] set_forward_context and CI test execution (#12014)
    
    Signed-off-by: Konrad Zawora <kzawora@habana.ai>

[33mcommit 1a401252b5c1cb6cab348531281c5bd340257733[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jan 13 17:24:36 2025 -0800

    [Docs] Add Sky Computing Lab to project intro (#12019)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit f35ec461fc655a50abc5146fa27a79fdf42f55a1[m
Author: Steve Luo <36296769+SunflowerAries@users.noreply.github.com>
Date:   Tue Jan 14 04:43:51 2025 +0800

    [Bugfix] Fix deepseekv3 gate bias error (#12002)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit 289b5191d5bd16c7b2e08cb19434f9f188393ac5[m
Author: Yikun Jiang <yikunkero@gmail.com>
Date:   Tue Jan 14 01:23:59 2025 +0800

    [Doc] Fix build from source and installation link in README.md (#12013)
    
    Signed-off-by: Yikun <yikunkero@gmail.com>

[33mcommit c6db21313cef3f1f9aa5714efba0d60b5f1a8dad[m
Author: elijah <30852919+e1ijah1@users.noreply.github.com>
Date:   Mon Jan 13 23:22:07 2025 +0800

    bugfix: Fix signature mismatch in benchmark's `get_tokenizer` function (#11982)
    
    Signed-off-by: elijah <f1renze.142857@gmail.com>

[33mcommit a7d59688fb75827db4316c24a057ac6097114bd3[m
Author: Shanshan Shen <467638484@qq.com>
Date:   Mon Jan 13 21:12:10 2025 +0800

    [Platform] Move get_punica_wrapper() function to Platform (#11516)
    
    Signed-off-by: Shanshan Shen <467638484@qq.com>

[33mcommit 458e63a2c6b18e7febfa30cecb59461f96fbe324[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jan 13 20:59:09 2025 +0800

    [platform] add device_control env var (#12009)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit e8c23ff989d4b061726315bbf74d0bca7136fdc4[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Mon Jan 13 12:27:36 2025 +0000

    [Doc] Organise installation documentation into categories and tabs (#11935)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit cd8249903f189c5f06424e67dbc6512ca494a046[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jan 13 03:58:54 2025 -0800

    [Doc][V1] Update model implementation guide for V1 support (#11998)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit 0f8cafe2d1550a33803fb64b2224e6bf3f913449[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Mon Jan 13 19:28:53 2025 +0800

    [Kernel] unified_attention for Attention.forward (#11967)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit 5340a30d0193547a19e236757fec1f3f246642f9[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Mon Jan 13 01:37:48 2025 -0700

    Fix Max Token ID for Qwen-VL-Chat (#11980)
    
    Signed-off-by: Alex-Brooks <Alex.brooks@ibm.com>

[33mcommit 89ce62a316e68c50121e74d5a832e0cb9a5101d1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jan 13 16:20:52 2025 +0800

    [platform] add ray_device_key (#11948)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit c3f05b09a040b9d13ad62914be3f7a84c535e417[m
Author: Chenguang Li <757486878@qq.com>
Date:   Mon Jan 13 15:47:05 2025 +0800

    [Misc]Minor Changes about Worker (#11555)
    
    Signed-off-by: Chenguang Li <757486878@qq.com>

[33mcommit cf6bbcb49324c24fc0f6f9381400c299c9c2d7ac[m
Author: Concurrensee <yida.wu@amd.com>
Date:   Mon Jan 13 01:05:06 2025 -0600

    [Misc] Fix Deepseek V2 fp8 kv-scale remapping (#11947)
    
    Signed-off-by: Yida Wu <yidawu@alumni.cmu.edu>

[33mcommit 80ea3af1a06ff445e6cdede072bda1429c9dac06[m
Author: Sungjae Lee <33976427+llsj14@users.noreply.github.com>
Date:   Mon Jan 13 15:50:35 2025 +0900

    [CI][Spec Decode] fix: broken test for EAGLE model (#11972)
    
    Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com>

[33mcommit 9dd02d85ca801c99241317a8061bd025c726af93[m
Author: Siyuan Li <94890248+liaoyanqing666@users.noreply.github.com>
Date:   Mon Jan 13 14:24:10 2025 +0800

    [Bug] Fix usage of `.transpose()` and `.view()` consecutively. (#11979)

[33mcommit f7b3ba82c3eec71f31f8d49f708ab328b5e908f6[m
Author: Yangcheng Li <liyangcheng.lyc@alibaba-inc.com>
Date:   Mon Jan 13 13:07:48 2025 +0800

    [MISC] fix typo in kv transfer send recv test (#11983)

[33mcommit 619ae268c3dc848a9b2f04579ea78ac5655f190f[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Jan 12 23:54:10 2025 -0500

    [V1] [2/n] Logging and Metrics - `OutputProcessor` Abstraction (#11973)
    
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>

[33mcommit d14e98d924724b284dc5eaf8070d935e214e50c0[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Mon Jan 13 08:13:44 2025 +0800

    [Model] Support GGUF models newly added in `transformers` 4.46.0 (#9685)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 9597a095f2c02670b44f5973635ce4b9852e8eab[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Jan 12 16:02:02 2025 -0500

    [V1][Core][1/n] Logging and Metrics (#11962)
    
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>

[33mcommit 263a870ee18bd6a90e25dbfa342be32c6b92c33e[m
Author: Avshalom Manevich <12231371+avshalomman@users.noreply.github.com>
Date:   Sun Jan 12 17:53:51 2025 +0200

    [Hardware][TPU] workaround fix for MoE on TPU (#11764)

[33mcommit 8bddb735123204872788a8ffe117321de7550e6c[m
Author: Akshat Tripathi <Akshat.tripathi6568@gmail.com>
Date:   Sun Jan 12 13:01:52 2025 +0000

    [Hardware][CPU] Multi-LoRA implementation for the CPU backend (#11100)
    
    Signed-off-by: Akshat Tripathi <akshat@krai.ai>
    Signed-off-by: Oleg Mosalov <oleg@krai.ai>
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: Oleg Mosalov <oleg@krai.ai>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit f967e51f386404c7ead21d3c59ddc195cf946975[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sun Jan 12 16:17:24 2025 +0800

    [Model] Initialize support for Deepseek-VL2 models (#11578)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 43f3d9e6990811461ecb42bc50a17aad944d30f9[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Sun Jan 12 03:17:13 2025 -0500

    [CI/Build] Add markdown linter (#11857)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit b25cfab9a03b5c460fb92340b310d2a5c2dbc5da[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Jan 11 22:36:38 2025 -0800

    [V1] Avoid sending text prompt to core engine (#11963)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 4b657d32922cb6d3179f901e312715279ad9c728[m
Author: sixgod <evethwillbeok@outlook.com>
Date:   Sun Jan 12 03:05:56 2025 +0800

    [Model] Add cogagent model support vLLM (#11742)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit d697dc01b4a25b96c3a1e88d72a058f17a717fd5[m
Author: Nicol√≤ Lucchesi <nlucches@redhat.com>
Date:   Sat Jan 11 15:05:09 2025 +0100

    [Bugfix] Fix RobertaModel loading (#11940)
    
    Signed-off-by: NickLucche <nlucches@redhat.com>

[33mcommit a991f7d5085e3e9474531f78639766eac3af607c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jan 11 21:27:24 2025 +0800

    [Doc] Basic guide for writing unit tests for new models (#11951)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 7a3a83e3b87f50fe9c0985a5c5bcc1d4cf2e95cd[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jan 11 13:50:05 2025 +0800

    [CI/Build] Move model-specific multi-modal processing tests (#11934)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit c32a7c7c0c688ed81d2f4ad701a09d0edd095ffe[m
Author: shaochangxu <85155497+shaochangxu@users.noreply.github.com>
Date:   Sat Jan 11 13:49:39 2025 +0800

    [Bugfix] fused_experts_impl wrong compute type for float32 (#11921)
    
    Signed-off-by: shaochangxu.scx <shaochangxu.scx@antgroup.com>
    Co-authored-by: shaochangxu.scx <shaochangxu.scx@antgroup.com>

[33mcommit 2118d0565cb52c69e0bbacdcf48af9ecef39e528[m
Author: Sungjae Lee <33976427+llsj14@users.noreply.github.com>
Date:   Sat Jan 11 13:49:38 2025 +0900

    [Bugfix][SpecDecode] Adjust Eagle model architecture to align with intended design (#11672)
    
    Signed-off-by: Sungjae Lee <33976427+llsj14@users.noreply.github.com>

[33mcommit 899136b857d510f0e19b0e21ea32b49f8aa117ed[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Jan 11 09:07:24 2025 +0800

    [ci] fix broken distributed-tests-4-gpus (#11937)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit c9f09a4fe83ef13824ea1663214ac7aad08d2b31[m
Author: Fred Reiss <frreiss@us.ibm.com>
Date:   Fri Jan 10 17:04:58 2025 -0800

    [mypy] Fix mypy warnings in api_server.py (#11941)
    
    Signed-off-by: Fred Reiss <frreiss@us.ibm.com>

[33mcommit d45cbe70f5bf25bb2f490f4152c256e9acb2a62b[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Fri Jan 10 16:26:00 2025 -0700

    [Bugfix] Check that number of images matches number of <|image|> tokens with mllama (#11939)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 8a579408f33e2f98a89d57418342b53a41622d2f[m
Author: minmin <rmm0811@gmail.com>
Date:   Sat Jan 11 04:39:22 2025 +0800

    [Misc] Update benchmark_prefix_caching.py fixed example usage (#11920)
    
    Signed-off-by: Ren MinMin <renmm6@chinaunicom.cn>
    Co-authored-by: Ren MinMin <renmm6@chinaunicom.cn>

[33mcommit 46fa98ccad444dbacc7f95995b79f65ddab3ff7c[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sat Jan 11 03:19:15 2025 +0800

    [Misc] Clean up debug code in Deepseek-V3 (#11930)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit aa1e77a19ce658abcbaa0836f96878a7ae9dea84[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Sat Jan 11 00:07:58 2025 +0800

    [Hardware][CPU] Support MOE models on x86 CPU (#11831)
    
    Signed-off-by: jiang1.li <jiang1.li@intel.com>

[33mcommit 5959564f94180a6a50e0d394e35a035c0c98a7fb[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Fri Jan 10 23:51:43 2025 +0800

    Doc fix in `benchmark_long_document_qa_throughput.py` (#11933)
    
    Signed-off-by: Kuntai Du <kuntai@uchicago.edu>

[33mcommit f33e033e2782a9258d8ef6a359643944629d4ced[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Fri Jan 10 23:51:02 2025 +0800

    [Docs] Fix docstring in `get_ip` function (#11932)
    
    Signed-off-by: Kuntai Du <kuntai@uchicago.edu>

[33mcommit 482cdc494e608b72303f49b56532f5c50b61cbdb[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Fri Jan 10 15:50:29 2025 +0000

    [Doc] Rename offline inference examples (#11927)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit 20410b2fdac1818ead453018fb07c2ff90ee6770[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Fri Jan 10 23:46:51 2025 +0800

    [platform] support custom torch.compile backend key (#11318)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 12664ddda522b3a22c5b71eca9b2c907e3a687b3[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jan 10 22:30:25 2025 +0800

    [Doc] [1/N] Initial guide for merged multi-modal processor (#11925)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 241ad7b301facac0728e2b3312d71fe47acc8c9e[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jan 10 20:45:33 2025 +0800

    [ci] Fix sampler tests (#11922)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d85c47d6ad24c286ae55fd9da231808b8ddd7a7f[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Fri Jan 10 12:05:56 2025 +0000

    Replace "online inference" with "online serving" (#11923)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit ef725feafcc1f2d6763cc888751fb2b36840587b[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Fri Jan 10 18:02:38 2025 +0800

    [platform] support pytorch custom op pluggable (#11328)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit d907be7dc7926e64d6240bf4425d7399eaed150e[m
Author: cennn <61925104+cennn@users.noreply.github.com>
Date:   Fri Jan 10 17:18:25 2025 +0800

    [misc] remove python function call for custom activation op (#11885)
    
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit d53575a5f0e5c0f9003b4ec6e33c8bf761e93cef[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jan 10 16:25:17 2025 +0800

    [ci] fix gh200 tests (#11919)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 61af6332565d0093855fee7266699e548b1c0d1c[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Fri Jan 10 16:20:46 2025 +0800

    [BUGFIX] Fix `UnspecifiedPlatform` package name (#11916)
    
    Signed-off-by: Kunshang Ji <kunshang.ji@intel.com>

[33mcommit ac2f3f7fee93cf9cd97c0078e362feab7b6c8299[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Fri Jan 10 00:56:36 2025 -0700

    [Bugfix] Validate lora adapters to avoid crashing server (#11727)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit cf5f000d218fbcbc4bf404de8ed9d9607a128c3b[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Fri Jan 10 13:14:42 2025 +0800

    [torch.compile] Hide KV cache behind torch.compile boundary (#11677)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit 3de2b1eafb12e420c563cb7153d4d2f0e8451ca9[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jan 10 11:25:20 2025 +0800

    [Doc] Show default pooling method in a table (#11904)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit b844b99ad309b05f37b1acb5360c82be7b16281d[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jan 10 11:24:00 2025 +0800

    [VLM] Enable tokenized inputs for merged multi-modal processor (#11900)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit c3cf54dda4df200bc8913ed69d210a7108dfa320[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jan 10 11:10:12 2025 +0800

    [Doc][5/N] Move Community and API Reference to the bottom (#11896)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 36f5303578397d122693a19007be38ba2f02bcbc[m
Author: Charles Frye <cfrye59@gmail.com>
Date:   Thu Jan 9 15:26:37 2025 -0800

    [Docs] Add Modal to deployment frameworks (#11907)

[33mcommit 9a228348d2f9a2c85dfc67d6b9fe883bf10a4680[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jan 10 01:19:37 2025 +0800

    [Misc] Provide correct Pixtral-HF chat template (#11891)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit bd8287221187279c668ac10c3edd5242b8d8b429[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jan 9 22:47:29 2025 +0800

    [ci]try to fix flaky multi-step tests (#11894)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 405eb8e3967eb9bd263b3919796cb3b45a2931d3[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Thu Jan 9 21:46:50 2025 +0800

    [platform] Allow platform specify attention backend (#11609)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>
    Signed-off-by: Mengqing Cao <cmq0113@163.com>
    Co-authored-by: Mengqing Cao <cmq0113@163.com>

[33mcommit 65097ca0af5c1d7caa3d9d8224fa8b4790a5f7bc[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jan 9 17:43:40 2025 +0800

    [Doc] Add model development API Reference (#11884)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 1d967acb45d5d18434409b822f105f087e379eee[m
Author: Ye (Charlotte) Qi <ye.charlotte.qi@gmail.com>
Date:   Thu Jan 9 01:36:39 2025 -0800

    [Bugfix] fix beam search input errors and latency benchmark script (#11875)
    
    Signed-off-by: Ye Qi <yeq@meta.com>
    Co-authored-by: yeq <yeq@devgpu004.lla3.facebook.com>

[33mcommit 0bd1ff43469f867f92786a3596c3e4a64df43400[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jan 9 17:02:53 2025 +0800

    [Bugfix] Override dunder methods of placeholder modules (#11882)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 310aca88c984983189a57f1b72e3b1dde89fb92f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jan 9 15:18:21 2025 +0800

    [perf]fix current stream (#11870)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit a732900efc4eb0d4393e3885d5df8ef3516d4834[m
Author: Guspan Tanadi <36249910+guspan-tanadi@users.noreply.github.com>
Date:   Thu Jan 9 12:39:39 2025 +0700

    [Doc] Intended links Python multiprocessing library (#11878)

[33mcommit d848800e884f581eeed9f154d6c2aeb38eac24de[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jan 9 12:48:12 2025 +0800

    [Misc] Move `print_*_once` from utils to logger (#11298)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Signed-off-by: Maxime Fournioux <55544262+mfournioux@users.noreply.github.com>
    Co-authored-by: Maxime Fournioux <55544262+mfournioux@users.noreply.github.com>

[33mcommit 730e9592e97c643474aa44e9d3dbe6f55c4b9ad9[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jan 8 22:37:48 2025 -0500

    [Doc] Recommend uv and python 3.12 for quickstart guide (#11849)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 1fe554bac32419a6d64a5c977849806a1efd9725[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Thu Jan 9 00:05:43 2025 -0300

    treat do_lower_case in the same way as the sentence-transformers library (#11815)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>

[33mcommit 615e4a54017136649db275b68932af80168781f8[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Jan 8 21:20:44 2025 -0500

    [CI] Turn on basic correctness tests for V1 (#10864)

[33mcommit 3db0cafdf1fe7f4cd7e41a145f78e8a568b4d63c[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Jan 8 12:38:28 2025 -0800

    [Docs] Add Google Cloud Meetup (#11864)

[33mcommit 526de822d501c792b051c864ba873a836d78d5bf[m
Author: rasmith <Randall.Smith@amd.com>
Date:   Wed Jan 8 14:23:15 2025 -0600

    [Kernel][Triton][AMD] Use block size heuristic for avg 2.8x speedup for int8 models (#11698)
    
    Signed-off-by: Randall Smith <Randall.Smith@amd.com>

[33mcommit 56fe4c297c7d9d872eccc19e3edbf1d75e1a30e2[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Wed Jan 8 14:33:29 2025 -0500

    [TPU][Quantization] TPU `W8A8` (#11785)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 47de8821d3cdd32fce7df6312318223aee591fd2[m
Author: WangErXiao <863579016@qq.com>
Date:   Thu Jan 9 02:21:30 2025 +0800

    [Misc]add some explanations for BlockHashType (#11847)

[33mcommit 5984499e473c387c17904aa9933b8ed080621ca6[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jan 9 01:14:14 2025 +0800

    [Doc] Expand Multimodal API Reference (#11852)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit ca47e176af9e0a4fa9f02325cdad5f11b40aedab[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jan 9 01:04:46 2025 +0800

    [Misc] Move some model utils into vision file (#11848)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 78f4590b60161dee1a444870ae682ba45f633502[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Thu Jan 9 00:11:50 2025 +0800

    [Bugfix][XPU] fix silu_and_mul (#11823)
    
    Signed-off-by: yan ma <yan.ma@intel.com>

[33mcommit 2f7024987e582b85b280909b87287668cd97c92f[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Wed Jan 8 23:18:28 2025 +0800

    [CI/Build][Bugfix] Fix CPU CI image clean up (#11836)
    
    Signed-off-by: jiang1.li <jiang1.li@intel.com>

[33mcommit 6cd40a5bfed24ef0ceca83b0450be6920d8ca6d4[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 8 21:34:44 2025 +0800

    [Doc][4/N] Reorganize API Reference (#11843)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit aba8d6ee006b78149ac4514f460e4038b2d4f607[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Wed Jan 8 13:09:53 2025 +0000

    [Doc] Move examples into categories (#11840)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit 2a0596bc480bb835dc05a30f5e708ecbfffbcd69[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 8 18:59:58 2025 +0800

    [VLM] Reorganize profiling/processing-related code (#11812)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit f12141170a95ad866b3c55762623bc718994e1d7[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jan 8 18:46:43 2025 +0800

    [torch.compile] consider relevant code in compilation cache (#11614)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit cfd3219f5881e2abea1f7c9d2866ed1838c5057b[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Wed Jan 8 05:35:49 2025 -0300

    [Hardware][Apple] Native support for macOS Apple Silicon (#11696)
    
    Signed-off-by: Wallas Santos <wallashss@ibm.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit a1b2b8606e75ab8fbc066e7f0fae20c1e60244ca[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Jan 7 23:05:46 2025 -0800

    [Docs] Update sponsor name: 'Novita' to 'Novita AI' (#11833)

[33mcommit ad9f1aa6796297a00456e715043f3eaad55bed53[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jan 8 14:36:49 2025 +0800

    [doc] update wheels url (#11830)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 889e662eae19fe8f30469883c6854ee4df4315a9[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jan 8 14:36:03 2025 +0800

    [misc] improve memory profiling (#11809)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit ef68eb28d8d45be6e0defe82245e16be9362e375[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 8 13:40:09 2025 +0800

    [Bug] Fix pickling of `ModelConfig` when RunAI Model Streamer is used (#11825)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 259abd8953a8fea9abf3c4e66aa7c51391fa5b64[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Jan 7 21:16:08 2025 -0800

    [Docs] reorganize sponsorship page (#11639)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit f645eb69545672d394e9e9e0ce46c725504fd2a0[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Jan 8 13:08:48 2025 +0800

    [Bugfix] Add checks for LoRA and CPU offload (#11810)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit f4923cb8bce7d9c3038ad6c597ae1ff3ed90fe93[m
Author: Ilya Lavrenov <ilya.lavrenov@intel.com>
Date:   Wed Jan 8 09:08:30 2025 +0400

    [OpenVINO] Fixed Docker.openvino build (#11732)
    
    Signed-off-by: Ilya Lavrenov <ilya.lavrenov@intel.com>

[33mcommit b640b19cc0babe256c5455befe95340f951763d9[m
Author: Nishidha <nishidha.panpaliya@partner.ibm.com>
Date:   Wed Jan 8 10:35:37 2025 +0530

    Fixed docker build for ppc64le (#11518)
    
    Signed-off-by: Nishidha Panpaliya <nishidha.panpaliya@partner.ibm.com>

[33mcommit dc71af0a71f347badcd917810440fad136e73ba6[m
Author: WangErXiao <863579016@qq.com>
Date:   Wed Jan 8 12:09:25 2025 +0800

    Remove the duplicate imports of MultiModalKwargs and PlaceholderRange‚Ä¶ (#11824)

[33mcommit 4d29e91be84d27ca313d657eee92c067439a4c23[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Tue Jan 7 20:57:04 2025 -0600

    [Misc] sort torch profiler table by kernel timing (#11813)

[33mcommit 91445c7bc8000a6f6f1efed0882076d7001be968[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 8 10:17:16 2025 +0800

    [Bugfix] Fix image input for Pixtral-HF (#11741)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 5950f555a1d2ce19c30efb24abe03737320d05c1[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Wed Jan 8 01:20:12 2025 +0000

    [Doc] Group examples into categories (#11782)
    
    Signed-off-by: Harry Mellor <19981378+hmellor@users.noreply.github.com>

[33mcommit a4e2b268568b335d8fe37f8eaaa894cec3ba9397[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Wed Jan 8 08:15:50 2025 +0800

    [Bugfix] Significant performance drop on CPUs with --num-scheduler-steps > 1 (#11794)

[33mcommit 973f5dc581c35a9c5b9176116e2f42f3f97d0d01[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Tue Jan 7 11:19:12 2025 -0800

    [Doc]Add documentation for using EAGLE in vLLM (#11417)
    
    Signed-off-by: Sourashis Roy <sroy@roblox.com>

[33mcommit c994223d569221652643e897d8402b835ead411d[m
Author: jiangjiadi <34134495+jiangjiadi@users.noreply.github.com>
Date:   Wed Jan 8 02:36:34 2025 +0800

    [Bugfix] update the prefix for qwen2 (#11795)
    
    Co-authored-by: jiadi.jjd <jiadi.jjd@antgroup.com>

[33mcommit 869579a702cb086cca6bd6ec4500f954a9adec1c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jan 8 01:04:28 2025 +0800

    [optimization] remove python function call for custom op (#11750)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit c0efe92d8b9ef968a5b796fd7d6ebc426d78e726[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jan 7 21:50:58 2025 +0800

    [Doc] Add note to `gte-Qwen2` models (#11808)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit d9fa1c05ad7149a43051a283d0cbeeb65bf6b4a3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jan 7 21:42:58 2025 +0800

    [doc] update how pip can install nightly wheels (#11806)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 2de197bdd4b82a004ff99806d054dce1d93b3ced[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jan 7 03:47:36 2025 -0800

    [V1] Support audio language models on V1 (#11733)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 869e829b853cc35747c5e4bc9d773a4cff704d12[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jan 7 18:41:17 2025 +0800

    [doc] add doc to explain how to use uv (#11773)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 8f37be38ebfe0295a4925837c501c87149997a4d[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jan 7 18:25:02 2025 +0800

    [Bugfix] Comprehensively test and fix LLaVA-NeXT feature size calculation (#11800)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 8082ad7950ad96fdc15e6b5a42e8098dd7087f6f[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jan 7 01:55:39 2025 -0800

    [V1][Doc] Update V1 support for `LLaVa-NeXT-Video` (#11798)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 1e4ce295ae70771f8e0eaa50962b3dda29c3f0d6[m
Author: Yuan <yuan.zhou@intel.com>
Date:   Tue Jan 7 15:28:01 2025 +0800

    [CI][CPU] adding build number to docker image name (#11788)
    
    Signed-off-by: Yuan Zhou <yuan.zhou@intel.com>

[33mcommit ce1917fcf211458dfbe6bb86d6a9d2d9bd346e63[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Jan 7 01:57:32 2025 -0500

    [Doc] Create a vulnerability management team (#9925)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit e512f76a898d61b8857b36b138bb9cf93ea04d03[m
Author: XiaobingZhang <xiaobingzhangupc@gmail.com>
Date:   Tue Jan 7 14:12:48 2025 +0800

    fix init error for MessageQueue when n_local_reader is zero (#11768)

[33mcommit 898cdf033e31dc28042f7181b1565c78d905196e[m
Author: Liangfu Chen <liangfc@amazon.com>
Date:   Mon Jan 6 21:36:10 2025 -0800

    [CI] Fix neuron CI and run offline tests (#11779)
    
    Signed-off-by: Liangfu Chen <liangfc@amazon.com>

[33mcommit 0f3f3c86ec44467fa80b60cb9f971f9ede028f76[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jan 6 20:36:24 2025 -0800

    [Bugfix] Update attention interface in `Whisper` (#11784)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit b278557935d78b337fb5e82a32b02f75678b4101[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Jan 7 12:01:39 2025 +0800

    [Kernel][LoRA]Punica prefill  kernels fusion (#11234)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Signed-off-by: Abatom <abzhonghua@gmail.com>
    Co-authored-by: Zhonghua Deng <abatom@163.com>

[33mcommit 8ceffbf3152d3b26d293ba1e157d0c187884572b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jan 7 11:20:01 2025 +0800

    [Doc][3/N] Reorganize Serving section (#11766)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit d93d2d74fd807a091add17c2065ee8869339f76a[m
Author: YiSheng5 <yi.sheng@intel.com>
Date:   Tue Jan 7 11:09:58 2025 +0800

    [XPU] Make pp group initilized for pipeline-parallelism (#11648)
    
    Signed-off-by: yisheng <yi.sheng@intel.com>

[33mcommit d0169e1b0fa44a80ba40baf92dd2cedd3611076b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jan 7 11:05:17 2025 +0800

    [Model] Future-proof Qwen2-Audio multi-modal processor (#11776)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 08fb75c72e39dcb4f0751dc59583b95bda4d3656[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jan 7 09:10:54 2025 +0800

    [Bugfix] Fix LLaVA-NeXT feature size precision error (for real) (#11772)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 91b361ae898c944f823534121613f9d3dc19d7d1[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jan 6 11:58:16 2025 -0800

    [V1] Extend beyond image modality and support mixed-modality inference with Llava-OneVision (#11685)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit e20c92bb618384ce8d0013e0c9ad273d0c23d65b[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Tue Jan 7 00:11:28 2025 +0800

    [Kernel] Move attn_type to Attention.__init__() (#11690)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit 32c9eff2fff8ee91a60c9410c69042dc4c1cc5c8[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Mon Jan 6 23:22:25 2025 +0800

    [Bugfix][V1] Fix molmo text-only inputs (#11676)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 4ca5d40adc53aca2a1fbaed81d9d622fde46ebf1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jan 6 21:57:44 2025 +0800

    [doc] explain how to add interleaving sliding window support (#11771)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 9279b9f83dd3aa5bb3d3ce57bf92d9361755d164[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jan 6 05:48:53 2025 -0800

    [Bugfix] Fix max image size for LLaVA-Onevision (#11769)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit ee77fdb5de42a6fead2b897d87d99d4b1e5650a9[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jan 6 21:40:31 2025 +0800

    [Doc][2/N] Reorganize Models and Usage sections (#11755)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 996357e4808ca5eab97d4c97c7d25b3073f46aab[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jan 6 16:02:21 2025 +0800

    [VLM] Separate out profiling-related logic (#11746)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 2a622d704a4270c8d6fab057e8a545ed86ac35b7[m
Author: Suraj Deshmukh <surajd.service@gmail.com>
Date:   Mon Jan 6 00:01:22 2025 -0800

    k8s-config: Update the secret to use stringData (#11679)
    
    Signed-off-by: Suraj Deshmukh <surajd.service@gmail.com>

[33mcommit 9c749713f6990a9f9d12e526d9bfc2669dfa8ee6[m
Author: Lucas Tucker <47258766+lucas-tucker@users.noreply.github.com>
Date:   Mon Jan 6 01:59:36 2025 -0600

    [mypy] Forward pass function type hints in lora (#11740)
    
    Signed-off-by: lucast2021 <lucast2021@headroyce.org>
    Co-authored-by: lucast2021 <lucast2021@headroyce.org>

[33mcommit 022c5c6944bcf28ac4d0d28ce14f2b559358be52[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Sun Jan 5 23:59:16 2025 -0800

    [V1] Refactor get_executor_cls (#11754)

[33mcommit f8fcca100beada88136944976da88f47f363acab[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Sun Jan 5 23:12:38 2025 -0800

    [Misc] Fix typo for valid_tool_parses  (#11753)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit 06bfb51963953d6ae31b87965bfb91b6eca4fd24[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jan 6 14:24:42 2025 +0900

    [V1] Add BlockTable class (#11693)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 408e5600158bfa34306cfbd034a3779e488752fa[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Sun Jan 5 20:49:55 2025 -0800

    [Bugfix] Remove block size constraint (#11723)

[33mcommit 402d37836059463c7ec8b1e25d40c29138f1dd40[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jan 6 10:18:33 2025 +0800

    [Doc] [1/N] Reorganize Getting Started section (#11645)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 9e764e7b105a483ebc702cad33922ba8d8c210e1[m
Author: cennn <61925104+cennn@users.noreply.github.com>
Date:   Mon Jan 6 09:05:48 2025 +0800

    [distributed] remove pynccl's redundant change_state (#11749)

[33mcommit 33fc1e2e86ce5d60940463f8f71daaa61728d3b7[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Jan 5 16:35:01 2025 -0500

    [Frontend] Improve `StreamingResponse` Exception Handling (#11752)

[33mcommit eba17173d34548a39989eae2530dce53496a1f3d[m
Author: Lancer <402430575@qq.com>
Date:   Mon Jan 6 00:48:16 2025 +0800

    fix: [doc] fix typo (#11751)
    
    Co-authored-by: Lancer <maruixiang6688@gmail.com>

[33mcommit 635b897246da121238454ed4b2bbc87cb4d4166b[m
Author: cennn <61925104+cennn@users.noreply.github.com>
Date:   Sun Jan 5 23:09:11 2025 +0800

    [distributed] remove pynccl's redundant stream (#11744)

[33mcommit 4068f4b5b5dc5e2d1114be0cbb126bc44fb4e906[m
Author: Lu Fang <30275821+houseroad@users.noreply.github.com>
Date:   Sat Jan 4 17:20:34 2025 -0800

    [MISC] Replace c10::optional with std::optional (#11730)
    
    Signed-off-by: Lu Fang <lufang@fb.com>

[33mcommit 47831430cc943cd470d38d27f8c69a5782795ec3[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Jan 5 00:07:59 2025 +0800

    [Bugfix][V1] Fix test_kv_cache_utils.py (#11738)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 65c08928c2db934b18f7c6f5eeb02617826fae8e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jan 4 23:46:21 2025 +0800

    [Model] Remove unnecessary weight initialization logic (#11736)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit ba214dffbeec070051b61c1985ce6342c947f598[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jan 4 23:45:57 2025 +0800

    [Bugfix] Fix precision error in LLaVA-NeXT (#11735)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit eed11ebee93e9d137ac74d8e6e97427354bd3797[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jan 4 19:40:53 2025 +0800

    [VLM] Merged multi-modal processors for LLaVA-NeXT-Video and LLaVA-OneVision (#11717)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 300acb83472512b14ec7ba8cdf45efe07e8c8f68[m
Author: Yan Burman <yanburman@users.noreply.github.com>
Date:   Sat Jan 4 08:50:16 2025 +0200

    [Core][Bugfix] Use correct device to initialize GPU data during CUDA-graph-capture (#11233)
    
    Signed-off-by: Yan Burman <yanburman@users.noreply.github.com>
    Signed-off-by: Ido Asraff <idoa@atero.ai>

[33mcommit d91457d529c2df5d66bdfd939b90b7c75a9729b8[m
Author: xcnick <xcnick0412@gmail.com>
Date:   Sat Jan 4 14:49:46 2025 +0800

    [V1] Add kv cache utils tests. (#11513)
    
    Signed-off-by: xcnick <xcnick0412@gmail.com>

[33mcommit fbf25645542fdcfb3f1a27ba05486492e368925c[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Sat Jan 4 14:41:31 2025 +0800

    [V1] Add `RayExecutor` support for `AsyncLLM` (api server) (#11712)

[33mcommit d1d49397e7f8d1ac472d763dae395b67fdda1ef8[m
Author: Alberto Ferrer <albertof@barrahome.org>
Date:   Sat Jan 4 00:29:02 2025 -0600

    Update bnb.md with example for OpenAI (#11718)

[33mcommit 9c93636d84414591ae4d7b9c1174af7e91052fd8[m
Author: Hust_YangXian <bryceyx@gmail.com>
Date:   Sat Jan 4 14:16:30 2025 +0800

    Update tool_calling.md (#11701)

[33mcommit e5d7ed0c5374d38e75a8ef0243cc348f0f6f9185[m
Author: WangErXiao <863579016@qq.com>
Date:   Sat Jan 4 08:13:12 2025 +0800

    [V1] log GPU blocks num for MultiprocExecutor (#11656)

[33mcommit ad0d567e1cdc77aff435b20bac918bfd0f55db0a[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jan 3 18:25:02 2025 -0500

    [V1] Chore: cruft removal (#11724)

[33mcommit bf0d97d78619b290ed273199ad3800b57b638603[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Jan 3 17:36:46 2025 -0500

    Update requirements-tpu.txt to support python 3.9 and 3.11 (#11695)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit a655eb30252fe266ce16fde2aa9f8f9554ccd46e[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sat Jan 4 06:19:02 2025 +0800

    [Misc]Add BNB quantization for Qwen2VL (#11719)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 1543914c04697fb252e4468b7c9d14be512b050a[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jan 3 16:29:11 2025 -0500

    [V1] Improve TP>1 Error Handling + Stack Trace (#11721)
    
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 61fed92c7e646d6f2ec5d9de54568a860870e6a4[m
Author: ZincCat <52513999+zinccat@users.noreply.github.com>
Date:   Fri Jan 3 13:02:34 2025 -0800

    [Bugfix] Fix ColumnParallelLinearWithLoRA slice (#11708)
    
    Signed-off-by: ZincCat <zincchloride@outlook.com>

[33mcommit 80c751e7f68ade3d4c6391a0f3fce9ce970ddad0[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jan 3 12:25:38 2025 -0500

    [V1] Simplify Shutdown (#11659)

[33mcommit e1a5c2f0a123835558b1b1c9895181161527c55e[m
Author: Aurick Qiao <aurickq@users.noreply.github.com>
Date:   Fri Jan 3 03:39:19 2025 -0500

    [Model] Whisper model implementation (#11280)
    
    Co-authored-by: Aurick Qiao <aurick.qiao@snowflake.com>

[33mcommit fd3a62a122fcbc9331d000b325e72687629ef1bd[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Fri Jan 3 13:38:37 2025 +0700

    [perf-benchmark] Fix dependency for steps in benchmark pipeline (#11710)

[33mcommit 07064cb1d49d2b04ec58d8876bee2cd8281eedf5[m
Author: Lu Fang <30275821+houseroad@users.noreply.github.com>
Date:   Thu Jan 2 16:58:56 2025 -0800

    [Bugfix] Check chain_speculative_sampling before calling it (#11673)
    
    Signed-off-by: Lu Fang <lufang@fb.com>

[33mcommit 2f1e8e8f54032e38998e90427aedf649c0beee39[m
Author: Sachin Varghese <sachin.mathew31@gmail.com>
Date:   Thu Jan 2 19:25:53 2025 -0500

    Update default max_num_batch_tokens for chunked prefill (#11694)

[33mcommit 68d37809b9b52f4d012fa0dfbb187f0fe978bdbc[m
Author: Nathan Azrak <42650258+nathan-az@users.noreply.github.com>
Date:   Fri Jan 3 10:59:25 2025 +1100

    [Misc] Minimum requirements for SageMaker compatibility (#11576)

[33mcommit 5dba2575065f5e27d468f2776e3d460a21d916e6[m
Author: wchen61 <wchen61@foxmail.com>
Date:   Fri Jan 3 06:58:56 2025 +0800

    Resolve race conditions in Marlin kernel (#11493)
    
    Signed-off-by: wchen61 <wchen61@foxmail.com>

[33mcommit 187e32997cdc20bbed5c21d3cef2609ab8ed9080[m
Author: bjmsong <wq.songbob@gmail.com>
Date:   Fri Jan 3 05:11:39 2025 +0800

    [Bugfix] Change kv scaling factor by param json on nvidia gpu (#11688)
    
    Signed-off-by: bjmsong <bjmsong@126.com>
    Co-authored-by: bjmsong <bjmsong@126.com>

[33mcommit b55ed6ef8ab0dce7fb0f79ff292dafdb4d22610c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jan 3 04:04:58 2025 +0900

    [V1][Minor] Optimize token_ids_cpu copy (#11692)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 2f385183f35497e030ef22c9820d83b83bc4f6db[m
Author: Kathy Yu <143133934+kathyyu-google@users.noreply.github.com>
Date:   Thu Jan 2 10:28:09 2025 -0800

    [Bugfix] Free cross attention block table for preempted-for-recompute sequence group. (#10013)
    
    Signed-off-by: Kathy Yu <feiyangyu@google.com>

[33mcommit 84c35c374a8fd3d10559ef220793fea6c5497cf2[m
Author: Chunyang Wen <chunyang.wen@gmail.com>
Date:   Fri Jan 3 02:14:16 2025 +0800

    According to vllm.EngineArgs, the name should be distributed_executor_backend (#11689)

[33mcommit 8c38ee7007c50ac5aef9ed43ae91c6f031799c40[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jan 3 00:39:27 2025 +0800

    [VLM] Merged multi-modal processor for LLaVA-NeXT (#11682)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit b6087a6beead9165f4c77ceba592b3651bb37de9[m
Author: Tobias Pitters <31857876+CloseChoice@users.noreply.github.com>
Date:   Thu Jan 2 17:18:15 2025 +0100

    [mypy] Pass type checking in vllm/inputs (#11680)
    
    Signed-off-by: Tobias Pitters <tobias.pitters@gmail.com>

[33mcommit 23c1b10a4c8cd77c5b13afa9242d67ffd055296b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jan 2 17:00:00 2025 +0800

    [VLM][Bugfix] Multi-modal processor compatible with V1 multi-input (#11674)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit a115ac46b5be22289dec975c2c06653b22cd6315[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 1 23:44:42 2025 +0800

    [VLM] Move supported limits and max tokens to merged multi-modal processor (#11669)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 73001445fbfc42d386d68066519738dfffa62df3[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jan 1 21:56:46 2025 +0900

    [V1] Implement Cascade Attention (#11635)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 6d70198b17b008f5b845582590b96a507b4d68b5[m
Author: Kazuhiro Serizawa <nserihiro@gmail.com>
Date:   Wed Jan 1 17:10:10 2025 +0900

    [Doc] Fix typo (#11666)
    
    Signed-off-by: Kazuhiro Serizawa <nserihiro@gmail.com>

[33mcommit f962f426bc63b66301da61d2ac7078bf0ba941b0[m
Author: Lu Fang <30275821+houseroad@users.noreply.github.com>
Date:   Tue Dec 31 23:39:30 2024 -0800

    [Misc] Replace space with - in the file names (#11667)
    
    Signed-off-by: Lu Fang <lufang@fb.com>

[33mcommit 11d8a091c6c775575a53d37408c94faa0b07730f[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Jan 1 14:42:23 2025 +0800

    [Misc] Optimize Qwen2-VL LoRA test (#11663)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 365801feddaf5c4448704a1f55269dd992f5a4b1[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jan 1 14:15:21 2025 +0800

    [VLM] Add max-count checking in data parser for single image models (#11661)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 4db72e57f6e8da5e78285e9868e9327167bea973[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Tue Dec 31 18:21:51 2024 -0800

    [Bugfix][Refactor] Unify model management in frontend (#11660)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 0c6f9985547d6b510d34c6c873db54abe03eb346[m
Author: Yihua Cheng <yihua98@uchicago.edu>
Date:   Tue Dec 31 18:10:55 2024 -0600

    [Benchmark] Add benchmark script for CPU offloading  (#11533)
    
    Signed-off-by: ApostaC <yihua98@uchicago.edu>
    Co-authored-by: KuntaiDu <kuntai@uchicago.edu>

[33mcommit e7c7c5e822a886e3dba202ca1b756c3260efffcc[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Dec 31 13:17:22 2024 -0800

    [V1][VLM] V1 support for selected single-image models. (#11632)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 8c3230d8c1cf114618c2316c54bf06b7d0c198b6[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Tue Dec 31 16:56:01 2024 +0800

    [V1] Simpify vision block hash for prefix caching by removing offset from hash (#11646)

[33mcommit 2c5718809bb5f4bce2ae8e05041d613215dac1aa[m
Author: sakunkun <zhou.qianjun@zte.com.cn>
Date:   Tue Dec 31 14:29:04 2024 +0800

    [Bugfix] Move the _touch(computed_blocks) call in the allocate_slots method to after the check for allocating new blocks. (#11565)

[33mcommit 82c49d3260f1fb9fcd686736e8439dc69cd2f1c4[m
Author: John Giorgi <johnmgiorgi@gmail.com>
Date:   Tue Dec 31 01:15:58 2024 -0500

    [Misc][LoRA] Support Rank Stabilized LoRA (RSLoRA) (#6909)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 74fa1d123c2818065d862d2ceb2338468914fa79[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Dec 30 22:43:54 2024 -0500

    [Bugfix] Fix OpenAI parallel sampling when using xgrammar (#11637)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit a2a40bcd0d8275e19c46e9cc06ee994d8839b98d[m
Author: Matthias Vogler <60004995+ayylemao@users.noreply.github.com>
Date:   Tue Dec 31 02:33:06 2024 +0100

    [Model][LoRA]LoRA support added for MolmoForCausalLM (#11439)
    
    Signed-off-by: Matthias Vogler <matthias.vogler@joesecurity.org>
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: Matthias Vogler <matthias.vogler@joesecurity.org>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit ccb1aabccaa7aaf07b08fd8be30380e828efba0f[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Dec 30 12:27:07 2024 -0800

    [benchmark] Remove dependency for H100 benchmark step (#11572)

[33mcommit 36e76700453924c8d421db99af70a88a1df835cd[m
Author: whyiug <whyiug@hotmail.com>
Date:   Tue Dec 31 02:51:04 2024 +0800

    [Bugfix] Validate and concatenate image embeddings in MiniCPMVBaseModel (#11631)

[33mcommit 5886aa496e8fa31c9180bcfc8e89faaa8899907d[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Mon Dec 30 10:51:02 2024 -0500

    [V1] [6/N] API Server: Better Shutdown (#11586)

[33mcommit 8d9b6721e7f5b7d191951c6f1cd12710ffd08093[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Dec 30 23:01:35 2024 +0800

    [VLM] Abstract out multi-modal data parsing in merged processor (#11620)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit b12e87f942eb7740c17ab546b964bc327afdda37[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 30 20:24:45 2024 +0800

    [platforms] enable platform plugins (#11602)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 5dbf854553cb6ac97f0c633ed36ba64e0fc9bb29[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Mon Dec 30 18:17:04 2024 +0800

    [CI/Build][CPU] Fix CPU CI by lazy importing triton FP8 kernels (#11618)
    
    Signed-off-by: jiang1.li <jiang1.li@intel.com>

[33mcommit 970d6d0776076f17604077ba4d484cdadd604ceb[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Dec 30 04:22:13 2024 -0500

    [Build][Kernel] Update CUTLASS to v3.6.0 (#11607)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 628ec6c17b8121517e8f303b64567573036cdb38[m
Author: Liangfu Chen <liangfc@amazon.com>
Date:   Sun Dec 29 21:46:14 2024 -0800

    [Docker] bump up neuron sdk v2.21 (#11593)
    
    Signed-off-by: Liangfu Chen <liangfc@amazon.com>

[33mcommit 3682e33f9ff9d8baade6112a8e75a77da898f504[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 30 12:24:12 2024 +0800

    [v1] fix compilation cache (#11598)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 0aa38d16f56327622c1689d7510171662757deee[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sun Dec 29 15:16:46 2024 -0500

    Remove print statement in DeepseekScalingRotaryEmbedding (#11604)

[33mcommit faef77c0d69c5429182f475a57127676e6bcb230[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Sun Dec 29 10:08:09 2024 -0600

    [Misc] KV cache transfer connector registry (#11481)
    
    Signed-off-by: KuntaiDu <kuntai@uchicago.edu>

[33mcommit dba4d9dec606da028fbb28240e99cabd5a761e6a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Dec 29 17:03:49 2024 +0800

    [v1][bugfix] fix cudagraph with inplace buffer assignment (#11596)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 32b4c63f02b2ab28a49a040b1d170a903a5cd9dc[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Dec 29 15:56:22 2024 +0800

    [Doc] Convert list tables to MyST (#11594)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 4fb8e329fd6f51d576bcf4b7e8907e0d83c4b5cf[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Dec 28 15:51:57 2024 -0500

    [V1] [5/N] API Server: unify `Detokenizer` and  `EngineCore` input (#11545)
    
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>

[33mcommit 328841d00294fb8226f0368cc380350b3d671d77[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Dec 29 00:55:42 2024 +0800

    [bugfix] interleaving sliding window for cohere2 model (#11583)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d427e5cfda8d2536b81e6021128e71b2dbc281aa[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Dec 28 21:53:59 2024 +0800

    [Doc] Minor documentation fixes (#11580)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 42bb201fd6f79d6ed2e28e0263ffa891cd993c4c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Dec 28 22:33:12 2024 +0900

    [V1][Minor] Set pin_memory=False for token_ids_cpu tensor (#11581)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 59d6bb4c863e511e58799efac847065c28c52c8b[m
Author: hj-wei <hjwei_xd@163.com>
Date:   Sat Dec 28 19:17:35 2024 +0800

    [Hardware][AMD]: Replace HIPCC version with more precise ROCm version (#11515)
    
    Signed-off-by: hjwei <hjwei_xd@163.com>

[33mcommit b7dcc003dc1ace7605946d52b7e077ba1d3bbe86[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Dec 28 02:54:23 2024 -0800

    [Model] Remove hardcoded image tokens ids from Pixtral (#11582)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit d34be24bb196cb0cce167257c97449f0cd6858f7[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sat Dec 28 14:14:10 2024 +0800

    [Model] Support InternLM2 Reward models (#11571)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit b5cbe8eeb30e86c8477d91c66f5c7a10e4ee754b[m
Author: Rajveer Bachkaniwala <46040700+rajveerb@users.noreply.github.com>
Date:   Fri Dec 27 22:34:46 2024 -0500

    [Bugfix] Last token measurement fix (#11376)
    
    Signed-off-by: rajveerb <46040700+rajveerb@users.noreply.github.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit df04dffade84c87cafd74de4c39e6fd7cb95c24f[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Dec 27 20:45:08 2024 -0500

    [V1] [4/N] API Server: ZMQ/MP Utilities (#11541)

[33mcommit a60731247fba82fae5e71af7a19ea0df96de1caa[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Sat Dec 28 08:31:10 2024 +0800

    [Doc] Update mllama example based on official doc (#11567)
    
    Signed-off-by: Chen Zhang <zhangch99@outlook.com>

[33mcommit ac797994039ba9e6ed0c2b3a503099cb122a936e[m
Author: Selali <selali.adobor@gmail.com>
Date:   Fri Dec 27 12:12:11 2024 -0800

    [Bugfix] Fix for ROCM compressed tensor support (#11561)

[33mcommit dde1fa18c9f9ba992a8300a300543d6c18d5f08d[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sat Dec 28 03:45:13 2024 +0800

    [Misc] Improve BNB loader to handle mixture of sharded and merged weights with same suffix (#11566)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 0240402c4632604c9cd02f7eae4ae36fa990b38f[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sat Dec 28 02:48:24 2024 +0800

    [Misc]Add BNB quantization for MolmoForCausalLM  (#11551)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 55509c2114718c1292c11348f002461ba44cb23b[m
Author: ErezSC42 <erezs@ai21.com>
Date:   Fri Dec 27 19:58:21 2024 +0200

    [MODEL] LoRA support for Jamba model (#11209)
    
    Signed-off-by: Erez Schwartz <erezs@ai21.com>

[33mcommit 101418096ffe3c83b6d541e1303b10e9d5e03861[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Dec 28 01:22:48 2024 +0800

    [VLM] Support caching in merged multi-modal processor (#11396)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 5ce4627a7ec4cf4e19ff4be7f030883ef486393f[m
Author: Chen1022 <112855051+ccjincong@users.noreply.github.com>
Date:   Fri Dec 27 21:05:10 2024 +0800

    [Doc]  Add xgrammar in doc (#11549)
    
    Signed-off-by: ccjincong <chenjincong11@gmail.com>

[33mcommit 7af553ea30031446b4c1c74ad83187f9fd3de4e7[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Dec 27 19:21:23 2024 +0800

    [Misc] Abstract the logic for reading and writing media content (#11527)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 2c9b8ea2b006e763b8268b8ab02181c9822cfe76[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Fri Dec 27 18:39:15 2024 +0800

    [Bugfix] Fix TeleChat2ForCausalLM weights mapper (#11546)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit d003f3ea391b4c879f6f848dd485dd3c04fa6ca9[m
Author: AlexHe99 <alehe@amd.com>
Date:   Fri Dec 27 18:00:04 2024 +0800

    Update deploying_with_k8s.md with AMD ROCm GPU example (#11465)
    
    Signed-off-by: Alex He <alehe@amd.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 6c6f7fe8a850ca08f9a8774de020163a2a7c2164[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Fri Dec 27 16:45:25 2024 +0800

    [Platform] Move model arch check to platform (#11503)
    
    Signed-off-by: Mengqing Cao <cmq0113@163.com>

[33mcommit 2339d59f9260499599d60599f83978fad1827999[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Dec 27 01:23:29 2024 -0500

    [BugFix] Fix quantization for all other methods (#11547)

[33mcommit 1b875a0ef3767a7da7507943f46e4a53d3f552c9[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Dec 27 00:19:21 2024 -0500

    [V1][3/N] API Server: Reduce Task Switching + Handle Abort Properly (#11534)

[33mcommit eb881ed006ca458b052905e33f0d16dbb428063a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Dec 27 11:05:08 2024 +0800

    [misc] fix typing (#11540)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 46d4359450cd194ab2a4f2fdc370ff4b33a188e2[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Dec 26 21:49:16 2024 -0500

    [CI] Fix broken CI (#11543)

[33mcommit 81b979f2a8f7ec91c262dac7dcbf30ed577ebafd[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Dec 27 09:47:10 2024 +0900

    [V1] Fix yapf (#11538)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 371d04d39bf056e4cc56100c83d4812b7cb230e4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Dec 27 09:32:38 2024 +0900

    [V1] Use FlashInfer Sampling Kernel for Top-P & Top-K Sampling (#11394)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 0c0c2015c526f1fe6f86fdd8d6bd99a935d2d275[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Dec 26 19:26:18 2024 -0500

    Update openai_compatible_server.md (#11536)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 82d24f7aacf79bbccb6413333dff6303fbbb44b9[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Dec 26 16:21:56 2024 -0800

    [Docs] Document Deepseek V3 support (#11535)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit f49777ba62b4926d0f8c100ab06edb03c5c10098[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Dec 26 16:09:44 2024 -0800

    Deepseek v3 (#11502)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: robertgshaw2-neuralmagic <rshaw@neuralmagic.com>

[33mcommit 55fb97f7bd61273fe8464a72866a72eaa88b5759[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Dec 26 18:43:05 2024 -0500

    [2/N] API Server: Avoid ulimit footgun (#11530)

[33mcommit 2072924d1480460d3b3578a4548c2bffe33fe1c3[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Dec 26 18:33:30 2024 -0500

    [Model] [Quantization] Support deepseek_v3 w8a8 fp8 block-wise quantization (#11523)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Signed-off-by: simon-mo <simon.mo@hey.com>
    Signed-off-by: simon-mo <xmo@berkeley.edu>
    Co-authored-by: simon-mo <simon.mo@hey.com>
    Co-authored-by: simon-mo <xmo@berkeley.edu>
    Co-authored-by: HandH1998 <1335248067@qq.com>

[33mcommit 720b10fdc6891b2540fce172b63eb07c1ba48958[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Dec 26 18:03:43 2024 -0500

    [1/N] API Server  (Remove Proxy) (#11529)

[33mcommit b85a977822c4216430c5a27a2fc47c93277e4b29[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Dec 27 01:31:29 2024 +0800

    [Doc] Add video example to openai client for multimodal (#11521)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit eec906d8114cd786315e49ab7f5a3093d1896880[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Dec 26 21:12:51 2024 +0800

    [Misc] Add placeholder module (#11501)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit f57ee5650dd402c6147980824c6936c96cfa59fe[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Dec 26 21:12:05 2024 +0800

    [Model]  Modify MolmoForCausalLM MLP  (#11510)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit dcb1a944d4cf95b4a7b3522ddf970e6d3a28b8b5[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Thu Dec 26 02:02:58 2024 -0800

    [V1] Adding min tokens/repetition/presence/frequence penalties to V1 sampler (#10681)
    
    Signed-off-by: Sourashis Roy <sroy@roblox.com>
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 7492a362077ace26b4f0374a39ba5b0846962b87[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Dec 26 01:44:32 2024 -0800

    [Doc] Add `QVQ` and `QwQ` to the list of supported models (#11509)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit aa25985bd1e7a4925a7061fdfbc93893b492627b[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Dec 26 15:52:48 2024 +0800

    [Misc][LoRA] Fix LoRA weight mapper (#11495)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit dbeac95dbbf898bcc0965528fc767e9cadbbe0c5[m
Author: Lucas Tucker <47258766+lucas-tucker@users.noreply.github.com>
Date:   Wed Dec 25 23:04:07 2024 -0600

    Mypy checking for vllm/compilation (#11496)
    
    Signed-off-by: lucast2021 <lucast2021@headroyce.org>
    Co-authored-by: lucast2021 <lucast2021@headroyce.org>

[33mcommit 51a624bf024e351e678b598521b72a2e19b5e2ef[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Dec 26 12:23:20 2024 +0800

    [Misc] Move some multimodal utils to modality-specific modules (#11494)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 6ad909fdda54f91379bbee7590a37e38600b6204[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Dec 26 06:49:26 2024 +0800

    [Doc] Improve GitHub links (#11491)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit b689ada91e381ac8a1b197b5a52d7f1fa32fac05[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Dec 26 00:33:55 2024 +0800

    [Frontend] Enable decord to load video from base64 (#11492)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit fc601665eb372d0dce9a873ea94eebf2ff5b1d27[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Tue Dec 24 22:58:48 2024 -0800

    [Misc] Update disaggregation benchmark scripts and test logs (#11456)
    
    Signed-off-by: Jiaxin Shan <seedjeffwan@gmail.com>

[33mcommit 9832e5572a602967beac0ccb8a4eb65bc18478a3[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Tue Dec 24 19:49:46 2024 -0800

    [V1] Unify VLLM_ENABLE_V1_MULTIPROCESSING handling in RayExecutor (#11472)

[33mcommit 3f3e92e1f2e332547f7d4bac2358bc4e8e5d018b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Dec 25 02:22:22 2024 +0800

    [Model] Automatic conversion of classification and reward models (#11469)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 409475a827795000301f0d27582befab0563888b[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Tue Dec 24 11:53:28 2024 -0500

    [Bugfix] Fix issues in CPU build Dockerfile. Fixes #9182 (#11435)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit 196c34b0acdd19014feb6c065c324036407f3b36[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Dec 24 21:05:25 2024 +0800

    [Misc] Move weights mapper (#11443)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 5c7963249daf0b57e803605079e8869e8b071247[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Tue Dec 24 20:39:36 2024 +0800

    [attn][tiny fix] fix attn backend in MultiHeadAttention (#11463)
    
    Signed-off-by: Mengqing Cao <cmq0113@163.com>

[33mcommit 461cde20801eb77be32227e0f23d43a6a1299b48[m
Author: Ilya Lavrenov <ilya.lavrenov@intel.com>
Date:   Tue Dec 24 15:38:21 2024 +0400

    [OpenVINO] Fixed installation conflicts (#11458)
    
    Signed-off-by: Ilya Lavrenov <ilya.lavrenov@intel.com>

[33mcommit 7a5286cc047112c7cc52bad8da8c17aedc880ef5[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Tue Dec 24 17:59:51 2024 +0800

    [Bugfix][Hardware][CPU] Fix CPU `input_positions` creation for text-only inputs with mrope (#11434)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit b1b1038fbdc1f14b32c5e348194aae395124b43c[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Dec 24 17:56:10 2024 +0800

    [Bugfix] Fix Qwen2-VL LoRA weight loading  (#11430)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 9edca6bf8fa81e2dc678be68e9cdcede572947c1[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Dec 24 17:54:30 2024 +0800

    [Frontend] Online Pooling API (#11457)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 4f074fbf53f9e11a57a4c3d8b084796d155a270a[m
Author: dpxa <shiquan1988@gmail.com>
Date:   Tue Dec 24 16:43:39 2024 +0800

    [Misc]Suppress irrelevant exception stack trace information when CUDA‚Ä¶ (#11438)
    
    Co-authored-by: shiquan <shiquan>

[33mcommit a491d6f535d96939d17e5290991dc975495c9580[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Mon Dec 23 15:00:12 2024 -0800

    [V1] TP Ray executor (#11107)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit 32aa2059addd97be1afce7a199d228191710c294[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Mon Dec 23 17:35:38 2024 -0500

    [Docs] Convert rST to MyST (Markdown) (#11145)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit 94d545a1a18e20ea8763a6760194589b8a3c9065[m
Author: yansh97 <yansh97@foxmail.com>
Date:   Tue Dec 24 04:20:44 2024 +0800

    [Doc] Fix typo in the help message of '--guided-decoding-backend' (#11440)

[33mcommit 60fb4f3bcfce9c84e09ba61e4b59bb1abe19953d[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Dec 23 14:30:45 2024 -0500

    [Bugfix] Add kv cache scales to gemma2.py (#11269)

[33mcommit 63afbe9215813780e0327e31072c4292bd99e46b[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Dec 23 13:35:38 2024 -0500

    [CI] Expand OpenAI test_chat.py guided decoding tests (#11048)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 8cef6e02dcba8a1fa680cd130222bd3d47d54796[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Mon Dec 23 13:33:20 2024 -0500

    [Misc] add w8a8 asym models (#11075)

[33mcommit b866cdbd05b13e0c0ab349efc6fca834fbe21760[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Mon Dec 23 13:23:38 2024 -0500

    [Misc] Add assertion and helpful message for marlin24 compressed models (#11388)

[33mcommit 2e726680b386a06dfac1144853fd58964da3914f[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Mon Dec 23 12:20:22 2024 -0500

    [Bugfix] torch nightly version in ROCm installation guide (#11423)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit 5bfb30a529283f7d9a8baa6715ab3bfef204cddd[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Dec 23 10:06:20 2024 -0500

    [Bugfix] Fix CFGGuide and use outlines for grammars that can't convert to GBNF (#11389)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit e51719ae72dd1dcdf55436a99ac8bed245b51422[m
Author: Lucas Tucker <47258766+lucas-tucker@users.noreply.github.com>
Date:   Mon Dec 23 07:55:49 2024 -0600

    mypy type checking for vllm/worker (#11418)
    
    Signed-off-by: lucast2021 <lucast2021@headroyce.org>
    Co-authored-by: lucast2021 <lucast2021@headroyce.org>

[33mcommit f30581c51831b74795cb55419b2fffc928cfd7d2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 23 00:01:08 2024 -0800

    [misc][perf] remove old code (#11425)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 048fc57a0fb599a3e39bbc9228432b0d1bb9e88d[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Dec 22 14:17:43 2024 -0800

    [CI] Unboock H100 Benchmark (#11419)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit f1d1bf6288abfe051ec4ad891c5a96575e347bfc[m
Author: Jason T. Greene <jason@stacksmash.com>
Date:   Sun Dec 22 09:25:10 2024 -0600

    [Bugfix] Fix fully sharded LoRAs with Mixtral (#11390)
    
    Signed-off-by: Jason Greene <jason.greene@redhat.com>

[33mcommit 72d9c316d3f6ede485146fe5aabd4e61dbc59069[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Dec 22 00:39:11 2024 -0800

    [cd][release] fix race conditions (#11407)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 4a9139780ad78a648415f07dd7a5a216fb3f96ab[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Dec 21 23:53:44 2024 -0800

    [cd][release] add pypi index for every commit and nightly build (#11404)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit 29c748930e0d35a98351a8cf8a093fba4b758114[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Dec 21 21:08:44 2024 -0800

    [CI] Fix flaky entrypoint tests (#11403)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit c2d1b075ba88271ccc23b981c223a0617afc6bfc[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Dec 21 02:15:03 2024 -0800

    [Bugfix] Fix issues for `Pixtral-Large-Instruct-2411` (#11393)
    
    Signed-off-by: ywang96 <ywang@example.com>
    Co-authored-by: ywang96 <ywang@example.com>

[33mcommit 584f0ae40d6f64a7097525f04feb236e94ad37fd[m
Author: Ricky Xu <xuchen727@hotmail.com>
Date:   Fri Dec 20 23:14:08 2024 -0800

    [V1] Make AsyncLLMEngine v1-v0 opaque (#11383)
    
    Signed-off-by: Ricky Xu <xuchen727@hotmail.com>

[33mcommit 51ff216d851ba2457a601b47a2a3f19b47f80940[m
Author: George <george@neuralmagic.com>
Date:   Sat Dec 21 01:36:23 2024 -0500

    [Bugfix] update should_ignore_layer (#11354)
    
    Signed-off-by: George Ohashi <george@neuralmagic.com>

[33mcommit dd2b5633dd5fb0ecb5fb7247351ebedc1d69d054[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Dec 21 14:22:21 2024 +0900

    [V1][Bugfix] Skip hashing empty or None mm_data (#11386)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 47a0b615b45efd0a9ed57049d8ca6eff1c249844[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Fri Dec 20 13:54:55 2024 -0800

    Add ray[default] to wget to run distributed inference out of box (#11265)
    
    Signed-off-by: Jiaxin Shan <seedjeffwan@gmail.com>

[33mcommit 5d2248d81ab1f83a2874bfa726f0a1933ef2d048[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Dec 20 13:00:56 2024 -0800

    [doc] explain nccl requirements for rlhf (#11381)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d573aeadcc891976f09d6d50f1a4f98c8ff809aa[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Dec 20 14:03:50 2024 -0500

    [Bugfix] Don't log OpenAI field aliases as ignored (#11378)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 995f56236bc08300ea11fc8cd3d66029ffec8678[m
Author: omer-dayan <omer@run.ai>
Date:   Fri Dec 20 18:46:24 2024 +0200

    [Core] Loading model from S3 using RunAI Model Streamer as optional loader (#10192)
    
    Signed-off-by: OmerD <omer@run.ai>

[33mcommit 7c7aa37c6933c40a94da0789d0f330a8d89f091b[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Fri Dec 20 17:14:40 2024 +0100

    [CI/Build] fix pre-compiled wheel install for exact tag (#11373)
    
    Signed-off-by: Daniele Trifir√≤ <dtrifiro@redhat.com>

[33mcommit 04139ade599eedd493ce8effcda7ceabb57f2fb5[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Dec 20 04:04:21 2024 -0800

    [V1] Fix profiling for models with merged input processor (#11370)
    
    Signed-off-by: ywang96 <ywang@roblox.com>

[33mcommit 1ecc645b8f5431f1404551ad24721a63f01aea4e[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Dec 19 21:33:53 2024 -0800

    [doc] backward compatibility for 0.6.4 (#11359)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit c954f21ac05642c416cbd87861ddebe9af2ae1b4[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Dec 19 21:18:25 2024 -0800

    [misc] add early error message for custom ops (#11355)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 86c2d8fd1cb27e607928ca8c92fa20d9694d2e4b[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Fri Dec 20 02:15:31 2024 -0300

    [Bugfix] Fix spec decoding when seed is none in a batch (#10863)
    
    Signed-off-by: Wallas Santos <wallashss@ibm.com>

[33mcommit b880ffb87e0bcde5e3693203b480df49e46d67bc[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Dec 19 23:35:18 2024 -0500

    [Misc] Add tqdm progress bar during graph capture (#11349)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 7801f56ed76d9bec0344728bfa3359b42c926074[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Dec 19 18:13:06 2024 -0800

    [ci][gh200] dockerfile clean up (#11351)
    
    Signed-off-by: drikster80 <ed.sealing@gmail.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: drikster80 <ed.sealing@gmail.com>
    Co-authored-by: cenzhiyao <2523403608@qq.com>

[33mcommit 48edab8041741a82a1fd2f4d463cc0f393561b05[m
Author: Akash kaothalkar <61960177+Akashcodes732@users.noreply.github.com>
Date:   Fri Dec 20 07:02:07 2024 +0530

    [Bugfix][Hardware][POWERPC] Fix auto dtype failure in case of POWER10 (#11331)
    
    Signed-off-by: Akash Kaothalkar <0052v2@linux.vnet.ibm.com>

[33mcommit a985f7af9f7b249974b283a9d999575ac30fac3d[m
Author: Yuan <yuan.zhou@intel.com>
Date:   Fri Dec 20 03:46:55 2024 +0800

    [CI] Adding CPU docker pipeline (#11261)
    
    Signed-off-by: Yuan Zhou <yuan.zhou@intel.com>
    Co-authored-by: Kevin H. Luu <kevin@anyscale.com>

[33mcommit e461c262f0d4c9911f1bf75bea723f8ae17219be[m
Author: yangzhibin <45459326+Ghjk94522@users.noreply.github.com>
Date:   Fri Dec 20 01:54:24 2024 +0800

    [Misc] Remove unused vllm/block.py (#11336)

[33mcommit 276738ce0f6aac48ace36bc79aa4a0765fccdfb2[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Dec 20 01:37:31 2024 +0800

    [Bugfix] Fix broken CPU compressed-tensors test (#11338)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit cdf22afddad7b29e8d584b77863a563a91ac09fb[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Dec 20 00:59:32 2024 +0800

    [Misc] Clean up and consolidate LRUCache (#11339)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit e24113a8fe5de5b96459d1f8509d1b48fd7ceebe[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Dec 20 00:28:00 2024 +0800

    [Model] Refactor Qwen2-VL to use merged multimodal processor (#11258)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 7379b3d4b2e0b85de43e7c5145ff26c8200aac8a[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Dec 19 08:27:22 2024 -0800

    [V1] Fix multimodal profiling for `Molmo` (#11325)
    
    Signed-off-by: ywang96 <ywang@example.com>
    Co-authored-by: ywang96 <ywang@example.com>

[33mcommit 6c7f8815416f1968a8c1578f52a7e5b63f9310ed[m
Author: Yehoshua Cohen <61619195+yecohn@users.noreply.github.com>
Date:   Thu Dec 19 16:48:06 2024 +0200

    [Model] Add JambaForSequenceClassification model  (#10860)
    
    Signed-off-by: Yehoshua Cohen <yehoshuaco@ai21.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: Yehoshua Cohen <yehoshuaco@ai21.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit a0f7d53beb176034546c6deb328a3d49e94e1f6d[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Dec 19 21:22:00 2024 +0800

    [Bugfix] Cleanup Pixtral HF code (#11333)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 5aef49806da2e6cc8a92c948d44e8a722469135f[m
Author: Yanyi Liu <wolfsonliu@163.com>
Date:   Thu Dec 19 18:50:38 2024 +0800

    [Feature] Add load generation config from model (#11164)
    
    Signed-off-by: liuyanyi <wolfsonliu@163.com>
    Signed-off-by: Yanyi Liu <wolfsonliu@163.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit 98356735ac51e25877f1b63c5f0733df7cebe5f7[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Thu Dec 19 02:43:16 2024 -0500

    [misc] benchmark_throughput : Add LoRA (#11267)
    
    Signed-off-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit f26c4aeecba481ce1445be7a998b0b97460a13bb[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Wed Dec 18 23:38:02 2024 -0800

    [Misc] Optimize ray worker initialization time (#11275)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 8936316d587ca0afb5ef058584c407d404c0ffb0[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Thu Dec 19 02:00:18 2024 -0500

    [Kernel] Refactor Cutlass c3x (#10049)
    
    Signed-off-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 6142ef0adafd76f6b33ff0adb9a097e45a5df279[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Dec 19 14:14:17 2024 +0800

    [VLM] Merged multimodal processor for Qwen2-Audio (#11303)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit c6b0a7d3ba03ca414be1174e9bd86a97191b7090[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Wed Dec 18 20:17:12 2024 -0800

    [V1] Simplify prefix caching logic by removing `num_evictable_computed_blocks` (#11310)

[33mcommit a30482f0545a216d6c02241f6663b9cddbcb066e[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Dec 18 23:00:38 2024 -0500

    [CI] Expand test_guided_generate to test all backends (#11313)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 17ca964273464fad7e682380bab8288d4fac05c5[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed Dec 18 20:27:24 2024 -0700

    [Model] IBM Granite 3.1 (#11307)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 5a9da2e6e952160a80936b0119364e789661c7a1[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Dec 18 21:43:30 2024 -0500

    [Bugfix][Build/CI] Fix sparse CUTLASS compilation on CUDA [12.0, 12.2) (#11311)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit fdea8ec16775e1645620b5ff46b799d60df4624c[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Wed Dec 18 18:54:46 2024 -0500

    [V1] VLM - enable processor cache by default (#11305)
    
    Signed-off-by: Alexander Matveev <alexm@neuralmagic.com>

[33mcommit ca5f54a9b93a9d044458b8103ed8c9dcc62e6611[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Wed Dec 18 10:34:26 2024 -0800

    [Bugfix] fix minicpmv test (#11304)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit f954fe0e65cc078e62a40e8407f329996541d8c4[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Thu Dec 19 02:17:05 2024 +0800

    [FIX] update openai version (#11287)
    
    Signed-off-by: Kunshang Ji <kunshang.ji@intel.com>

[33mcommit 362cff1eb3d6c1af434d29e8ed022dec048211fa[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Dec 18 10:16:53 2024 -0800

    [CI][Misc] Remove Github Action Release Workflow (#11274)

[33mcommit 996aa70f00818933866d8cfdbbf8f131a6a63664[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Thu Dec 19 02:16:40 2024 +0800

    [Bugfix] Fix broken phi3-v mm_processor_kwargs tests (#11263)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 60508ffda91c22e4cde3b18f149d222211db8886[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Wed Dec 18 09:57:16 2024 -0500

    [Kernel]: Cutlass 2:4 Sparsity + FP8/Int8 Quant Support (#10995)
    
    Co-authored-by: Faraz Shahsavan <faraz.shahsavan@gmail.com>
    Co-authored-by: ilmarkov <markovilya197@gmail.com>
    Co-authored-by: Rahul Tuli <rahul@neuralmagic.com>
    Co-authored-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>

[33mcommit f04e407e6b6b9ce65c16cffda836f05c2ad32682[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Wed Dec 18 14:34:23 2024 +0800

    [MISC][XPU]update ipex link for CI fix (#11278)

[33mcommit 8b79f9e107fd4214187bf65485b3ea1bb3191a46[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Wed Dec 18 03:34:08 2024 -0300

    [Bugfix] Fix guided decoding with tokenizer mode mistral (#11046)

[33mcommit 866fa4550d572f4ff3521ccf503e0df2e76591a1[m
Author: Konrad Zawora <kzawora@habana.ai>
Date:   Wed Dec 18 01:39:07 2024 +0100

    [Bugfix] Restore support for larger block sizes (#11259)
    
    Signed-off-by: Konrad Zawora <kzawora@habana.ai>

[33mcommit bf8717ebaea8d74279df84fbe127ad22cf62e219[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Tue Dec 17 16:37:59 2024 -0800

    [V1] Prefix caching for vision language models (#11187)
    
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit c77eb8a33ceb62858d951ffef87ae626a0d09973[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Dec 17 19:34:06 2024 -0500

    [Bugfix] Set temperature=0.7 in test_guided_choice_chat (#11264)

[33mcommit 2d1b9baa8f57fc59912c7bcd07fd630fb9d72c9d[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Tue Dec 17 13:26:32 2024 -0700

    [Bugfix] Fix request cancellation without polling (#11190)

[33mcommit f9ecbb18bf03338a4272c933a49a87021363b048[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Tue Dec 17 16:37:04 2024 +0800

    [Misc] Allow passing logits_soft_cap for xformers backend (#11252)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 02222a0256f60319f5bcd56d1d036a943d6334f8[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Dec 16 22:57:02 2024 -0800

    [Misc] Kernel Benchmark for `RMSNorm` (#11241)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Xiaoyu Zhang <BBuf@users.noreply.github.com>

[33mcommit 2bfdbf2a36256bb08547cea3d4ef83b5d27c4b04[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Dec 17 01:11:33 2024 -0500

    [V1][Core] Use weakref.finalize instead of atexit (#11242)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit e88db68cf5712956f36e77c288699592327b15bd[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Tue Dec 17 14:11:06 2024 +0800

    [Platform] platform agnostic for EngineArgs initialization (#11225)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit 59c9b6ebeba79b2d744eec86734a7e13b03dcab7[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Dec 16 22:10:57 2024 -0800

    [V1][VLM] Proper memory profiling for image language models (#11210)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: ywang96 <ywang@example.com>

[33mcommit 66d4b16724226e9f377551198cc7425c12ddafae[m
Author: kYLe <kylhuang@nvidia.com>
Date:   Tue Dec 17 00:09:58 2024 -0600

    [Frontend] Add OpenAI API support for input_audio (#11027)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 0064f697d318a2ce38342f7c20754cf229311b8b[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Dec 16 22:39:58 2024 -0500

    [CI] Add test case with JSON schema using references + use xgrammar by default with OpenAI parse (#10935)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 35bae114a89e03e3dc6a6d2f758378e58938bffa[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 16 17:22:38 2024 -0800

    fix gh200 tests on main (#11246)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 88a412ed3d964de3443c42a6a35108115ee0ad25[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 16 16:15:22 2024 -0800

    [torch.compile] fast inductor (#11108)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit c301616ed23fef433db1a49df332b9d61d3178ad[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 16 15:53:18 2024 -0800

    [ci][tests] add gh200 tests (#11244)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 35ffa682b1cd3f47eb6cda586a16dab5c0401477[m
Author: bk-TurbaAI <babar.khan@turba.ai>
Date:   Mon Dec 16 23:20:39 2024 +0100

    [Docs] hint to enable use of GPU performance counters in profiling tools for multi-node distributed serving (#11235)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 551603feffd9b4ba98ccdd34e02e403e04db88c1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 16 13:32:25 2024 -0800

    [core] overhaul memory profiling and fix backward compatibility (#10511)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit efbce85f4d375d7851a491a0126a224e25d9f91d[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Mon Dec 16 13:14:57 2024 -0500

    [misc] Layerwise profile updates (#10242)
    
    Signed-off-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 2ca830dbaa1a7c30b8ff4d7c860c63f87dc18be3[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Mon Dec 16 19:23:33 2024 +0800

    [Doc] Reorder vision language examples in alphabet order (#11228)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit d927dbcd889fb2476cb61ea477ff51e5dd9e1ae3[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Mon Dec 16 18:09:53 2024 +0800

    [Model] Refactor Ultravox to use merged input processor (#11198)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit bddbbcb132429084ede62855bcd6a1023a3645c1[m
Author: Jani Monoses <jani.monoses@gmail.com>
Date:   Mon Dec 16 11:56:19 2024 +0200

    [Model] Support Cohere2ForCausalLM (Cohere R7B) (#11203)

[33mcommit b3b1526f03906c935e6ef80a2cdc971a65fdf7e2[m
Author: cennn <61925104+cennn@users.noreply.github.com>
Date:   Mon Dec 16 17:20:49 2024 +0800

    WIP: [CI/Build] simplify Dockerfile build for ARM64 / GH200 (#11212)
    
    Signed-off-by: drikster80 <ed.sealing@gmail.com>
    Co-authored-by: drikster80 <ed.sealing@gmail.com>

[33mcommit 17138af7c45eba3aba3e9b84a3852b4ba81e460f[m
Author: yansh97 <yansh97@foxmail.com>
Date:   Mon Dec 16 16:15:40 2024 +0800

    [Bugfix] Fix the default value for temperature in ChatCompletionRequest (#11219)

[33mcommit 69ba344de8683ec4d3d42d11ae4e147a2a302da8[m
Author: chenqianfzh <51831990+chenqianfzh@users.noreply.github.com>
Date:   Sun Dec 15 16:38:40 2024 -0800

    [Bugfix] Fix block size validation (#10938)

[33mcommit da6f40924609e084ced486cae5b4ddf97133acd9[m
Author: AlexHe99 <alehe@amd.com>
Date:   Mon Dec 16 08:33:58 2024 +0800

    Update deploying_with_k8s.rst (#10922)

[33mcommit 25ebed2f8ca6d747d63f2be9ede023c561851ac8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 15 13:33:00 2024 -0800

    [V1][Minor] Cache np arange to reduce input preparation overhead (#11214)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit d263bd9df7b2f5586910e5d006a11ff11ba7c310[m
Author: shangmingc <caishangming@linux.alibaba.com>
Date:   Mon Dec 16 05:28:18 2024 +0800

    [Core] Support disaggregated prefill with Mooncake Transfer Engine (#10884)
    
    Signed-off-by: Shangming Cai <caishangming@linux.alibaba.com>

[33mcommit 38e599d6a84bb7477030a5488035cd23f529b644[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Sun Dec 15 13:31:16 2024 -0600

    [Doc] add documentation for disaggregated prefilling (#11197)
    
    Signed-off-by: Kuntai Du <kuntai@uchicago.edu>

[33mcommit 96d673e0f897aa8eec234e690c9c5425782d6ffb[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Dec 16 01:59:42 2024 +0800

    [Bugfix] Fix error handling of unsupported sliding window (#11213)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit b10609e6a11554be61976981304984510a0469c9[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Dec 15 14:30:28 2024 +0800

    [Misc] Clean up multi-modal processor (#11207)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit a1c02058baf47be1a91ee743378a340ee1b10416[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Dec 14 19:45:00 2024 -0800

    [torch.compile] allow tracking forward time (#11081)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 15859f2357059ef488405e5336d2c6e5d246687b[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Dec 15 11:03:06 2024 +0800

    [[Misc]Upgrade bitsandbytes to the latest version 0.45.0 (#11201)

[33mcommit 886936837ca89e5645bc1f71cc0e1492b65b1590[m
Author: Sungjae Lee <33976427+llsj14@users.noreply.github.com>
Date:   Sun Dec 15 04:38:10 2024 +0900

    [Performance][Core] Optimize the performance of evictor v1 and v2 by applying a priority queue and lazy deletion (#7209)

[33mcommit 6d917d0eebd03990edf2443780a5f2506026ea78[m
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Sat Dec 14 17:54:04 2024 +0000

    Enable mypy checking on V1 code (#11105)
    
    Signed-off-by: Mark McLoughlin <markmc@redhat.com>

[33mcommit 93abf23a648051fe6dc053ba0b74499d119920bf[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Dec 15 01:52:18 2024 +0800

    [VLM] Fully dynamic prompt replacement in merged input processor (#11199)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 9c3dadd1c97df2b37388c6898a0725457391f647[m
Author: Brad Hilton <brad.hilton.nw@gmail.com>
Date:   Sat Dec 14 09:46:42 2024 -0700

    [Frontend] Add `logits_processors` as an extra completion argument (#11150)
    
    Signed-off-by: Brad Hilton <brad.hilton.nw@gmail.com>

[33mcommit 3cb5769883fa104e42248f2b3f41a310947f357c[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Dec 15 00:38:27 2024 +0800

    [Misc] Minor improvements to the readability of PunicaWrapperBase (#11200)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit ea7bd68d101884165ffd75c1fd6e94a97510f194[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sat Dec 14 03:21:23 2024 -0500

    [V1][Bugfix] Fix V1 TP trust-remote-code (#11182)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 48259264a4012e756215adc87e3682bf1e7dfee9[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Sat Dec 14 02:46:18 2024 -0500

    [Core] Update outlines and increase its threadpool size (#11140)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 24a3d12b821a081850c1659f61762e799eeba902[m
Author: dhuangnm <74931910+dhuangnm@users.noreply.github.com>
Date:   Fri Dec 13 22:22:44 2024 -0500

    update compressed-tensors to latest version (#11183)
    
    Co-authored-by: dhuangnm <dhuang@MacBook-Pro-2.local>

[33mcommit 9855aea21b6aec48b12cef3a1614e7796b970a73[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Dec 13 17:08:23 2024 -0800

    [Bugfix][V1] Re-compute an entire block when fully cache hit (#11186)
    
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 4b5b8a6a3bd94d9b0248b36b0eb4739d76fbb386[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Dec 13 20:02:35 2024 -0500

    [V1][Bugfix] Fix EngineCoreProc profile (#11185)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 4863e5fba51b8e1a5012e2a7582aece0ca575b89[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Dec 13 19:27:32 2024 -0500

    [Core] V1: Use multiprocessing by default (#11074)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 0d8451c3a45d309e58de5e1c546f043de461d478[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Fri Dec 13 12:17:37 2024 -0800

    [Distributed] Allow the placement group more time to wait for resources to be ready (#11138)
    
    Signed-off-by: Jiaxin Shan <seedjeffwan@gmail.com>

[33mcommit 0a56bcc03de0857be464c3f8783258d590cbc762[m
Author: Jani Monoses <jani.monoses@gmail.com>
Date:   Fri Dec 13 20:00:40 2024 +0200

    [Bugfix][Hardware][CPU] Enable Gemma2 with SDPA on CPU backend (#11169)

[33mcommit 0920ab9131274df143cfc49245409378a009b3c6[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Dec 14 00:22:22 2024 +0800

    [Doc] Reorganize online pooling APIs (#11172)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 238c0d93b40008244fae64530d82f1860b1f9121[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Fri Dec 13 11:19:10 2024 -0500

    [Misc] Add tokenizer_mode param to benchmark_serving.py (#11174)
    
    Signed-off-by: Alexander Matveev <alexm@neuralmagic.com>

[33mcommit 5b0ed8391d497439595a1968d65df93da98265ca[m
Author: zhangjf <1061683512@qq.com>
Date:   Fri Dec 13 23:56:19 2024 +0800

    [Bugfix] using len(tokenizer) instead of tokenizer.vocab_size in AllowedTokenIdsLogitsProcessor (#11156)

[33mcommit c31d4a57a6b639900a7c70b6e844db0116c2f9f6[m
Author: Sungjae Lee <33976427+llsj14@users.noreply.github.com>
Date:   Sat Dec 14 00:51:25 2024 +0900

    [Core] support LoRA and prompt adapter in content-based hashing for Block Manager v2 prefix caching (#8240)

[33mcommit d1fa714cb1c9a708d7da0de27c99f7eee07fe663[m
Author: Chenguang Li <757486878@qq.com>
Date:   Fri Dec 13 21:39:00 2024 +0800

    [Refactor]A simple device-related refactor (#11163)
    
    Signed-off-by: noemotiovon <noemotiovon@gmail.com>
    Co-authored-by: noemotiovon <noemotiovon@gmail.com>

[33mcommit 969da7d70bc0539f6be12027b71bef758325a61a[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Dec 13 03:09:30 2024 -0800

    [V1][VLM] Fix edge case bug for InternVL2 (#11165)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit eeec9e339005d887e0064f7b3e7771295ecd68e7[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Dec 13 18:40:07 2024 +0800

    [Frontend] Separate pooling APIs in offline inference (#11129)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit f93bf2b1897cca5b644fe03f31925e4faff40056[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Fri Dec 13 16:50:35 2024 +0800

    [Bugfix][CI][CPU] add missing datasets package to requirements-cpu.txt  (#11159)
    
    Signed-off-by: jiang1.li <jiang1.li@intel.com>

[33mcommit 7cd7409142ff97aee1a13568753db9263fcf8f6b[m
Author: Jani Monoses <jani.monoses@gmail.com>
Date:   Fri Dec 13 09:40:07 2024 +0200

    PaliGemma 2 support (#11142)

[33mcommit be39e3cd18781c4571410323f3c767e67240eb51[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Dec 12 22:57:50 2024 -0800

    [core] clean up cudagraph batchsize padding logic (#10996)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 34f1a806d5771c4ee81fdaf4feb7f9fd4071d779[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Thu Dec 12 22:30:06 2024 -0800

    [Bugfix][V1] Fix 'NoneType' object has no attribute 'hash_value' (#11157)
    
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 00c1bde5d8cd30b14f661b11d9ad1c1d4470ddbf[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Fri Dec 13 00:31:26 2024 -0500

    [ROCm][AMD] Disable auto enabling chunked prefill on ROCm (#11146)
    
    Signed-off-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>

[33mcommit 3989a798249bfa24b6dd22aff599796fcf92dce9[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Fri Dec 13 00:07:20 2024 -0500

    [Bugfix] Update starcoder2 to remap k/v scale names for kv_cache quantization (#11148)

[33mcommit 1efce686053c15cd6f84361bb0bd1898fbb23a82[m
Author: Pooya Davoodi <pooya.davoodi@parasail.io>
Date:   Thu Dec 12 20:09:53 2024 -0800

    [Bugfix] Use runner_type instead of task in GritLM (#11144)
    
    Signed-off-by: Pooya Davoodi <pooya.davoodi@parasail.io>

[33mcommit 30870b4f66414020645608b81dced94d8a99111c[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Thu Dec 12 22:19:23 2024 -0500

    [torch.compile] Dynamic fp8 + rms_norm fusion (#10906)
    
    Signed-off-by: luka <luka@neuralmagic.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 78ed8f57d8815cdd5567533f7d3e25b959d861ab[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Thu Dec 12 16:57:40 2024 -0800

    [Misc][V1] Fix type in v1 prefix caching (#11151)

[33mcommit db6c264a1e658e37782570f5155c77be0d41f312[m
Author: shangmingc <csmthu@gmail.com>
Date:   Fri Dec 13 05:19:17 2024 +0800

    [Bugfix] Fix value unpack error of simple connector for KVCache transfer. (#11058)
    
    Signed-off-by: ShangmingCai <csmthu@gmail.com>

[33mcommit 9f3974a31911b551d416bb4d435273409d23f021[m
Author: Jeremy Arnold <103538711+JArnoldAMD@users.noreply.github.com>
Date:   Thu Dec 12 14:05:57 2024 -0600

    Fix logging of the vLLM Config (#11143)

[33mcommit 2c97eca1fff5297089794d2bd8ebd0bf98e12641[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Thu Dec 12 10:34:26 2024 -0800

    [Misc] Validate grammar and fail early (#11119)

[33mcommit 5d712571afd87f5cc1b6c6c25feaac5c706f3712[m
Author: Jeff Cook <jeff@jeffcook.io>
Date:   Thu Dec 12 11:09:20 2024 -0700

    [Bugfix] Quick fix to make Pixtral-HF load correctly again after 39e227c7ae. (#11024)

[33mcommit d4d5291cc216ccc7ce824c03ab25141026b9a394[m
Author: Ramon Ziai <ramon.ziai@bettermarks.com>
Date:   Thu Dec 12 18:36:32 2024 +0100

    fix(docs): typo in helm install instructions (#11141)
    
    Signed-off-by: Ramon Ziai <ramon.ziai@bettermarks.com>

[33mcommit 4816d20aa43fdc4abf66c28f6690a1953d8adbe9[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Dec 12 07:51:53 2024 -0800

    [V1] Fix torch profiling for offline inference (#11125)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 85362f028c0324d8d00b0438f29c3d9f64737b9a[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Thu Dec 12 01:25:16 2024 -0800

    [Misc][LoRA] Ensure Lora Adapter requests return adapter name (#11094)
    
    Signed-off-by: Jiaxin Shan <seedjeffwan@gmail.com>
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 62de37a38ed4a3877f3b1607b7163135f7ab9e36[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Dec 12 01:04:19 2024 -0800

    [core][distributed] initialization from StatelessProcessGroup (#10986)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 8195824206ad2e3c45d1807b321c11f06ccb3a91[m
Author: Sanju C Sudhakaran <scsudhakaran@habana.ai>
Date:   Thu Dec 12 13:39:28 2024 +0530

    [Hardware][Intel-Gaudi] Enable LoRA support for Intel Gaudi (HPU) (#10565)
    
    Signed-off-by: Sanju C Sudhakaran <scsudhakaran@habana.ai>

[33mcommit f092153fbe349a9a1742940e3703bfcff6aa0a6d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Dec 11 23:14:20 2024 -0800

    [V1] Use more persistent buffers to optimize input preparation overheads (#11111)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 1da8f0e1dddaf8625829e7ecca7fce93eb685c03[m
Author: Pooya Davoodi <pooya.davoodi@parasail.io>
Date:   Wed Dec 11 22:39:16 2024 -0800

    [Model] Add support for embedding model GritLM (#10816)
    
    Signed-off-by: Pooya Davoodi <pooya.davoodi@parasail.io>

[33mcommit ccede2b264668d854cba4fce7f8fbbf203908f60[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Dec 11 22:12:24 2024 -0500

    [Core] cleanup zmq ipc sockets on exit (#11115)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 24a36d6d5f789fd2d5105174c24528fc7e659b00[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Wed Dec 11 21:39:21 2024 -0500

    Update link to LlamaStack remote vLLM guide in serving_with_llamastack.rst (#11112)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit 8fb26dac614425de5b14f8e77a10bde35bacf155[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Dec 11 17:33:11 2024 -0800

    [Docs] Add media kit (#11121)

[33mcommit 7439a8b5fcbc4d77bd73496f27d4048c5b43cb22[m
Author: Clayton <132770471+cedonley@users.noreply.github.com>
Date:   Wed Dec 11 17:10:12 2024 -0800

    [Bugfix] Multiple fixes to tool streaming with hermes and mistral (#10979)
    
    Signed-off-by: cedonley <clayton@donley.io>

[33mcommit 4e116833686f3e0c0a223b05b5859ad76843a017[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Wed Dec 11 19:55:30 2024 -0500

    [V1] VLM preprocessor hashing (#11020)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Signed-off-by: Alexander Matveev <alexm@neuralmagic.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 452a723bf2e8410ee9b47f82f90c7ea48aa6d14f[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Dec 11 18:34:54 2024 -0500

    [V1][Core] Remove should_shutdown to simplify core process termination (#11113)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit d1e21a979bba4712f48dac1bbf410e0b57c92e7a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Dec 12 06:18:16 2024 +0800

    [CI/Build] Split up VLM tests (#11083)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 72ff3a968682e6a3f7620ab59f2baf5e8eb2777b[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Wed Dec 11 11:36:35 2024 -0800

    [core] Bump ray to use _overlap_gpu_communication in compiled graph tests (#10410)
    
    Signed-off-by: Rui Qiao <ubuntu@ip-172-31-15-128.us-west-2.compute.internal>
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>
    Co-authored-by: Rui Qiao <ubuntu@ip-172-31-15-128.us-west-2.compute.internal>

[33mcommit 66aaa7722df3d7ef9e9bd2942cab5cd0d7473174[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Dec 11 10:59:50 2024 -0800

    [torch.compile] remove graph logging in ci (#11110)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d643c2aba1cd5421200f3a3bad1813dd067233b4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Dec 11 10:49:23 2024 -0800

    [V1] Use input_ids as input for text-only models  (#11032)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 91642db952458fbb6ae7c2d167757dc86b105991[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Dec 11 10:43:05 2024 -0800

    [torch.compile] use depyf to dump torch.compile internals (#10972)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit fd22220687af5ccd89d9f8f2812069ef0422244c[m
Author: bingps <46775742+bingps@users.noreply.github.com>
Date:   Wed Dec 11 23:43:24 2024 +0800

    [Doc] Installed version of llmcompressor for int8/fp8 quantization (#11103)
    
    Signed-off-by: Guangda Liu <bingps@users.noreply.github.com>
    Co-authored-by: Guangda Liu <bingps@users.noreply.github.com>

[33mcommit b2f775456e4af7412308320a9c11e4dac3086205[m
Author: hissu-hyvarinen <hissu.hyvarinen@amd.com>
Date:   Wed Dec 11 17:23:37 2024 +0200

    [CI/Build] Enable prefix caching test for AMD (#11098)
    
    Signed-off-by: Hissu Hyvarinen <hissu.hyvarinen@amd.com>

[33mcommit cad5c0a6eda057eeece87a42fff49fef3e18a2ac[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Dec 11 21:36:27 2024 +0800

    [Doc] Update docs to refer to pooling models (#11093)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 8f10d5e3930f05c2057a831cd80ba24c52b8ceef[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Dec 11 17:28:00 2024 +0800

    [Misc] Split up pooling tasks (#10820)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 40766ca1b8b0ef92e220595bda96c4336b597e5b[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Wed Dec 11 04:27:39 2024 -0500

    [Bugfix]: Clamp `-inf` logprob values in prompt_logprobs (#11073)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit 2e32f5d28db3cd79f6a421f640e083be1f9468b7[m
Author: B-201 <Joy25810@foxmail.com>
Date:   Wed Dec 11 17:27:07 2024 +0800

    [Bugfix] Fix Idefics3 fails during multi-image inference (#11080)
    
    Signed-off-by: B-201 <Joy25810@foxmail.com>

[33mcommit 61b1d2f6aef8e29c6a0d795a9c6682d525f4d8cc[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Dec 11 04:26:36 2024 -0500

    [Core] v1: Use atexit to handle engine core client shutdown (#11076)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 9974fca047bb332ec68377be4579ea515a300d69[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Dec 11 01:01:53 2024 -0800

    [ci/build] Fix entrypoints test and pin outlines version (#11088)

[33mcommit 3fb4b4f1634a896653acc12c72b8e5d6d87a8f82[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Dec 11 00:39:53 2024 -0800

    [ci/build] Fix AMD CI dependencies (#11087)

[33mcommit 2e33fe419186c65a18da6668972d61d7bbc31564[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Dec 11 13:02:02 2024 +0800

    [CI/Build] Check transformers v4.47 (#10991)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit e39400a4b60d28ff5c0a1a5194068c928adcaf98[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Wed Dec 11 01:51:40 2024 -0300

    Fix streaming for granite tool call when <|tool_call|> is present (#11069)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>

[33mcommit ffa48c9146fda1e8810d1cfa159e1d70aadae6c6[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Wed Dec 11 04:53:37 2024 +0200

    [Model] PP support for Mamba-like models (#10992)
    
    Signed-off-by: mzusman <mor.zusmann@gmail.com>

[33mcommit d5c5154fcf4c5d65551c98e458cbb027e5f4b672[m
Author: Aurick Qiao <aurickq@users.noreply.github.com>
Date:   Tue Dec 10 21:09:20 2024 -0500

    [Misc] LoRA + Chunked Prefill (#9057)

[33mcommit 9a93973708d7f52f1d1439f8f32b8c1514d18b86[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Dec 10 19:16:22 2024 -0500

    [Bugfix] Fix Mamba multistep (#11071)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 134810b3d9a05510622282479f0f9e2114b88017[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Dec 10 14:41:23 2024 -0800

    [V1][Bugfix] Always set enable_chunked_prefill = True for V1 (#11061)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 75f89dc44c6e44cc28bae59d5b40a588735b507b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Dec 10 12:40:52 2024 -0800

    [torch.compile] add a flag to track batchsize statistics (#11059)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit e7391949267a4eff3d84f02119f442f46b16d163[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Dec 10 15:08:16 2024 -0500

    [Core] Update to outlines >= 0.1.8 (#10576)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 250ee65d72a0c7b86ec5cea9cbe9377da21d6439[m
Author: Fl√°via B√©o <119421251+flaviabeo@users.noreply.github.com>
Date:   Tue Dec 10 14:38:15 2024 -0300

    [BUG] Remove token param #10921 (#11022)
    
    Signed-off-by: Flavia Beo <flavia.beo@ibm.com>

[33mcommit 9b9cef3145381721fa950c89718fe71849ac2a55[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Tue Dec 10 09:38:23 2024 -0700

    [Bugfix] Backport request id validation to v0 (#11036)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit d05f88679bedd73939251a17c3d785a354b2946c[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Dec 10 19:12:01 2024 +0800

    [Misc][LoRA] Add PEFTHelper  for LoRA  (#11003)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit beb16b2c810a87b28e7b8a7aa29d26f842f654b9[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Tue Dec 10 03:27:11 2024 -0700

    [Bugfix] Handle <|tool_call|> token in granite tool parser (#11039)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit fe2e10c71b98a43ccde0e8aba0d4fe0d23369538[m
Author: Maxime Fournioux <55544262+mfournioux@users.noreply.github.com>
Date:   Tue Dec 10 10:19:27 2024 +0100

    Add example of helm chart for vllm deployment on k8s (#9199)
    
    Signed-off-by: Maxime Fournioux <55544262+mfournioux@users.noreply.github.com>

[33mcommit 82c73fd5104e010c2c98820f3e761e1e4f36c135[m
Author: Gene Der Su <e870252314@gmail.com>
Date:   Mon Dec 9 23:41:11 2024 -0800

    [Bugfix] cuda error running llama 3.2 (#11047)

[33mcommit bfd610430c04d2962a03a2db304fb13b09b4f1b3[m
Author: Diego Marinho <dmztheone@gmail.com>
Date:   Tue Dec 10 18:08:10 2024 +1100

    Update README.md (#11034)

[33mcommit e35879c27601b09aab49e054786ce2a459f7a384[m
Author: Jeff Cook <jeff@jeffcook.io>
Date:   Mon Dec 9 23:54:22 2024 -0700

    [Bugfix] Fix xgrammar failing to read a vocab_size from LlavaConfig on PixtralHF. (#11043)

[33mcommit ebf778061db4e67c6903f8d6e8ad97c3db0174d8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 9 22:35:36 2024 -0800

    monitor metrics of tokens per step using cudagraph batchsizes (#11031)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 28b3a1c7e596c08efac0fcfa59a629d16197be30[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Dec 10 01:28:14 2024 -0500

    [V1] Multiprocessing Tensor Parallel Support for v1 (#9856)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit bc192a2b099558ec94864974b2a91b84c271a84d[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Tue Dec 10 07:09:32 2024 +0100

    [Pixtral] Improve loading (#11040)

[33mcommit 980ad394a83a6f12c576a035922db3c2e743beff[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Mon Dec 9 22:46:29 2024 -0700

    [Frontend] Use request id from header (#10968)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 391d7b2763df0b90a975c7232f38c4de4be2ff85[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Dec 10 13:45:47 2024 +0800

    [Bugfix] Fix usage of `deprecated` decorator (#11025)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit d1f6d1c8af892c7269f113711783374eebb52511[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Tue Dec 10 10:23:07 2024 +0800

    [Model] Add has_weight to RMSNorm and re-enable weights loading tracker for Mamba (#10739)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 6d525288c1a40ee70f9cff2fe08657f23bae88dc[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Dec 9 20:15:34 2024 -0500

    [Docs] Add dedicated tool calling page to docs (#10554)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 6faec545057e6152e92e8ab619fc018e20864943[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 9 15:08:19 2024 -0800

    [V1] Do not store `None` in self.generators (#11038)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 5ed5d5f128d26a48c1b1db16c319fcb96c93799d[m
Author: Richard Liu <39319471+richardsliu@users.noreply.github.com>
Date:   Mon Dec 9 15:07:48 2024 -0800

    Build tpu image in release pipeline (#10936)
    
    Signed-off-by: Richard Liu <ricliu@google.com>
    Co-authored-by: Kevin H. Luu <kevin@anyscale.com>

[33mcommit b63ba848323efd88207b12d7582501d525503b8a[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Mon Dec 9 17:00:29 2024 -0500

    [ROCm][bugfix] scpecilative decoding worker class (#11035)
    
    Signed-off-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>

[33mcommit 9c6459e4cb020ec1ad9ea08cac9309b83d432fc8[m
Author: xendo <xendoo@gmail.com>
Date:   Mon Dec 9 22:53:24 2024 +0100

    [Neuron] Upgrade neuron to 2.20.2 (#11016)
    
    Signed-off-by: Jerzy Zagorski <jzagorsk@amazon.com>
    Co-authored-by: Jerzy Zagorski <jzagorsk@amazon.com>

[33mcommit 1a2f8fb828f0444705db319786b2e901159f184e[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 9 13:47:24 2024 -0800

    [v1] fix use compile sizes (#11000)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit cbcbdb1ceb9c219d13b2386e101992c399410551[m
Author: Konrad Zawora <kzawora@habana.ai>
Date:   Mon Dec 9 22:21:06 2024 +0100

    [Bugfix][Hardware][Gaudi] Bump vllm_hpu_extension version (#11028)
    
    Signed-off-by: Konrad Zawora <kzawora@habana.ai>

[33mcommit a811dd660856a5c222a1447fe1d93deccbc162fd[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Tue Dec 10 04:55:10 2024 +0800

    [Model] merged input processor for Phi-3-Vision models (#10977)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit ca871491edb0fba11fe9aa94300bd8d282fa29e1[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Dec 10 04:54:44 2024 +0800

    [Misc][LoRA] Abstract PunicaWrapper (#10955)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 3b61cb450d899dc423feb264c297d4d18d701678[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 9 12:38:46 2024 -0800

    [V1] Further reduce CPU overheads in flash-attn (#10989)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit edc4fa31888b4a41060acb7b16250540f051ad59[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Dec 9 11:46:58 2024 -0800

    [ci/build] Recompile CI dependencies list with Python 3.12 (#11013)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 25b79d9fd38e2c53ce281be23241d8939ec7320c[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Mon Dec 9 12:33:41 2024 -0500

    [V1] Input Batch Relocation (#10962)
    
    Signed-off-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit aea2fc38c3b31b9a8ea7d1cffb8f37a2da6f6075[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Tue Dec 10 01:24:46 2024 +0800

    [Platform] Move `async output` check to platform (#10768)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit e691b26f6fae5a3a1c220d15f20de83c7d78ed51[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Mon Dec 9 11:44:27 2024 -0500

    [Core] Require xgrammar >= 0.1.6 (#11021)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit c690357928fd2812f450bfb0c3629a816f5e9a55[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Dec 9 08:27:10 2024 -0800

    [V1] Fix Detokenizer loading in `AsyncLLM` (#10997)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit d1c2e15eb31ef12e688ce0cb71895f88eaf4cd4f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Dec 8 23:09:04 2024 -0800

    [torch.compile] add dynamo time tracking (#11005)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit af7c4a92e654684066e61518d6ed90feda983635[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Dec 8 22:29:16 2024 -0800

    [Doc][V1] Add V1 support column for multimodal models (#10998)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 46004e83a2e0b908f28099d93171bfb4934e4722[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Dec 8 17:28:27 2024 -0800

    [misc] clean up and unify logging (#10999)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 43b05fa314e90e551d87211e8bdde2e2bb5a0bdc[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Dec 8 11:18:18 2024 -0800

    [torch.compile][misc] fix comments (#10993)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit a11f3265282c712d1d9fa75368e2a8c40019fbb7[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Dec 8 04:50:51 2024 -0800

    [V1] Initial support of multimodal models for V1 re-arch (#10699)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit fd57d2b5347e8fe6da9287553d4b5a3aaf2e6693[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Dec 8 03:05:21 2024 -0800

    [torch.compile] allow candidate compile sizes (#10984)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 7be15d9356a10c6ae3537565548e4f8bf46f35dd[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Dec 7 12:06:08 2024 -0800

    [core][misc] remove use_dummy driver for _run_workers (#10920)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 1b62745b1d00153c5e99879edaf0c2d7ceb4e2c6[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Dec 7 09:33:45 2024 -0800

    [core][executor] simplify instance id (#10976)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 78029b34ed1be46baf06f92c9e971ea1961d0867[m
Author: zhou fan <1247714429@qq.com>
Date:   Sun Dec 8 01:21:18 2024 +0800

    [BugFix][Kernel]: fix illegal memory access in causal_conv1d when conv_states is None (#10928)
    
    Signed-off-by: xffxff <1247714429@qq.com>

[33mcommit c889d5888bf6bbfbe3f4ea55bf27ce84a239c3d0[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Dec 8 01:20:49 2024 +0800

    [Doc] Explicitly state that PP isn't compatible with speculative decoding yet (#10975)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 39e227c7ae3149eb8345ea1a1ffee672ef76c09a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Dec 8 01:10:05 2024 +0800

    [Model] Update multi-modal processor to support Mantis(LLaVA) model (#10711)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 1c768fe53713ef333d74a6645e6a59fb7516134f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Dec 8 00:58:02 2024 +0800

    [Doc] Explicitly state that InternVL 2.5 is supported (#10978)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit bf0e382e16065edebbbb414f7889d31523a569e1[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Dec 7 22:22:52 2024 +0800

    [Model] Composite weight loading for multimodal Qwen2 (#10944)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit b26b4cd03c5468c68c3ce328ea6498a5d816870d[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sat Dec 7 18:33:49 2024 +0800

    [Misc][LoRA] Refactor and clean MergedQKVParallelLinearWithLora implementation  (#10958)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit f13cf9ad5049e386f766014877dee78d2f438799[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Sat Dec 7 04:03:44 2024 -0500

    [Build] Fix for the Wswitch-bool clang warning (#10060)
    
    Signed-off-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>

[33mcommit 955fa9533afde0d232e73f079d72239c8a87c636[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Dec 7 16:50:58 2024 +0800

    [3/N] Support and implement merged input processor for LLaVA model (#10676)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit acf092d34802b187f27daa8e1626f67552bde193[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sat Dec 7 12:08:54 2024 +0800

    [Bugfix] Fix test-pipeline.yaml (#10973)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 69d357ba125a8c4243c25d7d9162f1c93cfddd1f[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Dec 6 21:30:23 2024 -0500

    [Core] Cleanup startup logging a bit (#10961)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit dcdc3fafe535178037ef0a58f53607b2fb3e4190[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Dec 6 11:25:47 2024 -0800

    [ci] fix broken tests (#10956)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit c05cfb67da12f84bd142ba51cca98e59139bea42[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Dec 6 11:25:20 2024 -0800

    [misc] fix typo (#10960)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 74062740416db8572627dda1f87925268ba2f1d3[m
Author: Sam Stoelinga <sammiestoel@gmail.com>
Date:   Fri Dec 6 09:03:56 2024 -0800

    [Doc] add KubeAI to serving integrations (#10837)
    
    Signed-off-by: Sam Stoelinga <sammiestoel@gmail.com>

[33mcommit 8b5963185512eb7799f12240570e0ac7e7462a88[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Dec 6 10:34:29 2024 -0500

    [Core] Support Lark grammars for XGrammar (#10870)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit a1887f2c96480e597db8c35cb8389c4025fb4db9[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Dec 6 03:01:23 2024 -0800

    [torch.compile] fix deprecated code (#10948)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 222f5b082a62d0b2675cb461e223ae43368eea92[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Dec 6 18:41:23 2024 +0800

    [CI/Build] Fix broken multimodal test (#10950)

[33mcommit b031a455a9fa9d57952281dac2a1146d6440790f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Dec 6 02:07:15 2024 -0800

    [torch.compile] add logging for compilation time (#10941)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit db87eb6c67271eb61ba9fd8559ce811a1a398a4d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Dec 5 20:30:41 2024 -0800

    [torch.compile] use size tuning for specific sizes (#10933)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 9743d64e4e04a88174c76553fcbffa33a18c7db5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Dec 5 08:54:47 2024 -0800

    [ci][build] add tests for python only compilation (#10915)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit a43065272f73a7468b1a35dd44fb5b0ed80f88c7[m
Author: Konrad Zawora <kzawora@habana.ai>
Date:   Thu Dec 5 17:47:46 2024 +0100

    [Misc][Gaudi] Avoid torch.compile and enable lazy collectives (#10897)
    
    Signed-off-by: Konrad Zawora <kzawora@habana.ai>

[33mcommit 998eeafe58c0263323b7fd8813c8b3d3f839bcbc[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Dec 6 00:05:52 2024 +0800

    [CI/Build] Bump test transformers version (#10106)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 571da8fc431ec36427ee1034a7779b23229b015e[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Dec 5 21:22:28 2024 +0800

    [Misc][LoRA] Clean up the function interface of Punica (#10917)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 39c89e71a84779c0758ec603efcded7a48bb5fc0[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed Dec 4 22:54:06 2024 -0700

    [Misc] Update llama 3.2 template to support system prompt with images (#10901)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 1f958a7d52b24314e41c4bb56c51b1dce5405e05[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Dec 5 13:20:26 2024 +0800

    [Bugfix] Fix BNB loader target_modules (#10720)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit aa39a8e17537f9127b3da65dba6b33067bfd2f78[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Dec 5 11:19:35 2024 +0800

    [Doc] Create a new "Usage" section (#10827)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 8d370e91cb0049dc150c85710a08e85952504bfc[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Dec 4 22:14:06 2024 -0500

    [Bugfix] Fallback to outlines for complex json schemas (#10899)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 7883c2bbe7d0ab47160d205822f7b188a5a2771b[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Dec 4 17:02:17 2024 -0800

    [benchmark] Make H100 benchmark optional (#10908)

[33mcommit 2a56e1264f3f0f32e25de42c32eac67cbc86a098[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Dec 4 16:54:05 2024 -0800

    [V1] Fix when max_model_len is not divisible by block_size (#10903)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit e4c34c23de2a90ab837772ac182638ac3bc1636d[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Wed Dec 4 22:48:13 2024 +0100

    [CI/Build] improve python-only dev setup (#9621)
    
    Signed-off-by: Daniele Trifir√≤ <dtrifiro@redhat.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 82eb5ea8f3bd3aabbe5c2fd43e37d263768603c5[m
Author: Chendi.Xue <chendi.xue@intel.com>
Date:   Wed Dec 4 15:28:21 2024 -0600

    Benchmark serving structured output (#10880)
    
    Signed-off-by: Chendi Xue <chendi.xue@intel.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 10398b4706ee71d0bddc32c1d33b11e73df12a27[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Thu Dec 5 02:11:08 2024 +0800

    [Model] Consolidate ViTs attention implementation without mask (#10893)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 01d079fd8e65ed9a243ebbf6b771393607942907[m
Author: Xin Yang <105740670+xyang16@users.noreply.github.com>
Date:   Wed Dec 4 09:40:16 2024 -0800

    [LoRA] Change lora_tokenizers capacity (#10796)
    
    Signed-off-by: Xin Yang <xyang19@gmail.com>

[33mcommit c92acb9693c0504d7dabed2a0251b9f5d4ddaebb[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Dec 4 01:01:20 2024 -0800

    [ci/build] Update vLLM postmerge ECR repo (#10887)

[33mcommit 8db957ee3a8234574430d9e570e520501d8539e9[m
Author: jianzheng <57654625+o2363286@users.noreply.github.com>
Date:   Wed Dec 4 16:48:22 2024 +0800

    [bugfix] fixed parameter ‚Äún‚Äù when set parameter ‚Äúbestof‚Äù > 1 (#10854)
    
    Signed-off-by: jianzheng <57654625+o2363286@users.noreply.github.com>

[33mcommit c9ca4fce3f48e27801e1bad03d4bc0b963567d24[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Dec 3 23:02:40 2024 -0800

    [ci/build] Job to build and push release image (#10877)

[33mcommit fa2dea61df9bb3fa3dbd081f42f464c45e3db5b2[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Dec 3 23:02:16 2024 -0800

    [ci/build] Change queue name for Release jobs (#10875)

[33mcommit b5b647b084de3a5a29d35ca527c9901f8e6a4e7e[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Wed Dec 4 12:32:21 2024 +0800

    Drop ROCm load format check (#10767)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit d2bd88b1226fc93ba42cdcba51daff5e026343f0[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Dec 3 22:23:21 2024 -0500

    [CI/Build] Replace mean with torch.all in test_pynccl.py (#10876)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 381ac93bb5a41347a025367bc58119cb45357095[m
Author: Chendi.Xue <chendi.xue@intel.com>
Date:   Tue Dec 3 18:21:06 2024 -0600

    [Benchmark] Benchmark structured output with datasets (#10557)
    
    Signed-off-by: Aaron Pham <contact@aarnphm.xyz>
    Signed-off-by: Chendi Xue <chendi.xue@intel.com>
    Co-authored-by: Aaron Pham <contact@aarnphm.xyz>

[33mcommit a061fe601eb165f11a4808b3ab1ac57d99e0d84e[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Tue Dec 3 15:47:55 2024 -0500

    [Build][Bugfix] Using the correct type hint (#10866)
    
    Signed-off-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>

[33mcommit 7c32b6861e20b6521959b6cc1ce7ccc84614974d[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Tue Dec 3 21:13:31 2024 +0200

    [Frontend] correctly record prefill and decode time metrics  (#10853)
    
    Signed-off-by: Tomer Asida <tomera@ai21.com>

[33mcommit 7090c27bb2cb0d9c4e0acd644e484291df3aff2a[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Dec 3 13:32:21 2024 -0500

    [Bugfix] Only require XGrammar on x86 (#10865)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 2f2cdc745a7a569637c58cfd5f6789c1d0741c84[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Wed Dec 4 01:16:31 2024 +0800

    [MISC][XPU] quick fix for XPU CI (#10859)
    
    Signed-off-by: yan ma <yan.ma@intel.com>

[33mcommit 3bc94cab695387eb16be90b6368029f56ce5dbc7[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Tue Dec 3 05:33:10 2024 -0500

    [V1] VLM - Run the mm_mapper preprocessor in the frontend process (#10640)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit f6084f63248a89df52bed9d9c24d6604f87e51f3[m
Author: Yang Zheng <50227060+zhengy001@users.noreply.github.com>
Date:   Tue Dec 3 17:01:39 2024 +0800

    [Speculative Decoding] Move indices to device before filtering output (#10850)
    
    Co-authored-by: Yang Zheng(SW)(Alex) <you@example.com>

[33mcommit 9323a3153b20d4a2ca7ac04a2784609d6ce656e0[m
Author: Aaron Pham <contact@aarnphm.xyz>
Date:   Tue Dec 3 02:17:00 2024 -0500

    [Core][Performance] Add XGrammar support for guided decoding and set it as default (#10785)
    
    Signed-off-by: Aaron Pham <contact@aarnphm.xyz>
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit 3257d449fa0fd3e05aa20cc8c5fff79ad101984f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Dec 3 14:52:57 2024 +0800

    [Misc] Remove deprecated names (#10817)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit ef51831ee8dbd64833b25e042d4e984d169202f9[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Dec 3 01:46:07 2024 -0500

    [Doc] Add github links for source code references (#10672)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit dc5ce861bf0e10fc002384859b93b1eebbd70933[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 2 22:19:02 2024 -0800

    [torch.compile] remove compilation_context and simplify code (#10838)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 21fe7b481a3a84dc9ebe2497ec89a17002ad52c5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 2 20:53:23 2024 -0800

    [core][distributed] add pynccl broadcast (#10843)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit a4cf2561599448d4a5c3de4d79c73ca37cb8d647[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Dec 3 12:10:29 2024 +0800

    [Bugfix] Fix QKVParallelLinearWithShardedLora bias bug (#10844)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit d746268e92dc97d3a816c70637e20073eeac5103[m
Author: zixuanzhang226 <zixuanzhang@bytedance.com>
Date:   Mon Dec 2 19:06:41 2024 -0800

    [Model] support bitsandbytes quantization with minicpm model (#10842)
    
    Signed-off-by: Ubuntu <zixuanzhang@bytedance.com>

[33mcommit 4433195ab75e2bb367303ba5f34c97521c5677ce[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Dec 2 21:26:15 2024 -0500

    [Bugfix] Prevent benchmark_throughput.py from using duplicated random prompts (#10753)

[33mcommit 4c05edb33ae4ae279421ddf981816d070e8ec37a[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Tue Dec 3 07:06:09 2024 +0800

    [Model] Add TP and BNB quantization support to LlavaMultiModalProjector (#10834)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 9b14d978aa8c286b738f107fab4626273f4fc088[m
Author: Jani Monoses <jani.monoses@gmail.com>
Date:   Mon Dec 2 20:52:19 2024 +0200

    Fix openvino on GPU (#10793)

[33mcommit 519cc6ca12dc89eec35bc2579494e399da33c31a[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Tue Dec 3 01:53:55 2024 +0800

    [Misc][XPU] Avoid torch compile for XPU platform (#10747)
    
    Signed-off-by: yan ma <yan.ma@intel.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit b45f0d79469f583736052b80bfc8b3bab29f50d8[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Dec 3 01:53:36 2024 +0800

    [Misc][LoRA] Move the implementation of lora bias to punica.py (#10829)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit a4c4daf3642ae2629608d5181487739b044fabe8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Dec 2 02:50:10 2024 -0800

    [misc] use out argument for flash attention (#10822)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit e95f275f57bcff44b43e1b4300ae6ea4ee871211[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Dec 2 18:26:10 2024 +0800

    [CI/Build] Update `mistral_common` version for tests and docs (#10825)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit ef31eabc68099ff2f64bbe5f42dc06101451a18d[m
Author: zhou fan <1247714429@qq.com>
Date:   Mon Dec 2 13:36:36 2024 +0800

    [Model]: add some tests for aria model (#10770)
    
    Signed-off-by: xffxff <1247714429@qq.com>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 995a148575aaacc7889ff0d29a96195c329422ab[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Mon Dec 2 12:14:45 2024 +0800

    [doc]Update config docstring (#10732)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit 63a164172dbcc43857dbcf6443a7594faa143151[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Dec 1 19:27:13 2024 -0800

    [misc] remove xverse modeling file (#10814)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit e25810ae29058299b7bf845c7ed572f2474a1d85[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Sun Dec 1 23:05:32 2024 -0300

    Fill TorchSDPAAttentionMetadata seq_lens_field for prefill (#10799)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>

[33mcommit 073a4bd1c04164af29843cb5478740e9839d2d8a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 1 17:55:39 2024 -0800

    [Kernel] Use `out` arg in flash_attn_varlen_func (#10811)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit b7954776fd338cab442a8004d240f7fe74e4e51b[m
Author: cduk <19917266+cduk@users.noreply.github.com>
Date:   Mon Dec 2 02:49:48 2024 +0100

    [core] Avoid metrics log noise when idle - include speculative decodi‚Ä¶ (#10809)

[33mcommit b18c9bbaba6e1c6dfb92fe52e5a6cb22dd6bfa81[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Mon Dec 2 09:31:09 2024 +0800

    [Model] Add BNB support to Llava and Pixtral-HF (#10795)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 0590ec3fd9857063c43c80df281e24c16c51b2ec[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Sun Dec 1 19:01:00 2024 -0600

    [Core] Implement disagg prefill by StatelessProcessGroup (#10502)
    
    This PR provides initial support for single-node disaggregated prefill in 1P1D scenario.
    Signed-off-by: KuntaiDu <kuntai@uchicago.edu>
    Co-authored-by: ApostaC <yihua98@uchicago.edu>
    Co-authored-by: YaoJiayi <120040070@link.cuhk.edu.cn>

[33mcommit c11f172187b6f44710e1f011ca8bff923ce49a7f[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Dec 1 00:47:05 2024 -0800

    [Misc] Adding `MMMU-Pro` vision dataset to serving benchmark (#10804)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Chen Zhang <zhangch99@outlook.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 169a0ff911134b930adc0afc0d8c6f370091e10d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Dec 1 00:41:38 2024 -0800

    [doc] add warning about comparing hf and vllm outputs (#10805)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d2f058e76c2a28d2109e163dc1123ead6983943c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Dec 1 14:36:51 2024 +0800

    [Misc] Rename embedding classes to pooling (#10801)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit f877a7d12a0490705e6bea0987c89548d1a015ea[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Dec 1 09:48:35 2024 +0800

    [Misc] Improve type annotations for `support_torch_compile` (#10763)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 133707123e730a3544875d432a9435bdfe5e34cf[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Dec 1 08:02:54 2024 +0800

    [Model] Replace embedding models with pooling adapter (#10769)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 7e4bbda5735eaca3ce01860b8168feed32e339f4[m
Author: wangxiyuan <wangxiyuan1007@gmail.com>
Date:   Sat Nov 30 19:38:40 2024 +0800

    [doc] format fix (#10789)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit e7cfc4ef4cc017e0a0229adff9f4b143b38fb421[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Sat Nov 30 08:45:50 2024 +0100

    [Interleaved ATTN] Support for Mistral-8B (#10591)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 16ee07f22ade57eb882b3c16ad3a6944635996df[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sat Nov 30 12:19:14 2024 +0800

    [Model] Refactor Molmo weights loading to use AutoWeightsLoader (#10771)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 40bc242579d260e6da7614e1494cbd80a6f985b2[m
Author: Nicol√≤ Lucchesi <nlucches@redhat.com>
Date:   Sat Nov 30 05:07:13 2024 +0100

    [Bugfix] Fix OpenVino/Neuron `driver_worker` init (#10779)
    
    Signed-off-by: NickLucche <nlucches@redhat.com>
    Signed-off-by: Cyrus Leung <tlleungac@connect.ust.hk>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit 661175bc826f4caba04182a1faeeca9e7a3259ac[m
Author: wangxiyuan <wangxiyuan@huawei.com>
Date:   Fri Nov 29 23:22:21 2024 +0800

    [platform] Add verify_quantization in platform. (#10757)
    
    Signed-off-by: wangxiyuan <wangxiyuan1007@gmail.com>

[33mcommit 3132aac04326286ae996bf0887e920096b2bb210[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Fri Nov 29 21:56:46 2024 +0800

    [Bugfix] Fix Idefics3 bug (#10778)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit c82b432d4a40fd6376a35fd38cb5fc37e9c53798[m
Author: wang.yuqi <noooop@126.com>
Date:   Fri Nov 29 13:17:57 2024 +0800

    [Misc] typo find in sampling_metadata.py (#10740)

[33mcommit fa6ecb9aa7a55a99f87fdec7a75011f87af2176c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 29 12:47:06 2024 +0800

    [Model] Clean up MiniCPMV (#10751)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit c83919c7a6bd47bb452321f08017ef5a5cdd553a[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Nov 29 01:29:04 2024 +0800

    [Model] Add Internlm2 LoRA support (#5064)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 98f47f2a4032f8c395268de80858c64ffcfc60fa[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 28 09:01:02 2024 -0800

    [V1] Optimize the CPU overheads in FlashAttention custom op (#10733)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 8c1e77fb585c4f42783a3d88c1efc7c9e15fd89f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 28 08:31:28 2024 -0800

    [Kernel] Update vllm-flash-attn version to reduce CPU overheads (#10742)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 5fc5ce0fe45f974fc8840175e8321652238400f0[m
Author: sixgod <evethwillbeok@outlook.com>
Date:   Thu Nov 28 22:53:31 2024 +0800

    [Model] Added GLM-4 series hf format model support vllm==0.6.4 (#10561)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit 3ed5e7314667f0a9c0c47e6d635ac82fd93296a2[m
Author: Richard Liu <39319471+richardsliu@users.noreply.github.com>
Date:   Thu Nov 28 02:30:48 2024 -0800

    [TPU] Update requirements-tpu (#10726)
    
    Signed-off-by: Richard Liu <ricliu@google.com>

[33mcommit 9a8bff028595d1c5c52bc225013908ca7a7b66d8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 28 02:25:59 2024 -0800

    [Kernel] Update vllm-flash-attn version (#10736)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit a79b1224005836bdf0ab6d3bab807d2f5d8a5ef1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 28 00:13:15 2024 -0800

    [V1] Do not allocate beyond the max_model_len (#10730)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit d9b4b3f069a9f602b067a5bb3efe57b106d39c09[m
Author: Ricky Xu <rickyx@anyscale.com>
Date:   Wed Nov 27 23:59:28 2024 -0800

    [Bug][CLI] Allow users to disable prefix caching explicitly (#10724)
    
    Signed-off-by: rickyx <rickyx@anyscale.com>

[33mcommit 278be671a355ea89843141928a426a303bfd8036[m
Author: ÁΩóÊ≥ΩËΩ© <spacewanderlzx@gmail.com>
Date:   Thu Nov 28 15:58:39 2024 +0800

    [Doc] Update model in arch_overview.rst to match comment (#10701)
    
    Signed-off-by: spacewander <spacewanderlzx@gmail.com>

[33mcommit 70dc14fbd09d054ff75850036b81212ca67e5275[m
Author: zixuanzhang226 <zixuanzhang@bytedance.com>
Date:   Wed Nov 27 23:58:02 2024 -0800

    [Model] support bitsandbytes quantization with minicpm3 model (#10682)
    
    Signed-off-by: Ubuntu <zixuanzhang@bytedance.com>

[33mcommit cb4e1c3f3aee507130b64c9bacf5778ed265785d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 27 19:54:58 2024 -0800

    [misc] upgrade filelock version (#10731)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 395b1c74543053ebf25d4ab3af828cd145506caa[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Wed Nov 27 23:21:10 2024 +0200

    [Frontend] don't block event loop in tokenization (preprocess) in OpenAI compatible server (#10635)
    
    Signed-off-by: Tomer Asida <tomera@ai21.com>

[33mcommit 9b4b150395d509a35031e58fb6e0f3331b532055[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Nov 28 03:05:29 2024 +0800

    [Bugfix] Ignore `lm_head` when loading embedding models (#10719)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 197b4484a3fba4a98921f903d6242677f97c63db[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Wed Nov 27 21:02:27 2024 +0200

    [Bugfix][Mamba] Fix Multistep on Mamba-like models (#10705)
    
    Signed-off-by: mzusman <mor.zusmann@gmail.com>

[33mcommit b98c62ba4947b93673c522b13464854acf8090a4[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Thu Nov 28 02:43:17 2024 +0800

    [Bugfix] Fix GGUF inference with FP16 unquantized checkpoint (#10675)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit c411def234b0e85a349c8d95b5f32eade4aa1ed6[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 27 10:16:10 2024 -0800

    [torch.compile] fix shape specialization (#10722)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 308cc5e21e12fb0eea0a960d147dca7efc59d92f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 27 09:26:14 2024 -0800

    [ci] fix slow tests (#10698)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 9e0a147d502758ed31b35df1361e37ea6bacd4a0[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Nov 27 04:26:27 2024 -0800

    [V1] Update interface for mistral-format Pixtral (#10703)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 418cb3b93fbf85f0735b5c0ed3f62d4b36808968[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Wed Nov 27 19:55:38 2024 +0800

    [Bugfix][Hardware][CPU] Fix intel-omp version to avoid segfault (#10700)
    
    Signed-off-by: jiang1.li <jiang1.li@intel.com>

[33mcommit 1209261e937f7cc5a933da48d625d17e6ee8eea9[m
Author: shunxing12345 <168084185+shunxing12345@users.noreply.github.com>
Date:   Wed Nov 27 19:32:35 2024 +0800

    [Model] Support telechat2 (#10311)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: xiangw2 <xiangw2@chinatelecom.cn>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit e2251109c746f0d08ab9b37b5abcf44ca105d426[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Nov 27 01:55:32 2024 -0500

    [Kernel] Remove if-else with identical branches in marlin 2:4 (#10687)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 15cc2a9f1acb70b68366da0a6d2a4549da3d32f4[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Nov 27 14:54:12 2024 +0800

    [Misc]Further  reduce BNB static variable (#10597)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit e85250b1d164c9975816fa7aaf591aa5abad577d[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Wed Nov 27 14:49:40 2024 +0800

    [Hardware][Gaudi]add get_name method for HPUAttentionBackend (#10667)
    
    Signed-off-by: Kunshang Ji <kunshang.ji@intel.com>

[33mcommit cfb3bf25fb981494fa6c575fb0714388c9df99b0[m
Author: yansh97 <yansh97@foxmail.com>
Date:   Wed Nov 27 13:55:23 2024 +0800

    [bugfix] fix the default value of llm_int8_threshold in BitsAndBytesConfig (#10657)

[33mcommit 1bf905ddaa969e6458fe0d15a1db80318f39fade[m
Author: jeongin601 <78595701+jeongin601@users.noreply.github.com>
Date:   Wed Nov 27 14:07:30 2024 +0900

    [Bugfix][SpecDecode] apply sampling parameters to target probabilities for consistency in rejection sampling. (#10198)
    
    Signed-off-by: jeongin601 <0200angela@gmail.com>
    Signed-off-by: jeong_in.bae <jeong_in.bae@navercorp.com>

[33mcommit 0a4d96850013eb2c295b25df53177ad2302110ca[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Nov 26 18:04:01 2024 -0800

    [V1] Update interface for idefics3 (#10680)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 0a71900bc92b4a18d5545e9d5dc0ca750add3c69[m
Author: Chendi.Xue <chendi.xue@intel.com>
Date:   Tue Nov 26 19:57:11 2024 -0600

    Remove hard-dependencies of Speculative decode to CUDA workers (#10587)
    
    Signed-off-by: Chendi Xue <chendi.xue@intel.com>

[33mcommit 2f0a0a17a47436fe9709462dfee3bb9d2f91e0a0[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Nov 26 12:46:11 2024 -0800

    [V1] Refactor model executable interface for multimodal models (#10570)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 7576cd38dfdf1672d04f4fe659f8260a9d319e8b[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Nov 26 15:29:00 2024 -0500

    [Bugfix] Check bnb_4bit_quant_storage for bitsandbytes (#10642)

[33mcommit 9a99273b482a3e90431069f37858d60827983e2f[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Nov 26 13:44:01 2024 -0500

    [Bugfix] Fix using `-O[0,3]` with LLM entrypoint (#10677)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit f5792c7c4a63ecdd2dcaa068ac7986dc4a22436b[m
Author: Conroy Cheers <conroy@corncheese.org>
Date:   Wed Nov 27 05:26:28 2024 +1100

    [Hardware][NVIDIA] Add non-NVML CUDA mode for Jetson (#9735)
    
    Signed-off-by: Conroy Cheers <conroy@corncheese.org>

[33mcommit db66e018eaabcc5e5855e994b49931dbb4800ce1[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Tue Nov 26 09:11:16 2024 -0800

    [Bugfix] Fix for Spec model TP + Chunked Prefill (#10232)
    
    Signed-off-by: andoorve <37849411+andoorve@users.noreply.github.com>
    Signed-off-by: Sourashis Roy <sroy@roblox.com>
    Co-authored-by: Sourashis Roy <sroy@roblox.com>

[33mcommit 1f6584ee851501cfae672973b9e55d000729818c[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Tue Nov 26 18:36:45 2024 +0800

    [V1] Enable profile for LLMEngine (#10665)

[33mcommit 334d64d1e816cc7c9fa2f67e22d24638e63c8e15[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 26 00:20:04 2024 -0800

    [ci] add vllm_test_utils (#10659)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 940635343a087a5fb6548449989b84de77af5e73[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Nov 26 14:55:00 2024 +0800

    [Misc] Remove outdated init protocols (#10655)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 9a88f897993a83fad79d1bf6b95595be25a8d68a[m
Author: Sage Moore <sage@neuralmagic.com>
Date:   Tue Nov 26 00:00:16 2024 -0600

    custom allreduce + torch.compile (#10121)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 519e8e4182af8e25d78b062ba5e613df661e6e5d[m
Author: Ricky Xu <rickyx@anyscale.com>
Date:   Mon Nov 25 21:09:43 2024 -0800

    [v1] EngineArgs for better config handling for v1 (#10382)
    
    Signed-off-by: rickyx <rickyx@anyscale.com>

[33mcommit a6760f6456b714409685e23301c820a85da856ca[m
Author: Sanket Kale <sanket.kale@fujitsu.com>
Date:   Tue Nov 26 08:02:39 2024 +0530

    [Feature] vLLM ARM Enablement for AARCH64 CPUs (#9228)
    
    Signed-off-by: Sanket Kale <sanketk.kale@fujitsu.com>
    Co-authored-by: Sanket Kale <sanketk.kale@fujitsu.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit 45ac4ff270b267765457159c0b75e1bb7ebf6d79[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 25 18:32:09 2024 -0800

    [bugfix] fix aria model and add torch.compile (#10645)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 6e9ff050c8e83ad6d5e5eab621e83549e35933a1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 25 17:04:50 2024 -0800

    [misc] do not read HOST_IP (#10644)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 9db713a1dca7e1bc9b6ecf5303c63c7352c52a13[m
Author: Shane A <shanea@allenai.org>
Date:   Mon Nov 25 14:26:40 2024 -0800

    [Model] Add OLMo November 2024 model (#10503)

[33mcommit 1b583cfefad4ffa030bda1c1265aec6e7755a6d2[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Nov 26 02:15:45 2024 +0800

    [Doc] Fix typos in docs (#10636)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit cf73f0c95e09836efff876d5bfd9b9c6cc1ba06e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Nov 26 02:14:33 2024 +0800

    [Model] Enable optional prefix when loading embedding models (#10639)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit b1d920531f6d5fd6c020096499c91a8f26620cd6[m
Author: zhou fan <1247714429@qq.com>
Date:   Tue Nov 26 02:10:55 2024 +0800

    [Model]: Add support for Aria model (#10514)
    
    Signed-off-by: xffxff <1247714429@qq.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 452a4e80c3dfc6596cd89c7a87dfb7036bab8acd[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Nov 25 09:34:46 2024 -0800

    [Docs] Add Snowflake Slides (#10641)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit c27df94e1ff98551b987b40bb2049bf4640e202a[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Mon Nov 25 14:23:32 2024 -0300

    [Bugfix] Fix chunked prefill with model dtype float32 on Turing Devices (#9850)
    
    Signed-off-by: Wallas Santos <wallashss@ibm.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit d04b13a380da422afa1883efc81e0d4c4b18d091[m
Author: Chauncey <chaunceyjiang@gmail.com>
Date:   Tue Nov 26 00:21:41 2024 +0800

    [Bug]: Authorization ignored when root_path is set (#10606)
    
    Signed-off-by: chaunceyjiang <chaunceyjiang@gmail.com>

[33mcommit 2b0879bfc273a08d339b952890c4e88e77f0a014[m
Author: fzyzcjy <5236035+fzyzcjy@users.noreply.github.com>
Date:   Mon Nov 25 21:08:30 2024 +0800

    Super tiny little typo fix (#10633)

[33mcommit ed46f143212203b7afcbc8538119b6e8155c643e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Nov 25 17:51:20 2024 +0800

    [Model] Support `is_causal` HF config field for Qwen2 model (#10621)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 05d1f8c9c64b4458ae7cee2650eb97498146ee50[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 25 01:27:30 2024 -0800

    [misc] move functions to config.py (#10624)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 25d806e95391a8556deb69bdb214714425f776c9[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Nov 24 23:40:08 2024 -0800

    [misc] add torch.compile compatibility check (#10618)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 65813781a2e2e76d18741601afe66b870a90a717[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Nov 24 23:27:51 2024 -0800

    [torch.compile] add warning for unsupported models (#10622)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 7c2134beda9a4f72c71c4faffcca22cebd4e1c3c[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Mon Nov 25 15:04:21 2024 +0800

    [torch.compile] force inductor threads (#10620)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit a30a605d214e051c31057f8c0cb948c841a2f743[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Nov 25 14:34:07 2024 +0800

    [Doc] Add encoder-based models to Supported Models page (#10616)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 571841b7fcc67f8b1d171522f6249ed4224033e1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Nov 24 21:24:33 2024 -0800

    [torch.compile] support encoder based models (#10613)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 7ea3cd7c3e9fa1db06cdf8ad1973237b061b7d64[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Mon Nov 25 13:14:56 2024 +0800

    [Refactor][MISC] del redundant code in ParallelConfig.postinit (#10614)
    
    Signed-off-by: MengqingCao <cmq0113@163.com>

[33mcommit 214efc2c3cb568e8eb3f7d234f3bd8f5bbe24795[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Sun Nov 24 23:56:20 2024 -0300

    Support Cross encoder models (#10400)
    
    Signed-off-by: Max de Bayser <maxdebayser@gmail.com>
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
    Signed-off-by: Flavia Beo <flavia.beo@ibm.com>
    Co-authored-by: Flavia Beo <flavia.beo@ibm.com>

[33mcommit 49628fe13e1021ce036bbae257242ab71e40aa25[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Nov 24 16:45:09 2024 -0800

    [Doc] Update README.md with Ray Summit talk links (#10610)

[33mcommit e4fbb1441454847fdd871c9959b5cb05b5037aa2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Nov 24 11:21:40 2024 -0800

    [doc] update the code to add models (#10603)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit c055747867e771dbc791c9aa3c394c4d4489cd82[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 23 22:22:54 2024 -0800

    [model][utils] add extract_layer_index utility function (#10599)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit eda2b3589c8b27a9b8f8aea24afe1673890d19d2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 23 21:31:47 2024 -0800

    Revert "Print running script to enhance CI log readability" (#10601)

[33mcommit 1c445dca51a877ac6a5b7e03ecdb73e0e34d139e[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Nov 24 11:57:13 2024 +0800

    [CI/Build] Print running script to enhance CI log readability (#10594)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 1700c543a556e669e559c369a36c0a0d36a8de19[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Nov 24 09:23:17 2024 +0800

    [Bugfix] Fix LoRA weight sharding (#10450)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 17d8fc1806c61e3f859a45b69be9f8dccf9a5fcc[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Nov 24 09:22:33 2024 +0800

    [bugfix] Fix example/tensorize_vllm_model tests (#10595)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 04668ebe7a35b69f1d2f8b04ef255bb16c8d2a01[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sun Nov 24 02:12:20 2024 +0800

    [Bugfix] Avoid import AttentionMetadata explicitly in Mllama (#10593)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 651f6c31ac86f29aa72fa682ef6c34349bcc75db[m
Author: Nishidha <nishidha.panpaliya@partner.ibm.com>
Date:   Sat Nov 23 15:03:53 2024 +0530

    For ppc64le, disabled tests for now and addressed space issues (#10538)

[33mcommit 86a44fb8967f757b0701aaa33aeaa8a431714a27[m
Author: JiHuazhong <hzji210@gmail.com>
Date:   Sat Nov 23 14:23:12 2024 +0800

    [Platforms] Refactor openvino code (#10573)
    
    Signed-off-by: statelesshz <hzji210@gmail.com>

[33mcommit 4cfe5d2bcafe1f47d1df046e6788ebbe038eaf3f[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Sat Nov 23 13:25:46 2024 +0800

    [Bugfix] `multi_modal_kwargs` broadcast for CPU tensor parallel (#10541)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit c8acd80548c77bd5d6302353708dd16ea705f031[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Nov 23 13:25:09 2024 +0800

    [2/N] handling placeholders in merged multi-modal processor (#10485)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 4634a89d18569ef0ee2d7dd2d535377a1f460188[m
Author: Ricky Xu <rickyx@anyscale.com>
Date:   Fri Nov 22 21:15:55 2024 -0800

    Prefix Cache Aware Scheduling [1/n] (#10128)
    
    Signed-off-by: rickyx <rickyx@anyscale.com>

[33mcommit 7c25fe45a6ef4fb5be148217cc7110e88e186446[m
Author: kliuae <17350011+kliuae@users.noreply.github.com>
Date:   Sat Nov 23 13:14:49 2024 +0800

    [AMD] Add support for GGUF quantization on ROCm (#10254)

[33mcommit 02a43f82a97e37581b48f1c177d3393aca4fe3f2[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sat Nov 23 00:14:19 2024 -0500

    Update default max_num_batch_tokens for chunked prefill to 2048 (#10544)

[33mcommit cfea9c04ef43420be594f23fc1773009d1fe88c3[m
Author: Chen Wu <72850361+CNTRYROA@users.noreply.github.com>
Date:   Sat Nov 23 13:13:59 2024 +0800

    [Model] Fix Baichuan BNB online quantization (#10572)
    
    Signed-off-by: Chen Wu <cntryroa@gmail.com>

[33mcommit 7d8ffb344f3b9a571d94073644b829eb4baa0a65[m
Author: Varun Vinayak Shenoy <shenoyvvarun@gmail.com>
Date:   Fri Nov 22 21:13:29 2024 -0800

    [Bugfix] Internal Server Error when tool_choice is incorrect. (#10567)
    
    Signed-off-by: Varun Shenoy <varun.vinayak.shenoy@oracle.com>

[33mcommit 4aba6e3d1a0cc5cec45efdee0adeaa09278f7518[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 22 20:13:54 2024 -0800

    [core] gemma2 full context length support (#10584)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 978b39744b22e90d49a0f5367c3d933ed26d66c8[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Nov 22 22:14:03 2024 -0500

    [Misc] Add pynccl wrappers for all_gather and reduce_scatter (#9432)

[33mcommit ebda51968b12b85c8b5b82727b2b7713dfc44f88[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Nov 22 21:23:51 2024 -0500

    [Core] Fix broken log configuration (#10458)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 9195dbdbcadb681db67181a664521bd6ef98deee[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Fri Nov 22 19:17:38 2024 -0700

    [Bugfix][Frontend] Update Llama Chat Templates to also support Non-Tool use (#10164)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit d559979c548c4bee6eca089d5e6dc318630bf465[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 22 17:34:03 2024 -0800

    [bugfix] fix cpu tests (#10585)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d345f409b7478c0e547b238916ec9e90b6156bbc[m
Author: Zhonghua Deng <abzhonghua@gmail.com>
Date:   Sat Nov 23 09:16:15 2024 +0800

    [V1] EngineCore supports profiling (#10564)
    
    Signed-off-by: Abatom <abzhonghua@gmail.com>

[33mcommit 28598f3939f9a04800f514e7fe62ab9bb8f617ec[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Nov 22 19:22:53 2024 -0500

    [Core] remove temporary local variables in LLMEngine.__init__ (#10577)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 948c859571af9588e344079cc0e79bbf8597cb18[m
Author: zixuanzhang226 <zixuanzhang@bytedance.com>
Date:   Fri Nov 22 16:16:14 2024 -0800

    support bitsandbytes quantization with qwen model (#10549)
    
    Signed-off-by: Ubuntu <zixuanzhang@bytedance.com>

[33mcommit 97814fbf0f847a11d2e0eb339e3e7572ca69379d[m
Author: Ricky Xu <rickyx@anyscale.com>
Date:   Fri Nov 22 15:27:25 2024 -0800

    [v1] Refactor KVCacheManager for more hash input than token ids (#10507)
    
    Signed-off-by: rickyx <rickyx@anyscale.com>
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit eebad39f265606cfe35af4d1e0bea678516648a3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 22 14:04:42 2024 -0800

    [torch.compile] support all attention backends (#10558)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit db100c5cdebc7140b57cbb40b20b5a28d7bff386[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 22 10:02:14 2024 -0800

    [bugfix] fix full graph tests (#10581)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 11fcf0e0661365f24bfff9591434a0cec640df6c[m
Author: Noam Gat <noamgat@gmail.com>
Date:   Fri Nov 22 09:59:47 2024 +0200

    Remove token-adding chat embedding params (#10551)
    
    Signed-off-by: Noam Gat <noamgat@gmail.com>

[33mcommit b6374e09b0af4f8fa4c0b911b3cd1bd45342ead6[m
Author: Isotr0py <mozf@mail2.sysu.edu.cn>
Date:   Fri Nov 22 15:01:56 2024 +0800

    [Bugfix] Fix Phi-3 BNB quantization with tensor parallel (#9948)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit a111d0151ffed94582bec65635979e04e5b63676[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Nov 21 21:00:32 2024 -0800

    [platforms] absorb worker cls difference into platforms folder (#10555)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Nick Hill <nhill@redhat.com>

[33mcommit 446c7806b21d810b90604097487cc87393542aad[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 21 19:40:40 2024 -0800

    [Minor] Fix line-too-long (#10563)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 33e0a2540a6bff23cbc6a4b8f7a6784a2bc87d47[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Nov 21 19:13:31 2024 -0800

    [9/N] torch.compile LLM usage (#10552)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit aed074860a46536faf77bacd76d02efccbaf4a5d[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Nov 21 18:27:20 2024 -0800

    [Benchmark] Add new H100 machine  (#10547)

[33mcommit 9afa01455237892c878bb2810912c487d66149a9[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Nov 21 18:43:43 2024 -0500

    Add small example to metrics.rst (#10550)

[33mcommit 46fe9b46d83e733130ce952eb3967a9c96713583[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 21 13:28:16 2024 -0800

    [Minor] Revert change in offline inference example (#10545)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit cf656f5a022c1ef6f0513c53c5106c8eeff7fdaa[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Nov 21 13:13:17 2024 -0800

    [misc] improve error message (#10553)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit edec3385b641afb22739a6ec0fd0145f8f1141c5[m
Author: Yunmeng <cym103@126.com>
Date:   Fri Nov 22 05:03:58 2024 +0800

    [CI][Installation] Avoid uploading CUDA 11.8 wheel (#10535)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>
    Co-authored-by: simon-mo <simon.mo@hey.com>

[33mcommit f9310cbd0c1109c4f22cf9f1dc615b2d08f06408[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 21 12:53:39 2024 -0800

    [V1] Fix Compilation config & Enable CUDA graph by default (#10528)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 7560ae5cafbae3af9967ac7dc979cb31a40fc572[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Nov 21 12:30:42 2024 -0800

    [8/N] enable cli flag without a space (#10529)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit e7a8341c7c7481a0c797d50ead7a698255ac8a9f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 22 02:09:43 2024 +0800

    [Bugfix] Allow token ID-only inputs in Qwen2-Audio (#10536)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit c51e397fe8db2ef0664814ef3f80e1237c7283da[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Nov 21 09:21:31 2024 -0800

    [Misc] Suppress duplicated logging regarding multimodal input pipeline (#10530)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 2385b60d8300ce730ae67d9ea945f06de9ec4e21[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Fri Nov 22 01:18:11 2024 +0800

    [Kernel] Register punica ops directly (#10522)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit da7e702c6fae521bf8633affb8fe7b834f5cb94b[m
Author: Chauncey <chaunceyjiang@gmail.com>
Date:   Fri Nov 22 00:24:32 2024 +0800

    [Bug]: When apply continue_final_message for OpenAI server, the "echo":false is ignored (#10180)
    
    Signed-off-by: chaunceyjiang <chaunceyjiang@gmail.com>

[33mcommit 4d676f085295d92a9248c4944433b4ade52a8ff3[m
Author: Xiaoyu Zhang <35585791+BBuf@users.noreply.github.com>
Date:   Thu Nov 21 22:40:02 2024 +0800

    [Bugfix] Embedding model pooling_type equals ALL and multi input's bug (#10494)

[33mcommit d5ec121f95f51184acce4e2c27ad8fc01904d3d9[m
Author: Isotr0py <2037008807@qq.com>
Date:   Thu Nov 21 22:20:08 2024 +0800

    [Model] Expose `dynamic_image_size` as mm_processor_kwargs for InternVL2 models (#10518)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 8a93a598d9ac265882e55432e7aef55c8bff23f4[m
Author: Wang, Yi <yi.a.wang@intel.com>
Date:   Thu Nov 21 19:15:36 2024 +0800

    fix the issue that len(tokenizer(prompt)["input_ids"]) > prompt_len (#10524)
    
    Signed-off-by: Wang, Yi A <yi.a.wang@intel.com>

[33mcommit 1cfde82ffd6edfca6029a7e312c848386ea322c1[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Thu Nov 21 03:46:20 2024 -0700

    [Model] Add Support for Multimodal Granite Models (#10291)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit f0e02380169b99a20cc5a4cd1848bbe085b50d5c[m
Author: Zhong Qishuai <FerdinandZhong@gmail.com>
Date:   Thu Nov 21 17:05:23 2024 +0800

    [Doc] fix a small typo in docstring of llama_tool_parser (#10513)

[33mcommit aaddce5d268d2c82d49b0240d6c112ba4941f69e[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 20 23:07:56 2024 -0800

    [platforms] improve error message for unspecified platforms (#10520)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 3430857b641131ffabf215ab569c41696b57b953[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Nov 21 15:06:42 2024 +0800

    [Misc] Increase default video fetch timeout (#10495)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 8b0fe06c890a202eba24d517cc77562e4a8b0d0c[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Thu Nov 21 00:44:57 2024 -0500

    [torch.compile] Inductor code caching fix (#10273)
    
    Signed-off-by: luka <luka@neuralmagic.com>
    Signed-off-by: Luka Govedic <luka.govedic@gmail.com>

[33mcommit 9d827170a3aa586dfb458bf28d18fd279bdbf580[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Thu Nov 21 12:44:20 2024 +0800

    [Platforms] Add `device_type` in `Platform` (#10508)
    
    Signed-off-by: MengqingCao <cmq0113@163.com>

[33mcommit 6c1208d083fbaaf89c6d812f4d3424e15182f652[m
Author: Pavani Majety <pmajety@nvidia.com>
Date:   Wed Nov 20 19:56:47 2024 -0800

    [Core] Add Sliding Window Support with Flashinfer (#10462)
    
    Signed-off-by: Pavani Majety <pmajety@nvidia.com>

[33mcommit 388ee3de665c3055fbe610b66ebeef096a23cfe1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 20 18:36:33 2024 -0800

    [torch.compile] limit inductor threads and lazy import quant (#10482)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 2f77b6cfec32c8054f996aee4b021f511630ea6f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Nov 20 13:54:15 2024 -0800

    [TPU] Implement prefix caching for TPUs (#10307)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit c68f7ede6a4aef0cd31f531b5d7ec22ab224de95[m
Author: Guillaume Calmettes <gcalmettes@scaleway.com>
Date:   Wed Nov 20 22:42:21 2024 +0100

    [Bugfix]: allow extra fields in requests to openai compatible server (#10463)
    
    Signed-off-by: Guillaume Calmettes <gcalmettes@scaleway.com>

[33mcommit 0cd3d9717e38c7a122ed01fe2a8fddd8b37dff4b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 20 11:20:38 2024 -0800

    [7/N] torch.compile, reduce compilation time (#10460)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 5f1d6af2b619b07b2af3151d6aa59f9adc17e1eb[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Nov 20 11:06:56 2024 -0800

    [perf bench] H200 development (#9768)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit 772a66732d0ff58a43dbd1ae79c0d165659aa96d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 20 09:13:28 2024 -0800

    [platforms] restore xpu check for parallel config (#10479)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 63f1fde277d063fbd36ccf43cb709fafca754ed5[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Wed Nov 20 18:57:39 2024 +0800

    [Hardware][CPU] Support chunked-prefill and prefix-caching on CPU (#10355)
    
    Signed-off-by: jiang1.li <jiang1.li@intel.com>

[33mcommit d5b28447e005a79dec417a706900db0dad4e1a47[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Wed Nov 20 14:52:13 2024 +0800

    [Platforms] Refactor xpu code (#10468)
    
    Signed-off-by: MengqingCao <cmq0113@163.com>

[33mcommit 09dbf9ff16410d0f83adcc9705764ea1c7f5f017[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Nov 20 14:45:08 2024 +0800

    [Bugfix] Handle conflicts between modern and legacy fields (#10471)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 343041c4c4db93b4693ba437df7ae8bea485d18e[m
Author: Sky Lee <46676799+skylee-01@users.noreply.github.com>
Date:   Wed Nov 20 14:05:55 2024 +0800

    [model] Reduce medusa weight (#10454)
    
    Signed-off-by: skylee-01 <497627264@qq.com>

[33mcommit ed701ca9637306a44ba8403ba9e85be024e0dafd[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Nov 19 19:36:03 2024 -1000

    [ci/build] Combine nightly and optional (#10465)

[33mcommit 7629a9c6e5e29d60be9ef60e4afb9842effcdc73[m
Author: wchen61 <wchen61@foxmail.com>
Date:   Wed Nov 20 13:35:50 2024 +0800

    [CI/Build] Support compilation with local cutlass path (#10423) (#10424)

[33mcommit 709c9f1f257fd15545ad19b89ed5019cb5ea338b[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Wed Nov 20 00:35:31 2024 -0500

    [CI/Build] Add sphinx/rst linter for docs (#10366)

[33mcommit b4be5a8adba95020187ae3cb43a7db7eef20c0ff[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Nov 20 13:12:51 2024 +0800

    [Bugfix] Enforce no chunked prefill for embedding models (#10470)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit ad44437ba33e8d31962d272be238eeed4a1b4f84[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Nov 20 13:04:05 2024 +0800

    [Bugfix] Fix Mamba model initialization and MLP Speculator weights loading (#10456)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 9e05252b46a92a5d14e4e6fd02b75383c5cf243b[m
Author: Yanyi Liu <wolfsonliu@163.com>
Date:   Wed Nov 20 12:44:57 2024 +0800

    [Misc] Add __setitem__ for LazyDict (#10469)
    
    Signed-off-by: Yanyi Liu <wolfsonliu@163.com>

[33mcommit d200972e7f4969da50f533b46c856c5ff5a9d27d[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Tue Nov 19 22:40:33 2024 -0500

    [Bugfix] Marlin 2:4 temp fix for large M dim (>256) (#10464)
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit d5b68aba2ff6dd17060a62c0cb799c0acedb524f[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Tue Nov 19 19:19:59 2024 -0600

    [CI/Build] Update Dockerfile.rocm (#10434)
    
    Signed-off-by: Alexei V. Ivanov <alexei.ivanov@amd.com>

[33mcommit a324d3a1a74ab0a3fafc0f2d19860bd1d1301a85[m
Author: Maximilien de Bayser <maxdebayser@gmail.com>
Date:   Tue Nov 19 22:16:54 2024 -0300

    Change granite chat template to keep json list formatting for tool calls (#10452)
    
    Signed-off-by: Max de Bayser <maxdebayser@gmail.com>

[33mcommit b00b33d77e33c5516e73de663539dff96e8b61a4[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Tue Nov 19 22:31:12 2024 +0100

    [Model][Quantization] HQQ support through Marlin kernel expansion (#9766)
    
    Signed-off-by: ElizaWszola <eliza@neuralmagic.com>

[33mcommit efa9084628b32787ae1901a2d1e9b80f7d08809b[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Nov 19 16:05:25 2024 -0500

    [Core] Avoid metrics log noise when idle (#8868)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 803f37eaaa11568f65acbf0bcd1044fb9b1610bf[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 19 10:09:03 2024 -0800

    [6/N] torch.compile rollout to users (#10437)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit fd9f124971c58376ca294091951dfcc96cc03474[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Nov 19 12:48:30 2024 -0500

    [Doc] fix link for page that was renamed (#10455)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 1ea291a4173a82c537ab42487e23375be4926d30[m
Author: Manjul Mohan <49657164+mikejuliet13@users.noreply.github.com>
Date:   Tue Nov 19 23:04:57 2024 +0530

    Fix: Build error seen on Power Architecture (#10421)
    
    Signed-off-by: Manjul Mohan <manjul.mohan@ibm.com>
    Signed-off-by: B-201 <Joy25810@foxmail.com>
    Signed-off-by: Isotr0py <2037008807@qq.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Signed-off-by: ismael-dm <ismaeldm99@gmail.com>
    Signed-off-by: Andrew Nesbitt <andrewnez@gmail.com>
    Signed-off-by: mgoin <michael@neuralmagic.com>
    Signed-off-by: yan ma <yan.ma@intel.com>
    Signed-off-by: Angus Wang <wangjadehao@gmail.com>
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>
    Signed-off-by: rickyx <rickyx@anyscale.com>
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Signed-off-by: Mengqing Cao <cmq0113@163.com>
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>
    Co-authored-by: Manjul Mohan manjul.mohan@ibm.com <manjulmohan@ltcd97-lp2.aus.stglabs.ibm.com>
    Co-authored-by: B-201 <Joy25810@foxmail.com>
    Co-authored-by: Isotr0py <2037008807@qq.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: ismael-dm <ismaeldm99@gmail.com>
    Co-authored-by: Andrew Nesbitt <andrewnez@gmail.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>
    Co-authored-by: Yan Ma <yan.ma@intel.com>
    Co-authored-by: Angus Wang <wangjadehao@gmail.com>
    Co-authored-by: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
    Co-authored-by: Ricky Xu <rickyx@anyscale.com>
    Co-authored-by: Kevin H. Luu <kevin@anyscale.com>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>
    Co-authored-by: Mengqing Cao <cmq0113@163.com>
    Co-authored-by: Travis Johnson <tsjohnso@us.ibm.com>
    Co-authored-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 11fd7ea639cf3c4fae29322d8e5c839ff6f8a1ca[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Tue Nov 19 18:33:06 2024 +0100

    [Pixtral-Large] Pixtral actually has no bias in vision-lang adapter (#10449)

[33mcommit f028dff33d3d0b0dfe71e0e0354b355b8232a4ec[m
Author: COSMOPlat <lixiyuan@haier.com>
Date:   Tue Nov 19 21:42:50 2024 +0800

    [BugFix] Fix hermes tool parser output error stream arguments in some cases (#10395) (#10398)
    
    Signed-off-by: xiyuan lee <lixiyuan@haier.com>

[33mcommit b4614656b832aa8ac95e5450ca7b861f46049635[m
Author: Yuan <yuan.zhou@intel.com>
Date:   Tue Nov 19 21:16:43 2024 +0800

    [CI][CPU] adding numa node number as container name suffix (#10441)
    
    Signed-off-by: Yuan Zhou <yuan.zhou@intel.com>

[33mcommit 25f9c78961daae10b9084d78901d71bc56691aa1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 19 02:43:21 2024 -0800

    [misc][plugin] improve plugin loading (#10443)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 5390d6664f65d84f37a5fb524e967b01baad9100[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Nov 19 04:52:11 2024 -0500

    [Doc] Add the start of an arch overview page (#10368)

[33mcommit 382b6a4852b9afc9a740b02736688e20f7d58446[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Nov 19 16:54:58 2024 +0800

    [Misc] Avoid misleading warning messages (#10438)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 272e31c0bd8640c15e85211c74fc9b428ad86902[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Mon Nov 18 21:57:10 2024 -0700

    [Bugfix] Guard for negative counter metrics to prevent crash (#10430)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 74f8c2cf5f6a34fd21cfbe6d72bcc1b2a2a6754a[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Nov 18 23:37:46 2024 -0500

    Add openai.beta.chat.completions.parse example to structured_outputs.rst (#10433)

[33mcommit 8c1fb507052d385d94ac49a7388fd6db5d0069e7[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Tue Nov 19 11:22:26 2024 +0800

    [Platform][Refactor] Extract func `get_default_attn_backend` to `Platform` (#10358)
    
    Signed-off-by: Mengqing Cao <cmq0113@163.com>

[33mcommit 7eb719df13cf8059485f52648a6a115700158301[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Nov 19 11:21:42 2024 +0800

    [Bugfix]Fix Phi-3 BNB online quantization    (#10417)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 284203f171d86a9581295436d6175246215437fd[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Nov 18 15:04:25 2024 -1000

    [ci/build] Have dependabot ignore all patch update (#10436)
    
    We have too many dependencies and all patch updates can be a little noisy. This is to have dependabot ignore all patch version updates.

[33mcommit 90a6c759caf84ff7722449a33895e397ccf1a2af[m
Author: Ricky Xu <rickyx@anyscale.com>
Date:   Mon Nov 18 15:39:14 2024 -0800

    [misc] partial prefix & random input generation benchmark (#9929)
    
    Signed-off-by: rickyx <rickyx@anyscale.com>

[33mcommit 2298e69b5f1dc77f00aee687a3843a4dae12cb91[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 18 15:29:37 2024 -0800

    [ci][bugfix] fix kernel tests (#10431)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit a03ea40792201ac8ff547d37d9f9255b347b9ccd[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 18 15:14:59 2024 -0800

    [3/N][torch.compile] consolidate custom op logging (#10399)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 96d999fbe8d610fa4c5b7cad6bb0d0158d1d5b8b[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Mon Nov 18 14:59:29 2024 -0500

    [Kernel] Initial Machete W4A8 support + Refactors (#9855)
    
    Signed-off-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit c2170a5b395acb9f5f4ce8425c3be18aacb67513[m
Author: Angus Wang <wangjadehao@gmail.com>
Date:   Mon Nov 18 11:39:40 2024 -0800

    [Kernel] Explicitly specify other value in tl.load calls (#9014)
    
    Signed-off-by: Angus Wang <wangjadehao@gmail.com>

[33mcommit 6b2d25efc78f21867ca37e3f707c5a94f906478f[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Tue Nov 19 02:18:05 2024 +0800

    [Hardware][XPU] AWQ/GPTQ support for xpu backend (#10107)
    
    Signed-off-by: yan ma <yan.ma@intel.com>

[33mcommit 281cc4b3cd2f6c84c2cd8272ef83d97edd1c323a[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Nov 18 13:04:14 2024 -0500

    [Model][Bugfix] Support TP for PixtralHF ViT (#10405)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 4f686d139f6acb31ea31eaf57ed1bb3920a77682[m
Author: Andrew Nesbitt <andrewnez@gmail.com>
Date:   Mon Nov 18 17:52:42 2024 +0000

    Fix open_collective value in FUNDING.yml (#10426)
    
    Signed-off-by: Andrew Nesbitt <andrewnez@gmail.com>

[33mcommit 31894a21559436f4a9d72f751e8bd7ba4ab18613[m
Author: ismael-dm <ismaeldm99@gmail.com>
Date:   Mon Nov 18 18:52:12 2024 +0100

    [Doc] Add documentation for Structured Outputs (#9943)
    
    Signed-off-by: ismael-dm <ismaeldm99@gmail.com>

[33mcommit 7851b45196aff994277ec832c0cf5bec0073f08e[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 18 07:20:06 2024 -0800

    [5/N][torch.compile] torch.jit.script --> torch.compile (#10406)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 4186be8111e20c64d0cbcbdebbdd1081e77f1075[m
Author: B-201 <Joy25810@foxmail.com>
Date:   Mon Nov 18 23:08:30 2024 +0800

    [Doc] Update doc for LoRA support in GLM-4V (#10425)
    
    Signed-off-by: B-201 <Joy25810@foxmail.com>

[33mcommit e7ebb662d777a9617644428031c1cf80c38939ba[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Nov 18 21:45:21 2024 +0800

    [Model] Remove transformers attention porting in VITs (#10414)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 5be4e52b6522113f7276e60b32cb5c1f912de6fd[m
Author: B-201 <Joy25810@foxmail.com>
Date:   Mon Nov 18 20:57:10 2024 +0800

    [Model][LoRA]LoRA support added for glm-4v (#10418)
    
    Signed-off-by: B-201 <Joy25810@foxmail.com>

[33mcommit 01aae1cc68d6013dd91e87418a6d82fa02c58457[m
Author: Maybewuss <38156589+Maybewuss@users.noreply.github.com>
Date:   Mon Nov 18 18:05:36 2024 +0800

    [Model] Remove redundant  softmax when using PoolingType.STEP (#10415)

[33mcommit c7dec926f6f1beaed759b8689373926e68867358[m
Author: lkchen <github@lkchen.net>
Date:   Mon Nov 18 00:06:16 2024 -0800

    [VLM] Report multi_modal_placeholders in output (#10407)
    
    Signed-off-by: Linkun Chen <lkchen+anyscale@github.com>

[33mcommit 51bb12d17b374d5c4521cd01e5b066fd2419a8fa[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Nov 17 23:57:20 2024 -0800

    [4/N][torch.compile] clean up set_torch_compile_backend (#10401)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 47826cacf0e037b4e109f0b2d8d594e47def500e[m
Author: ‚Ñçùï†ùïùùïùùï†ùï® ùïÑùïíùïü <hollowman@opensuse.org>
Date:   Mon Nov 18 05:29:26 2024 +0200

    [Bugfix] Ignore ray reinit error when current platform is ROCm or XPU (#10375)
    
    Signed-off-by: Hollow Man <hollowman@opensuse.org>

[33mcommit c4e464333eac5a46e1cc2701e095a44057c82927[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Nov 18 09:07:46 2024 +0800

    [Misc] Add uninitialized params tracking for `AutoWeightsLoader` (#10327)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit d1557e66d3227355e5aed8018a945a5e6a733147[m
Author: wchen61 <wchen61@foxmail.com>
Date:   Sun Nov 17 19:32:40 2024 +0800

    [Misc] Enhance offline_inference to support user-configurable paramet‚Ä¶ (#10392)
    
    Signed-off-by: wchen61 <wchen61@foxmail.com>

[33mcommit 80d85c5d7bc33ce0ae210ebad3c45e4361b57640[m
Author: ÁîµËÑëÊòü‰∫∫ <kerorek@outlook.com>
Date:   Sun Nov 17 16:50:24 2024 +0800

    [Bugfix] Fix mrope_position_delta in non-last prefill chunk (#10403)
    
    Signed-off-by: imkero <kerorek@outlook.com>

[33mcommit 76aab90ab68476c353ad58019fd51fd18622056a[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Sun Nov 17 16:44:44 2024 +0800

    [Hardware] [HPU]add `mark_step` for hpu (#10239)
    
    Signed-off-by: Kunshang Ji <kunshang.ji@intel.com>

[33mcommit 8d74b5aee9e780852de870c936b59707835e84f5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 16 23:14:23 2024 -0800

    [platforms] refactor cpu code (#10402)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit cf349c4a97adb36354bdc2b14448ea55279d1575[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sun Nov 17 15:12:04 2024 +0800

    [Bugfix][CPU] Fix CPU embedding runner with tensor parallel (#10394)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 905d0f0af4e2c07893e36778da9ab02bde01ace8[m
Author: Chendi.Xue <chendi.xue@intel.com>
Date:   Sun Nov 17 00:58:22 2024 -0600

    [CI/Build] Fix IDC hpu [Device not found] issue (#10384)
    
    Signed-off-by: Chendi Xue <chendi.xue@intel.com>

[33mcommit 643ecf7b11a3e74c838f438cfc1b3e59c018853b[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Nov 16 21:18:46 2024 -0800

    [V1] Refactor model executable interface for all text-only language models (#10374)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 4fd937502827a7e06c54ded1f9d9b70ff640e222[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 16 18:02:14 2024 -0800

    [2/N][torch.compile] make compilation cfg part of vllm cfg (#10383)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 661a34fd4fdd700a29b2db758e23e4e243e7ff18[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Nov 16 10:45:26 2024 -0800

    [V1] Add code owners for V1 (#10397)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 361c29e1740e0b2186f8cca3ed96ad235a8a960a[m
Author: ÁîµËÑëÊòü‰∫∫ <kerorek@outlook.com>
Date:   Sun Nov 17 02:10:00 2024 +0800

    [Bugfix] Fix M-RoPE position calculation when chunked prefill is enabled (#10388)
    
    Signed-off-by: imkero <kerorek@outlook.com>

[33mcommit b98d89efd4b1a09c11c4d0cf30c9af0e93514764[m
Author: Sky Lee <46676799+skylee-01@users.noreply.github.com>
Date:   Sun Nov 17 00:33:01 2024 +0800

    [Misc] Medusa supports custom bias (#10361)

[33mcommit 8b6725b0cf4ee5f363218f4bc341970c80297ccf[m
Author: Jaehyun An <steve.ai@kakaocorp.com>
Date:   Sat Nov 16 19:15:40 2024 +0900

    [Misc] Update benchmark to support image_url file or http (#10287)
    
    Signed-off-by: rbbang <anjaehyun87@gmail.com>

[33mcommit 1d754726265d52773653e53e1a18f6eb63122480[m
Author: rasmith <Randall.Smith@amd.com>
Date:   Sat Nov 16 03:55:05 2024 -0600

    [BugFix] [Kernel] Fix GPU SEGV occuring in fused_moe kernel (#10385)
    
    Signed-off-by: Randall Smith <Randall.Smith@amd.com>

[33mcommit 2f427c2d163b5c6d5923a8808e9d786e170944ce[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 16 01:23:20 2024 -0800

    [misc][plugin] improve log messages (#10386)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 755b85359be910fabe39a75299439fc11beb57d4[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 15 21:46:27 2024 -0800

    [doc] add doc for the plugin system (#10372)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 32e46e000f77499f4dd7c0bed194e33856f2df24[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Nov 16 13:35:40 2024 +0800

    [Frontend] Automatic detection of chat content format from AST (#9919)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 4f168f69a3e856bda3f30e02fcee7db2a01ff32b[m
Author: Michael Green <59619482+mikegre-google@users.noreply.github.com>
Date:   Fri Nov 15 21:26:17 2024 +0000

    [Docs] Misc updates to TPU installation instructions (#10165)

[33mcommit 3e8d14d8a1e3e54655f79d7bb3481cde02943281[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Nov 15 16:20:20 2024 -0500

    [Doc] Move PR template content to docs (#10159)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit a067f85e08f6604b328a16efe3ead4629e0ead5b[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Nov 15 16:13:53 2024 -0500

    [Frontend] Add --version flag to CLI (#10369)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit c76ac49d266e27aa3fea84ef2df1f813d24c91c7[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Nov 15 12:47:40 2024 -0800

    [Docs] Add Nebius as sponsors (#10371)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit a6221a144af772fd1a68fe7e627935dc53e81738[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Nov 15 09:48:07 2024 -0800

    [Misc] bump mistral common version (#10367)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit 79ee45b42822d750ead6121c8c741c8a947bfeaf[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Fri Nov 15 17:31:18 2024 +0100

    [Misc] Bump up test_fused_moe tolerance (#10364)
    
    Signed-off-by: ElizaWszola <eliza@neuralmagic.com>

[33mcommit 691a3ec0475ba1fe4255bc975d02cc7a4392bf2c[m
Author: Guillaume Calmettes <gcalmettes@scaleway.com>
Date:   Fri Nov 15 15:50:40 2024 +0100

    [Bugfix] Ensure special tokens are properly filtered out for guided structured output with MistralTokenizer (#10363)
    
    Signed-off-by: Guillaume Calmettes <gcalmettes@scaleway.com>

[33mcommit 3a763ba0c3a92fdde78e855ded94f9ff29e02088[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 15 05:55:51 2024 -0800

    [core][misc] keep compatibility for old-style classes (#10356)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit f2056f726d9b0f257bc0e79938a9a6f483ce9e2d[m
Author: shangmingc <csmthu@gmail.com>
Date:   Fri Nov 15 20:40:30 2024 +0800

    [Misc] Fix some help info of arg_utils to improve readability (#10362)

[33mcommit 1d65ec7eeb35f03eb87ed080094f1aa5ff2ae3d3[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Fri Nov 15 18:34:58 2024 +0800

    [Bugfix] Fix fully sharded LoRA bug (#10352)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 26908554b2ecc8f76fa57942566629ec5713ef5b[m
Author: Xin Yang <105740670+xyang16@users.noreply.github.com>
Date:   Fri Nov 15 02:22:57 2024 -0800

    [Doc] Remove float32 choice from --lora-dtype (#10348)
    
    Signed-off-by: Xin Yang <xyang19@gmail.com>

[33mcommit b311efd0bd84faffcb1fe47aaa27ffd8c53688be[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 15 17:34:17 2024 +0800

    [Misc] Fix import error in tensorizer tests and cleanup some code (#10349)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 3d158cdc8dad62dfed45d5d808ae9f14f16e4dae[m
Author: wchen61 <183351030@qq.com>
Date:   Fri Nov 15 16:52:20 2024 +0800

    Add default value to avoid Falcon crash (#5363) (#10347)
    
    Signed-off-by: wchen61 <wchen61@foxmail.com>

[33mcommit 02dbf30e9a4389b41d95dd595bfe1224592dd404[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Nov 14 23:31:52 2024 -0800

    [Build] skip renaming files for release wheels pipeline (#9671)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit 2ac6d0e75bc846998da56b50bf4f8853cb36d484[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 15 14:59:00 2024 +0800

    [Misc] Consolidate pooler config overrides (#10351)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 2ec88272881a49d40d91ae0cd858b19d22996c70[m
Author: Sky Lee <46676799+skylee-01@users.noreply.github.com>
Date:   Fri Nov 15 13:40:10 2024 +0800

    [Bugfix]  Qwen-vl output is inconsistent in speculative decoding (#10350)

[33mcommit b40cf6402e356a10415e969e648a32911fb9b8ec[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 15 12:23:09 2024 +0800

    [Model] Support Qwen2 embeddings and use tags to select model tests (#10184)

[33mcommit 2885ba0e24e536d0a5b2439be5e96aef504a2e7f[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Nov 14 21:44:26 2024 -0500

    [Misc] Change RedundantReshapesPass and FusionPass logging from info to debug (#10308)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit bf2ddc6610094524a61e90441e579d502c7dee06[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Thu Nov 14 20:35:11 2024 -0500

    [bugfix] Fix static asymmetric quantization case (#10334)
    
    Signed-off-by: DanieÃàl de Kok <me@danieldk.eu>
    Signed-off-by: luka <luka@neuralmagic.com>
    Co-authored-by: DanieÃàl de Kok <me@danieldk.eu>

[33mcommit 972112d82f00e1396c0376cde78c083208b77127[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 15 08:55:54 2024 +0800

    [Bugfix] Fix unable to load some models (#10312)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 11cd1ae6ad6fa7d35060fea35133e08c0a1c227c[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Fri Nov 15 01:42:49 2024 +0100

    [Tool parsing] Improve / correct mistral tool parsing (#10333)

[33mcommit 554af9228df620a63d4736240a8f76a64a675f4d[m
Author: Zijin Xiao <ZijinX@outlook.com>
Date:   Fri Nov 15 08:38:53 2024 +0800

    [Bugfix] use AF_INET6 for OpenAI Compatible Server with ipv6 (#9583)
    
    Signed-off-by: xiaozijin <xiaozijin@bytedance.com>

[33mcommit b2e0ad3b598ed0e022cdbd678a20821d411873c2[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Thu Nov 14 16:38:20 2024 -0800

    [Perf] Reduce peak memory usage of llama (#10339)
    
    Signed-off-by: andoorve <37849411+andoorve@users.noreply.github.com>

[33mcommit 4a18fd14ba4a349291c798a16bf62fa8a9af0b6b[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Thu Nov 14 18:23:29 2024 -0300

    Support Roberta embedding models (#9387)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
    Signed-off-by: Flavia Beo <flavia.beo@ibm.com>
    Co-authored-by: Flavia Beo <flavia.beo@ibm.com>

[33mcommit 1dbae0329c6d907b72b373667b4d5716bae4415f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 14 08:19:38 2024 -0800

    [Docs] Publish meetup slides (#10331)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 675d603400616dcb45093ffc9f57c4859c22df76[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Nov 14 17:47:53 2024 +0800

    [CI/Build] Make shellcheck happy (#10285)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 03025c023f99bea58652e9b5a8a4a8b50af6bdd0[m
Author: Isotr0py <2037008807@qq.com>
Date:   Thu Nov 14 16:45:32 2024 +0800

    [CI/Build] Fix CPU CI online inference timeout (#10314)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 29f3ef26a38e5afab529fb9f6098704fd106a779[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Nov 14 00:23:39 2024 -0800

    [ci][distributed] disable hanging tests (#10317)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 294bf467bacc2c9532cc56d1a512edde01bed947[m
Author: B-201 <Joy25810@foxmail.com>
Date:   Thu Nov 14 14:31:44 2024 +0800

    [Model] Add BNB quantization support for Idefics3 (#10310)
    
    Signed-off-by: B-201 <Joy25810@foxmail.com>
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 52b48c1ead683ec2afe6b0396ece32d73884cd21[m
Author: Guillaume Calmettes <gcalmettes@scaleway.com>
Date:   Thu Nov 14 05:48:16 2024 +0100

    [BugFix]: properly deserialize `tool_calls` iterator before processing by mistral-common when MistralTokenizer is used (#9951)
    
    Signed-off-by: Guillaume Calmettes <gcalmettes@scaleway.com>

[33mcommit f67ce05d0b826322f85403f1113f69ca3853aa39[m
Author: Mike Depinet <mike.depinet@gmail.com>
Date:   Wed Nov 13 20:14:34 2024 -0800

    [Frontend] Pythonic tool parser (#9859)
    
    Signed-off-by: Mike Depinet <mike@fixie.ai>

[33mcommit e0853b65089b94c9bab9f480970dc73e1e8a0c0d[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Nov 13 22:12:35 2024 -0500

    [Misc] format.sh: Simplify tool_version_check (#10305)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 504ac53d18fc057d2a98741fa27d89df9054422d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 13 18:55:39 2024 -0800

    [misc] error early for old-style class (#10304)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 15bb8330aa50ca6ec86f827a0fe79134b1dbac8c[m
Author: Isotr0py <2037008807@qq.com>
Date:   Thu Nov 14 10:54:59 2024 +0800

    [Bugfix] Fix tensor parallel for qwen2 classification model (#10297)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit ac49b59d8b01ffb9979e18e67b252d45410bc1e6[m
Author: HoangCongDuc <55457046+HoangCongDuc@users.noreply.github.com>
Date:   Thu Nov 14 00:56:39 2024 +0800

    [Bugfix] bitsandbytes models fail to run pipeline parallel (#10200)
    
    Signed-off-by: Hoang Cong Duc <hoangcongducltt@gmail.com>

[33mcommit 0b8bb86bf19d68950b4d92a99350e07a26ec0d2c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Nov 13 20:39:03 2024 +0800

    [1/N] Initial prototype for multi-modal processor (#10044)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit bb7991aa291054a30f408e626273caa6769a07eb[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Nov 13 03:02:56 2024 -0800

    [V1] Add missing tokenizer options for `Detokenizer` (#10288)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit d909acf9fe17b7db42d7de61903c0058c8b9b344[m
Author: B-201 <Joy25810@foxmail.com>
Date:   Wed Nov 13 17:25:59 2024 +0800

    [Model][LoRA]LoRA support added for idefics3 (#10281)
    
    Signed-off-by: B-201 <Joy25810@foxmail.com>

[33mcommit b6dde330198848a4a9903c1f0f97c3235fba0ba0[m
Author: Pavani Majety <pmajety@nvidia.com>
Date:   Wed Nov 13 00:29:32 2024 -0800

    [Core] Flashinfer - Remove advance step size restriction (#10282)

[33mcommit 1b886aa104248a95720fda7be9f979fc665b3d02[m
Author: Austin Veselka <50646302+FurtherAI@users.noreply.github.com>
Date:   Wed Nov 13 02:28:13 2024 -0600

    [Model] Adding Support for Qwen2VL as an Embedding Model. Using MrLight/dse-qwen2-2b-mrl-v1 (#9944)
    
    Signed-off-by: FurtherAI <austin.veselka@lighton.ai>
    Co-authored-by: FurtherAI <austin.veselka@lighton.ai>

[33mcommit 3945c82346dae3129213607663bfd17edd905fef[m
Author: ÁîµËÑëÊòü‰∫∫ <kerorek@outlook.com>
Date:   Wed Nov 13 15:07:22 2024 +0800

    [Model] Add support for Qwen2-VL video embeddings input & multiple image embeddings input with varied resolutions (#10221)
    
    Signed-off-by: imkero <kerorek@outlook.com>

[33mcommit 032fcf16ae9d924cc98a083c3c8464173f87a49e[m
Author: Xin Yang <105740670+xyang16@users.noreply.github.com>
Date:   Tue Nov 12 21:54:52 2024 -0800

    [Doc] Fix typo in arg_utils.py (#10264)
    
    Signed-off-by: Xin Yang <xyang19@gmail.com>

[33mcommit 56a955e7748e497d8c24c79a76c75f3f982fab4a[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Wed Nov 13 00:54:10 2024 -0500

    Bump to compressed-tensors v0.8.0 (#10279)
    
    Signed-off-by: Dipika <dipikasikka1@gmail.com>

[33mcommit bbd3e86926f15e59e4c62246b4b3185e71fe7ff2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Nov 12 20:53:13 2024 -0800

    [V1] Support VLMs with fine-grained scheduling (#9871)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 0d4ea3fb5c8c499b70cea8b1deee3e34a147cff1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 12 17:36:08 2024 -0800

    [core][distributed] use tcp store directly (#10275)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 112fa0bbe5e5354f592a42913a4e6d72e0407b93[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Nov 12 16:17:20 2024 -0800

    [V1] Fix CI tests on V1 engine (#10272)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 377b74fe877c7eb4632c2ca0778b9da9a5db8ae6[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 12 15:06:48 2024 -0800

    Revert "[ci][build] limit cmake version" (#10271)

[33mcommit 18081451f9f5dd3ae476ff1e217d5573832b2604[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 12 14:43:52 2024 -0800

    [doc] improve debugging doc (#10270)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 96ae0eaeb270be8741abb30f2251670b4554e886[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 12 14:34:39 2024 -0800

    [doc] fix location of runllm widget (#10266)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 1f55e0571350f3dd2c04638e13e52d8ed557d93e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Nov 12 13:39:56 2024 -0800

    [V1] Enable Inductor when using piecewise CUDA graphs (#10268)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 8a06428c70657b3310a317b3caf3c562b0e042ae[m
Author: Umesh <lessimpumesh@gmail.com>
Date:   Tue Nov 12 11:08:40 2024 -0800

    [LoRA] Adds support for bias in LoRA (#5733)
    
    Signed-off-by: Umesh Deshpande <udeshpa@us.ibm.com>
    Co-authored-by: Umesh Deshpande <udeshpa@us.ibm.com>

[33mcommit b41fb9d3b10dcf187ac0501ca80ede96d387617f[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Tue Nov 12 10:53:57 2024 -0800

    [Encoder Decoder] Update Mllama to run with both FlashAttention and XFormers (#9982)
    
    Signed-off-by: Sourashis Roy <sroy@roblox.com>

[33mcommit 7c65527918cd16286961a2a779e15743ca41ab0e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Nov 12 08:57:14 2024 -0800

    [V1] Use pickle for serializing EngineCoreRequest & Add multimodal inputs to EngineCoreRequest (#10245)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 47db6ec8310129699a62567b61d8ed380636b053[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Tue Nov 12 08:42:28 2024 -0800

    [Frontend] Add per-request number of cached token stats (#10174)

[33mcommit 176fcb1c71655d825d2363e5f1468fa248fe783b[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Wed Nov 13 00:36:51 2024 +0800

    [Bugfix] Fix QwenModel argument (#10262)
    
    Signed-off-by: Jie Fu <jiefu@tencent.com>

[33mcommit a838ba7254c98a7adc60a0976bdf277fb20b4221[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Nov 12 21:07:11 2024 +0800

    [Misc]Fix Idefics3Model argument (#10255)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 36c513a0762b104c9076ab6a3449ea3efff6db4d[m
Author: Guillaume Calmettes <gcalmettes@scaleway.com>
Date:   Tue Nov 12 12:13:46 2024 +0100

    [BugFix] Do not raise a `ValueError` when `tool_choice` is set to the supported `none` option and `tools` are not defined. (#10000)
    
    Signed-off-by: Guillaume Calmettes <gcalmettes@scaleway.com>

[33mcommit d201d419730dec120b0ecb60ae212f08c0b68be0[m
Author: Yuan <yuan.zhou@intel.com>
Date:   Tue Nov 12 18:07:32 2024 +0800

    [CI][CPU]refactor CPU tests to allow to bind with different cores (#10222)
    
    Signed-off-by: Yuan Zhou <yuan.zhou@intel.com>

[33mcommit 3a28f18b0bb954cc9886e5ee63cd616997165024[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 11 22:56:44 2024 -0800

    [doc] explain the class hierarchy in vLLM (#10240)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 812c981fa00a8b2b95865c6e76b6c3735a56d7d9[m
Author: Aleksandr Malyshev <164964928+maleksan85@users.noreply.github.com>
Date:   Mon Nov 11 22:55:07 2024 -0800

    Splitting attention kernel file (#10091)
    
    Signed-off-by: maleksan85 <maleksan@amd.com>
    Co-authored-by: Aleksandr Malyshev <maleksan@amd.com>

[33mcommit 7f5edb5900c4010c1daa5bfeb3829974d3f6dff1[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Nov 12 11:10:15 2024 +0800

    [Misc][LoRA] Replace hardcoded cuda device with configurable argument  (#10223)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit eea55cca5b0896eab7fa213291090f70c858a3bc[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 11 18:01:06 2024 -0800

    [1/N] torch.compile user interface design (#10237)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 9cdba9669cb32191aa0ae6782c0648be3e0e44ed[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Mon Nov 11 20:55:09 2024 -0500

    [Doc] Update help text for `--distributed-executor-backend` (#10231)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit d1c6799b8870e513bf4f2305cbf6cda9fc3d773b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 11 15:21:12 2024 -0800

    [doc] update debugging guide (#10236)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 6ace6fba2ca42b79a948a9b47af00487b5f73868[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Mon Nov 11 18:05:38 2024 -0500

    [V1] `AsyncLLM` Implementation (#9826)
    
    Signed-off-by: Nick Hill <nickhill@us.ibm.com>
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>
    Signed-off-by: Nick Hill <nhill@redhat.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Nick Hill <nhill@redhat.com>
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 08f93e743972abd3060723f63352ef42cdf161a8[m
Author: Nikolai Shcheglov <ndnd@mail.ru>
Date:   Mon Nov 11 16:29:19 2024 -0600

    Make shutil rename in python_only_dev (#10233)
    
    Signed-off-by: shcheglovnd <shcheglovnd@avride.ai>

[33mcommit 9d5b4e4deaa3318df49419d325490730391efd75[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Nov 11 11:58:07 2024 -0800

    [V1] Enable custom ops with piecewise CUDA graphs (#10228)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 8a7fe47d322920bdff1b1c3472fe7f423a73a23b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 11 11:54:59 2024 -0800

    [misc][distributed] auto port selection and disable tests (#10226)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 4800339c6287465a128288231ac9dcd94ddf27ba[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Mon Nov 11 14:28:55 2024 -0500

    Add docs on serving with Llama Stack (#10183)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>
    Co-authored-by: Russell Bryant <rbryant@redhat.com>

[33mcommit fe15729a2b77d760fcf99da76f15806c5eab33df[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Nov 11 11:26:48 2024 -0800

    [V1] Use custom ops for piecewise CUDA graphs (#10227)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 330e82d34a36ccee3f2f80fded3e7cc0d67718d6[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 11 11:10:27 2024 -0800

    [v1][torch.compile] support managing cudagraph buffer (#10203)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit d7a4f2207bd0ff31cacf311a05266557d66e474e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Nov 11 11:05:57 2024 -0800

    [V1] Do not use inductor for piecewise CUDA graphs (#10225)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit f9dadfbee331aeff9cb45c94e635ab8e16335a10[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Nov 11 10:42:07 2024 -0800

    [V1] Fix detokenizer ports (#10224)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 25144ceed0cfb5883b594137c83c3ec70c9d1c2f[m
Author: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Date:   Mon Nov 11 17:24:10 2024 +0000

    Bump actions/setup-python from 5.2.0 to 5.3.0 (#10209)
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>

[33mcommit e6de9784d26fb3b0c9a55be4ab4ea3127f1900a0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 11 09:02:14 2024 -0800

    [core][distributed] add stateless process group (#10216)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 36fc439de00a11d82d75d1e571cc4360fab11cdb[m
Author: Yangcheng Li <bluebluelitchi@hotmail.com>
Date:   Tue Nov 12 00:53:07 2024 +0800

    [Doc] fix doc string typo in block_manager `swap_out` function (#10212)

[33mcommit 874f551b3626321f6bf9a902b8fd9fc1fa7c7f2e[m
Author: harrywu <63134210+HarryWu99@users.noreply.github.com>
Date:   Tue Nov 12 00:17:38 2024 +0800

    [Metrics] add more metrics (#4464)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: Robert Shaw <rshaw@neuralmagic.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 2cebda42bb9f52a99e566b9b439fdcca2e9f950e[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Nov 11 20:37:58 2024 +0800

    [Bugfix][Hardware][CPU] Fix broken encoder-decoder CPU runner (#10218)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 5fb1f935b04c29c5c379952681a8a49ad533355d[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Nov 11 02:01:18 2024 -0800

    [V1] Allow `tokenizer_mode` and `trust_remote_code` for Detokenizer (#10211)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 36e4acd02a955f71ebb7b220cbfae4a4379bc57b[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Mon Nov 11 17:43:23 2024 +0800

    [LoRA][Kernel] Remove the unused libentry module (#10214)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 58170d65034f7a89edc56c716f1fcf05ff336aa5[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Nov 11 16:54:28 2024 +0800

    [Hardware][CPU] Add embedding models support for CPU backend (#10193)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 9804ac7c7ce34a62f648cce579d89e355fb0bfc0[m
Author: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Date:   Mon Nov 11 07:22:40 2024 +0000

    Bump the patch-update group with 5 updates (#10210)
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>

[33mcommit f89d18ff74e48f97c76afbab31956218d2486e36[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Nov 10 22:41:46 2024 -0800

    [6/N] pass whole config to inner model (#10205)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit f0f2e5638ef4858b00b137bea1c3f8312e48efa6[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Nov 10 17:49:40 2024 -0800

    [doc] improve debugging code (#10206)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit ad9a78bf640cca930de76a066a2f34139b9acb65[m
Author: yansh97 <yansh97@foxmail.com>
Date:   Mon Nov 11 08:14:22 2024 +0800

    [Doc] Fix typo error in vllm/entrypoints/openai/cli_args.py (#10196)

[33mcommit 73b9083e99c02c6ba91f6be9479b88e7e9a94cdf[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Nov 10 16:10:53 2024 -0800

    [misc] improve cloudpickle registration and tests (#10202)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 20cf2f553c223792ad3f65236b267586fa9bed6c[m
Author: Shawn Du <shawnd200@outlook.com>
Date:   Mon Nov 11 07:21:06 2024 +0800

    [Misc] small fixes to function tracing file path (#9543)
    
    Signed-off-by: Shawn Du <shawnd200@outlook.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit bfb7d61a7c16e642ff3b84a62d6a308da6548a29[m
Author: Yongzao <532741407@qq.com>
Date:   Mon Nov 11 02:22:04 2024 +0800

    [doc] Polish the integration with huggingface doc (#10195)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 19682023b62c7ed00cee52a805dfa279dfc9c7a2[m
Author: FuryMartin <fany@buaa.edu.cn>
Date:   Sun Nov 10 15:47:24 2024 +0800

    [Doc] Fix typo error in CONTRIBUTING.md (#10190)
    
    Signed-off-by: FuryMartin <furymartin9910@outlook.com>

[33mcommit 9fa4bdde9d091af250d90a233bb54420610037cb[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 9 16:27:26 2024 -0800

    [ci][build] limit cmake version (#10188)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 51c2e1fcef59ca42b378c433997c77affd114d30[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Nov 10 03:39:14 2024 +0800

    [CI/Build] Split up models tests (#10069)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit b09895a61843e654088773851a2b1acae4cdf184[m
Author: Krishna Mandal <43015249+KrishnaM251@users.noreply.github.com>
Date:   Sat Nov 9 08:19:27 2024 -0800

    [Frontend][Core] Override HF `config.json` via CLI (#5836)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit d88bff1b96c6f4c8abbd3d5ab4758bdc040f7b62[m
Author: cjackal <44624812+cjackal@users.noreply.github.com>
Date:   Sat Nov 9 19:18:29 2024 +0900

    [Frontend] add `add_request_id` middleware (#9594)
    
    Signed-off-by: cjackal <44624812+cjackal@users.noreply.github.com>

[33mcommit 9e372664208b4905f7343f1fc76aca758fbf6f8f[m
Author: Zhao Yingzhuo <38399296+caijizhuo@users.noreply.github.com>
Date:   Sat Nov 9 18:09:48 2024 +0800

    bugfix: fix the bug that stream generate not work (#2756)

[33mcommit 8a4358ecb5ba457fad2be0ed930132489eddddf5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 9 01:02:54 2024 -0800

    [doc] explaining the integration with huggingface (#10173)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit bd46357ad90fdb4263a3155c358d37d32dab127c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 9 00:04:50 2024 -0800

    [bugfix] fix broken tests of mlp speculator (#10177)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit f192aeba74ebf5a6d1a0fccc9a84e8fe99f8c619[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Sat Nov 9 03:01:27 2024 -0500

    [Bugfix] Enable some fp8 and quantized fullgraph tests (#10171)
    
    Signed-off-by: Bill Nell <bill@neuralmagic.com>

[33mcommit 8e1529dc573c9b4697fca24944918b8d68fd5906[m
Author: Chendi.Xue <chendi.xue@intel.com>
Date:   Sat Nov 9 00:26:52 2024 -0600

    [CI/Build] Add run-hpu-test.sh script (#10167)
    
    Signed-off-by: Chendi.Xue <chendi.xue@intel.com>

[33mcommit 1a95f10ee7d2ffa538a6d210b53bf363e039feee[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 8 22:17:28 2024 -0800

    [5/N] pass the whole config to model (#9983)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 49d2a41a860f5aeffe850fb8bbe3b268966299bb[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Nov 9 12:07:10 2024 +0800

    [Doc] Adjust RunLLM location (#10176)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 47672f38b58581cf2b7c33201e6ae01639c5ff51[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sat Nov 9 12:02:59 2024 +0800

    [CI/Build] Fix VLM broadcast tests `tensor_parallel_size` passing (#10161)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit f83feccd7f661d0a582f9c0cb0bc9f802f4d995e[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Nov 8 22:36:46 2024 -0500

    [Bugfix] Ignore GPTQ quantization of Qwen2-VL visual module (#10169)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit e0191a95d88c454dbb989b7457a41c93cb7f7051[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Nov 9 11:31:02 2024 +0800

    [0/N] Rename `MultiModalInputs` to `MultiModalKwargs` (#10040)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit d7edca1dee96e6caeeadcee4914a6b00d1c99fd5[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Sat Nov 9 11:27:11 2024 +0800

    [CI/Build] Adding timeout in CPU CI to avoid CPU test queue blocking (#6892)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 127c07480ecea15e4c2990820c457807ff78a057[m
Author: rasmith <Randall.Smith@amd.com>
Date:   Fri Nov 8 18:59:22 2024 -0600

    [Kernel][Triton] Add Triton implementation for scaled_mm_triton to support fp8 and int8 SmoothQuant, symmetric case (#9857)
    
    Signed-off-by: Randall Smith <Randall.Smith@amd.com>

[33mcommit 10b67d865d92e376956345becafc249d4c3c0ab7[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Fri Nov 8 17:44:18 2024 -0500

    [Bugfix] SymIntArrayRef expected to contain concrete integers (#10170)
    
    Signed-off-by: Bill Nell <bill@neuralmagic.com>

[33mcommit 4f93dfe952522c3f784be6542d69be2a172b8496[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Fri Nov 8 16:20:08 2024 -0500

    [torch.compile] Fuse RMSNorm with quant (#9138)
    
    Signed-off-by: luka <luka@neuralmagic.com>
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit e1b5a8217974af541abda462e75dc8ce1a7e4004[m
Author: Florian Zimmermeister <flozi00.fz@gmail.com>
Date:   Fri Nov 8 21:53:24 2024 +0100

    Rename vllm.logging to vllm.logging_utils (#10134)

[33mcommit 87713c605334da837cac8367fa3e59c95153df88[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Fri Nov 8 14:53:36 2024 -0500

    [CI/Build] Ignore .gitignored files for shellcheck (#10162)
    
    Signed-off-by: luka <luka@neuralmagic.com>

[33mcommit b5815c8413b4e09ba6ccd9c41ea3f9fb2d057aa8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Nov 8 10:23:04 2024 -0800

    [V1] Fix non-cudagraph op name (#10166)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 6b30471586f6128797272db654c42c5131d3a1f1[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Fri Nov 8 12:51:04 2024 -0500

    [Misc] Improve Web UI (#10090)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit f6778620a95baf925eb54694ab4666524d0d8584[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Fri Nov 8 07:56:18 2024 -0800

    Disable spec-decode + chunked-prefill for draft models with tensor parallelism > 1 (#10136)
    
    Signed-off-by: Sourashis Roy <sroy@roblox.com>

[33mcommit 0535e5fe6c38a25bad71d92bb7a396f04fd1aee5[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Fri Nov 8 16:42:27 2024 +0100

    Fix edge case Mistral tokenizer (#10152)

[33mcommit b489fc3c91778d8815243f89132d36b2c6eefd5a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 8 23:30:04 2024 +0800

    [CI/Build] Update CPU tests to include all "standard" tests (#5481)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 208ce622c712fef75623f785597dbbd698700fa6[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Nov 8 06:39:41 2024 -0800

    [V1]Enable APC by default only for text models (#10148)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 1ff4aed5bddd995c5a2847993e2fb5be88763872[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Nov 8 17:56:58 2024 +0800

    [Model] Expose size to Idefics3 as mm_processor_kwargs (#10146)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit f10797c0ce4533412d41842180ca792ad07df11c[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Fri Nov 8 17:41:03 2024 +0800

    [Bugfix][XPU] Fix xpu tp by introducing XpuCommunicator (#10144)
    
    Signed-off-by: yan ma <yan.ma@intel.com>

[33mcommit f4c2187e2967ef4052d173b422b0249ab9532753[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 8 17:07:01 2024 +0800

    [Misc] Fix typo in #5895 (#10145)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit aea6ad629ff92f072a11b21dcdb1105677744007[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Nov 8 03:35:25 2024 -0500

    Add hf_transfer to testing image (#10096)

[33mcommit da07a9ead7a9b3c0ca0ecc1cc787faf1e1a1ccf7[m
Author: Tao He <linzhu.ht@alibaba-inc.com>
Date:   Fri Nov 8 13:31:28 2024 +0800

    Fixes a typo about 'max_decode_seq_len' which causes crashes with cuda graph. (#9285)
    
    Signed-off-by: Tao He <linzhu.ht@alibaba-inc.com>

[33mcommit 3a7f15a398727887137a021b8b32dc372b532087[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Nov 8 00:15:12 2024 -0500

    [Doc] Move CONTRIBUTING to docs site (#9924)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 7371749d54db40999d896c4a7f8935bc6984c093[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Fri Nov 8 13:08:51 2024 +0800

    [Misc] Fix ImportError causing by triton (#9493)

[33mcommit ad39bd640cdaaf2963cd07a7cc912c1dde516ed0[m
Author: DearPlanet <junsong.zhang2021.work@outlook.com>
Date:   Fri Nov 8 12:58:37 2024 +0800

    [Bugfix] Add error handling when server cannot respond any valid tokens (#5895)

[33mcommit 40d0e7411dbeb276befd33c4485115ac3d4d7f2a[m
Author: whyiug <whyiug@hotmail.com>
Date:   Fri Nov 8 12:44:58 2024 +0800

    [Doc] Update FAQ links in spec_decode.rst (#9662)
    
    Signed-off-by: whyiug <whyiug@hotmail.com>

[33mcommit 6bb52b0f97c11d30fa38290926372148e231f408[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Thu Nov 7 23:10:20 2024 -0500

    [CI/Build] Give PR cleanup job PR write access (#10139)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 201fc07730ec96dd88b758064f148a424f4b251b[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Thu Nov 7 17:34:44 2024 -0800

    [V1] Prefix caching (take 2) (#9972)
    
    Signed-off-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 42b4f46b71572e21582fd12c498ec3b0b78ada7b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 7 17:08:24 2024 -0800

    [V1] Add all_token_ids attribute to Request (#10135)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 073a4727282b00f3626d5fdf720bd19589db7b48[m
Author: Jiangtao Hu <ycool@users.noreply.github.com>
Date:   Thu Nov 7 16:14:01 2024 -0800

    [Misc] report relevant env vars in collect_env.py tool (#9293)

[33mcommit 93bff421bc012cc96b6eb91db459faf1b731f123[m
Author: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Date:   Thu Nov 7 21:44:58 2024 +0000

    Bump actions/checkout from 4.2.1 to 4.2.2 (#9746)
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>

[33mcommit 28b2877d303caa6b2febc9d0b425f17828634a4c[m
Author: litianjian <45817262+litianjian@users.noreply.github.com>
Date:   Fri Nov 8 04:25:59 2024 +0800

    Online video support for VLMs (#10020)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: litianjian <litianjian@bytedance.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 97b8475bebf4598fb4847997323267be46457465[m
Author: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Date:   Thu Nov 7 18:55:35 2024 +0000

    Bump actions/setup-python from 5.2.0 to 5.3.0 (#9745)
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>

[33mcommit a2f1f3b0896be5e0fcd01727257438ba629e48af[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Thu Nov 7 13:26:28 2024 -0500

    [CI/Build] Automate PR body text cleanup (#10082)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 3be5b26a7651b57aeb2cbdfc6aee81152ba68da5[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Thu Nov 7 13:17:29 2024 -0500

    [CI/Build] Add shell script linting using shellcheck (#7925)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit de0e61a3239abff67c789138187a98465b806f76[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Thu Nov 7 11:43:16 2024 -0500

    [CI/Build] Always run mypy (#10122)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 9d43afcc538645625ea5fc2bca01d3697dd0595c[m
Author: Nicol√≤ Lucchesi <nlucches@redhat.com>
Date:   Thu Nov 7 17:15:14 2024 +0100

    [Feature] [Spec decode]: Combine chunked prefill with speculative decoding (#9291)
    
    Signed-off-by: NickLucche <nlucches@redhat.com>

[33mcommit ae62fd17c0023f7ec363c1141787b8c017937c44[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Thu Nov 7 12:09:02 2024 -0300

    [Frontend] Tool calling parser for Granite 3.0 models (#9027)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>

[33mcommit a62bc0109c3864b9dc770dc637e3acd332c730ea[m
Author: Atlas <163425173+spliii@users.noreply.github.com>
Date:   Thu Nov 7 19:20:30 2024 +0800

    [Misc] Add Gamma-Distribution Request Generation Support for Serving Benchmark. (#10105)
    
    Signed-off-by: Mozhou <spli161006@gmail.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit 999df95b4eefb920cd3539a7fa3a21b2911f3650[m
Author: Jiahao Li <liplus17@163.com>
Date:   Thu Nov 7 18:50:44 2024 +0800

    [Bugfix] Make image processor respect `mm_processor_kwargs` for Qwen2-VL (#10112)
    
    Signed-off-by: Jiahao Li <liplus17@163.com>

[33mcommit a6f332d0d9ac3e795949da7703f203b6b1a42797[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Thu Nov 7 18:42:50 2024 +0800

    [Hardware][CPU][bugfix] Fix half dtype support on AVX2-only target (#10108)
    
    Signed-off-by: jiang1.li <jiang1.li@intel.com>

[33mcommit 0dfba97b42032987fd6bd3d304ac22dd314c89b1[m
Author: Lei Yang <DIYer22@users.noreply.github.com>
Date:   Thu Nov 7 17:07:19 2024 +0800

    [Frontend] Fix multiple values for keyword argument error (#10075) (#10076)
    
    Signed-off-by: Lei <ylxx@live.com>

[33mcommit aa9078fa035abfac54179cbdca8b741e49c8cd0b[m
Author: Fl√°via B√©o <119421251+flaviabeo@users.noreply.github.com>
Date:   Thu Nov 7 05:42:40 2024 -0300

    Adds method to read the pooling types from model's files (#9506)
    
    Signed-off-by: Flavia Beo <flavia.beo@ibm.com>
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
    Co-authored-by: Max de Bayser <mbayser@br.ibm.com>

[33mcommit e036e527a08fbf00ba725b12c9ebff6cd9bfab52[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Thu Nov 7 02:54:16 2024 -0500

    [CI/Build] Improve mypy + python version matrix (#10041)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 6192e9b8fef8492c3e52bd65c7d954a1ef9b40c8[m
Author: Hanzhi Zhou <hanzhi713@gmail.com>
Date:   Wed Nov 6 23:50:47 2024 -0800

    [Core][Distributed] Refactor ipc buffer init in CustomAllreduce (#10030)
    
    Signed-off-by: Hanzhi Zhou <hanzhi713@gmail.com>

[33mcommit d7263a1bb837648bec67d99ed35db56c58832d3f[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Thu Nov 7 02:50:35 2024 -0500

    Doc: Improve benchmark documentation (#9927)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit 104d729656fe746d1b91a0528e51e5efc8d14b4a[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Thu Nov 7 01:54:46 2024 -0500

    [CI/Build] re-add codespell to CI (#10083)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit db7db4aab9fd23e818d89ca9037099d30c071a5a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Nov 7 14:00:21 2024 +0800

    [Misc] Consolidate ModelConfig code related to HF config (#10104)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 1fa020c539485e398d10ca9be376c1d0d87ae19b[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Nov 7 05:06:57 2024 +0000

    [V1][BugFix] Fix Generator construction in greedy + seed case (#10097)
    
    Signed-off-by: Nick Hill <nhill@redhat.com>

[33mcommit e7b84c394d221d0c528584511f56ef3359630706[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 6 21:06:41 2024 -0800

    [doc] add back Python 3.8 ABI (#10100)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit a4b3e0c1e999d214c6355b16a1c68250e6c030e2[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Thu Nov 7 12:43:08 2024 +0800

    [Hardware][CPU] Update torch 2.5 (#9911)
    
    Signed-off-by: jiang1.li <jiang1.li@intel.com>

[33mcommit 29862b884bb5c59a35a9bcf62913c233d8b82471[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Nov 7 04:07:51 2024 +0000

    [Frontend] Adjust try/except blocks in API impl (#10056)
    
    Signed-off-by: Nick Hill <nhill@redhat.com>

[33mcommit d3859f18915a1e3c50ee88bcbb0af4f4fe754b4e[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Thu Nov 7 09:29:03 2024 +0800

    [Misc][XPU] Upgrade to Pytorch 2.5 for xpu backend (#9823)
    
    Signed-off-by: Kunshang Ji <kunshang.ji@intel.com>
    Signed-off-by: yan ma <yan.ma@intel.com>
    Co-authored-by: Kunshang Ji <kunshang.ji@intel.com>

[33mcommit 4ab32566449558f2b5dbfbe44aeb6417e02e2e88[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Nov 6 19:54:13 2024 -0500

    [Bugfix] Fix FP8 torch._scaled_mm fallback for torch>2.5 with CUDA<12.4 (#10095)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 719c1ca468537d2be2616ddc3163236af7f5bd62[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Nov 6 16:42:09 2024 -0800

    [core][distributed] add stateless_init_process_group (#10072)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 74f2f8a0f1d4a2afb27d7be87ed2ff12c8319eee[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Nov 6 17:25:23 2024 -0500

    [CI/Build] Always run the ruff workflow (#10092)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit d58268c56a8ee0eb01c30e7ab7c07c934e1791c2[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Wed Nov 6 12:57:35 2024 -0700

    [V1] Make v1 more testable (#9888)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 87bd7e0515eebd9344272a3136d7bd662c607438[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Nov 6 13:15:42 2024 -0500

    [CI/Build] change conflict PR comment from mergify (#10080)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 098f94de42859f8251fe920f87adb88336129c53[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Nov 6 09:31:01 2024 -0500

    [CI/Build] Drop Python 3.8 support (#10038)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 399c7986088ed66184e69ac6ae2b28003b642711[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Nov 6 09:27:06 2024 -0500

    Remove ScaledActivation for AWQ (#10057)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 406d4cc480bbc01d41f34b83102548bae229671a[m
Author: Eric <ericperfectttt@gmail.com>
Date:   Wed Nov 6 22:13:15 2024 +0800

    [Model][LoRA]LoRA support added for Qwen2VLForConditionalGeneration (#10022)
    
    Signed-off-by: ericperfect <ericperfectttt@gmail.com>

[33mcommit a5bba7d234b4e0d82e6a64de82a8497760ed44cf[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Nov 6 19:41:17 2024 +0800

    [Model] Add Idefics3 support (#9767)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>
    Signed-off-by: B-201 <Joy25810@foxmail.com>
    Co-authored-by: B-201 <Joy25810@foxmail.com>

[33mcommit 2003cc35135319b240230e686f26f13524403ee0[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Nov 6 17:49:19 2024 +0800

    [Model][LoRA]LoRA support added for LlamaEmbeddingModel (#10071)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 6a585a23d2e7960164c7bd9d767858d50ac54c47[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Nov 6 01:24:28 2024 -0800

    [Hotfix] Fix ruff errors (#10073)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit a02a50e6e5bb74f9d48f75942e47197d22ec6444[m
Author: Konrad Zawora <kzawora@habana.ai>
Date:   Wed Nov 6 10:09:10 2024 +0100

    [Hardware][Intel-Gaudi] Add Intel Gaudi (HPU) inference backend (#6143)
    
    Signed-off-by: yuwenzho <yuwen.zhou@intel.com>
    Signed-off-by: Chendi.Xue <chendi.xue@intel.com>
    Signed-off-by: Bob Zhu <bob.zhu@intel.com>
    Signed-off-by: zehao-intel <zehao.huang@intel.com>
    Signed-off-by: Konrad Zawora <kzawora@habana.ai>
    Co-authored-by: Kunshang Ji <kunshang.ji@intel.com>
    Co-authored-by: Sanju C Sudhakaran <scsudhakaran@habana.ai>
    Co-authored-by: Michal Adamczyk <madamczyk@habana.ai>
    Co-authored-by: Marceli Fylcek <mfylcek@habana.ai>
    Co-authored-by: Himangshu Lahkar <49579433+hlahkar@users.noreply.github.com>
    Co-authored-by: Vivek Goel <vgoel@habana.ai>
    Co-authored-by: yuwenzho <yuwen.zhou@intel.com>
    Co-authored-by: Dominika Olszewska <dolszewska@habana.ai>
    Co-authored-by: barak goldberg <149692267+bgoldberg-habana@users.noreply.github.com>
    Co-authored-by: Michal Szutenberg <37601244+szutenberg@users.noreply.github.com>
    Co-authored-by: Jan Kaniecki <jkaniecki@habana.ai>
    Co-authored-by: Agata Dobrzyniewicz <160237065+adobrzyniewicz-habana@users.noreply.github.com>
    Co-authored-by: Krzysztof Wisniewski <kwisniewski@habana.ai>
    Co-authored-by: Dudi Lester <160421192+dudilester@users.noreply.github.com>
    Co-authored-by: Ilia Taraban <tarabanil@gmail.com>
    Co-authored-by: Chendi.Xue <chendi.xue@intel.com>
    Co-authored-by: Micha≈Ç Kuligowski <mkuligowski@habana.ai>
    Co-authored-by: Jakub Maksymczuk <jmaksymczuk@habana.ai>
    Co-authored-by: Tomasz Zielinski <85164140+tzielinski-habana@users.noreply.github.com>
    Co-authored-by: Sun Choi <schoi@habana.ai>
    Co-authored-by: Iryna Boiko <iboiko@habana.ai>
    Co-authored-by: Bob Zhu <41610754+czhu15@users.noreply.github.com>
    Co-authored-by: hlin99 <73271530+hlin99@users.noreply.github.com>
    Co-authored-by: Zehao Huang <zehao.huang@intel.com>
    Co-authored-by: Andrzej Kot≈Çowski <Andrzej.Kotlowski@intel.com>
    Co-authored-by: Yan Tomsinsky <73292515+Yantom1@users.noreply.github.com>
    Co-authored-by: Nir David <ndavid@habana.ai>
    Co-authored-by: Yu-Zhou <yu.zhou@intel.com>
    Co-authored-by: Ruheena Suhani Shaik <rsshaik@habana.ai>
    Co-authored-by: Karol Damaszke <kdamaszke@habana.ai>
    Co-authored-by: Marcin Swiniarski <mswiniarski@habana.ai>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: Jacek Czaja <jacek.czaja@intel.com>
    Co-authored-by: Jacek Czaja <jczaja@habana.ai>
    Co-authored-by: Yuan <yuan.zhou@outlook.com>

[33mcommit a5fda50a10641e47c0c290907f30ef2add6d4e7a[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Nov 6 16:50:37 2024 +0800

    [CI/Build] Fix large_gpu_mark reason (#10070)
    
    Signed-off-by: Isotr0py <2037008807@qq.com>

[33mcommit 21063c11c7d340dbb01460e22d98d3619737cd4d[m
Author: Aaron Pham <contact@aarnphm.xyz>
Date:   Wed Nov 6 02:11:55 2024 -0500

    [CI/Build] drop support for  Python 3.8 EOL (#8464)
    
    Signed-off-by: Aaron Pham <contact@aarnphm.xyz>

[33mcommit 4be3a45158a7fb707973d4b00410e0d2981e6825[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 5 22:35:03 2024 -0800

    [distributed] add function to create ipc buffers directly (#10064)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 40899855520eb9497606bdb2b1b4e619233e598a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Nov 5 22:16:04 2024 -0800

    [V1] Integrate Piecewise CUDA graphs (#10058)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 9d59b755934899b7ec5d7bb5b90d15bfd2302475[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Tue Nov 5 21:13:09 2024 -0800

    [Bugfix] Remove CustomChatCompletionContentPartParam multimodal input type (#10054)
    
    Signed-off-by: Zifei Tong <zifeitong@gmail.com>

[33mcommit ea928f608c44b825d28609460e0d375a5f877940[m
Author: arakowsk-amd <182798202+arakowsk-amd@users.noreply.github.com>
Date:   Tue Nov 5 21:10:40 2024 -0800

    [Bugfix] Gpt-j-6B patch kv_scale to k_scale path  (#10063)
    
    Signed-off-by: Alex Rakowski <alex.rakowski@amd.com>
    Signed-off-by: Alex Rakowski <182798202+arakowsk-amd@users.noreply.github.com>

[33mcommit 2bcbae704c0d52913c6a2887260fc6bde6c20361[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Tue Nov 5 21:28:29 2024 -0700

    [Bugfix] Fix edge-case crash when using chat with the Mistral Tekken Tokenizer (#10051)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit ffc0f2b47add6e0f70e2b5d4b4aaac64ee97f8ad[m
Author: Peter Salas <peter@fixie.ai>
Date:   Tue Nov 5 20:19:15 2024 -0800

    [Model][OpenVINO] Fix regressions from #8346 (#10045)
    
    Signed-off-by: Peter Salas <peter@fixie.ai>

[33mcommit 82bfc38d079b1ef5f4b88ac7094a00029d2e99af[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Nov 6 12:05:05 2024 +0800

    [Misc] Sort the list of embedding models (#10037)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit c4cacbaa7faf9d0d3b2aa26e5df496724e80cb05[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 5 18:19:50 2024 -0800

    [v1] reduce graph capture time for piecewise cudagraph (#10059)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 0c63c34f725f0b519fa094fbeca6e3cf12c911c1[m
Author: Sungjae Lee <33976427+llsj14@users.noreply.github.com>
Date:   Wed Nov 6 10:45:45 2024 +0900

    [Bugfix][SpecDecode] kv corruption with bonus tokens in spec decode (#9730)
    
    Co-authored-by: LiuXiaoxuanPKU <lilyliupku@gmail.com>

[33mcommit 966e31697bdeb47b33b3e26b4aab5999c85f3e90[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Tue Nov 5 21:39:26 2024 -0300

    [Bugfix] Fix pickle of input when async output processing is on (#9931)
    
    Signed-off-by: Wallas Santos <wallashss@ibm.com>

[33mcommit 43300bd98a54d48e97d9fb78c9db88eda3a88c64[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Tue Nov 5 16:34:40 2024 -0800

    [Bugfix] Properly propagate trust_remote_code settings (#10047)
    
    Signed-off-by: Zifei Tong <zifeitong@gmail.com>

[33mcommit ca9844b340f45f23f8d30fdce23777d215ad987c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Nov 5 14:49:20 2024 -0800

    [bugfix] fix weak ref in piecewise cudagraph and tractable test (#10048)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 235366fe2eb3144321978e181af94487f0215595[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Nov 5 16:02:32 2024 -0500

    [CI] Prune back the number of tests in tests/kernels/* (#9932)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 02462465ea1c45163fde632fb94e0e4939ee8a59[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Nov 5 16:02:23 2024 -0500

    [CI] Prune tests/models/decoder_only/language/* tests (#9940)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit b9c64c0ca79ccdea608f337fbb7e4b0c75fe3aac[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Nov 6 03:40:08 2024 +0800

    [Misc] Modify BNB parameter name (#9997)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit d2e80332a7cedcfd23ec705b109c5fa3ad94fcc0[m
Author: lkchen <github@lkchen.net>
Date:   Tue Nov 5 11:30:02 2024 -0800

    [Feature] Update benchmark_throughput.py to support image input (#9851)
    
    Signed-off-by: Linkun Chen <github+anyscale@lkchen.net>
    Co-authored-by: Linkun Chen <github+anyscale@lkchen.net>

[33mcommit a53046b16fd11436eb2b15421079b7c5b353f955[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Nov 5 13:42:20 2024 -0500

    [Model] Support quantization of PixtralHFTransformer for PixtralHF (#9921)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 731aec5be713a89dccf1d7106290da17621af816[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Nov 5 13:30:42 2024 -0500

    [CI/Build] Limit github CI jobs based on files changed (#9928)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 09d3550372db10f8c75fddd437325a863265fd82[m
Author: Chenghao (Alan) Yang <chenghao@uchicago.edu>
Date:   Tue Nov 5 11:50:50 2024 -0600

    [Misc] Add logging for CUDA memory (#10027)
    
    Signed-off-by: Chenghao Yang <yangalan1996@gmail.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Chenghao Yang <yangalan1996@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit cd34029e91ad2d38a58d190331a65f9096c0b157[m
Author: Richard Liu <39319471+richardsliu@users.noreply.github.com>
Date:   Tue Nov 5 08:48:44 2024 -0800

    Refactor TPU requirements file and pin build dependencies (#10010)
    
    Signed-off-by: Richard Liu <ricliu@google.com>

[33mcommit 5952d811398d3a22f30d72d2d2943787a78f66ea[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Nov 5 10:50:57 2024 -0500

    [Frontend] Fix tcp port reservation for api server (#10012)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 93dee88f6b0ff28c2e8b79d638b4e56d58128927[m
Author: Chauncey <chaunceyjiang@gmail.com>
Date:   Tue Nov 5 18:59:56 2024 +0800

    [Misc] vllm CLI flags should be ordered for better user readability (#10017)
    
    Signed-off-by: chaunceyjiang <chaunceyjiang@gmail.com>

[33mcommit 7a83b1aec06834e58174694042105e365828507a[m
Author: Gene Der Su <e870252314@gmail.com>
Date:   Tue Nov 5 02:04:10 2024 -0800

    [BugFix] Lazy import ray (#10021)

[33mcommit ad23318928d40ef7ac969451afa0dc198428c04b[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Nov 4 22:46:38 2024 -0500

    [Bugfix] Fixup Mamba (#10004)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit bbc3619dc806b25fd5e14eef90819052ab76e1c6[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Nov 5 10:07:31 2024 +0800

    [Core] Make encoder-decoder inputs a nested structure to be more composable (#9604)
    
    Signed-off-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 04bbf38e05fe75539577184f6ca776df39e70dcd[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Nov 4 20:08:21 2024 -0500

    [Core] Use os.sched_yield in ShmRingBuffer instead of time.sleep (#9994)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 8f0a9ca890a125f2b0fef49ba042ecf5b37830a8[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Nov 4 18:57:44 2024 -0500

    [Bugfix] Respect modules_to_not_convert within awq_marlin (#9895)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 2094062b4eafe465826e936fbd5cbd8f099d7762[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 4 15:11:59 2024 -0800

    [4.5/N] bugfix for quant config in speculative decode (#10007)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d93478b399535d4b31e49d584d323172e6060653[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Mon Nov 4 18:11:28 2024 -0500

    [Bugfix] Upgrade to pytorch 2.5.1 (#10001)
    
    Signed-off-by: Bill Nell <bill@neuralmagic.com>

[33mcommit ac04a97a9fbc122bb14ff4eb590314d453cdf57c[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Tue Nov 5 00:53:24 2024 +0200

    [Frontend] Add max_tokens prometheus metric (#9881)
    
    Signed-off-by: Tomer Asida <tomera@ai21.com>

[33mcommit 9a5664d4a4d212a6ebad79b15b11eb8d3ab2a0b2[m
Author: lkchen <github@lkchen.net>
Date:   Mon Nov 4 14:32:16 2024 -0800

    [Misc] Refactor benchmark_throughput.py (#9779)
    
    Signed-off-by: Linkun Chen <github+anyscale@lkchen.net>
    Co-authored-by: Linkun Chen <lkchen@github.com>
    Co-authored-by: Linkun Chen <github+anyscale@lkchen.net>

[33mcommit 04cef2c6ab0ea47bb1dfa73d3343985499fe1c4b[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Mon Nov 4 16:01:43 2024 -0500

    [Bugfix] Fix `MQLLMEngine` hanging (#9973)
    
    Signed-off-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>

[33mcommit 6e056bcf0414dfaee4db646f8f36ec961f0c9a33[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Nov 4 11:47:11 2024 -0800

    [Doc] Update VLM doc about loading from local files (#9999)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit 5208dc7a203b210fa4462332a56c0012ab8b7a89[m
Author: hissu-hyvarinen <hissu.hyvarinen@amd.com>
Date:   Mon Nov 4 21:37:46 2024 +0200

    [Bugfix][CI/Build][Hardware][AMD] Shard ID parameters in AMD tests running parallel jobs (#9279)
    
    Signed-off-by: Hissu Hyvarinen <hissu.hyvarinen@amd.com>

[33mcommit 1c45f4c38576db6a27a52f36af9b693807d862b7[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Mon Nov 4 14:34:26 2024 -0500

    [CI] Basic Integration Test For TPU (#9968)
    
    Signed-off-by: Robert Shaw <rshaw@neuralmagic.com>

[33mcommit 603a661ae8ccadd8401284f7db8563164b232651[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Mon Nov 4 20:00:00 2024 +0200

    [Model] factoring out MambaMixer out of Jamba (#8993)
    
    Signed-off-by: mzusman <mor.zusmann@gmail.com>

[33mcommit fb2716d64117aaa6c36b97b09765aa10a89e2fe5[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Nov 5 01:04:40 2024 +0800

    [Misc]Reduce BNB static variable (#9987)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 8d72bb20fae1a8a9d6ec6dcb2a833a190e1225d3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Nov 4 08:51:31 2024 -0800

    [4/N] make quant config first-class citizen (#9978)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit ac6b8f19b9007433b9cbf057c1d01ae9d4efdad5[m
Author: Chauncey <chaunceyjiang@gmail.com>
Date:   Mon Nov 4 23:34:57 2024 +0800

    [Frontend] Multi-Modality Support for Loading Local Image Files (#9915)
    
    Signed-off-by: chaunceyjiang <chaunceyjiang@gmail.com>

[33mcommit ccb5376a9a88bb6251c4434b79c173151e6f7729[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Mon Nov 4 18:14:13 2024 +0800

    [Bugfix][OpenVINO] Fix circular reference #9939 (#9974)
    
    Signed-off-by: MengqingCao <cmq0113@163.com>

[33mcommit ea4adeddc12412ad0854f93882e214000e91ce05[m
Author: Tran Quang Dai <62875701+daitran2k1@users.noreply.github.com>
Date:   Mon Nov 4 16:37:58 2024 +0700

    [Bugfix] Fix E2EL mean and median stats (#9984)
    
    Signed-off-by: daitran2k1 <tranquangdai7a@gmail.com>

[33mcommit 4dbcbbeb09628eb3181dedb6789f0ccb05e83957[m
Author: Yang Zheng <50227060+zhengy001@users.noreply.github.com>
Date:   Mon Nov 4 16:54:37 2024 +0800

    [Misc] Compute query_start_loc/seq_start_loc on CPU (#9447)
    
    Co-authored-by: Yang Zheng(SW)(Alex) <you@example.com>

[33mcommit b67feb12749ef8c01ef77142c3cd534bb3d87eda[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Mon Nov 4 01:19:51 2024 -0500

    [Bugfix]Using the correct type hints (#9885)
    
    Signed-off-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>

[33mcommit c49f0407ba60bfee538892a09561c1fe7484adf8[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Mon Nov 4 11:36:41 2024 +0800

    [Bugfix] Fix MiniCPMV and Mllama BNB  bug (#9917)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 91c9ebbb1bfc39e98aa2bd444b9569e5f2f92c9e[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Nov 3 19:24:40 2024 -0500

    [V1] Fix Configs (#9971)

[33mcommit 54597724f4c6b52d50152f3cc46e86c101d9c820[m
Author: shanshan wang <cooleel@gmail.com>
Date:   Sun Nov 3 18:15:36 2024 -0600

    [Model] Add support for H2OVL-Mississippi models (#9747)
    
    Signed-off-by: Shanshan Wang <shanshan.wang@h2o.ai>
    Signed-off-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 1f1b6d6eda3ea5fbdf4566632ac8a9fa61b31593[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sun Nov 3 17:14:17 2024 +0000

    [V1] Support per-request seed (#9945)
    
    Signed-off-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 3bb4befea7166850bdee3f72fe060c9c4044ba85[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 2 15:54:05 2024 -0700

    [bugfix] fix tsts (#9959)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit ae5279a16385e15c07ab2bcadcbcab44367595e9[m
Author: Yongzao <532741407@qq.com>
Date:   Sun Nov 3 03:56:05 2024 +0800

    [torch.compile] Adding torch compile to vision-language models (#9946)

[33mcommit 1b73ab2a1f0761a60b28aabe0456a5735de027c5[m
Author: Nikita Furin <nokados@yandex.ru>
Date:   Sat Nov 2 22:50:28 2024 +0300

    [CI/Build] Quoting around > (#9956)

[33mcommit cea808f32549973cc19204355c950ad005eeed87[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 2 12:08:49 2024 -0700

    [3/N] model runner pass the whole config to model (#9958)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 74b529ceeead8d4b44ded858f7c28bca9c1629ba[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 2 08:03:33 2024 -0700

    [bugfix] fix chatglm dummy_data_for_glmv (#9955)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit d6459b4516dbac4f346ce29fe90d43ebfafa1114[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Nov 2 10:44:38 2024 -0400

    [V1] Fix `EngineArgs` refactor on V1 (#9954)

[33mcommit e8937954434037ac787efa800f01d9d294185439[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Nov 2 07:35:05 2024 -0700

    [2/N] executor pass the complete config to worker/modelrunner (#9938)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Nick Hill <nhill@redhat.com>

[33mcommit 1d4cfe2be1907408d610489bdca7bc8f8d2345b1[m
Author: Michael Green <59619482+mikegre-google@users.noreply.github.com>
Date:   Sat Nov 2 14:06:45 2024 +0000

    [Doc] Updated tpu-installation.rst with more details (#9926)
    
    Signed-off-by: Michael Green <mikegre@google.com>

[33mcommit eed92f12fc829ff074e7341283cb1677b7e65aa2[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sat Nov 2 09:02:18 2024 +0000

    [Docs] Update Granite 3.0 models in supported models table (#9930)
    
    Signed-off-by: Nick Hill <nhill@redhat.com>
    Signed-off-by: Nick Hill <nickhill@us.ibm.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit af7380d83b0d67726a4a6c7a86766423bed6a7a8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 1 23:35:47 2024 -0700

    [torch.compile] fix cpu broken code (#9947)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit a78dd3303efac284afc6785eddba5f175285863b[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Fri Nov 1 23:22:49 2024 -0700

    [Encoder Decoder] Add flash_attn kernel support for encoder-decoder models (#9559)

[33mcommit d522034c85e8f994bbd193514393056232edd247[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Fri Nov 1 13:56:13 2024 -1000

    [ci/build] Have dependabot ignore pinned dependencies (#9935)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 6c0b7f548d80b5f61bfa472ad1497597c922dbc2[m
Author: Peter Salas <peter@fixie.ai>
Date:   Fri Nov 1 16:21:10 2024 -0700

    [Core][VLM] Add precise multi-modal placeholder tracking (#8346)
    
    Signed-off-by: Peter Salas <peter@fixie.ai>

[33mcommit d151fde8341d34592e1e5e14d2152d067421cf63[m
Author: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Date:   Fri Nov 1 23:04:42 2024 +0000

    [ci/build] Bump the patch-update group with 10 updates (#9897)
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
    Co-authored-by: Kevin H. Luu <kevin@anyscale.com>

[33mcommit 27cd36e6e2e808464c8343066b03db5db2d15413[m
Author: Gene Der Su <gdsu@ucdavis.edu>
Date:   Fri Nov 1 15:08:23 2024 -0700

    [Bugfix] PicklingError on RayTaskError (#9934)
    
    Signed-off-by: Gene Su <e870252314@gmail.com>

[33mcommit 18bd7587b78b3b9868fea29d59ae8c3600c3e5a5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 1 13:51:57 2024 -0700

    [1/N] pass the complete config from engine to executor (#9933)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 598b6d7b070149aae5884aa8b17a0c91c93172f5[m
Author: Pavani Majety <pmajety@nvidia.com>
Date:   Fri Nov 1 12:15:05 2024 -0700

    [Bugfix/Core] Flashinfer k_scale and v_scale (#9861)

[33mcommit aff1fd81881bf29f82ad6ba55b301828764cd120[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Nov 1 11:50:37 2024 -0700

    [torch.compile] use interpreter with stable api from pytorch (#9889)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 4581d2cc02f655e76233f9cb129f07c6b65d39f4[m
Author: Andr√© Jonasson <andre.jonasson@gmail.com>
Date:   Fri Nov 1 19:41:38 2024 +0100

    [Core] Refactor: Clean up unused argument in Scheduler._preempt (#9696)
    
    Signed-off-by: Andr√© Jonasson <andre.jonasson@gmail.com>

[33mcommit 1dd4cb2935fc3fff9c156b5772d18e0a0d1861f0[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Fri Nov 1 11:33:15 2024 -0600

    [Bugfix] Fix edge cases for MistralTokenizer (#9625)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>
    Signed-off-by: Prashant Gupta <prashantgupta@us.ibm.com>
    Co-authored-by: Prashant Gupta <prashantgupta@us.ibm.com>
    Co-authored-by: Patrick von Platen <patrick.v.platen@gmail.com>

[33mcommit ba0d8920742597269745f3551eb97b1b19f5e582[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 1 22:09:07 2024 +0800

    [Frontend] Use a proper chat template for VLM2Vec (#9912)

[33mcommit 30a2e8074246e11a1452ab5e84a7be65ecac6119[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Nov 1 09:55:29 2024 -0400

    [CI/Build] Add Model Tests for PixtralHF (#9813)

[33mcommit 06386a64dd706cf3fdab82510124ca2c2f9eee9d[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 1 16:13:35 2024 +0800

    [Frontend] Chat-based Embeddings API (#9759)

[33mcommit d3aa2a8b2f93f50ed40fe7d8617701a2294a13e4[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Nov 1 15:34:49 2024 +0800

    [Doc] Update multi-input support (#9906)

[33mcommit 2b5bf20988edaab21621b78a9eb589edc93f2763[m
Author: Yongzao <532741407@qq.com>
Date:   Fri Nov 1 15:25:47 2024 +0800

    [torch.compile] Adding torch compile annotations to some models (#9876)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 93a76dd21dcec8977f1ffd0e21faa88fb515b9e4[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Nov 1 01:31:56 2024 -0400

    [Model] Support bitsandbytes for MiniCPMV (#9891)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 566cd277979bc1a46b7e99657112416af9874a58[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Oct 31 22:20:17 2024 -0700

    [torch.compile] rework test plans (#9866)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 37a4947dcd68c602d0911920e2c1a9168dea1ecb[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Nov 1 01:12:44 2024 -0400

    [Bugfix] Fix layer skip logic with bitsandbytes (#9887)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 96e0c9cbbd65ad0b8ad20611b90bcc86a8559aae[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Oct 31 21:56:09 2024 -0700

    [torch.compile] directly register custom op (#9896)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 031a7995f38d3c73b0790280cc0fa1fe25d33bff[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Thu Oct 31 19:09:46 2024 -0600

    [Bugfix][Frontend] Reject guided decoding in multistep mode (#9892)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit b63c64d95b01cc955a56bba37d055ad36aa81abd[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Oct 31 12:55:38 2024 -1000

    [ci/build] Configure dependabot to update pip dependencies  (#9811)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 9fb12f7848d427b6c1c29052271030a5e96bd74a[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Thu Oct 31 22:06:25 2024 +0200

    [BugFix][Kernel] Fix Illegal memory access in causal_conv1d in H100 (#9838)
    
    Signed-off-by: mzusman <mor.zusmann@gmail.com>

[33mcommit 55650c83a0c386526ed04912a0c60eccca202f3e[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Thu Oct 31 18:46:36 2024 +0000

    [Bugfix] Fix `illegal memory access` error with chunked prefill, prefix caching, block manager v2 and xformers enabled together (#9532)
    
    Signed-off-by: sasha0552 <admin@sasha0552.org>

[33mcommit 77f7ef29088fef854421239e7c41df6b11bc4b5b[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Thu Oct 31 12:02:58 2024 -0500

    [CI/Build] Adding a forced docker system prune to clean up space (#9849)

[33mcommit 16b8f7a86f5a93d2b0dc4bd20709a47d34918b8f[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Thu Oct 31 10:10:52 2024 -0600

    [CI/Build] Add Model Tests for Qwen2-VL (#9846)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 5608e611c2116cc17c6808b2ae1ecb4a3e263493[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Oct 31 16:54:18 2024 +0800

    [Doc] Update Qwen documentation (#9869)

[33mcommit 3ea2dc2ec49d1ddd7875045e2397ae76a8f50b38[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Oct 31 00:22:07 2024 -0700

    [Misc] Remove deprecated arg for cuda graph capture (#9864)
    
    Signed-off-by: Roger Wang <ywang@roblox.com>

[33mcommit d087bf863e0d228c8b5aaae6535de15c5817eb7b[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Oct 31 01:41:20 2024 -0400

    [Model] Support quantization of Qwen2VisionTransformer (#9817)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 890ca3607208a10514e65cfdf182bdd4125baef6[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Oct 30 15:44:51 2024 -1000

    Revert "[Bugfix] Use host argument to bind to interface (#9798)" (#9852)

[33mcommit abbfb6134dc73359cba015dbd1ad30fafd25a891[m
Author: Guillaume Calmettes <gcalmettes@scaleway.com>
Date:   Thu Oct 31 02:15:56 2024 +0100

    [Misc][OpenAI] deprecate max_tokens in favor of new max_completion_tokens field for chat completion endpoint (#9837)

[33mcommit 64384bbcdfe6bdf4b50ff82bda90e728160325f5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Oct 30 16:34:22 2024 -0700

    [torch.compile] upgrade tests (#9858)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 00d91c8a2cf3ebaf0f3ea69312f6e3882ed9f372[m
Author: Yongzao <532741407@qq.com>
Date:   Thu Oct 31 05:52:05 2024 +0800

    [CI/Build] Simplify exception trace in api server tests (#9787)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit c2cd1a21420e5cac847808bd3113b4c1100633c1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Oct 30 13:36:51 2024 -0700

    [doc] update pp support (#9853)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit c787f2d81ddc25a3505a2075238f1f54233ff76b[m
Author: Harsha vardhan manoj Bikki <39381063+hbikki@users.noreply.github.com>
Date:   Wed Oct 30 12:22:02 2024 -0700

    [Neuron] Update Dockerfile.neuron to fix build failure (#9822)

[33mcommit 33d257735f35da437262f381cc9cb5a02f3d6b6b[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Wed Oct 30 11:28:29 2024 -0600

    [Doc] link bug for multistep guided decoding (#9843)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 3b3f1e743631667795469946a33d8352fcc74efd[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Wed Oct 30 10:34:07 2024 -0600

    [Bugfix][core] replace heartbeat with pid check (#9818)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 9ff4511e43bb95efefd4e28048ca257e408277fb[m
Author: Elfie Guo <164945471+elfiegg@users.noreply.github.com>
Date:   Wed Oct 30 09:33:53 2024 -0700

    [Misc] Add chunked-prefill support on FlashInfer. (#9781)

[33mcommit 81f09cfd80a5a2e1572ee79facd60bb823923367[m
Author: Went-Liang <wenteng_liang@163.com>
Date:   Thu Oct 31 00:33:42 2024 +0800

    [Model] Support math-shepherd-mistral-7b-prm model (#9697)
    
    Signed-off-by: Went-Liang <wenteng_liang@163.com>

[33mcommit cc98f1e0798cf2b5ea5bc5d0c565af2f884bf6e8[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Wed Oct 30 10:32:17 2024 -0600

    [CI/Build] VLM Test Consolidation (#9372)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit 211fe91aa88730c04df439298d8103a587302493[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Oct 30 02:41:38 2024 -0700

    [TPU] Correctly profile peak memory usage & Upgrade PyTorch XLA (#9438)

[33mcommit 6aa6020f9bd4c1e414c10f7bd3a7c2555f1950b2[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Oct 30 14:05:43 2024 +0800

    [Misc] Specify minimum pynvml version (#9827)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit ff5ed6e1bcbd112a26f8eb43b6bfdbc5ec73726e[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Oct 29 23:03:49 2024 -0700

    [torch.compile] rework compile control with piecewise cudagraph (#9715)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 7b0365efef35bb03aa94e0085199d20750409363[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Oct 30 01:22:23 2024 -0400

    [Doc] Add the DCO to CONTRIBUTING.md (#9803)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 04a3ae0acae3d522299ec90b5730f876daa845e6[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Wed Oct 30 12:34:45 2024 +0800

    [Bugfix] Fix multi nodes TP+PP for XPU (#8884)
    
    Signed-off-by: YiSheng5 <syhm@mail.ustc.edu.cn>
    Signed-off-by: yan ma <yan.ma@intel.com>
    Co-authored-by: YiSheng5 <syhm@mail.ustc.edu.cn>

[33mcommit 62fac4b9aab3c05124d83fcd71db5732774b17d8[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Oct 29 17:34:55 2024 -1000

    [ci/build] Pin CI dependencies version with pip-compile  (#9810)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 226688bd6114749633132b9ed074c59d50904830[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Oct 29 22:49:44 2024 -0400

    [Bugfix][VLM] Make apply_fp8_linear work with >2D input (#9812)

[33mcommit 64cb1cdc3f3a6c0ca976d68b19d454122c720e6d[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Tue Oct 29 17:28:43 2024 -0700

    Update README.md (#9819)

[33mcommit 1ab6f6b4ad5c4aac6ee72e51b7f6712098f9ccff[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Oct 29 17:06:24 2024 -0700

    [core][distributed] fix custom allreduce in pytorch 2.5 (#9815)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit bc73e9821cb4f90a88c04e7d550f132d8911266b[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Oct 29 19:02:59 2024 -0400

    [Bugfix] Fix prefix strings for quantized VLMs (#9772)

[33mcommit 8d7724104aef4381cf268de094360f27ff68f4ab[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Oct 29 15:19:02 2024 -0700

    [Docs] Add notes about Snowflake Meetup (#9814)
    
    Signed-off-by: simon-mo <simon.mo@hey.com>

[33mcommit 882a1ad0deb9fd26283db611e78e122ac19fb72f[m
Author: Will Eaton <wseaton@users.noreply.github.com>
Date:   Tue Oct 29 18:07:37 2024 -0400

    [Model] tool calling support for ibm-granite/granite-20b-functioncalling (#8339)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
    Co-authored-by: Max de Bayser <mbayser@br.ibm.com>
    Co-authored-by: Maximilien de Bayser <maxdebayser@gmail.com>

[33mcommit 67bdf8e523e4020a559b6d74981936c8156243f9[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Tue Oct 29 16:13:20 2024 -0500

    [Bugfix][Frontend] Guard against bad token ids (#9634)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 0ad216f5750742115c686723bf38698372d483fd[m
Author: Kunjan <kunjanp@google.com>
Date:   Tue Oct 29 12:52:19 2024 -0700

    [MISC] Set label value to timestamp over 0, to keep track of recent history  (#9777)
    
    Signed-off-by: Kunjan Patel <kunjanp@google.com>

[33mcommit 7585ec996f7ec88735627cb2ab13949226f9bfce[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Oct 29 15:24:42 2024 -0400

    [CI/Build] mergify: fix rules for ci/build label (#9804)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit ab6f981671c4e5035575f5e5ef6172f4df52e121[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Oct 29 14:12:43 2024 -0400

    [CI][Bugfix] Skip chameleon for transformers 4.46.1 (#9808)

[33mcommit ac3d748dba446b9a8417fe3005345c12989d8de0[m
Author: Junichi Sato <junichi.sato@sbintuitions.co.jp>
Date:   Wed Oct 30 02:40:35 2024 +0900

    [Model]  Add LlamaEmbeddingModel as an embedding Implementation of LlamaModel (#9806)

[33mcommit 0ce7798f44c586e11c65d59725724eb805086e93[m
Author: yannicks1 <43552841+yannicks1@users.noreply.github.com>
Date:   Tue Oct 29 18:39:20 2024 +0100

    [Misc]: Typo fix: Renaming classes (casualLM -> causalLM) (#9801)
    
    Signed-off-by: Yannick Schnider <Yannick.Schnider1@ibm.com>

[33mcommit 0f43387157010bf84da05c68fc5ff366b3252f01[m
Author: Sven Seeberg <sven@geeq.de>
Date:   Tue Oct 29 18:37:59 2024 +0100

    [Bugfix] Use host argument to bind to interface (#9798)

[33mcommit 08600ddc685558d8504eb94bbbf382230f6de386[m
Author: tastelikefeet <58414341+tastelikefeet@users.noreply.github.com>
Date:   Wed Oct 30 01:36:59 2024 +0800

    Fix the log to correct guide user to install modelscope (#9793)
    
    Signed-off-by: yuze.zyz <yuze.zyz@alibaba-inc.com>

[33mcommit 74fc2d77aec13304550bb52b459bd8c6da756d39[m
Author: ÁßëËã± <abatom@163.com>
Date:   Wed Oct 30 01:32:56 2024 +0800

    [Misc] Add metrics for request queue time, forward time, and execute time (#9659)

[33mcommit 622b7ab955186f37879208d7a30e9faf985be220[m
Author: wangshuai09 <391746016@qq.com>
Date:   Tue Oct 29 22:47:44 2024 +0800

    [Hardware] using current_platform.seed_everything (#9785)
    
    Signed-off-by: wangshuai09 <391746016@qq.com>

[33mcommit 09500f7ddeb974730972fd9284bd93c08a557cf6[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue Oct 29 20:20:02 2024 +0800

    [Model] Add BNB quantization support for Mllama (#9720)

[33mcommit ef7865b4f9013e1d328058091b12b28c4a078e91[m
Author: Zhong Qishuai <FerdinandZhong@gmail.com>
Date:   Tue Oct 29 19:49:47 2024 +0800

    [Frontend] re-enable multi-modality input in the new beam search implementation (#9427)
    
    Signed-off-by: Qishuai Ferdinandzhong@gmail.com

[33mcommit eae3d48181b1ad27f132f14df18e8cff203f7552[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Oct 29 13:08:20 2024 +0800

    [Bugfix] Use temporary directory in registry (#9721)

[33mcommit e74f2d448c9b984f6b2c91137c58919441456503[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Oct 29 13:07:57 2024 +0800

    [Doc] Specify async engine args in docs (#9726)

[33mcommit 7a4df5f200f0943113dd2d9be49cbcae38ad10bb[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Oct 29 12:14:07 2024 +0800

    [Model][LoRA]LoRA support added for Qwen (#9622)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit c5d7fb9ddc16d9eb68f1018cfb384faf3be301be[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Mon Oct 28 22:39:21 2024 -0400

    [Doc] fix third-party model example (#9771)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 76ed5340f0ec0e481593ea1a94459b4b55136a4f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Oct 28 14:35:17 2024 -0700

    [torch.compile] add deepseek v2 compile (#9775)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 97b61bfae63636e4916b49c3a2ff20353cb86db7[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Oct 28 13:51:23 2024 -0700

    [misc] avoid circular import (#9765)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit aa0addb39726b685522e7cf154b564b4159759ad[m
Author: Yongzao <532741407@qq.com>
Date:   Tue Oct 29 04:49:56 2024 +0800

    Adding "torch compile" annotations to moe models (#9758)

[33mcommit 5f8d8075f957d5376b2f1cc451e35a2a757e95a5[m
Author: litianjian <45817262+litianjian@users.noreply.github.com>
Date:   Tue Oct 29 02:04:10 2024 +0800

    [Model][VLM] Add multi-video support for LLaVA-Onevision (#8905)
    
    Co-authored-by: litianjian <litianjian@bytedance.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 8b0e4f2ad7b5a3ddd6d61acbe8ceb50b4ea3c309[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Mon Oct 28 12:38:09 2024 -0400

    [CI/Build] Adopt Mergify for auto-labeling PRs (#9259)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 2adb4409e0359039135b5aa6501994da12aa5a26[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Mon Oct 28 15:13:03 2024 +0800

    [Bugfix] Fix ray instance detect issue (#9439)

[33mcommit feb92fbe4ab6803527df48658a87ebd00b99969f[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Mon Oct 28 02:59:37 2024 -0400

    Fix beam search eos (#9627)

[33mcommit 32176fee733b76b295346870d717d44cb7102944[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Oct 27 21:58:04 2024 -0700

    [torch.compile] support moe models (#9632)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 4e2d95e372ad5fbef7b27c66d527c37477c0c8bb[m
Author: wangshuai09 <391746016@qq.com>
Date:   Mon Oct 28 12:07:00 2024 +0800

    [Hardware][ROCM] using current_platform.is_rocm (#9642)
    
    Signed-off-by: wangshuai09 <391746016@qq.com>

[33mcommit 34a9941620d00879599a51609225452b705bae89[m
Author: madt2709 <55849102+madt2709@users.noreply.github.com>
Date:   Sun Oct 27 10:46:41 2024 -0700

    [Bugfix] Fix load config when using bools (#9533)

[33mcommit e130c40e4eba63ee8f04d493d83bca8c59b5ada5[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Sun Oct 27 17:30:03 2024 +0000

    Fix cache management in "Close inactive issues and PRs" actions workflow (#9734)

[33mcommit 3cb07a36a20f9af11346650559470d685e9dc711[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Sun Oct 27 05:44:24 2024 -0400

    [Misc] Upgrade to pytorch 2.5 (#9588)
    
    Signed-off-by: Bill Nell <bill@neuralmagic.com>
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 8549c82660cfa59a13cccd622f8afcc29cbd4281[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Oct 27 00:19:28 2024 -0700

    [core] cudagraph output with tensor weak reference (#9724)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit 67a6882da474a45dde0d35b3789e096e7bd0fd4e[m
Author: ÁßëËã± <abatom@163.com>
Date:   Sun Oct 27 12:18:03 2024 +0800

    [Misc] SpecDecodeWorker supports profiling (#9719)
    
    Signed-off-by: Abatom <abatom@163.com>

[33mcommit 6650e6a930dbdf1cd4def9b58e952376400ccfcf[m
Author: kakao-kevin-us <kevin.us@kakaocorp.com>
Date:   Sun Oct 27 02:53:35 2024 +0900

    [Model] Add classification Task with Qwen2ForSequenceClassification  (#9704)
    
    Signed-off-by: Kevin-Yang <ykcha9@gmail.com>
    Co-authored-by: Kevin-Yang <ykcha9@gmail.com>

[33mcommit 07e981fdf43bb7a7186c782a5ad6b99b36c2fc19[m
Author: Vasiliy Alekseev <alvasian@yandex.ru>
Date:   Sat Oct 26 19:29:38 2024 +0300

    [Frontend] Bad words sampling parameter (#9717)
    
    Signed-off-by: Vasily Alexeev <alvasian@yandex.ru>

[33mcommit 55137e8ee32509b2fa3b83d5caaee018a929f82d[m
Author: ErkinSagiroglu <52523336+MErkinSag@users.noreply.github.com>
Date:   Sat Oct 26 13:12:57 2024 +0100

    Fix: MI100 Support By Bypassing Custom Paged Attention (#9560)

[33mcommit 5cbdccd151ef50e3fc040690248a8d86d3b93c2a[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Sat Oct 26 18:59:06 2024 +0800

    [Hardware][openvino] is_openvino --> current_platform.is_openvino (#9716)

[33mcommit 067e77f9a87c3466fce41c8fe8710fddc69ec26c[m
Author: Sam Stoelinga <sammiestoel@gmail.com>
Date:   Fri Oct 25 22:05:47 2024 -0700

    [Bugfix] Steaming continuous_usage_stats default to False (#9709)
    
    Signed-off-by: Sam Stoelinga <sammiestoel@gmail.com>

[33mcommit 6567e13724110fac2042d06a9e4c01fd822e8909[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Fri Oct 25 16:42:56 2024 -0600

    [Bugfix] Fix crash with llama 3.2 vision models and guided decoding (#9631)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>
    Co-authored-by: pavlo-ruban <pavlo.ruban@servicenow.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 228cfbd03fd1ad9b26001817a6d414cc9f2c22ae[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Fri Oct 25 17:32:10 2024 -0400

    [Doc] Improve quickstart documentation (#9256)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit ca0d92227e3a5e5880dde67da9d96c6d06454328[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Oct 25 15:40:33 2024 -0400

    [Bugfix] Fix compressed_tensors_moe bad config.strategy (#9677)

[33mcommit 9645b9f646024b1e416ed5a61cfba7d14d54b571[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Oct 24 22:20:37 2024 -0700

    [V1] Support sliding window attention (#9679)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit a6f37218619df39760624d541bf7911ab911f792[m
Author: Will Johnson <mwjohnson728@gmail.com>
Date:   Fri Oct 25 01:00:17 2024 -0400

    [Model] add a lora module for granite 3.0 MoE models (#9673)

[33mcommit 9f7b4ba86578fbb0b6e80a2b0c1a334d88787a57[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Oct 24 17:59:00 2024 -1000

    [ci/Build] Skip Chameleon for transformers 4.46.0 on broadcast test #9675 (#9676)

[33mcommit c91ed47c436f2d45299bed5eacd257e8cbc7c312[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Oct 24 18:38:05 2024 -0400

    [Bugfix] Remove xformers requirement for Pixtral (#9597)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit 59449095ab536febe9ff341b2a88a4fed572a70f[m
Author: Charlie Fu <charlifu@amd.com>
Date:   Thu Oct 24 17:37:52 2024 -0500

    [Performance][Kernel] Fused_moe Performance Improvement (#9384)
    
    Signed-off-by: charlifu <charlifu@amd.com>

[33mcommit e26d37a185fd33c3f91d0035611c26cfb03883da[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Oct 24 13:44:38 2024 -0400

    [Log][Bugfix] Fix default value check for `image_url.detail` (#9663)

[33mcommit 722d46edb974315c7d2d8feed75520ea7a30d7fa[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Thu Oct 24 11:42:24 2024 -0600

    [Model] Compute Llava Next Max Tokens / Dummy Data From Gridpoints (#9650)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit c866e0079de05cf6aee5931f3b9e200e8cbcf26c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Oct 25 01:40:40 2024 +0800

    [CI/Build] Fix VLM test failures when using transformers v4.46 (#9666)

[33mcommit d27cfbf791ef01483db9c45e215f3f299e54a079[m
Author: Yongzao <532741407@qq.com>
Date:   Fri Oct 25 00:31:42 2024 +0800

    [torch.compile] Adding torch compile annotations to some models (#9641)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit de662d32b5d928d30e8923db548ed1fd94206158[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Thu Oct 24 17:17:45 2024 +0100

    Increase operation per run limit for "Close inactive issues and PRs" workflow (#9661)
    
    Signed-off-by: Harry Mellor <hej.mellor@gmail.com>

[33mcommit f58454968fe1c5ddf84199b341a6ed5c99f0c0cc[m
Author: litianjian <45817262+litianjian@users.noreply.github.com>
Date:   Thu Oct 24 22:52:07 2024 +0800

    [Bugfix]Disable the post_norm layer of the vision encoder for LLaVA models (#9653)

[33mcommit b979143d5bbe35192b55875f04a24de4108eb514[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Oct 24 17:43:59 2024 +0800

    [Doc] Move additional tips/notes to the top (#9647)

[33mcommit ad6f78053ed33b2386713b574976523858a879b5[m
Author: Yongzao <532741407@qq.com>
Date:   Thu Oct 24 16:32:15 2024 +0800

    [torch.compile] expanding support and fix allgather compilation (#9637)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 295a061fb34ec6fb251abf1dbece5b1bb7dc9006[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Oct 24 16:18:27 2024 +0800

    [Kernel] add kernel for FATReLU (#9610)
    
    Signed-off-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 8a02cd045ac661481ba2672846e09f5b57110f40[m
Author: Yongzao <532741407@qq.com>
Date:   Thu Oct 24 15:54:57 2024 +0800

    [torch.compile] Adding torch compile annotations to some models (#9639)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 4fdc581f9e5740ba10b16ebf8a4c467e65bb9822[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Oct 24 00:16:44 2024 -0700

    [core] simplify seq group code (#9569)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 3770071eb4dc97eb728ad68adde027769ee31afe[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Oct 23 23:33:22 2024 -0700

    [V1][Bugfix] Clean up requests when aborted (#9629)
    
    Signed-off-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 836e8ef6eeafcd1e24b25c990da6331f48a95fd2[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Oct 24 14:12:05 2024 +0800

    [Bugfix] Fix PP for ChatGLM and Molmo (#9422)

[33mcommit 056a68c7dbaff03252d2f8c058d3fb700565ad1f[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Thu Oct 24 13:14:00 2024 +0800

    [XPU] avoid triton import for xpu (#9440)
    
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 33bab4106011b4c4b4b68640676a076a2bcccfed[m
Author: Vinay R Damodaran <vrdn@hey.com>
Date:   Thu Oct 24 01:05:49 2024 -0400

    [Bugfix]: Make chat content text allow type content (#9358)
    
    Signed-off-by: Vinay Damodaran <vrdn@hey.com>

[33mcommit b7df53cd42f3eab007b4f287c151960858e949df[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Oct 23 22:07:44 2024 -0400

    [Bugfix] Use "vision_model" prefix for MllamaVisionModel (#9628)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit bb01f2915eb3ade94b086033d7f2a6fe7de3c067[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Oct 23 22:03:44 2024 -0400

    [Bugfix][Model] Fix Mllama SDPA illegal memory access for batched multi-image (#9626)
    
    Signed-off-by: mgoin <michael@neuralmagic.com>

[33mcommit b548d7a5f4aabd1ee7ba90a80ccee0ca5c401524[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Oct 23 18:45:26 2024 -0400

    [CI/Build] Add bot to close stale issues and PRs (#9436)

[33mcommit fc6c27462614924dca90898ef762d6c56c0874ba[m
Author: Yunfei Chu <faychu@qq.com>
Date:   Thu Oct 24 01:54:22 2024 +0800

    [Model] Add Qwen2-Audio model support (#9248)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 150b779081381124609a30383b5f87dbd6d110e5[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Wed Oct 23 11:28:57 2024 -0600

    [Frontend] Enable Online Multi-image Support for MLlama (#9393)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 9013e24f7b09a19405c6856b88c004afd4e3fc57[m
Author: Yongzao <532741407@qq.com>
Date:   Thu Oct 24 01:07:48 2024 +0800

    [torch.compile] Adding torch compile annotations to some models (#9614)

[33mcommit fd0e2cfdb2e0fa6ee2822a73141441de51114f2a[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Oct 23 12:47:20 2024 -0400

    [Misc] Separate total and output tokens in benchmark_throughput.py (#8914)

[33mcommit e5ac6a4199fd967d2655310712cee6e642e91bd7[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Oct 23 12:40:43 2024 -0400

    [Bugfix] Fix divide by zero when serving Mamba models (#9617)
    
    Signed-off-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit dbdd3b5e5ace989923a5abb549780564980bc11e[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Oct 23 09:14:44 2024 -0700

    [misc] comment to avoid future confusion about baichuan (#9620)
    
    Signed-off-by: youkaichao <youkaichao@gmail.com>

[33mcommit e7116c017c86cb547f4d1888edaf13a9be2a4562[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 23 22:09:04 2024 +0800

    [Bugfix] Fix `_init_vision_model` in NVLM_D model (#9611)
    
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 31a08f5bd231c2ac547e9bb6b6490282d2e76f83[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Wed Oct 23 08:05:18 2024 -0600

    [Model] Add min_pixels / max_pixels to Qwen2VL as mm_processor_kwargs (#9612)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit c18e1a34189812af21aa504f9166de5ed4a86675[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 23 19:27:37 2024 +0800

    [VLM] Enable overriding whether post layernorm is used in vision encoder + fix quant args (#9217)
    
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 3ff57ebfcacdd4f7690ed8f5693657de2bdedea8[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Oct 23 18:42:47 2024 +0800

    [Model] Initialize Florence-2 language backbone support (#9555)

[33mcommit 2394962d7083f1c1001dba9efefadb674321e688[m
Author: Mengqing Cao <cmq0113@163.com>
Date:   Wed Oct 23 16:28:21 2024 +0800

    [Hardware][XPU] using current_platform.is_xpu (#9605)

[33mcommit 51c24c9736b1dbe65cb203deb9e56d4037eb1ec6[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Wed Oct 23 00:43:07 2024 -0400

    [Build] Fix `FetchContent` multiple build issue (#9596)
    
    Signed-off-by: luka <luka@neuralmagic.com>

[33mcommit 831540cf04b0b40cd1fe462356de4a30b831e4ea[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 23 11:35:29 2024 +0800

    [Model] Support E5-V (#9576)

[33mcommit 29061ed9df84f1298806b2fc525ce4bc7eba1d29[m
Author: Flex Wang <flex.wang@snowflake.com>
Date:   Tue Oct 22 20:17:28 2024 -0700

    [Misc] Add an env var VLLM_LOGGING_PREFIX, if set, it will be prepend to all logging messages (#9590)

[33mcommit 65050a40e63fb8d57f383ea833d8869f77e85c89[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Tue Oct 22 17:45:35 2024 -0700

    [Bugfix] Generate exactly input_len tokens in benchmark_throughput (#9592)

[33mcommit 208cb34c812585ce387d7aff82678a3776a66756[m
Author: Seth Kimmel <seth.kimmel3@gmail.com>
Date:   Tue Oct 22 15:43:25 2024 -0700

    [Doc]: Update tensorizer docs to include vllm[tensorizer] (#7889)
    
    Co-authored-by: Kaunil Dhruv <dhruv.kaunil@gmail.com>

[33mcommit b17046e2982cad4cc205851c5af98375e0d1c3f3[m
Author: yulei <yuulei12@gmail.com>
Date:   Wed Oct 23 06:43:03 2024 +0800

    [BugFix] Fix metrics error for --num-scheduler-steps > 1 (#8234)

[33mcommit d1e82408759067eca0ae55e548f6243a9e0aa12d[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Tue Oct 22 18:41:13 2024 -0400

    [Bugfix] Fix spurious "No compiled cutlass_scaled_mm ..." for W8A8 on Turing (#9487)

[33mcommit cb6fdaa0a0b31985df4fa3ddf069c022c1faacb9[m
Author: Jeremy Arnold <103538711+JArnoldAMD@users.noreply.github.com>
Date:   Tue Oct 22 17:40:38 2024 -0500

    [Misc] Make benchmarks use EngineArgs (#9529)

[33mcommit 23b899a8e62c7ea07981bf8487b0dc2cb17847b8[m
Author: Aurick Qiao <aurickq@users.noreply.github.com>
Date:   Tue Oct 22 18:38:12 2024 -0400

    [Bugfix] fix detokenizer shallow copy (#5919)

[33mcommit 17c79f3c364be166b68923bced94f902c00bd8bb[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Oct 22 13:43:37 2024 -0700

    [torch.compile] auto infer dynamic_arg_dims from type annotation (#9589)

[33mcommit cd5601ac37baadb6a6efa3450f1546ddab84c973[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Tue Oct 22 21:11:53 2024 +0300

    [BugFix] Prevent exporting duplicate OpenTelemetry spans (#9017)

[33mcommit 434984e665fe4134ec749de5f1c412b7a1e647a1[m
Author: Yuhong Guo <guoyuhong1985@outlook.com>
Date:   Wed Oct 23 02:07:30 2024 +0800

    [Frontend] Support custom request_id from request (#9550)
    
    Co-authored-by: Yuhong Guo <yuhong.gyh@antgroup.com>

[33mcommit 32a1ee74a0838e37e3b9dea2312ada925011c5ba[m
Author: Yuan <yuan.zhou@intel.com>
Date:   Tue Oct 22 10:38:04 2024 -0700

    [Hardware][Intel CPU][DOC] Update docs for CPU backend (#6212)
    
    Signed-off-by: Yuan Zhou <yuan.zhou@intel.com>
    Co-authored-by: Rafael Vasquez <rafvasq21@gmail.com>
    Co-authored-by: Gubrud, Aaron D <aaron.d.gubrud@intel.com>
    Co-authored-by: adgubrud <96072084+adgubrud@users.noreply.github.com>

[33mcommit 08075c34483843c75b4420bac92377b59ff9a8ac[m
Author: gopalsarda <gopal.sarda@servicenow.com>
Date:   Tue Oct 22 21:44:22 2024 +0530

    [Bugfix] Eagle: change config name for fc bias (#9580)

[33mcommit bb392ea2d2bfde4ce101ff8c87774b85100469c9[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Oct 23 00:01:46 2024 +0800

    [Model][VLM] Initialize support for Mono-InternVL model (#9528)

[33mcommit 9dbcce84a73742805433414ff9000cfe7a5ef1c5[m
Author: xendo <xendoo@gmail.com>
Date:   Tue Oct 22 14:51:41 2024 +0200

    [Neuron] [Bugfix] Fix neuron startup (#9374)
    
    Co-authored-by: Jerzy Zagorski <jzagorsk@amazon.com>

[33mcommit a48e3ec0523b4ac7230159bb38ae1dc4a2f0346a[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Oct 22 19:32:51 2024 +0800

    [CI/Build][LoRA] Temporarily fix long context failure issue (#9579)

[33mcommit 6c5af09b3969721da2e3a32d612a0fdd5cb077d6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Oct 22 01:24:07 2024 -0700

    [V1] Implement vLLM V1 [1/N] (#9289)

[33mcommit 3ddbe25502fb8c49e67096ba6e641ecdc3519757[m
Author: wangshuai09 <391746016@qq.com>
Date:   Tue Oct 22 15:50:43 2024 +0800

    [Hardware][CPU] using current_platform.is_cpu (#9536)

[33mcommit 0d02747f2ed5f65bd7100b6dcf1805cefb458f5d[m
Author: chenqianfzh <51831990+chenqianfzh@users.noreply.github.com>
Date:   Tue Oct 22 00:13:23 2024 -0700

    support TP in qwen2 bnb (#9574)

[33mcommit f7db5f0fa9db2ea5680e373fcb1b21fb0c32797e[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Tue Oct 22 02:43:24 2024 -0400

    [Doc] Use shell code-blocks and fix section headers (#9508)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit ca30c3c84b1c1a89b7083524854d81440e80c5bd[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Mon Oct 21 23:55:49 2024 -0500

    [Core] Remove evictor_v1 (#9572)

[33mcommit c0292211cea53dc5a761b3e51ce37a6c6aecd593[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Tue Oct 22 01:52:14 2024 -0300

    [CI/Build] Replaced some models on tests for smaller ones (#9570)
    
    Signed-off-by: Wallas Santos <wallashss@ibm.com>

[33mcommit 74692421f7d5013c313790559f7fc2a338ae5272[m
Author: Falko1 <61779598+Falko1@users.noreply.github.com>
Date:   Tue Oct 22 04:53:36 2024 +0200

    [Bugfix]: phi.py get rope_theta from config file (#9503)
    
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit 29acd2c34cc542c96dbb584ea089f4b5404e54ef[m
Author: ngrozae <104074686+ngrozae@users.noreply.github.com>
Date:   Tue Oct 22 04:47:52 2024 +0200

    [Bugfix][OpenVINO] fix_dockerfile_openvino (#9552)

[33mcommit f085995a7b073f0f4a330f469d9f489160e5b7a1[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Oct 22 10:47:29 2024 +0800

    [CI/Build] Remove unnecessary `fork_new_process` (#9484)

[33mcommit b729901139c93edd9ef8d48a16d269f070d8ba42[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Mon Oct 21 20:46:24 2024 -0600

    [Bugfix]: serialize config by value for --trust-remote-code (#6751)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 76a5e13270f32216bb28cfe185bada5e88e407d7[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Oct 21 17:31:44 2024 -0700

    [core] move parallel sampling out from vllm core (#9302)

[33mcommit ef7faad1b8e6473556b732a7e8d5bc9be5df556f[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Mon Oct 21 19:10:56 2024 -0500

    :bug: Fixup more test failures from memory profiling (#9563)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 575dcebe9adc587b26feba02e4c1d13cb69c0305[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Mon Oct 21 18:45:15 2024 -0500

    [CI] Make format checker error message more user-friendly by using emoji (#9564)
    
    This PR makes format checker error message more user-friendly by adding emojis.

[33mcommit 711f3a7806de8729e8e9cedf04e056c374d8e626[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Mon Oct 21 18:49:41 2024 -0300

    [Frontend] Don't log duplicate error stacktrace for every request in the batch (#9023)
    
    Signed-off-by: Wallas Santos <wallashss@ibm.com>

[33mcommit 15713e3b7579d56758fab1150c99dd49633b5669[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Oct 21 22:14:29 2024 +0100

    [BugFix] Update draft model TP size check to allow matching target TP size (#9394)
    
    Co-authored-by: Baoyuan Qi <qibaoyuan@126.com>

[33mcommit d621c43df72e118d9cbfb4ca408b84bdeefa4a94[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Oct 21 13:54:57 2024 -0700

    [doc] fix format (#9562)

[33mcommit 9d9186be971f0553cea771177db43edafb005b72[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Oct 21 21:28:10 2024 +0100

    [Frontend] Reduce frequency of client cancellation checking (#7959)

[33mcommit 5241aa1494a7410f7e89eb341700821e30d04199[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Oct 21 14:20:07 2024 -0400

    [Model][Bugfix] Fix batching with multi-image in PixtralHF (#9518)

[33mcommit ec6bd6c4c6a62f6a6d53d092ba44cc2e82cdf324[m
Author: Varad Ahirwadkar <86718090+varad-ahirwadkar@users.noreply.github.com>
Date:   Mon Oct 21 23:13:02 2024 +0530

    [BugFix] Use correct python3 binary in Docker.ppc64le entrypoint (#9492)
    
    Signed-off-by: Varad Ahirwadkar <varad.ahirwadkar1@ibm.com>

[33mcommit 8ca895484117e55c66c8b5643929866e634e5ce3[m
Author: yudian0504 <138860534+yudian0504@users.noreply.github.com>
Date:   Tue Oct 22 01:33:30 2024 +0800

    [Bugfix][Misc]: fix graph capture for decoder (#9549)

[33mcommit f6b97293aa7d52e52e9c5144cc98330733a8cf0d[m
Author: Dhia Eddine Rhaiem <163106757+dhiaEddineRhaiem@users.noreply.github.com>
Date:   Mon Oct 21 20:50:16 2024 +0400

    [Model] FalconMamba Support (#9325)

[33mcommit 496e991da82467874092e0be589071b971a63ab7[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Mon Oct 21 16:29:57 2024 +0200

    [Doc] Consistent naming of attention backends (#9498)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 696b01af8fac1819b2409cc0f205c73ef553558c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Oct 21 12:27:50 2024 +0800

    [CI/Build] Split up decoder-only LM tests (#9488)
    
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 855e0e6f97e5ddd5addf042f25c1f11522214569[m
Author: Andy Dai <76841985+Imss27@users.noreply.github.com>
Date:   Sun Oct 20 11:39:32 2024 -0700

    [Frontend][Misc] Goodput metric support (#9338)

[33mcommit 4fa3e3334978dce74eba296ee8cc2e970ed20e5e[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Sun Oct 20 10:57:52 2024 -0700

    [Kernel] Support sliding window in flash attention backend (#9403)

[33mcommit 962d2c63495e930cdd3b59479dce1de48be57ecd[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sun Oct 20 01:29:14 2024 -0400

    [Model][Pixtral] Use memory_efficient_attention for PixtralHFVision (#9520)

[33mcommit 5b59fe0f08c16e56813f2dad442d44cab222668b[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Sat Oct 19 17:05:02 2024 -0700

    [Bugfix] Pass json-schema to GuidedDecodingParams and make test stronger (#9530)

[33mcommit 8e3e7f271326e8cdb32c8f9581b2f98013a567c7[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sat Oct 19 10:44:29 2024 -0400

    [Model][Pixtral] Optimizations for input_processor_for_pixtral_hf (#9514)

[33mcommit 263d8ee150a737ddb8b2d49254bf712d8bb08a0b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Oct 19 14:49:40 2024 +0800

    [Bugfix] Fix missing task for speculative decoding (#9524)

[33mcommit c5eea3c8ba7586e54f87b53a104cf2ac0f75069c[m
Author: Yue Zhang <130511128+yue-anyscale@users.noreply.github.com>
Date:   Fri Oct 18 23:17:07 2024 -0700

    [Frontend] Support simpler image input format (#9478)

[33mcommit 85dc92fc98298b83e735752d8dbfc856f28c6e1c[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Sat Oct 19 02:04:18 2024 -0400

    [CI/Build] Configure matcher for actionlint workflow (#9511)
    
    Signed-off-by: Russell Bryant <russell.bryant@gmail.com>

[33mcommit dfd951ed9b9eb4af2452764edd808599b5e8901e[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Sat Oct 19 01:42:20 2024 -0400

    [CI/Build] Add error matching for ruff output (#9513)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 82c25151ec54f723de8589ccc3ad24d4a1817e90[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Fri Oct 18 22:26:36 2024 -0500

    [Doc] update gpu-memory-utilization flag docs (#9507)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 1325872ec8c97d797c18f490bdb6be7f4def5aa8[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sat Oct 19 04:21:01 2024 +0100

    [Frontend] Avoid creating guided decoding LogitsProcessor unnecessarily (#9521)

[33mcommit 380e18639f315a696bd5dcc93a24f250573b95a9[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Fri Oct 18 20:25:19 2024 -0500

    :bug: fix torch memory profiling (#9516)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 337ed76671812c4599560f73b8fa511927814e37[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Sat Oct 19 01:12:32 2024 +0000

    [Bugfix] Fix offline mode when using `mistral_common` (#9457)

[33mcommit 0c9a5258f905ff3b03019f9134914ab90dbdac01[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Sat Oct 19 02:55:48 2024 +0200

    [Kernel] Add env variable to force flashinfer backend to enable tensor cores (#9497)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>
    Co-authored-by: Chih-Chieh Yang <chih.chieh.yang@ibm.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit d11bf435a0bfdefece204aa6a725e849dc00d8cb[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Oct 18 14:30:55 2024 -0700

    [MISC] Consolidate cleanup() and refactor offline_inference_with_prefix.py (#9510)

[33mcommit 9bb10a7d276e085c72f2545cea1a3565937e7b22[m
Author: Kunjan <kunjan@ucla.edu>
Date:   Fri Oct 18 13:50:18 2024 -0700

    [MISC] Add lora requests to metrics (#9477)
    
    Co-authored-by: Kunjan Patel <kunjanp_google_com@vllm.us-central1-a.c.kunjanp-gke-dev-2.internal>

[33mcommit 3921a2f29e30df293459d824e20d2e546e4af0c7[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Oct 18 15:29:56 2024 -0400

    [Model] Support Pixtral models in the HF Transformers format (#9036)

[33mcommit 67a7e5ef384206f20294ce9bed2fa8953c83058a[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Oct 18 15:17:53 2024 -0400

    [CI/Build] Add error matching config for mypy (#9512)

[33mcommit 051eaf6db3d8feeb0779a4e942aadc85eda2f8b2[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Oct 19 02:31:58 2024 +0800

    [Model] Add user-configurable task for models that support both generation and embedding (#9424)

[33mcommit 7dbe738d653b563c646883c1ae6f6df927436d01[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Oct 18 14:15:28 2024 -0400

    [Misc] benchmark: Add option to set max concurrency (#9390)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit ae8b633ba354eaad163e8decf0e4752b5ce58ac2[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Oct 18 12:59:19 2024 -0400

    [Bugfix] Fix offline_inference_with_prefix.py (#9505)

[33mcommit 1bbbcc0b1d96384a72b13d34600b1bdd24cb0f7f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Oct 19 00:09:35 2024 +0800

    [CI/Build] Fix lint errors in mistral tokenizer (#9504)

[33mcommit 25aeb7d4c9e1b2b8d4a28c2797569a1f8edfccc5[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Fri Oct 18 15:10:26 2024 +0100

    [BugFix] Fix and simplify completion API usage streaming (#9475)

[33mcommit d2b1bf55ec0d50f76762b902ca84036ac53e9646[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Fri Oct 18 13:27:48 2024 +0300

    [Frontend][Feature] Add jamba tool parser (#9154)

[33mcommit 1ffc8a73628ee8e3f6ad5aab54782d64050d17ea[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Fri Oct 18 08:19:53 2024 +0100

    [BugFix] Typing fixes to RequestOutput.prompt and beam search (#9473)

[33mcommit 944dd8edafd1873a80cd3302a0f73043f2a1d71b[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Fri Oct 18 00:54:58 2024 -0400

    [CI/Build] Use commit hash references for github actions (#9430)

[33mcommit 154a8ae880c800a8e6250b38a66fbf24c5d1be39[m
Author: Haoyu Wang <30562758+blueyo0@users.noreply.github.com>
Date:   Fri Oct 18 12:40:14 2024 +0800

    [Qwen2.5] Support bnb quant for Qwen2.5 (#9467)

[33mcommit de4008e2abc50b8a5d72d7ba553037f03cf97caa[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Thu Oct 17 21:47:27 2024 -0500

    [Bugfix][Core] Use torch.cuda.memory_stats() to profile peak memory usage (#9352)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 48138a8415f416df502e68a24f0b3025a425c04c[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Thu Oct 17 21:54:00 2024 -0400

    [BugFix] Stop silent failures on compressed-tensors parsing (#9381)

[33mcommit 343f8e09055b67a000023fc9ae7254905090de9e[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Oct 17 19:21:01 2024 -0400

    Support `BERTModel` (first `encoder-only` embedding model) (#9056)
    
    Signed-off-by: Max de Bayser <maxdebayser@gmail.com>
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
    Co-authored-by: Andrew Feldman <afeldman@neuralmagic.com>
    Co-authored-by: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: laishzh <laishengzhang@gmail.com>
    Co-authored-by: Max de Bayser <maxdebayser@gmail.com>
    Co-authored-by: Max de Bayser <mbayser@br.ibm.com>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit bb76538bbdf6ad61c6359d3aaca4863541596685[m
Author: Shashwat Srijan <119712013+sssrijan-amazon@users.noreply.github.com>
Date:   Thu Oct 17 15:39:39 2024 -0700

    [Hardwware][Neuron] Simplify model load for transformers-neuronx library (#9380)

[33mcommit d615b5c9f8fe611613bf9495041363d387a52914[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Thu Oct 17 21:44:20 2024 +0000

    [Bugfix] Print warnings related to `mistral_common` tokenizer only once (#9468)

[33mcommit d65049daabe9a80783b0547fd85dd39a18a905b3[m
Author: Kai Wu <wukaixingxp@gmail.com>
Date:   Thu Oct 17 14:11:11 2024 -0700

    [Bugfix] Add random_seed to sample_hf_requests in benchmark_serving script (#9013)
    
    Co-authored-by: Isotr0py <2037008807@qq.com>

[33mcommit eca2c5f7c00d6c0b08051972d1e80fe822e7d1b8[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Thu Oct 17 15:08:34 2024 -0400

    [Bugfix] Fix support for dimension like integers and ScalarType (#9299)

[33mcommit 0f41fbe5a370c0b87bb9a038be592c9272d46364[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Thu Oct 17 14:36:37 2024 -0400

    [torch.compile] Fine-grained CustomOp enabling mechanism (#9300)

[33mcommit 7871659abb247563199a2f4cfbd7dd1c35586e0d[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Oct 18 01:34:37 2024 +0800

    [Misc] Remove commit id file (#9470)

[33mcommit a2c71c5405fdd8822956bcd785e72149c1cfb655[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Thu Oct 17 19:25:06 2024 +0200

    [CI/Build] remove .github from .dockerignore, add dirty repo check (#9375)

[33mcommit 81ede99ca44a5b3518932a07ea4a76a719e7416e[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Thu Oct 17 11:38:15 2024 -0500

    [Core] Deprecating block manager v1 and make block manager v2 default (#8704)
    
    Removing the block manager v1. This is the initial piece of prefix-caching-centric design. In order to achieve prefix-caching-centric design, we need to simplify the code path so that we only use v2 block manager (which has much higher performance on prefix caching).

[33mcommit 5eda21e773447d81ffc661ac094716420dc7b7cb[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Fri Oct 18 00:21:04 2024 +0800

    [Hardware][CPU] compressed-tensor INT8 W8A8 AZP support  (#9344)

[33mcommit 8e1cddcd44da6bc58d4201e2a388ed9afd5adfb8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Oct 17 09:00:11 2024 -0700

    [TPU] Call torch._sync(param) during weight loading (#9437)

[33mcommit 5e443b594fab5c4e93b462a0206ddd24b2e40238[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Thu Oct 17 15:06:37 2024 +0000

    [Bugfix] Allow prefill of assistant response when using `mistral_common` (#9446)

[33mcommit 9d30a056e7a1c81382a53ac63dc476c5fbe0091d[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Oct 17 10:36:09 2024 -0400

    [misc] CUDA Time Layerwise Profiler (#8337)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 390be746494c625030c44749c8fbd04b899266af[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Oct 17 21:55:48 2024 +0800

    [Misc] Print stack trace using `logger.exception` (#9461)

[33mcommit e312e52b44f872896171f860a76805bfbd1d80bf[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Oct 17 09:48:26 2024 -0400

    [Kernel] Add Exllama as a backend for compressed-tensors  (#9395)

[33mcommit dbfa8d31d5e7627a84671c6068ecc8fa58acd1d1[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Thu Oct 17 00:46:46 2024 -0400

    Add notes on the use of Slack (#9442)

[33mcommit 92d86da217c38f7e033fc56936a9db32a97c03bd[m
Author: rasmith <Randall.Smith@amd.com>
Date:   Wed Oct 16 20:34:06 2024 -0500

    [BugFix] [Kernel] Fix GPU SEGV occurring in int8 kernels (#9391)

[33mcommit c3fab5f7691c55e9fd0de5ed373f4dd5fb2152cf[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Oct 16 19:46:06 2024 -0400

    [Bugfix][Kernel] Prevent integer overflow in fp8 dynamic per-token quantize kernel (#9425)

[33mcommit 776dbd74f1d6a42a1e71c3b18a0d28e61f2e9ea5[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Oct 16 18:55:59 2024 -0400

    [CI/Build] mypy: Resolve some errors from checking vllm/engine (#9267)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 83450458339b07765b0e72a822e5fe93eeaf5258[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Wed Oct 16 12:37:45 2024 -0700

    [Performance][Spec Decode] Optimize ngram lookup performance (#9333)

[33mcommit 5b8a1fde84224e24ec121e0dc149d775330d911b[m
Author: Junhao Li <streaver91@gmail.com>
Date:   Wed Oct 16 12:40:24 2024 -0400

    [Model][Bugfix] Add FATReLU activation and support for openbmb/MiniCPM-S-1B-sft (#9396)

[33mcommit fb60ae9b91a4b3e1aed4a6e826895fe3c5a13c10[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Thu Oct 17 00:12:43 2024 +0800

    [Kernel][Model] Improve continuous batching for Jamba and Mamba (#9189)

[33mcommit 415f76a9cbcdec9346661e5b6f04c35a4d8eb3f4[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Wed Oct 16 15:28:30 2024 +0200

    Support mistral interleaved attn (#9414)

[33mcommit cf1d62a644d2539d2fd7af9beac0f3363d288d87[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Oct 16 19:52:01 2024 +0800

    [Model] Support SDPA attention for Molmo vision backbone (#9410)

[33mcommit 59230ef32b0b9132ea9a6ea39d8e823574657a87[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Oct 16 04:20:51 2024 -0700

    [Misc] Consolidate example usage of OpenAI client for multimodal models (#9412)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit cee711fdbb88d7c6506a9039d74cb2911c516f94[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 16 18:49:37 2024 +0800

    [Core] Rename input data types (#8688)

[33mcommit 1de76a0e55639dfec7436c21d0c0291d6ed900e3[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 16 17:44:30 2024 +0800

    [CI/Build] Test VLM embeddings (#9406)

[33mcommit 7abba39ee64c1e2c84f48d7c38b2cd1c24bb0ebb[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 16 14:31:00 2024 +0800

    [Model] VLM2Vec, the first multimodal embedding model in vLLM (#9303)

[33mcommit 7e7eae338d2774f90ba4b5a04d6c53e7299f40de[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 16 13:56:17 2024 +0800

    [Misc] Standardize RoPE handling for Qwen2-VL (#9250)

[33mcommit ed920135c8490440453a64e197fce5e1e6459225[m
Author: Reza Salehi <mrsalehi@cs.washington.edu>
Date:   Tue Oct 15 21:56:09 2024 -0700

    [Bugfix] Molmo text-only input bug fix (#9397)
    
    Co-authored-by: sanghol <sanghol@allenai.org>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 717a5f82cda6dd6a52be6504179adaa64bbdc67a[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Tue Oct 15 20:15:21 2024 -0400

    [Bugfix][CI/Build] Fix CUDA 11.8 Build (#9386)

[33mcommit ba30942240d35eb26b503e139eb4b01ccbbeb954[m
Author: Chang Su <chang.s.su@oracle.com>
Date:   Tue Oct 15 15:40:43 2024 -0700

    [Bugfix] Fix vLLM UsageInfo and logprobs None AssertionError with empty token_ids (#9034)
    
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 22f8a69549d30b9b00464141797d274fb6b7e65f[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Oct 15 18:40:25 2024 -0400

    [Misc] Directly use compressed-tensors for checkpoint definitions (#8909)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 5d264f4ab8d008f0ac5b7f0adb7189d70136f3ec[m
Author: Grace Ho <146482179+gracehonv@users.noreply.github.com>
Date:   Tue Oct 15 13:30:44 2024 -0700

    pass ignore_eos parameter to all benchmark_serving calls (#9349)

[33mcommit e9d517f27673ec8736c026f2311d3c250d5f9061[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Oct 15 07:19:48 2024 +0100

    [BugFix] Fix chat API continuous usage stats (#9357)

[33mcommit 55e081fbad29c6710318e1715372cc927e44de8b[m
Author: hhzhang16 <54051230+hhzhang16@users.noreply.github.com>
Date:   Mon Oct 14 21:29:19 2024 -0700

    [Bugfix] Update InternVL input mapper to support image embeds (#9351)

[33mcommit 8e836d982ab19afbfce2bc28074a64fa7dca104c[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Oct 15 00:29:11 2024 -0400

    [Doc] Fix code formatting in spec_decode.rst (#9348)

[33mcommit 44eaa5a5d966d41c5b19b38d60c41bec02399525[m
Author: Steve Grubb <ausearch.1@gmail.com>
Date:   Tue Oct 15 00:29:01 2024 -0400

    [Frontend] Clarify model_type error messages (#9345)

[33mcommit 169b530607c0102fdb02ce1fd3323fd6085477b0[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Oct 14 20:24:25 2024 -0400

    [Bugfix] Clean up some cruft in mamba.py (#9343)

[33mcommit f0fe4fe86d45763cb5904ac256ac6241c5eb2fde[m
Author: Xiang Xu <117880274+xiangxu-google@users.noreply.github.com>
Date:   Mon Oct 14 15:24:26 2024 -0700

    [Model] Make llama3.2 support multiple and interleaved images (#9095)

[33mcommit 4d31cd424bdd5935cefa8f03e137bba127be31dd[m
Author: Brendan Wong <35351983+LunrEclipse@users.noreply.github.com>
Date:   Mon Oct 14 15:05:52 2024 -0700

    [Frontend] merge beam search implementations (#9296)

[33mcommit 473e7b3606e9b95b39c7da46cce00a33c069dc00[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Oct 14 15:02:06 2024 -0700

    [TPU] Fix TPU SMEM OOM by Pallas paged attention kernel (#9350)

[33mcommit fd47e57f4b0d5f7920903490bce13bc9e49d8dba[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Oct 14 11:57:47 2024 -0700

    [Docs] Remove PDF build from Readtehdocs (#9347)

[33mcommit 203ab8f80f780baf899a8bc4b5c38a9929fa88ca[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Mon Oct 14 20:34:47 2024 +0200

    [CI/Build] setuptools-scm fixes (#8900)

[33mcommit 4141608c6a636952242b86e50d8f90ca674b7425[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Tue Oct 15 02:23:33 2024 +0800

    [Hardware][intel GPU] add async output process for xpu (#8897)

[33mcommit dfe43a207161051c10daaae064936f4a4d2a597c[m
Author: Reza Salehi <mrsalehi@cs.washington.edu>
Date:   Mon Oct 14 07:56:24 2024 -0700

    [Model] Molmo vLLM Integration (#9016)
    
    Co-authored-by: sanghol <sanghol@allenai.org>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 16b24e7dcd8da5f2ac50f149daa77288fa8c14d7[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sun Oct 13 19:02:11 2024 -0400

    [Bugfix] Bandaid fix for speculative decoding tests (#9327)

[33mcommit f519902c52cfd61da9026ab714fad9d95502d2f1[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Sat Oct 12 23:41:23 2024 -0700

    [CI] Fix merge conflict (#9317)

[33mcommit 250e26a63e241076d8182155b9c7ea4f9f157ea3[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Oct 13 00:36:47 2024 +0800

    [Bugfix]Fix MiniCPM's LoRA bug (#9286)

[33mcommit 2b184ddd4f9e4ff5305af87327410b9845a06baf[m
Author: Yunmeng <cym103@126.com>
Date:   Sun Oct 13 00:36:40 2024 +0800

    [Misc][Installation] Improve source installation script and doc (#9309)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 00298e092c38eb9819f6548a6a246fa207c20c36[m
Author: Xiang Xu <117880274+xiangxu-google@users.noreply.github.com>
Date:   Sat Oct 12 00:00:43 2024 -0700

    [Bugfix] Fix bug of xformer prefill for encoder-decoder (#9026)

[33mcommit 89feb4c84dc8938738ef5d7b613f0d351cc2dc11[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Fri Oct 11 22:13:37 2024 -0700

    [SpecDec] Remove Batch Expansion (2/3) (#9298)

[33mcommit ec10cb8511b7e30b8ff86caab2e4272ff3ceddca[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Fri Oct 11 22:24:26 2024 -0300

    [BugFix] Fix tool call finish reason in streaming case (#9209)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>

[33mcommit d11b46f3a5aba3371456bf7ae7b1332aa14501d8[m
Author: Prashant Gupta <prashantgupta@us.ibm.com>
Date:   Fri Oct 11 17:03:48 2024 -0700

    [bugfix] fix f-string for error (#9295)
    
    Signed-off-by: Prashant Gupta <prashantgupta@us.ibm.com>

[33mcommit c6cf9295e1dad2aeffbce1d92682971df9f71ddf[m
Author: Allen Wang <allencwang@google.com>
Date:   Fri Oct 11 15:28:10 2024 -0500

    [Bugfix] Sets `is_first_step_output` for TPUModelRunner (#9202)

[33mcommit de9fb4bef8bb1f62d425dd44533810d838908df6[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Fri Oct 11 15:57:39 2024 -0400

    [Bugfix][CI/Build] Fix docker build where CUDA archs < 7.0 are being detected (#9254)

[33mcommit 8baf85e4e9355611532e361a5cd4d458bc8fe1fe[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Fri Oct 11 15:18:50 2024 -0300

    [Doc] Compatibility matrix for mutual exclusive features (#8512)
    
    Signed-off-by: Wallas Santos <wallashss@ibm.com>

[33mcommit 1a1823871d76b9ce54f1c5bc0b61257aa9c53295[m
Author: homeffjy <74026382+homeffjy@users.noreply.github.com>
Date:   Sat Oct 12 02:02:03 2024 +0800

    [Doc] Remove outdated comment to avoid misunderstanding (#9287)

[33mcommit 6cf1167c1a82296d1ad6b841138c91698b8f84b0[m
Author: sixgod <evethwillbeok@outlook.com>
Date:   Sat Oct 12 01:36:13 2024 +0800

    [Model] Add GLM-4v support and meet vllm==0.6.2  (#9242)

[33mcommit f710090d8e40451879690b6a27b7d3b1a41b53ec[m
Author: Burkhard Ringlein <git@burkhard.engineer>
Date:   Fri Oct 11 08:54:22 2024 -0700

    [Kernel] adding fused moe kernel config for L40S TP4 (#9245)

[33mcommit 7342a7d7f87ea3f4e03ec0775093a0f1ce56e2a1[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Oct 11 11:40:06 2024 -0400

    [Model] Support Mamba (#6484)

[33mcommit df3dcdf49dccfa4914d825fa08b74de8ae050e1e[m
Author: Sebastian Schoennenbeck <sebastian.schoennenbeck@comma-soft.com>
Date:   Fri Oct 11 17:35:35 2024 +0200

    [Bugfix] Fix priority in multiprocessing engine (#9277)

[33mcommit 36ea79079bc499cd8fb07d3fe82fe069564e5570[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Fri Oct 11 20:31:21 2024 +0800

    [Misc][LoRA] Support loading LoRA weights for target_modules in reg format (#9275)

[33mcommit e808156f305ce2ecfbe87eefa19ce2ae11c83d00[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Oct 11 19:08:11 2024 +0800

    [Misc] Collect model support info in a single process per model (#9233)

[33mcommit cbc2ef55292b2af6ff742095c030e8425124c005[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Oct 10 21:30:44 2024 -0700

    [misc] hide best_of from engine (#9261)
    
    Co-authored-by: Brendan Wong <bjwpokemon@gmail.com>

[33mcommit 94bf9ae4e9b8199636668ccbe4dabcdc3b9e5ae6[m
Author: Andy Dai <76841985+Imss27@users.noreply.github.com>
Date:   Thu Oct 10 17:33:16 2024 -0700

    [Misc] Fix sampling from sonnet for long context case (#9235)

[33mcommit f990bab2a4198c4de6b5b349d35fc74bf0f36f3e[m
Author: omrishiv <327609+omrishiv@users.noreply.github.com>
Date:   Thu Oct 10 16:36:32 2024 -0700

    [Doc][Neuron] add note to neuron documentation about resolving triton issue (#9257)
    
    Signed-off-by: omrishiv <327609+omrishiv@users.noreply.github.com>

[33mcommit e00c094f15e79c5a113fdf975df1ee9018cb65b3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Oct 10 15:54:23 2024 -0700

    [torch.compile] generic decorators (#9258)

[33mcommit a78c6ba7c88a7bb42b38410f9dcfa5b342b95b57[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Oct 10 15:45:09 2024 -0700

    [ci/build] Add placeholder command for custom models test (#9262)

[33mcommit fb870fd491482cfe5a41648b8c081d1bd6941205[m
Author: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Date:   Thu Oct 10 13:30:46 2024 -0700

    Bump actions/setup-python from 3 to 5 (#9195)
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>

[33mcommit 270953bafb1ccf444f2018d1c0a88c51472de22e[m
Author: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Date:   Thu Oct 10 13:30:35 2024 -0700

    Bump actions/checkout from 3 to 4 (#9196)
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>

[33mcommit 9cc811c4ff3d5200cc23f16709f540821531b77c[m
Author: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Date:   Thu Oct 10 13:30:24 2024 -0700

    Bump actions/github-script from 6 to 7 (#9197)
    
    Signed-off-by: dependabot[bot] <support@github.com>
    Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>

[33mcommit e4d652ea3ed9b2a60c1582cb2e2605695e61280f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Oct 10 12:39:36 2024 -0700

    [torch.compile] integration with compilation control (#9058)

[33mcommit 78c0b4166cb097de749993970b51cb7b8becba58[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Oct 10 12:29:24 2024 -0700

    Suggest codeowners for the core componenets (#9210)

[33mcommit 21efb603f5f88a0d78ad11e4fbc6e18fe83916d4[m
Author: jordanyono <40174853+jyono@users.noreply.github.com>
Date:   Thu Oct 10 14:18:18 2024 -0400

    [CI/Build] Make the `Dockerfile.cpu` file's  `PIP_EXTRA_INDEX_URL` Configurable as a Build Argument (#9252)

[33mcommit 055f3270d40bbc492630d0f2c96ec8b64823ba34[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Thu Oct 10 13:48:51 2024 -0400

    [Doc] Improve debugging documentation (#9204)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit 18511aeda64b473314bb7727a97a220565e0af41[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Oct 10 13:39:56 2024 -0400

    [Bugfix] Fix Machete unittests failing with `NotImplementedError` (#9218)

[33mcommit 83ea5c72b9a287b65c9f7b95fbd868b3f613e6f5[m
Author: Ilya Lavrenov <ilya.lavrenov@intel.com>
Date:   Thu Oct 10 21:18:58 2024 +0400

    [OpenVINO] Use torch 2.4.0 and newer optimim version (#9121)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 04de9057ab8099291e66ad876e78693c7c2f2ce5[m
Author: whyiug <whyiug@hotmail.com>
Date:   Thu Oct 10 23:00:47 2024 +0800

    [Model] support input image embedding for minicpmv (#9237)

[33mcommit 07c11cf4d4b9a913fa52142fe134849f1e25e393[m
Author: Isotr0py <2037008807@qq.com>
Date:   Thu Oct 10 21:11:56 2024 +0800

    [Bugfix] Fix lm_head weights tying with lora for llama (#9227)

[33mcommit f3a507f1d31e13a99c4fc8ac02738a73c3e3136f[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Wed Oct 9 23:17:17 2024 -0700

    [Core] Add an environment variable which needs to be set explicitly to allow BlockSpaceManagerV1 (#9149)

[33mcommit a64e7b940734b68d849ed2b07ca1bc3824713555[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Oct 10 02:16:17 2024 -0400

    [Bugfix] Machete garbage results for some models (large K dim) (#9212)

[33mcommit ce00231a8bfb5eae85167b5a3def1b7304c723b6[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Oct 10 02:15:40 2024 -0400

    [Bugfix] Fix Weight Loading Multiple GPU Test - Large Models (#9213)

[33mcommit de895f1697d22ea19a5a4d4ab3dc17037a3e9af3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Oct 9 21:58:27 2024 -0700

    [misc] improve model support check in another process (#9208)

[33mcommit cf25b93bddb607077e52cbe4681332ca61aff189[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Thu Oct 10 00:10:09 2024 -0400

    [Core] Fix invalid args to _process_request (#9201)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit d5fbb8706d2c7fd00b64cff2efbe7c771fe82c3c[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Oct 9 14:51:47 2024 -0400

    [CI/Build] Update Dockerfile install+deploy image to ubuntu 22.04 (#9130)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit cdca8994bd856a234112875a92746c5782837768[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Oct 9 13:15:28 2024 -0400

    [CI/Build] mypy: check vllm/entrypoints (#9194)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit ca77dd7a44f2bc103c668560818918ac0335835a[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Thu Oct 10 00:28:08 2024 +0800

    [Hardware][CPU] Support AWQ for CPU backend (#7515)

[33mcommit 7dea289066eaed35538e74dfadafd1fea1dbe05d[m
Author: Ewout ter Hoeven <E.M.terHoeven@student.tudelft.nl>
Date:   Wed Oct 9 17:16:26 2024 +0200

    Add Dependabot configuration for GitHub Actions updates (#1217)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit cfaa6008e666d4e9bb5131ece68f8609b6f94ee4[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 9 22:59:57 2024 +0800

    [Bugfix] Access `get_vocab` instead of `vocab` in tool parsers (#9188)

[33mcommit 21906a6f50ee0edf49ede856a82e8840bab41471[m
Author: Ahmad Fahadh Ilyas <37577369+fahadh4ilyas@users.noreply.github.com>
Date:   Wed Oct 9 05:10:44 2024 -0700

    [Bugfix] Fix lora loading for Compressed Tensors in #9120 (#9179)

[33mcommit dc4aea677ab0520d91ff4979e80340cb5a090095[m
Author: Jiangtao Hu <ycool@users.noreply.github.com>
Date:   Wed Oct 9 16:59:42 2024 +0800

    [Doc] Fix VLM prompt placeholder sample bug (#9170)

[33mcommit c8627cd41b10747da393b76c382de5ef0eb635a2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Oct 9 00:38:40 2024 -0700

    [ci][test] use load dummy for testing (#9165)

[33mcommit 8bfaa4e31eb63d41499fec933e68969ebbedb01f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 9 15:36:55 2024 +0800

    [Bugfix] fix composite weight loading and EAGLE weight loading (#9160)

[33mcommit 0b5b5d767e7fdc0b1070b37319de749e46a4d42a[m
Author: AlpinDale <52078762+AlpinDale@users.noreply.github.com>
Date:   Wed Oct 9 07:03:14 2024 +0000

    [Frontend] Log the maximum supported concurrency (#8831)

[33mcommit cdc72e3c80b7029c49de9667150f68481f386956[m
Author: Hui Liu <96135754+hliuca@users.noreply.github.com>
Date:   Tue Oct 8 23:43:06 2024 -0700

    [Model] Remap FP8 kv_scale in CommandR and DBRX (#9174)

[33mcommit 7627172bf42b9cd628402c98845c6ac3de80859a[m
Author: Joe Rowell <joerowell4@gmail.com>
Date:   Wed Oct 9 06:43:34 2024 +0100

    [Bugfix][Doc] Report neuron error in output (#9159)

[33mcommit 480b7f40cfa9a900e03ea4e825abc1a46b5d085b[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Tue Oct 8 22:54:48 2024 -0600

    [Misc] Improve validation errors around best_of and n (#9167)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit acce7630c1dd655ca95a9f1abff23d92ef76262c[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Tue Oct 8 23:58:49 2024 -0400

    Update link to KServe deployment guide (#9173)

[33mcommit ffc4b27ea8924b4b5add13552063c93d0a14fb85[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Tue Oct 8 22:30:48 2024 -0400

    Add classifiers in setup.py (#9171)

[33mcommit 2f4117c38e101ee63b65521c93b22efe3526f77e[m
Author: chenqianfzh <51831990+chenqianfzh@users.noreply.github.com>
Date:   Tue Oct 8 18:52:19 2024 -0700

    support bitsandbytes quantization with more models (#9148)

[33mcommit 9ba0bd6aa6a9a3cefa5c320800ea736a0abbaf36[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Oct 8 21:22:31 2024 -0400

    Add `lm-eval` directly to requirements-test.txt (#9161)

[33mcommit 2a131965a8144d571a4a211a44d1fc32e202ae10[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Tue Oct 8 18:08:22 2024 -0400

    mypy: check additional directories (#9162)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit bd37b9fbe274e28e12c0687cb9a8111dda270936[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Tue Oct 8 17:28:12 2024 -0400

    [Bugfix] Try to handle older versions of pytorch (#9086)

[33mcommit de24046fcd24e8faa81de34b17351887bcdfbe51[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Tue Oct 8 16:22:08 2024 -0400

    [Doc] Improve contributing and installation documentation (#9132)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit 1874c6a1b0ae0f9eb2b485653b4e17ed1d861a32[m
Author: Sayak Paul <spsayakpaul@gmail.com>
Date:   Tue Oct 8 23:42:29 2024 +0530

    [Doc] Update vlm.rst to include an example on videos (#9155)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 9a94ca4a5d31c0ba57ca67fc1c252233d3284012[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Tue Oct 8 18:38:40 2024 +0200

    [Bugfix] fix OpenAI API server startup with --disable-frontend-multiprocessing (#8537)

[33mcommit cfba685bd462f360994da7ac0d33f9759589506e[m
Author: Peter Pan <peter.pan@daocloud.io>
Date:   Wed Oct 9 00:37:34 2024 +0800

    [CI/Build] Add examples folder into Docker image so that we can leverage the templates*.jinja when serving models (#8758)
    
    Signed-off-by: Peter Pan <Peter.Pan@daocloud.io>

[33mcommit 069d3bd8d01a72e93c0a5b51f8b567e8aaddc6e9[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Tue Oct 8 08:31:26 2024 -0600

    [Frontend] Add Early Validation For Chat Template / Tool Call Parser (#9151)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit a3691b6b5eb7e60039a8ff34550be5a7e8365394[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Tue Oct 8 08:12:56 2024 -0600

    [Core][Frontend] Add Support for Inference Time mm_processor_kwargs (#9131)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit 8c746226c956f7c8a4672689fee91c7d22befed6[m
Author: Brendan Wong <35351983+LunrEclipse@users.noreply.github.com>
Date:   Mon Oct 7 22:51:43 2024 -0700

    [Frontend] API support for beam search for MQLLMEngine (#9117)

[33mcommit e1faa2a59876bba99d804c0a94d427cee87b0995[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Oct 7 22:26:25 2024 -0700

    [misc] improve ux on readme (#9147)

[33mcommit 80b57f00d554db8a2126d351bb5374c190b56699[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Tue Oct 8 11:51:14 2024 +0800

    [Intel GPU] Fix xpu decode input  (#9145)

[33mcommit 04c12f81572be22c819018c2fcbddac5f08715d0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Oct 7 19:51:49 2024 -0700

    [misc] update utils to support comparing multiple settings (#9140)

[33mcommit 8eeb85708428b7735bbd1156c81692431fd5ff34[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Oct 7 17:06:21 2024 -0700

    Add Slack to README (#9137)

[33mcommit fa45513a5189b3a9f73a59730c9ac65d061e1311[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Oct 7 16:07:05 2024 -0700

    [misc] fix comment and variable name (#9139)

[33mcommit c0d9a98d0c7182b73c2e7f88508e690a186bf0e3[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Mon Oct 7 15:04:06 2024 -0700

    [Doc] Include performance benchmark in README (#9135)

[33mcommit e0dbdb013dfe5cdbe044317b4d7d55644d6399b3[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Mon Oct 7 17:18:10 2024 -0400

    [CI/Build] Add linting for github actions workflows (#7876)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 93cf74a8a7b0b483becdba95e3056adbf201b7b2[m
Author: TimWang <7367474+haitwang-cloud@users.noreply.github.com>
Date:   Tue Oct 8 04:31:45 2024 +0800

    [Doc]: Add deploying_with_k8s guide (#8451)

[33mcommit 151ef4efd2fb52554f4d30408aca619e181ea751[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Oct 7 19:55:12 2024 +0800

    [Model] Support NVLM-D and fix QK Norm in InternViT (#9045)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Isotr0py <mozf@mail2.sysu.edu.cn>

[33mcommit f19da64871065510691cd4fcaa5f4096b661dcec[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Oct 7 18:01:46 2024 +0800

    [Core] Refactor GGUF parameters packing and forwarding (#8859)

[33mcommit 4f95ffee6f40198911ee824ed06d645fe9678511[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Oct 7 14:50:35 2024 +0800

    [Hardware][CPU] Cross-attention and Encoder-Decoder models support on CPU backend (#9089)

[33mcommit 8c6de96ea1e6e51e49a170c28ad3efc16db9413e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Oct 7 14:10:35 2024 +0800

    [Model] Explicit interface for vLLM models and support OOT embedding models (#9108)

[33mcommit 18b296fdb2248e8a65bf005e7193ebd523b875b6[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Oct 6 22:47:04 2024 -0700

    [core] remove beam search from the core (#9105)

[33mcommit c8f26bb63694adb4202ab275efb0759c13edcaa8[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Sun Oct 6 20:52:42 2024 -0700

    [BugFix][Core] Fix BlockManagerV2 when Encoder Input is None (#9103)

[33mcommit 487678d046fe56560ff5dc6c91c3f3c31af7de6f[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Oct 7 10:14:27 2024 +0800

    [Bugfix][Hardware][CPU] Fix CPU model input for decode (#9044)

[33mcommit cb3b2b9ba4a95c413a879e30e2b8674187519a93[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Sun Oct 6 15:48:11 2024 -0400

    [Bugfix] Fix incorrect updates to num_computed_tokens in multi-step scheduling (#9038)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit fdf59d30eaf1a62979b2a13016b4f47f28f12f88[m
Author: Yanyi Liu <wolfsonliu@163.com>
Date:   Sun Oct 6 20:51:08 2024 +0800

    [Bugfix] fix tool_parser error handling when serve a model not support it (#8709)

[33mcommit b22b79847153ae10710523cdb4a5fb98ac864cf4[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Oct 6 16:35:27 2024 +0800

    [Model] PP support for embedding models and update docs (#9090)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit f22619fe96c842ee2406638678d2b60009d8ff14[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Oct 6 16:33:52 2024 +0800

    [Misc] Remove user-facing error for removed VLM args (#9104)

[33mcommit 168cab6bbfb733f97defc8c1aa13df90c5319f19[m
Author: Brendan Wong <35351983+LunrEclipse@users.noreply.github.com>
Date:   Sat Oct 5 23:39:03 2024 -0700

    [Frontend] API support for beam search (#9087)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 23fea8714a1e90f018163e0eee59d73bc5a500e7[m
Author: TJian <tunjian1996@gmail.com>
Date:   Sat Oct 5 22:00:04 2024 -0700

    [Bugfix] Fix try-catch conditions to import correct Flash Attention Backend in Draft Model (#9101)

[33mcommit f4dd830e0945300dbe2039af79d1994f074ffcbb[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Oct 5 19:37:31 2024 -0700

    [core] use forward context for flash infer (#9097)

[33mcommit 5df183489537a155bbaad9232f25b8e57694d7b8[m
Author: Andy Dai <76841985+Imss27@users.noreply.github.com>
Date:   Sat Oct 5 10:35:11 2024 -0700

    [Bugfix] Fix order of arguments matters in config.yaml (#8960)

[33mcommit cfadb9c68798c0cc4d674de19970a8e3b5ea1273[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Sat Oct 5 06:56:40 2024 -0700

    [Bugfix] Deprecate registration of custom configs to huggingface (#9083)

[33mcommit 15986f598c7b1f2969918c92f5c4cf7e28d5c0df[m
Author: Xin Yang <105740670+xyang16@users.noreply.github.com>
Date:   Fri Oct 4 23:57:05 2024 -0700

    [Model] Support Gemma2 embedding model (#9004)

[33mcommit 53b3a330273967a3c4124cbfef2cacac92f553ba[m
Author: hhzhang16 <54051230+hhzhang16@users.noreply.github.com>
Date:   Fri Oct 4 22:05:37 2024 -0700

    [Bugfix] Fixes Phi3v & Ultravox Multimodal EmbeddingInputs (#8979)

[33mcommit dac914b0d6bc36de4eb4bf70a9d20954560893ea[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Fri Oct 4 21:45:38 2024 -0700

    [Bugfix] use blockmanagerv1 for encoder-decoder (#9084)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit a95354a36ee65523a499b3eb42f70a4a0ea4322d[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Fri Oct 4 19:54:45 2024 -0700

    [Doc] Update README.md with Ray summit slides (#9088)

[33mcommit 663874e048d88aa7bf087628430d50f9f5245175[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Oct 4 16:43:50 2024 -0700

    [torch.compile] improve allreduce registration (#9061)

[33mcommit cc90419e89c358f906e17a5ec484fbe04092c277[m
Author: Chongming Ni <chongmni@amazon.com>
Date:   Fri Oct 4 16:42:20 2024 -0700

    [Hardware][Neuron] Add on-device sampling support for Neuron (#8746)
    
    Co-authored-by: Ashraf Mahgoub <ashymahg@amazon.com>

[33mcommit 27302dd5841d4b0fa4788076ad9ff2993e133409[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Oct 4 16:07:54 2024 -0700

    [Misc] Fix CI lint (#9085)

[33mcommit 0cc566ca8fd2d21a94f3a8e48bf5c5b60d42b59f[m
Author: Andy Dai <76841985+Imss27@users.noreply.github.com>
Date:   Fri Oct 4 14:58:57 2024 -0700

    [Misc] Add random seed for prefix cache benchmark (#9081)

[33mcommit 05c531be476e8a864a1ab83a65f7e056315ea1fc[m
Author: Andy Dai <76841985+Imss27@users.noreply.github.com>
Date:   Fri Oct 4 14:38:42 2024 -0700

    [Misc] Improved prefix cache example (#9077)

[33mcommit fbb74420e7018bf0cc1bc81e6fd71a2392347227[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Fri Oct 4 14:01:44 2024 -0700

    [CI] Update performance benchmark: upgrade trt-llm to r24.07, and add SGLang (#7412)

[33mcommit 05d686432f2e13296127962861b21c25cdcdfc8b[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Fri Oct 4 20:34:44 2024 +0200

    [Kernel] Zero point support in fused MarlinMoE kernel + AWQ Fused MoE (#8973)
    
    Co-authored-by: Dipika <dipikasikka1@gmail.com>
    Co-authored-by: Dipika Sikka <ds3822@columbia.edu>

[33mcommit 0dcc8cbe5abd4f2fafd495bd1c65fdd75d8dd919[m
Author: Fl√°via B√©o <119421251+flaviabeo@users.noreply.github.com>
Date:   Fri Oct 4 15:31:40 2024 -0300

    Adds truncate_prompt_tokens param for embeddings creation (#8999)
    
    Signed-off-by: Flavia Beo <flavia.beo@ibm.com>

[33mcommit 26aa325f4ffe8bf1d9b921535cc02fb31d80a96d[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Oct 4 10:38:25 2024 -0700

    [Core][VLM] Test registration for OOT multimodal models (#8717)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit e5dc713c2343b3549b43d6e2764a1036e4052bf8[m
Author: Varad Ahirwadkar <86718090+varad-ahirwadkar@users.noreply.github.com>
Date:   Fri Oct 4 22:54:42 2024 +0530

    [Hardware][PowerPC] Make oneDNN dependency optional for Power (#9039)
    
    Signed-off-by: Varad Ahirwadkar <varad.ahirwadkar1@ibm.com>

[33mcommit 36eecfbddb9ac2c491174c86b28ee83c4773eb5e[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Oct 4 10:17:16 2024 -0700

    Remove AMD Ray Summit Banner (#9075)

[33mcommit 9ade8bbc8dc63c03b9399f05e85a0d0ddc6f5788[m
Author: Prashant Gupta <prashantgupta@us.ibm.com>
Date:   Fri Oct 4 09:24:40 2024 -0700

    [Model] add a bunch of supported lora modules for mixtral (#9008)
    
    Signed-off-by: Prashant Gupta <prashantgupta@us.ibm.com>

[33mcommit 22482e495e00d409c9b5c78dade6e672ddf7fbc2[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Fri Oct 4 11:43:15 2024 -0400

    [Bugfix] Flash attention arches not getting set properly (#9062)

[33mcommit 3d826d2c52242f4f78789adcb7c02938c84ed18b[m
Author: whyiug <whyiug@hotmail.com>
Date:   Fri Oct 4 22:34:58 2024 +0800

    [Bugfix] Reshape the dimensions of the input image embeddings in Qwen2VL (#9071)

[33mcommit 0e36fd4909780392a9c5d0e367b0a84250d55fa8[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Oct 4 18:01:37 2024 +0800

    [Misc] Move registry to its own file (#9064)

[33mcommit 0f6d7a9a347944bffd2204cbf9686299e9dd6557[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Thu Oct 3 19:56:58 2024 -0700

    [Models] Add remaining model PP support (#7168)
    
    Signed-off-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>
    Signed-off-by: Murali Andoorveedu <muralidhar.andoorveedu@centml.ai>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 303d44790a2ccab86257f1b6097e67795f0845d4[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Oct 3 22:55:42 2024 -0400

    [Misc] Enable multi-step output streaming by default (#9047)

[33mcommit aeb37c2a725554791ff6f258b1e18830867a3ab9[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Oct 3 22:55:25 2024 -0400

    [CI/Build] Per file CUDA Archs (improve wheel size and dev build times) (#8845)

[33mcommit 3dbb215b38c010c050f7fde3528fe2c6673f7a07[m
Author: ‰ª£Âêõ <sydnash@users.noreply.github.com>
Date:   Fri Oct 4 10:36:39 2024 +0800

    [Frontend][Feature] support tool calling for internlm/internlm2_5-7b-chat model (#8405)

[33mcommit 2838d6b38e1e37b303b01f2af0a9ddee2dd66f39[m
Author: Domen Vre≈° <56541137+domenVres@users.noreply.github.com>
Date:   Fri Oct 4 01:53:29 2024 +0200

    [Bugfix] Weight loading fix for OPT model (#9042)
    
    Co-authored-by: dvres <dvres@fri.uni-lj.si>

[33mcommit 91add85ec409a3628d01a1e4d4b3230e0fd3aa3f[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Thu Oct 3 16:07:29 2024 -0700

    Fix failing spec decode test (#9054)

[33mcommit 9aaf14c62e16a7c74b5192a44d01a78125dab2fc[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Oct 3 12:09:42 2024 -0700

    [misc] add forward context for attention (#9029)

[33mcommit 63e39937f990818e2f22a9b821a4aa22387057a7[m
Author: xendo <xendoo@gmail.com>
Date:   Thu Oct 3 20:02:07 2024 +0200

    [Frontend] [Neuron] Parse literals out of override-neuron-config (#8959)
    
    Co-authored-by: Jerzy Zagorski <jzagorsk@amazon.com>

[33mcommit f5d72b2fc6771de19c351945f1fbbb0198d53b8e[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Thu Oct 3 09:44:21 2024 -0700

    [Core] Make BlockSpaceManagerV2 the default BlockManager to use. (#8678)

[33mcommit 83caf35e082b2657dce5f71ff965a13653a763b0[m
Author: Guillaume Calmettes <guillaume.calmettes@gmail.com>
Date:   Thu Oct 3 10:44:52 2024 +0200

    [BugFix] Enforce Mistral ToolCall id constraint when using the Mistral tool call parser (#9020)

[33mcommit 01843c89b8ddae00d4a0f0f56b8aa7fbaa3efc42[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Wed Oct 2 23:31:07 2024 -0500

    [Misc] log when using default MoE config (#8971)

[33mcommit 19a4dd09904975d121a10e5e3f707927f3e09faa[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed Oct 2 21:04:17 2024 -0600

    [Bugfix] example template should not add parallel_tool_prompt if tools is none (#9007)

[33mcommit 18c2e30c5754dc83f86d9b8c75af0499a77e4b3f[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Oct 3 03:42:24 2024 +0100

    [Doc] Update Granite model docs (#9025)

[33mcommit 19f0d2579695e518c9bfc166544cf23775772bf8[m
Author: Shawn Tan <shawn@wtf.sg>
Date:   Wed Oct 2 21:33:57 2024 -0400

    [Model]  Adding Granite MoE. (#8206)
    
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit f58d4fccc9b270838be438f5f0db71bea156a56d[m
Author: Sergey Shlyapnikov <Sergeishlyapnikov@gmail.com>
Date:   Thu Oct 3 01:50:01 2024 +0400

    [OpenVINO] Enable GPU support for OpenVINO vLLM backend (#8192)

[33mcommit afb050b29d0cac27c32c19c8206a9ac2a4662de2[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Wed Oct 2 15:44:39 2024 -0400

    [Core] CUDA Graphs for Multi-Step + Chunked-Prefill (#8645)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 7f60520deb05d2e097b408e3310f1d383fbf1de6[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Wed Oct 2 05:44:38 2024 -0600

    [Misc] Update Default Image Mapper Error Log (#8977)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit 563649aafe7d4b9cb0047bba60d6f58efa53fd28[m
Author: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
Date:   Wed Oct 2 03:52:20 2024 -0400

    [Core] Combined support for multi-step scheduling, chunked prefill & prefix caching (#8804)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Andrew Feldman <afeld2012@gmail.com>

[33mcommit 15702038642192002cd8973cf8948751b750fd07[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Tue Oct 1 16:04:42 2024 -0700

    [Spec Decode] (1/2) Remove batch expansion (#8839)

[33mcommit 22f5851b807376a836eb3551903c7fc6c81eaa9b[m
Author: vlsav <vl_sav@mail.ru>
Date:   Tue Oct 1 21:07:06 2024 +0300

    Update benchmark_serving.py to read and write json-datasets, results in UTF8, for better compatibility with Windows (#8997)

[33mcommit 4f341bd4bf35c5b431dc523bab86e4ae210baaf8[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Oct 2 00:35:39 2024 +0800

    [Doc] Update list of supported models (#8987)

[33mcommit 35bd2151684ffb20cdad825abe33e0e6f0cc005a[m
Author: Sebastian Schoennenbeck <sebastian.schoennenbeck@comma-soft.com>
Date:   Tue Oct 1 11:58:06 2024 +0200

    [Core] [Frontend] Priority scheduling for embeddings and in the OpenAI-API (#8965)

[33mcommit 1fe0a4264aa94ceeccc7e8d99ac0d72f0560f541[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Tue Oct 1 03:52:44 2024 -0600

    [Bugfix] Fix Token IDs Reference for MiniCPM-V When Images are Provided With No Placeholders (#8991)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit bc4eb65b5492b4f84a1b714bfc14bcff73d401f1[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue Oct 1 17:51:41 2024 +0800

    [Bugfix] Fix Fuyu tensor parallel inference (#8986)

[33mcommit 82f3937e599a4f088a62e59abe81d51e11bb8f83[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Mon Sep 30 22:46:41 2024 -0500

    [Misc] add process_weights_after_loading for DummyLoader (#8969)

[33mcommit 7da2487591888da043254f8c7045a48d5dbcc753[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Sep 30 20:40:48 2024 -0700

    [torch.compile] fix tensor alias (#8982)

[33mcommit aaccca2b4d3895d64d34b123e61731404c8fc2c0[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Sep 30 20:33:12 2024 -0700

    [CI/Build] Fix machete generated kernel files ordering (#8976)
    
    Signed-off-by: kevin <kevin@anyscale.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 062c89e7c9c6fa9fd7fb2d28fd50321c6f78f389[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Mon Sep 30 19:34:25 2024 -0600

    [Frontend][Core] Move guided decoding params into sampling params (#8252)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit bce324487a8e36140143ea37f4b27d273a0fd661[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Mon Sep 30 17:51:40 2024 -0700

    [CI][SpecDecode] Fix spec decode tests, use flash attention backend for spec decode CI tests. (#8975)

[33mcommit 1425a1bcf9c53e24fe5f4812acc5b656f2aa02f3[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Sep 30 17:47:08 2024 -0700

    [ci] Add CODEOWNERS for test directories  (#8795)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 1cabfcefb64a489c8ff9dcb289b4dd47cf8f89cf[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Mon Sep 30 20:57:39 2024 +0800

    [Misc] Adjust max_position_embeddings for LoRA compatibility (#8957)

[33mcommit be76e5aabf8c026e1a82028ad70167e8c652cee9[m
Author: Sebastian Schoennenbeck <sebastian.schoennenbeck@comma-soft.com>
Date:   Mon Sep 30 14:28:44 2024 +0200

    [Core] Make scheduling policy settable via EngineArgs (#8956)

[33mcommit 2ae25f79cf1e8d21f7bcba097e4c039463c22be4[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Sep 30 13:01:20 2024 +0800

    [Model] Expose InternVL2 max_dynamic_patch as a mm_processor_kwarg (#8946)

[33mcommit 8e60afa15eb9a0540ce6c453b974a945adff3320[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Mon Sep 30 12:31:55 2024 +0800

    [Model][LoRA]LoRA support added for MiniCPMV2.6 (#8943)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit b6d7392579286b6dbd8ca96c0bcb4cc6f7c3c4a0[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Sep 29 21:28:26 2024 -0700

    [Misc][CI/Build] Include `cv2` via `mistral_common[opencv]`  (#8951)

[33mcommit e01ab595d897698c9a5fe9eaebd983eb3e23470a[m
Author: whyiug <whyiug@hotmail.com>
Date:   Mon Sep 30 11:16:10 2024 +0800

    [Model] support input embeddings for qwen2vl (#8856)

[33mcommit f13a07b1f8c11ddbdc53b40f1fbb24bf3166b900[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Mon Sep 30 00:35:58 2024 +0300

    [Kernel][Model] Varlen prefill + Prefill chunking support for mamba kernels and Jamba model (#8533)

[33mcommit 6c9ba48fdebe2f44c82eabfe136dc8dc6ad6f4ed[m
Author: danieljannai21 <100521221+danieljannai21@users.noreply.github.com>
Date:   Sun Sep 29 20:59:47 2024 +0300

    [Frontend] Added support for HF's new `continue_final_message` parameter (#8942)

[33mcommit 1fb9c1b0bf8e65e6576ff4c45f5623d233d7194b[m
Author: juncheoll <127460634+juncheoll@users.noreply.github.com>
Date:   Mon Sep 30 00:05:54 2024 +0900

    [Misc] Fix typo in BlockSpaceManagerV1 (#8944)

[33mcommit 31f46a0d35da80118bac5f80c533019cd50ddd9a[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sun Sep 29 10:43:14 2024 +0100

    [BugFix] Fix seeded random sampling with encoder-decoder models (#8870)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 3d49776bbb25927abf91bb7c5537e0006c199c16[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Sep 29 14:59:45 2024 +0800

    [Model][LoRA]LoRA support added for MiniCPMV2.5 (#7199)

[33mcommit bc2ef1f77c1578612198f60ec392731efb3847c5[m
Author: Zilin Zhu <zilinzhu@tencent.com>
Date:   Sun Sep 29 12:19:39 2024 +0800

    [Model] Support Qwen2.5-Math-RM-72B (#8896)

[33mcommit 2e7fe7e79f41e294eeed2f484eeb791284ec48a2[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sat Sep 28 23:13:01 2024 -0400

    [Build/CI] Set FETCHCONTENT_BASE_DIR to one location for better caching (#8930)

[33mcommit 26a68d5d7e7dd47c7d8538a326493c8a171f5016[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Sep 29 10:50:51 2024 +0800

    [CI/Build] Add test decorator for minimum GPU memory (#8925)

[33mcommit d081da0064b5cda9e344f0fd519d67523a437a39[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Sun Sep 29 03:19:40 2024 +0200

    [Bugfix] Fix Marlin MoE act order when is_k_full == False (#8741)
    
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 5bf8789b2a28df1305f92b9999fe60264f839caa[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Sat Sep 28 18:17:45 2024 -0700

    [Bugfix] Block manager v2 with preemption and lookahead slots (#8824)

[33mcommit d1537039ce7e6018db510d0c0d9b0c0fccb62b63[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Sat Sep 28 21:17:07 2024 -0400

    [Core] Improve choice of Python multiprocessing method (#8823)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit cc276443b5ac0732b00a88472f4bc4330aa14606[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Sep 28 17:48:41 2024 -0700

    [doc] organize installation doc and expose per-commit docker (#8931)

[33mcommit e585b583a92903c9a5cc8055a444a208f4387891[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Sat Sep 28 11:51:22 2024 -0700

    [Bugfix] Support testing prefill throughput with benchmark_serving.py --hf-output-len 1 (#8891)

[33mcommit 090e945e36cfe849b484db5414f64df96e97d678[m
Author: Edouard B. <eduard.r.balzin@gmail.com>
Date:   Sat Sep 28 20:30:21 2024 +0200

    [Frontend] Make beam search emulator temperature modifiable (#8928)
    
    Co-authored-by: Eduard Balzin <nfunctor@yahoo.fr>

[33mcommit e1a3f5e831a467b2867a66e0e56ac0f70ed44394[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Sep 29 00:54:35 2024 +0800

    [CI/Build] Update models tests & examples (#8874)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 19d02ff93812fb6a28f0f1a0a0f9233e9388d616[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Sat Sep 28 11:52:46 2024 -0400

    [Bugfix] Fix PP for Multi-Step (#8887)

[33mcommit 39d3f8d94fd2691b70ee809e7565402f8a061c6b[m
Author: tastelikefeet <58414341+tastelikefeet@users.noreply.github.com>
Date:   Sat Sep 28 23:24:12 2024 +0800

    [Bugfix] Fix code for downloading models from modelscope (#8443)

[33mcommit b0298aa8cc4a54bde659e57271778630785abc9b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Sep 28 16:11:25 2024 +0800

    [Misc] Remove vLLM patch of `BaichuanTokenizer` (#8921)

[33mcommit 260024a3749fb6856625dfee28560a98a92dd339[m
Author: Tyler Titsworth <titswortht@gmail.com>
Date:   Fri Sep 27 23:45:50 2024 -0700

    [Bugfix][Intel] Fix XPU Dockerfile Build (#7824)
    
    Signed-off-by: tylertitsworth <tyler.titsworth@intel.com>
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit d86f6b2afb006ea4b4b14a49a58f64bf3b952de6[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Sep 27 22:10:44 2024 -0700

    [misc] fix wheel name (#8919)

[33mcommit bd429f2b75f3622fabaf9c9470ca2e921f6f56ca[m
Author: Sebastian Schoennenbeck <sebastian.schoennenbeck@comma-soft.com>
Date:   Sat Sep 28 00:07:10 2024 +0200

    [Core] Priority-based scheduling in async engine (#8850)

[33mcommit 18e60d7d1394541b48bf48b0a57a546a93607ac2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Sep 27 14:27:56 2024 -0700

    [misc][distributed] add VLLM_SKIP_P2P_CHECK flag (#8911)

[33mcommit c2ec430ab5713d0626c1a7809718ef6c4eebf389[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Fri Sep 27 16:32:07 2024 -0400

    [Core] Multi-Step + Single Step Prefills via Chunked Prefill code path (#8378)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit c5d55356f9d2b2075ac53cf20453358c1e2b7bde[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Fri Sep 27 15:12:34 2024 -0400

    [Bugfix] fix for deepseek w4a16 (#8906)
    
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit 172d1cd27634e9e7adc9cb9feac73552cfae1b24[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Fri Sep 27 14:25:10 2024 -0400

    [Kernel] AQ AZP 4/4: Integrate asymmetric quantization to linear method (#7271)

[33mcommit a9b15c606fea67a072416ea0ea115261a2756058[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Sep 27 08:11:32 2024 -0700

    [torch.compile] use empty tensor instead of None for profiling (#8875)

[33mcommit 8df2dc3c8812c0abb97ce3e2913411d88524e59f[m
Author: Brittany <24945384+bvrockwell@users.noreply.github.com>
Date:   Fri Sep 27 01:16:55 2024 -0700

    [TPU] Update pallas.py to support trillium (#8871)

[33mcommit 6d792d2f31b2cfb335d1a4a7c45fe4ce143c203a[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Sep 27 16:15:58 2024 +0800

    [Bugfix][VLM] Fix Fuyu batching inference with `max_num_seqs>1` (#8892)

[33mcommit 0e088750af2e8035c07d356b56c03393cfb56004[m
Author: Peter Pan <peter.pan@daocloud.io>
Date:   Fri Sep 27 16:13:25 2024 +0800

    [MISC] Fix invalid escape sequence '\' (#8830)
    
    Signed-off-by: Peter Pan <Peter.Pan@daocloud.io>

[33mcommit dc4e3df5c23282b2ebaead95f179c25c9d7ec4d8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Sep 27 00:26:38 2024 -0700

    [misc] fix collect env (#8894)

[33mcommit 3b00b9c26c91e9f9ada12975b613555698054e39[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Sep 27 11:35:15 2024 +0800

    [Core] rename`PromptInputs` and `inputs` (#8876)

[33mcommit 344cd2b6f4c22bf278cff96066001d216ec1fe82[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Thu Sep 26 21:01:42 2024 -0300

    [Feature] Add support for Llama 3.1 and 3.2 tool use (#8343)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>

[33mcommit 1b49148e474d4d18731e159ea0460145ae52e220[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Sep 27 07:54:09 2024 +0800

    [Installation] Allow lower versions of FastAPI to maintain Ray 2.9 compatibility (#8764)

[33mcommit 4b377d6febed7ddd964f1b96079d7e78c231325e[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Fri Sep 27 00:46:43 2024 +0100

    [BugFix] Fix test breakages from transformers 4.45 upgrade (#8829)

[33mcommit 71d21c73abfb9b12ea402ce6b11c1b8e31eddf4c[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Sep 26 19:23:45 2024 -0400

    [Bugfix] Fixup advance_step.cu warning (#8815)

[33mcommit ee2da3e9efb38add804e2023d47e9f42f38bd638[m
Author: Chirag Jain <jain.chirag925@gmail.com>
Date:   Fri Sep 27 04:53:17 2024 +0530

    fix validation: Only set tool_choice `auto` if at least one tool is provided (#8568)

[33mcommit e2f6f26e8636b8a23e5c0cda533a70c40ade01ec[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Sep 26 19:18:26 2024 -0400

    [Bugfix] Fix print_warning_once's line info (#8867)

[33mcommit b28d2104dea6ba80c0f1f6c4596b5703d7ef923d[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Sep 26 19:18:14 2024 -0400

    [Misc] Change dummy profiling and BOS fallback warns to log once (#8820)

[33mcommit 93d364da3406f5523e5e4772ffbc3c72dac7bbf4[m
Author: Pernekhan Utemuratov <pernekhan@deepinfra.com>
Date:   Thu Sep 26 15:47:00 2024 -0700

    [Bugfix] Include encoder prompts len to non-stream api usage response (#8861)

[33mcommit d9cfbc891e2e1d62d74c7aae93bde436a29bd574[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Sep 26 15:02:16 2024 -0700

    [ci] Soft fail Entrypoints, Samplers, LoRA, Decoder-only VLM (#8872)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 70de39f6b46f6b90aecba52358825127a50b3921[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Sep 26 13:19:04 2024 -0700

    [misc][installation] build from source without compilation (#8818)

[33mcommit 68988d4e0d8765901c51f07f9bfbda58f35f6f63[m
Author: fyuan1316 <yuanfang@alauda.io>
Date:   Fri Sep 27 02:04:39 2024 +0800

    [CI/Build] Fix missing ci dependencies (#8834)

[33mcommit 520db4dbc10cfc60be65e85ff4ef3a6aeeeb7836[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Sep 26 14:02:52 2024 -0400

    [Docs] Add README to the build docker image (#8825)

[33mcommit f70bccac75a0aecc0a5fc934859158a3e1f019a5[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Sep 26 13:07:18 2024 -0400

    [Build/CI] Upgrade to gcc 10 in the base build Docker image (#8814)

[33mcommit 4bb98f2190aaf408cb063df5184829fb54ee5f81[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Sep 26 07:45:30 2024 -0700

    [Misc] Update config loading for Qwen2-VL and remove Granite (#8837)

[33mcommit 7193774b1ff8603ad5bf4598e5efba0d9a39b436[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Sep 25 17:46:22 2024 -0400

    [Misc] Support quantization of MllamaForCausalLM (#8822)

[33mcommit e2c6e0a8291126c868b669f631837c7781646fdc[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Sep 25 13:29:48 2024 -0700

    [Doc] Update doc for Transformers 4.45 (#8817)

[33mcommit 770ec6024fc00cd696899f5c6fdc53b7148876e6[m
Author: Chen Zhang <zhangch99@outlook.com>
Date:   Wed Sep 25 13:29:32 2024 -0700

    [Model] Add support for the multi-modal Llama 3.2 model (#8811)
    
    Co-authored-by: simon-mo <xmo@berkeley.edu>
    Co-authored-by: Chang Su <chang.s.su@oracle.com>
    Co-authored-by: Simon Mo <simon.mo@hey.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 4f1ba0844b83b4e7d0ff1672b7ba502ce8732f95[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Sep 25 10:36:26 2024 -0700

    Revert "rename PromptInputs and inputs with backward compatibility (#8760) (#8810)

[33mcommit 873edda6cf8a2902e8b08eea0bf8f8f6d73704a8[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Sep 25 12:43:36 2024 -0400

    [Misc] Support FP8 MoE for compressed-tensors (#8588)

[33mcommit 64840dfae48621c5c2004eb8f1cb7fba49f9b24e[m
Author: ÁßëËã± <abatom@163.com>
Date:   Thu Sep 26 00:37:41 2024 +0800

    [Frontend] MQLLMEngine supports profiling. (#8761)

[33mcommit 28e1299e60e565a56a2db41396380f74b8d29e57[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Sep 26 00:36:47 2024 +0800

    rename PromptInputs and inputs with backward compatibility (#8760)

[33mcommit 0c4d2ad5e641de145682674066a84ffc632e714e[m
Author: DefTruth <31974251+DefTruth@users.noreply.github.com>
Date:   Thu Sep 26 00:35:53 2024 +0800

    [VLM][Bugfix] internvl with num_scheduler_steps > 1 (#8614)

[33mcommit c6f2485c823b5cd76cca70798e653c6eadb811de[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Sep 26 00:35:23 2024 +0800

    [[Misc]] Add extra deps for openai server image (#8792)

[33mcommit 300da09177477d0a4d2b55790addefd971f52ae0[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Wed Sep 25 10:35:52 2024 -0400

    [Kernel] Fullgraph and opcheck tests (#8479)

[33mcommit 1c046447a6d1ac3c99b9f453796f0d355d673deb[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Wed Sep 25 10:26:37 2024 -0400

    [CI/Build][Bugfix][Doc][ROCm] CI fix and doc update after ROCm 6.2 upgrade (#8777)

[33mcommit 8fae5ed7f6bfd63b81310fcb24b310d9205c9687[m
Author: Woo-Yeon Lee <wooyeon0.lee@samsung.com>
Date:   Wed Sep 25 16:53:03 2024 +0900

    [Misc] Fix minor typo in scheduler (#8765)

[33mcommit 3368c3ab36436af1342a3156971412e9efdb6419[m
Author: David Newman <darthhexx@gmail.com>
Date:   Wed Sep 25 17:52:26 2024 +1000

    [Bugfix] Ray 2.9.x doesn't expose available_resources_per_node (#8767)
    
    Signed-off-by: darthhexx <darthhexx@gmail.com>

[33mcommit 1ac3de09cd87290f7494ce6337623d6edd3f8667[m
Author: Adam Tilghman <agt@ucsd.edu>
Date:   Wed Sep 25 00:49:26 2024 -0700

    [Frontend] OpenAI server: propagate usage accounting to FastAPI middleware layer (#8672)

[33mcommit 3e073e66f1790f7ce339dad71514983e6e402f30[m
Author: sohamparikh <sohamparikh47@gmail.com>
Date:   Wed Sep 25 02:16:30 2024 -0400

    [Bugfix] load fc bias from config for eagle (#8790)

[33mcommit c23953675f78bc85045d66fa98aea7d0581c2167[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Sep 25 14:16:11 2024 +0800

    [Hardware][CPU] Enable mrope and support Qwen2-VL on CPU backend (#8770)

[33mcommit e3dd0692fa2c803cd6f59a88d2fdf8bca26d8d96[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Tue Sep 24 22:53:43 2024 -0700

    [BugFix] Propagate 'trust_remote_code' setting in internvl and minicpmv (#8250)

[33mcommit fc3afc20df410dd523f94967b98836084f561ab7[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Tue Sep 24 21:26:36 2024 -0700

    Fix tests in test_chunked_prefill_scheduler which fail with BlockManager V2 (#8752)

[33mcommit b4522474a32b6e0bf5573a9b6a6830cb787dfb63[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Wed Sep 25 04:26:33 2024 +0000

    [Bugfix][Kernel] Implement acquire/release polyfill for Pascal (#8776)

[33mcommit ee777d9c30418ffa9d98f98dd27c0ddea346c49c[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Tue Sep 24 21:26:18 2024 -0700

    Fix test_schedule_swapped_simple in test_scheduler.py (#8780)

[33mcommit 6e0c9d6bd07464b311eb098e2dac8196eed16721[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Tue Sep 24 21:37:38 2024 -0600

    [Bugfix] Use heartbeats instead of health checks (#8583)

[33mcommit 6da1ab6b4134d76391a0c31a048e5d04b6283769[m
Author: Archit Patke <apatke@illinois.edu>
Date:   Tue Sep 24 21:50:50 2024 -0500

    [Core] Adding Priority Scheduling (#5958)

[33mcommit 01b6f9e1f0530a7cb81486ff34d3d935e4f75d28[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Tue Sep 24 18:29:56 2024 -0600

    [Core][Bugfix] Support prompt_logprobs returned with speculative decoding (#8047)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 13f9f7a3d0373421ee9fd7498e450214e134aa6c[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Sep 25 08:08:55 2024 +0800

    [[Misc]Upgrade bitsandbytes to the latest version 0.44.0 (#8768)

[33mcommit 1e7d5c01f5c35424eede1bbe6f723dd8781120f0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Sep 24 15:48:39 2024 -0700

    [misc] soft drop beam search (#8763)

[33mcommit 2467b642dd9bde32a334fe5967efd78a53aa49da[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Tue Sep 24 21:38:12 2024 +0200

    [CI/Build] fix setuptools-scm usage (#8771)

[33mcommit 72fc97a0f100b92f1ff6c6a16e27d12f1c7569aa[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Tue Sep 24 14:33:21 2024 -0400

    [Bugfix] Fix torch dynamo fixes caused by `replace_parameters` (#8748)

[33mcommit 2529d09b5a4a124a316b6976e7d782f54e0bddde[m
Author: Andy <37781802+aandyw@users.noreply.github.com>
Date:   Tue Sep 24 12:44:11 2024 -0400

    [Frontend] Batch inference for llm.chat() API  (#8648)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>
    Co-authored-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit a928ded99519f803d4cf6389df6acc707239a5cc[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Tue Sep 24 18:31:42 2024 +0200

    [Kernel] Split Marlin MoE kernels into multiple files (#8661)
    
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit cc4325b66ac49e403ed9e1a8c38156a5324e1174[m
Author: Hanzhi Zhou <hanzhi713@gmail.com>
Date:   Tue Sep 24 01:08:14 2024 -0700

    [Bugfix] Fix potentially unsafe custom allreduce synchronization (#8558)

[33mcommit 8ff7ced996d5dc8b682913471f36c9fefb0e843f[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Tue Sep 24 01:36:46 2024 -0600

    [Model] Expose Phi3v num_crops as a mm_processor_kwarg (#8658)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 3f06bae9079ee495a34cfadcd9c1ef2a23636084[m
Author: Peter Salas <peter@fixie.ai>
Date:   Tue Sep 24 00:14:15 2024 -0700

    [Core][Model] Support loading weights by ID within models (#7931)

[33mcommit b8747e8a7c318ab774862f94ccbdbba5b7d9dd4a[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Mon Sep 23 23:10:03 2024 -0700

    [MISC] Skip dumping inputs when unpicklable (#8744)

[33mcommit 3185fb0ccae73816018d0936c03171b7cf1ba2f8[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Sep 23 22:45:20 2024 -0700

    Revert "[Core] Rename `PromptInputs` to `PromptType`, and `inputs` to `prompt`" (#8750)

[33mcommit 0250dd68c5df12ead29d2ec7d922855c9a257b06[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Sep 23 22:08:12 2024 -0700

    re-implement beam search on top of vllm core (#8726)
    
    Co-authored-by: Brendan Wong <bjwpokemon@gmail.com>

[33mcommit 88577ac92808cfd9468e4b54b757d5fcbe9aa486[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Mon Sep 23 21:43:13 2024 -0700

    Fix tests in test_scheduler.py that fail with BlockManager V2 (#8728)

[33mcommit 530821d00cb2beeb8dc62f74f0e4e0003868dc93[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Mon Sep 23 21:52:39 2024 -0400

    [Hardware][AMD] ROCm6.2 upgrade (#8674)

[33mcommit 1a2aef3e59f5429299618bd3b242833cb377f554[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Mon Sep 23 18:38:04 2024 -0400

    Add output streaming support to multi-step + async while ensuring RequestOutput obj reuse (#8335)

[33mcommit 5f7bb584272ee15147a411b887e7ababd6b9b9d0[m
Author: jiqing-feng <107918818+jiqing-feng@users.noreply.github.com>
Date:   Tue Sep 24 03:32:27 2024 +0800

    Fix typical acceptance sampler with correct recovered token ids (#8562)

[33mcommit b05f5c9238c3e0c3a98080b4ffc90acfa33f9e1f[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Mon Sep 23 15:15:41 2024 -0400

    [Core] Allow IPv6 in VLLM_HOST_IP with zmq (#8575)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit 9b0e3ec970f6a19427be358848a2ed663fd735e1[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Sep 24 02:57:42 2024 +0800

    [Kernel][LoRA]  Add assertion for punica sgmv kernels (#7585)

[33mcommit 86e9c8df29a954a7a2fc46e9985fecc2a2e15ae8[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Mon Sep 23 13:46:26 2024 -0400

    [Kernel] (2/N) Machete - Integrate into CompressedTensorsWNA16 and GPTQMarlin (#7701)
    
    Co-authored-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit ee5f34b1c2c71b2d56054a5ca23fe1c50c1458bb[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Mon Sep 23 18:44:26 2024 +0200

    [CI/Build] use setuptools-scm to set __version__ (#4738)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit f2bd246c17ba67d7749a2560a30711f74cd19177[m
Author: Jani Monoses <jani.monoses@gmail.com>
Date:   Mon Sep 23 17:43:09 2024 +0300

    [VLM] Fix paligemma, fuyu and persimmon with transformers 4.45 : use config.text_config.vocab_size (#8707)

[33mcommit a79e5229843e2800956956d0668b1b4858dbb61e[m
Author: Yanyi Liu <wolfsonliu@163.com>
Date:   Mon Sep 23 21:46:59 2024 +0800

    [Model] Support pp for qwen2-vl (#8696)

[33mcommit 3e83c12b5caa466bf533b144a9ec7944a9ce9d49[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Mon Sep 23 21:15:16 2024 +0800

    [Bugfix][CPU] fix missing input intermediate_tensors in the cpu_model_runner (#8733)

[33mcommit e551ca1555b64ba1ecb2310ea658f3e25c62571d[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Sep 23 20:12:20 2024 +0800

    [Hardware][CPU] Refactor CPU model runner (#8729)

[33mcommit 9b8c8ba1198cbcd311d28b7647f0f8d5dcdc9212[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Mon Sep 23 01:44:48 2024 -0600

    [Core][Frontend] Support Passing Multimodal Processor Kwargs (#8657)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit d23679eb9960ad2a876b88ebd0028dbe55c3172a[m
Author: Yan Ma <yan.ma@intel.com>
Date:   Mon Sep 23 13:54:18 2024 +0800

    [Bugfix] fix docker build for xpu (#8652)

[33mcommit 57a0702e63d9dc477ab7a82e686a30d14fb6c69d[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Sun Sep 22 23:40:46 2024 -0400

    [Bugfix] Fix CPU CMake build (#8723)
    
    Co-authored-by: Yuan <yuan.zhou@intel.com>

[33mcommit 3dda7c22502033854e963fef3826c1f64627e33b[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sun Sep 22 22:24:59 2024 -0400

    [Bugfix] Avoid some bogus messages RE CUTLASS's revision when building (#8702)

[33mcommit 92ba7e7477619ec81464ccb64a17226f3d5047bb[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Sep 22 15:41:59 2024 -0700

    [misc] upgrade mistral-common (#8715)

[33mcommit d4a2ac830291305f202a85e157bff3a07b58e616[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Sep 22 12:47:54 2024 -0700

    [build] enable existing pytorch (for GH200, aarch64, nightly) (#8713)

[33mcommit c6bd70d7728b50f358cb5cb6e66e02b75aeb3d20[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Sun Sep 22 12:34:14 2024 -0700

    [SpecDec][Misc] Cleanup, remove bonus token logic. (#8701)

[33mcommit 5b59532760c82a9d91f65a3e227524da2af7d4ef[m
Author: litianjian <45817262+litianjian@users.noreply.github.com>
Date:   Mon Sep 23 01:51:44 2024 +0800

    [Model][VLM] Add LLaVA-Onevision model support (#8486)
    
    Co-authored-by: litianjian <litianjian@bytedance.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit ca2b628b3c25b014b9951731c0331b75262a59e0[m
Author: Huazhong Ji <hzji210@gmail.com>
Date:   Mon Sep 23 01:44:09 2024 +0800

    [MISC] rename CudaMemoryProfiler to DeviceMemoryProfiler (#8703)

[33mcommit 8ca5051b9afb6f8d2b3ae1b71d45d84e5d1c6f57[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Sun Sep 22 06:56:20 2024 -0600

    [Misc] Use NamedTuple in Multi-image example (#8705)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit 06ed2815e2be50e527839c7ab09ce2639b7910b6[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Sep 22 20:24:21 2024 +0800

    [Model] Refactor BLIP/BLIP-2 to support composite model loading (#8407)

[33mcommit 0e40ac9b7b5d953dfe38933bc7d2fb0a6c8da53c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Sep 21 23:24:58 2024 -0700

    [ci][build] fix vllm-flash-attn (#8699)

[33mcommit 13d88d4137f97b8cf3c79f39d7df5e4c8348603a[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sun Sep 22 12:33:27 2024 +0800

    [Bugfix] Refactor composite weight loading logic (#8656)

[33mcommit d66ac62854e04c8fda83506dc93ef7971ebf593a[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sat Sep 21 19:45:02 2024 -0400

    [Kernel][Bugfix] Delete some more useless code in marlin_moe_ops.cu (#8643)

[33mcommit 9dc7c6c7f332ac6c08311c7a946c6945e0782701[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Sat Sep 21 16:09:39 2024 -0500

    [dbrx] refactor dbrx experts to extend FusedMoe class (#8518)

[33mcommit ec4aaad8124baadc7954e30c612ca9444b22d7e7[m
Author: rasmith <Randall.Smith@amd.com>
Date:   Sat Sep 21 04:20:54 2024 -0500

    [Kernel][Triton][AMD] Remove tl.atomic_add from awq_gemm_kernel, 2-5x speedup MI300, minor improvement for MI250 (#8646)

[33mcommit 4dfdf4319676c3dca72cdfba20470ac76d0cadf4[m
Author: Andy Dai <76841985+Imss27@users.noreply.github.com>
Date:   Sat Sep 21 00:24:12 2024 -0700

    [Doc] Fix typo in AMD installation guide (#8689)

[33mcommit 5e85f4f82a5b6eaad6869198d6ac76a0c12cf6d0[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Sep 21 14:28:56 2024 +0800

    [VLM] Use `SequenceData.from_token_counts` to create dummy data (#8687)

[33mcommit 71c60491f287d8a23bed1743513b4b3e7927c69e[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Sat Sep 21 02:27:10 2024 -0400

    [Kernel] Build flash-attn from source (#8245)

[33mcommit 0faab90eb006c677add65cd4c2d0f740a63e064d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Sep 20 19:55:33 2024 -0700

    [beam search] add output for manually checking the correctness (#8684)

[33mcommit 0455c46ed434d70f0a6219204e89ee04f1d01336[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Sep 21 10:30:39 2024 +0800

    [Core] Factor out common code in `SequenceData` and `Sequence` (#8675)

[33mcommit d4bf085ad064ba68a77862e2022f37c33a66e94a[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Sat Sep 21 10:03:55 2024 +0800

    [MISC] add support custom_op check (#8557)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 0057894ef7f8db0d51385aa7254219d7fbd6c784[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Sep 21 10:00:54 2024 +0800

    [Core] Rename `PromptInputs` and `inputs`(#8673)

[33mcommit 0f961b3ce9ac3d3fd13e201c4358884bc094905e[m
Author: zyddnys <zyddnys@outlook.com>
Date:   Fri Sep 20 18:48:32 2024 -0400

    [Bugfix] Fix incorrect llava next feature size calculation (#8496)

[33mcommit 7f9c8902e3d50a9d715b38e0531280a58d2bbe14[m
Author: omrishiv <327609+omrishiv@users.noreply.github.com>
Date:   Fri Sep 20 15:19:44 2024 -0700

    [Hardware][AWS] update neuron to 2.20 (#8676)
    
    Signed-off-by: omrishiv <327609+omrishiv@users.noreply.github.com>

[33mcommit 7c8566aa4ff16b79a576436fbb50f03643febf07[m
Author: omrishiv <327609+omrishiv@users.noreply.github.com>
Date:   Fri Sep 20 15:04:37 2024 -0700

    [Doc] neuron documentation update (#8671)
    
    Signed-off-by: omrishiv <327609+omrishiv@users.noreply.github.com>

[33mcommit b4e4eda92e1d3a013fc4007db64b69d8604264ff[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Fri Sep 20 23:33:03 2024 +0200

    [Bugfix][Core] Fix tekken edge case for mistral tokenizer (#8640)

[33mcommit 2874bac618052a079efd837fc82cf3f3519079c7[m
Author: PastelÔºÅ <1627301104@qq.com>
Date:   Sat Sep 21 05:00:45 2024 +0800

    [Bugfix] Config got an unexpected keyword argument 'engine' (#8556)

[33mcommit 035fa895ecedea87810889aabbe50ba8a2ad7d5d[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Sep 21 04:52:19 2024 +0800

    [Misc] Show AMD GPU topology in `collect_env.py` (#8649)

[33mcommit b28298f2f4bd4ec6d1020c10b923a9eb7993dc89[m
Author: saumya-saran <saumya.saran@c3.ai>
Date:   Fri Sep 20 12:46:02 2024 -0700

    [Bugfix] Validate SamplingParam n is an int (#8548)

[33mcommit 2940afa04e39fa9f248c565687d9a2acf7401355[m
Author: Alexey Kondratiev(AMD) <143633163+alexeykondrat@users.noreply.github.com>
Date:   Fri Sep 20 13:27:44 2024 -0400

    [CI/Build] Removing entrypoints/openai/test_embedding.py test from ROCm build (#8670)

[33mcommit 3b63de9353ce51ba6c1c167ae8d4b87b8bcf9c9e[m
Author: Niklas Muennighoff <n.muennighoff@gmail.com>
Date:   Fri Sep 20 09:31:41 2024 -0700

    [Model] Add OLMoE (#7922)

[33mcommit 260d40b5ea48df9421325388abcc8d907a560fc5[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Thu Sep 19 23:20:56 2024 -0700

    [Core] Support Lora lineage and base model metadata management (#6315)

[33mcommit 9e5ec35b1f8239453b1aaab28e7a02307db4ab1f[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Thu Sep 19 20:49:54 2024 -0700

    [bugfix] [AMD] add multi-step advance_step to ROCmFlashAttentionMetadata (#8474)

[33mcommit 18ae428a0d8792d160d811a9cd5bb004d68ea8bd[m
Author: Amit Garg <mitgarg17495@gmail.com>
Date:   Thu Sep 19 17:54:02 2024 -0700

    [Bugfix] Fix Phi3.5 mini and MoE LoRA inference (#8571)

[33mcommit de6f90a13d7b98c4958ba107ec16cb6f95efb10f[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Thu Sep 19 18:36:30 2024 -0400

    [Misc] guard against change in cuda library name (#8609)

[33mcommit 6cb748e190a94e20987314025614b8bd806602f2[m
Author: Alexey Kondratiev(AMD) <143633163+alexeykondrat@users.noreply.github.com>
Date:   Thu Sep 19 16:06:32 2024 -0400

    [CI/Build] Re-enabling Entrypoints tests on ROCm, excluding ones that fail (#8551)

[33mcommit 9e99407e3ccbb290bae77af230da38c70a52a055[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Sep 19 12:16:28 2024 -0700

    Create SECURITY.md (#8642)

[33mcommit ea4647b7d77c4738c5ed2ab77a2c9f5ad335f6fb[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Sep 20 03:15:55 2024 +0800

    [Doc] Add documentation for GGUF quantization (#8618)

[33mcommit e42c634acbd1b86b5becca51e8b8108a32a438d5[m
Author: Áõè‰∏Ä <w@hidva.com>
Date:   Fri Sep 20 02:28:25 2024 +0800

    [Core] simplify logits resort in _apply_top_k_top_p (#8619)

[33mcommit 9cc373f39036af789fb1ffc1e06b23766996d3f4[m
Author: Charlie Fu <charlifu@amd.com>
Date:   Thu Sep 19 12:37:57 2024 -0500

    [Kernel][Amd] Add fp8 kv cache support for rocm custom paged attention (#8577)

[33mcommit 76515f303b44cb3ffc6de63c49148d5081a77119[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Sep 19 17:51:06 2024 +0100

    [Frontend] Use MQLLMEngine for embeddings models too (#8584)

[33mcommit 855c8ae2c9a4085b1ebd66d9a978fb23f47f822c[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Thu Sep 19 13:33:20 2024 +0800

    [MISC] remove engine_use_ray in benchmark_throughput.py (#8615)

[33mcommit c52ec5f03471008fa1312d82fb17d40b95a3ca5d[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Wed Sep 18 22:24:24 2024 -0700

    [Bugfix] fixing sonnet benchmark bug in benchmark_serving.py (#8616)

[33mcommit 02c9afa2d04a85269faa2760e9af30527a61d7f6[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Sep 18 21:14:28 2024 -0700

    Revert "[Misc][Bugfix] Disable guided decoding for mistral tokenizer" (#8593)

[33mcommit 3118f63385c0d767fba8b6d2039fc35440678da9[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Wed Sep 18 19:24:15 2024 -0700

    [Bugfix] [Encoder-Decoder] Bugfix for encoder specific metadata construction during decode of encoder-decoder models.  (#8545)

[33mcommit 4c34ce8916da0e4967eadefcb7f91eb58dd7ac61[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Sep 18 21:42:49 2024 -0400

    [Kernel] Remove marlin moe templating on thread_m_blocks (#8573)
    
    Co-authored-by: lwilkinson@neuralmagic.com

[33mcommit 0d47bf3bf40edfe9fcfd7e5cd909388497535bc5[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Wed Sep 18 16:10:01 2024 -0600

    [Bugfix] add `dead_error` property to engine client (#8574)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit d9cd78eb718c233ebc5b84377fc2226af7ef0fa2[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Sep 18 21:17:55 2024 +0100

    [BugFix] Nonzero exit code if MQLLMEngine startup fails (#8572)

[33mcommit db9120cdedba5033037432775417df0b6117495d[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Sep 18 16:05:06 2024 -0400

    [Kernel] Change interface to Mamba selective_state_update for continuous batching (#8039)

[33mcommit b3195bc9e4d57b6107af2222afea26c51475e262[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Wed Sep 18 13:41:08 2024 -0400

    [AMD][ROCm]Quantization methods on ROCm; Fix _scaled_mm call (#8380)
    
    Co-authored-by: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit e18749ff09c277f7cdab278895ebdd9b1041b6e8[m
Author: Geun, Lim <shing100@Naver.com>
Date:   Thu Sep 19 02:04:00 2024 +0900

    [Model] Support Solar Model (#8386)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit d65798f78c76f03f068fc2f69a68cff430ee6b6f[m
Author: Russell Bryant <rbryant@redhat.com>
Date:   Wed Sep 18 12:10:27 2024 -0400

    [Core] zmq: bind only to 127.0.0.1 for local-only usage (#8543)
    
    Signed-off-by: Russell Bryant <rbryant@redhat.com>

[33mcommit a8c1d161a7d87dbc6c7cccfce303dcbe2e4ed6be[m
Author: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
Date:   Wed Sep 18 11:38:43 2024 -0400

    [Core] *Prompt* logprobs support in Multi-step (#8199)

[33mcommit 7c7714d856eee6fa94aade729b67f00584f72a4c[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Wed Sep 18 09:56:58 2024 -0400

    [Core][Bugfix][Perf] Introduce `MQLLMEngine` to avoid `asyncio` OH (#8157)
    
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>
    Co-authored-by: rshaw@neuralmagic.com <rshaw@neuralmagic.com>
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 9d104b5beb7bbb51c64b680e007f39169489ea86[m
Author: Aaron Pham <contact@aarnphm.xyz>
Date:   Wed Sep 18 07:00:56 2024 -0400

    [CI/Build] Update Ruff version (#8469)
    
    Signed-off-by: Aaron Pham <contact@aarnphm.xyz>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 6ffa3f314c59e42238f1c5f923ff2839e0af9698[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Sep 18 18:38:11 2024 +0800

    [CI/Build] Avoid CUDA initialization (#8534)

[33mcommit e351572900f7d87e14fe203ea3a49c1c7ddae0d6[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Wed Sep 18 02:51:59 2024 -0700

    [Misc] Add argument to disable FastAPI docs (#8554)

[33mcommit 95965d31b6ac2c9557816a6ffabe4a3117a5ccb2[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Wed Sep 18 04:49:53 2024 +0200

    [CI/Build] fix Dockerfile.cpu on podman (#8540)

[33mcommit 8110e44529f431d54b02060528601c0d3e3f7d02[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Sep 17 19:44:27 2024 -0400

    [Kernel] Change interface to Mamba causal_conv1d_update for continuous batching (#8012)

[33mcommit 09deb4721f830602d0417604c7e18b7e384f9594[m
Author: Alexey Kondratiev(AMD) <143633163+alexeykondrat@users.noreply.github.com>
Date:   Tue Sep 17 19:40:29 2024 -0400

    [CI/Build] Excluding kernels/test_gguf.py from ROCm (#8520)

[33mcommit fa0c114fad4e2b807503e78d5110558cfee92ba4[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Sep 17 16:24:06 2024 -0700

    [doc] improve installation doc (#8550)
    
    Co-authored-by: Andy Dai <76841985+Imss27@users.noreply.github.com>

[33mcommit 98f9713399bd602ff954a83e6e6abcb4cf8b8864[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Tue Sep 17 17:17:08 2024 -0600

    [Bugfix] Fix TP > 1 for new granite (#8544)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 56c3de018c35580fd088655c2f9951cd4da5335d[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Sep 17 20:24:29 2024 +0100

    [Misc] Don't dump contents of kvcache tensors on errors (#8527)

[33mcommit a54ed8024953dc6b59906072a7a89cd4791ec4f0[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Tue Sep 17 19:50:37 2024 +0200

    [Model] Add mistral function calling format to all models loaded with "mistral" format (#8515)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 9855b99502c7537db5ef018129e603650800ac46[m
Author: chenqianfzh <51831990+chenqianfzh@users.noreply.github.com>
Date:   Tue Sep 17 08:09:12 2024 -0700

    [Feature][kernel] tensor parallelism with bitsandbytes quantization (#8434)

[33mcommit 1009e93c5d634c724eeff3d4e453369337f502d4[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Tue Sep 17 07:35:01 2024 -0700

    [Encoder decoder] Add cuda graph support during decoding for encoder-decoder models (#7631)

[33mcommit 1b6de8352b878348974b3f117cbb68ed18daa609[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue Sep 17 15:34:27 2024 +0800

    [Benchmark] Support sample from HF datasets and image input for benchmark_serving (#8495)

[33mcommit cbdb25225914a04d94e8830f4e739faca8ff3b9d[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Tue Sep 17 00:06:26 2024 -0700

    [Misc] Limit to ray[adag] 2.35 to avoid backward incompatible change (#8509)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit 99aa4eddaf929f57dac405b00db3f5286624ee8b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Sep 16 22:57:57 2024 -0700

    [torch.compile] register allreduce operations as custom ops (#8526)

[33mcommit ee2bceaaa67bd2f420f62a924da5834a7c1c862b[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Sep 16 22:22:45 2024 -0700

    [Misc][Bugfix] Disable guided decoding for mistral tokenizer (#8521)

[33mcommit 1c1bb388e0d35a2d10da5c5cda2edac57bf62591[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Mon Sep 16 22:17:32 2024 -0600

    [Frontend] Improve Nullable kv Arg Parsing (#8525)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit 546034b466bf11f12936791312981b9982850eb0[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Sep 16 20:04:48 2024 -0700

    [refactor] remove triton based sampler (#8524)

[33mcommit cca61642e0484212e6cd78b35b4789afed8d19c6[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Mon Sep 16 18:01:45 2024 -0600

    [Bugfix] Fix 3.12 builds on main (#8510)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 5ce45eb54d3fb870f1fb6865c67aac05ec9bf555[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Sep 16 15:11:27 2024 -0700

    [misc] small qol fixes for release process (#8517)

[33mcommit 5478c4b41f60995b92b9997306b2e0702055341f[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Sep 16 14:30:02 2024 -0700

    [perf bench] set timeout to debug hanging (#8516)

[33mcommit 47f5e03b5b9fc719b7e5ee00cbd6d1e79627f105[m
Author: Kevin Lin <42618777+kevin314@users.noreply.github.com>
Date:   Mon Sep 16 15:56:28 2024 -0500

    [Bugfix] Bind api server port before starting engine (#8491)

[33mcommit 2759a43a26e4eecb7ff7d741c2b6da0d544462ad[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Sep 16 12:10:23 2024 -0700

    [doc] update doc on testing and debugging (#8514)

[33mcommit 5d73ae49d65394f8dbe46accd921fb21e8247b82[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Mon Sep 16 14:52:40 2024 -0400

    [Kernel] AQ AZP 3/4: Asymmetric quantization kernels (#7270)

[33mcommit 781e3b9a4281babf5576f8dc22445af69814d8f6[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Mon Sep 16 18:15:57 2024 +0000

    [Bugfix][Kernel] Fix build for sm_60 in GGUF kernel (#8506)

[33mcommit acd5511b6d0e196b273b6250201115b5c5cfd1ca[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Sep 16 17:33:46 2024 +0100

    [BugFix] Fix clean shutdown issues (#8492)

[33mcommit 837c1968f9f1fdd9d894b2071d605ca1bdc97942[m
Author: lewtun <lewis.c.tunstall@gmail.com>
Date:   Mon Sep 16 17:55:26 2024 +0200

    [Frontend] Expose revision arg in OpenAI server (#8501)

[33mcommit a091e2da3e3fcb4c63c8206839d7240a2a2a176a[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Mon Sep 16 17:47:19 2024 +0200

    [Kernel] Enable 8-bit weights in Fused Marlin MoE (#8032)
    
    Co-authored-by: Dipika <dipikasikka1@gmail.com>

[33mcommit fc990f97958636ce25e4471acfd5651b096b0311[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Sep 16 06:51:44 2024 +0800

    [Bugfix][Kernel] Add `IQ1_M` quantization implementation to GGUF kernel (#8357)

[33mcommit 3724d5f6b59d9859e5b47c047535bb8edc124eab[m
Author: Chris <34248815+chrisociepa@users.noreply.github.com>
Date:   Sun Sep 15 06:20:05 2024 +0200

    [Bugfix][Model] Fix Python 3.8 compatibility in Pixtral model by updating type annotations (#8490)

[33mcommit 50e9ec41fc2dbd1b80e7ec488650c327bdf81798[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Sep 14 16:58:31 2024 -0700

    [TPU] Implement multi-step scheduling (#8489)

[33mcommit 47790f3e328f1fbf250d8f858b6390496c1e61c0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Sep 14 13:07:16 2024 -0700

    [torch.compile] add a flag to disable custom op (#8488)

[33mcommit a36e070dad7d7098f69324b8275a533140221809[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Sep 14 09:46:04 2024 -0700

    [torch.compile] fix functionalization (#8480)

[33mcommit 8a0cf1ddc323a571c9f46a85da067d44af5d2453[m
Author: ywfang <47963924+SUDA-HLT-ywfang@users.noreply.github.com>
Date:   Sat Sep 14 22:50:26 2024 +0800

    [Model] support minicpm3 (#8297)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 1ef0d2efd07f93bc7b0cfb597d8947b49e2fdaac[m
Author: Charlie Fu <Charlie.Fu@amd.com>
Date:   Fri Sep 13 19:01:11 2024 -0500

    [Kernel][Hardware][Amd]Custom paged attention kernel for rocm (#8310)

[33mcommit 851725202af36dafecd47af802db1d465b25b815[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Sat Sep 14 07:54:34 2024 +0800

    [Hardware][intel GPU] bump up ipex version to 2.3 (#8365)
    
    Co-authored-by: Yan Ma <yan.ma@intel.com>

[33mcommit 9ba0817ff1eb514f51cc6de9cb8e16c98d6ee44f[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Sep 13 11:35:00 2024 -0700

    bump version to v0.6.1.post2 (#8473)

[33mcommit 18e9e1f7b34c46857466fe24e9f9bdee17542f2c[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Fri Sep 13 19:31:12 2024 +0100

    [HotFix] Fix final output truncation with stop string + streaming (#8468)

[33mcommit f57092c00b53d6da887f2b8071af332d42ccb6d4[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sat Sep 14 02:06:30 2024 +0800

    [Doc] Add oneDNN installation to CPU backend documentation (#8467)

[33mcommit a84e598e2125960d3b4f716b78863f24ac562947[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Sep 14 01:20:06 2024 +0800

    [CI/Build] Reorganize models tests (#7820)

[33mcommit 0a4806f0a99880df1f74b10a6dceaf638cd3981c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Sep 13 09:32:42 2024 -0700

    [plugin][torch.compile] allow to add custom compile backend (#8445)

[33mcommit ecd7a1d5b69589257d36626195ece6658b61b93c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Sep 14 00:02:26 2024 +0800

    [Installation] Gate FastAPI version for Python 3.8 (#8456)

[33mcommit a2469127db6144eedb38d0b505287c0044e4ce06[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Sep 13 02:20:14 2024 -0700

    [misc][ci] fix quant test (#8449)

[33mcommit 06311e295666916d3456a357cdd91dd2a03c34e2[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Fri Sep 13 15:58:28 2024 +0800

    [Misc] Skip loading extra bias for Qwen2-VL GPTQ-Int8 (#8442)

[33mcommit cab69a15e49aa592db7042f0dc675bbe9b684f83[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Sep 12 23:52:41 2024 -0700

    [doc] recommend pip instead of conda (#8446)

[33mcommit 9b4a3b235e5bdf0df7901c77a4b01f5358db3638[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Sep 13 14:35:20 2024 +0800

    [CI/Build] Enable InternVL2 PP test only on single node (#8437)

[33mcommit acda0b35d00e733982aa4c1198f2bd381d368cb5[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Sep 12 21:39:49 2024 -0700

    bump version to v0.6.1.post1 (#8440)

[33mcommit ba7752795567e3f2bfcc1dca340d107e003d32ad[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Thu Sep 12 21:30:00 2024 -0700

    [bugfix] torch profiler bug for single gpu with GPUExecutor (#8354)

[33mcommit 68210201099e6ce1c0a1453633c77fc0185af488[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Thu Sep 12 23:48:59 2024 -0400

    [Bugfix] Fix async log stats (#8417)

[33mcommit 84275504885ae5d4b3c63209f711706c8b758882[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Sep 13 11:47:52 2024 +0800

    [CI/Build] Update pixtral tests to use JSON (#8436)

[33mcommit 3f79bc3d1a65b7ed266702bb745c66b10283361f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Sep 13 11:21:42 2024 +0800

    [Bugfix] Bump fastapi and pydantic version (#8435)

[33mcommit 40c396533d00b9b6efe08241525630dcf8d88c72[m
Author: shangmingc <csmthu@gmail.com>
Date:   Fri Sep 13 11:06:28 2024 +0800

    [Bugfix] Mapping physical device indices for e2e test utils (#8290)

[33mcommit 5ec9c0fb3c667c30117eb1fd743e0e7c13ccf997[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Sep 13 10:56:13 2024 +0800

    [Core] Factor out input preprocessing to a separate class (#7329)

[33mcommit 8f44a92d852935c8378eaab85bad47ef3174e02b[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Thu Sep 12 21:23:42 2024 -0400

    [BugFix] fix group_topk (#8430)

[33mcommit 360ddbd37ec82d5a83fd02ee94d7401684bc3c92[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Sep 12 17:31:18 2024 -0700

    [Misc] Update Pixtral example (#8431)

[33mcommit a480939e8e3b8e5b5571531c30212a1a947ee32e[m
Author: Wenxiang <8460860+wenxcs@users.noreply.github.com>
Date:   Fri Sep 13 07:25:00 2024 +0800

    [Bugfix] Fix weight loading issue by rename variable. (#8293)

[33mcommit d31174a4e1ff7ac1efbdb5d89a24f0e477f95cc8[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Fri Sep 13 00:21:51 2024 +0200

    [Hotfix][Pixtral] Fix multiple images bugs (#8415)

[33mcommit b61bd98f907180c70f65e21505b3af6d1cc2bf36[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Sep 12 15:05:35 2024 -0700

    [CI/Build] Disable multi-node test for InternVL2 (#8428)

[33mcommit c16369455f9568b709d286be0857375a860842ab[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Sep 12 14:06:51 2024 -0700

    [Hotfix][Core][VLM] Disable chunked prefill by default and prefix caching for multimodal models (#8425)

[33mcommit 019877253be473bf0c12daaf2c29022150402052[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Thu Sep 12 17:01:50 2024 -0400

    [Bugfix] multi-step + flashinfer: ensure cuda graph compatible  (#8427)

[33mcommit 551ce01078a655068e5ec3764d0a55ac744ea425[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Sep 12 20:02:00 2024 +0100

    [Core] Add engine option to return only deltas or final output (#7381)

[33mcommit a6c0f3658da4f2f23460e3e15bfa7d70ac7e60c1[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Thu Sep 12 11:16:22 2024 -0700

    [multi-step] add flashinfer backend (#7928)

[33mcommit f2e263b801743596f5dda0680e0bcb0fc3c05e26[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Thu Sep 12 12:11:57 2024 -0600

    [Bugfix] Offline mode fix (#8376)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 1f0c75afa95303fcb628861f040199090e82004d[m
Author: Luis Vega <vegaluisjose@users.noreply.github.com>
Date:   Thu Sep 12 11:10:11 2024 -0700

    [BugFix] Fix Duplicate Assignment in Hermes2ProToolParser (#8423)

[33mcommit 8a23e933026bdb66b0b141c69454457428aa056d[m
Author: WANGWEI <lnykww@gmail.com>
Date:   Fri Sep 13 01:47:42 2024 +0800

    [BugFix] lazy init _copy_stream to avoid torch init wrong gpu instance (#8403)

[33mcommit c6202daeedb22cd675942c37ae5e194549803c89[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Thu Sep 12 11:10:54 2024 -0600

    [Model] Support multiple images for qwen-vl (#8247)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit e56bf2774158dca80637a1b8309bbc4d308774b1[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Sep 13 01:10:35 2024 +0800

    [Bugfix] Fix InternVL2 inference with various num_patches (#8375)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 520ca380aef75f34cd2f5a146d30849b483e3be4[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Sep 12 09:28:37 2024 -0700

    [Hotfix][VLM] Fixing max position embeddings for Pixtral (#8399)

[33mcommit 7de49aa86c7f169eb0962b6db29ad53fff519ffb[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Sep 12 00:11:55 2024 -0700

    [torch.compile] hide slicing under custom op for inductor (#8384)

[33mcommit 42ffba11ad4597289b5ae609900a74a153fbd067[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Sep 11 23:13:14 2024 -0700

    [Misc] Use RoPE cache for MRoPE (#8396)

[33mcommit 295c4730a85ce419e5b46e256240d69ad1cce619[m
Author: Kevin Lin <42618777+kevin314@users.noreply.github.com>
Date:   Thu Sep 12 00:45:24 2024 -0500

    [Misc] Raise error when using encoder/decoder model with cpu backend (#8355)

[33mcommit 1bf2dd9df025feb82e27f90f534a3bf829ae75e9[m
Author: Blueyo0 <30562758+blueyo0@users.noreply.github.com>
Date:   Thu Sep 12 12:53:12 2024 +0800

    [Gemma2] add bitsandbytes support for Gemma2 (#8338)

[33mcommit 5a60699c452c0b9b8086a978d8572c257c2c3cc4[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Thu Sep 12 06:55:30 2024 +0300

    [Bugfix]: Fix the logic for deciding if tool parsing is used (#8366)

[33mcommit b6c75e1cf27681ec92629930c03b616c7c9b9929[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Sep 11 23:35:33 2024 -0400

    Fix the AMD weight loading tests (#8390)

[33mcommit b71c956debf045a9a1545ebfe06961ca5163d91c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Sep 11 20:31:51 2024 -0700

    [TPU] Use Ray for default distributed backend (#8389)

[33mcommit f842a7aff143a4a1ddc59e1fb57109cb377f5475[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Sep 11 18:23:36 2024 -0700

    [misc] remove engine_use_ray (#8126)

[33mcommit a65cb160679d096b988846aab5206bc1fb1255c4[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Sep 11 18:12:25 2024 -0700

    [MISC] Dump model runner inputs when crashing (#8305)

[33mcommit 3fd2b0d21cd9ec78de410fdf8aa1de840e9ad77a[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Sep 11 14:42:11 2024 -0700

    Bump version to v0.6.1 (#8379)

[33mcommit d394787e5268903a705850413e494ebf2ddcefb5[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Wed Sep 11 23:41:55 2024 +0200

    Pixtral (#8377)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 775f00f81e4f5a12b17816d39261c628e2f36683[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Wed Sep 11 14:07:34 2024 -0700

    [Speculative Decoding] Test refactor (#8317)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 8baa454937be70c2b6f283b3bf8538848531b769[m
Author: Aarni Koskela <akx@iki.fi>
Date:   Wed Sep 11 23:25:58 2024 +0300

    [Misc] Move device options to a single place (#8322)

[33mcommit 73202dbe77913df9cf520bf18172ac40e0b9951f[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Wed Sep 11 15:52:19 2024 -0400

    [Kernel][Misc] register ops to prevent graph breaks (#6917)
    
    Co-authored-by: Sage Moore <sage@neuralmagic.com>

[33mcommit 7015417fd4910a47263ea34c79c2cdb2ff314fdf[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Sep 12 02:36:54 2024 +0800

    [Bugfix] Add missing attributes in mistral tokenizer (#8364)

[33mcommit aea02f30def76b188112b553fbd89e47829f6327[m
Author: Alexey Kondratiev(AMD) <143633163+alexeykondrat@users.noreply.github.com>
Date:   Wed Sep 11 14:31:41 2024 -0400

    [CI/Build] Excluding test_moe.py from AMD Kernels tests for investigation (#8373)

[33mcommit 0b952af458ce86a69e58333f956081ab4b2665de[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Thu Sep 12 00:46:46 2024 +0800

    [Hardware][Intel] Support compressed-tensor W8A8 for CPU backend (#7257)

[33mcommit 3b7fea770f44369d077e40010bb4983ff3641535[m
Author: Yang Fan <suyang.fy@alibaba-inc.com>
Date:   Thu Sep 12 00:31:19 2024 +0800

    [Model][VLM] Add Qwen2-VL model support (#7905)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit cea95dfb941878b3370a7c40ca7ab2d549524445[m
Author: Pooya Davoodi <pooya.davoodi@parasail.io>
Date:   Tue Sep 10 22:30:11 2024 -0700

    [Frontend] Create ErrorResponse instead of raising exceptions in run_batch (#8347)

[33mcommit 6a512a00dfa306762c2878bffc3a5664a758d105[m
Author: Yangshen‚ö°Deng <yangshen.d@outlook.com>
Date:   Wed Sep 11 13:21:36 2024 +0800

    [model] Support for Llava-Next-Video model (#7559)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit efcf946a158f02a597086199890b5c7673ffe467[m
Author: Pavani Majety <pavanimajety@gmail.com>
Date:   Tue Sep 10 21:38:40 2024 -0700

    [Hardware][NV] Add support for ModelOpt static scaling checkpoints. (#6112)

[33mcommit 1230263e161caa9fd698e109d33437950769ec09[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Sep 11 10:11:01 2024 +0800

    [Bugfix] Fix InternVL2 vision embeddings process with pipeline parallel (#8299)

[33mcommit e497b8aeff5799d4ca2cfd6e01105194ebd39eac[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Sep 11 08:59:19 2024 +0800

    [Misc] Skip loading extra bias for Qwen2-MOE GPTQ models (#8329)

[33mcommit 94144e726cfeeba0c1758751b7fd46a20b6bd3b4[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Sep 10 19:51:58 2024 -0400

    [CI/Build][Kernel] Update CUTLASS to 3.5.1 tag (#8043)

[33mcommit 1d5e397aa4d94d0ccc1c9dbad533afa5cb60bb69[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Tue Sep 10 16:46:08 2024 -0700

    [Core/Bugfix] pass VLLM_ATTENTION_BACKEND to ray workers (#8172)

[33mcommit 22f3a4bc6c6801101728d97edd25ffcdd5a7fd8c[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Tue Sep 10 19:00:35 2024 -0400

    [Bugfix] lookahead block table with cuda graph max capture (#8340)
    
    [Bugfix] Ensure multistep lookahead allocation is compatible with cuda graph max capture (#8340)

[33mcommit b1f3e189586dce42bb3dcda20169a9308c9a25fa[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Tue Sep 10 15:28:28 2024 -0700

    [MISC] Keep chunked prefill enabled by default with long context when prefix caching is enabled (#8342)

[33mcommit 04e7c4e77118159e0b892681acd04a1b50a7ea6e[m
Author: Prashant Gupta <prashantgupta@us.ibm.com>
Date:   Tue Sep 10 14:21:56 2024 -0700

    [Misc] remove peft as dependency for prompt models (#8162)

[33mcommit 5faedf1b6224f6e7348e9223f3e3107ec03954d3[m
Author: Kevin Lin <42618777+kevin314@users.noreply.github.com>
Date:   Tue Sep 10 15:18:14 2024 -0500

    [Spec Decode] Move ops.advance_step to flash attn advance_step (#8224)

[33mcommit 02751a7a42c18454030ff35e350afab31e26f51d[m
Author: sumitd2 <91451282+sumitd2@users.noreply.github.com>
Date:   Wed Sep 11 01:28:34 2024 +0530

    Fix ppc64le buildkite job (#8309)

[33mcommit f421f3cefb58d968767536d745fcc6e9ac342df5[m
Author: Alexey Kondratiev(AMD) <143633163+alexeykondrat@users.noreply.github.com>
Date:   Tue Sep 10 14:51:15 2024 -0400

    [CI/Build] Enabling kernels tests for AMD, ignoring some of then that fail (#8130)

[33mcommit 8c054b7a6290551c868451dfd449d40cf37d8b62[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Sep 11 00:49:11 2024 +0800

    [Frontend] Clean up type annotations for mistral tokenizer (#8314)

[33mcommit 6234385f4a826edd5c4e0ca7dbdea480be215c5e[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Tue Sep 10 17:55:08 2024 +0200

    [CI/Build] enable ccache/scccache for HIP builds (#8327)

[33mcommit da1a844e61366b473cef6b3f7437ea5dc41876a1[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Sep 10 16:22:50 2024 +0800

    [Bugfix] Fix missing `post_layernorm` in CLIP (#8155)

[33mcommit a1d874224d9c29ae84f3850474b4816f0ed9574b[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Sep 9 23:21:00 2024 -0700

    Add NVIDIA Meetup slides, announce AMD meetup, and add contact info (#8319)

[33mcommit 6cd5e5b07e4415d064d93b8a66331a097bd9287e[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Mon Sep 9 23:02:52 2024 -0400

    [Misc] Fused MoE Marlin support for GPTQ (#8217)

[33mcommit c7cb5c333564cb00fc4f6a99d32c35e9ebc0f1ed[m
Author: Kyle Sayers <kylesayrs@gmail.com>
Date:   Mon Sep 9 16:27:26 2024 -0400

    [Misc] GPTQ Activation Ordering (#8135)

[33mcommit f9b4a2d41587da0692d32797221df55a02d890a6[m
Author: Vladislav Kruglikov <vladislavkruglikov@outlook.com>
Date:   Mon Sep 9 21:20:46 2024 +0300

    [Bugfix] Correct adapter usage for cohere and jamba (#8292)

[33mcommit 58fcc8545a149c9c5b1f91f417a68f5ba1fdabf3[m
Author: Adam Lugowski <alugowski@gmail.com>
Date:   Mon Sep 9 11:16:37 2024 -0700

    [Frontend] Add progress reporting to run_batch.py (#8060)
    
    Co-authored-by: Adam Lugowski <adam.lugowski@parasail.io>

[33mcommit 08287ef6751e79a89bf4f060f5f9545560a6de12[m
Author: Kyle Mistele <kyle@mistele.com>
Date:   Mon Sep 9 09:45:11 2024 -0500

    [Bugfix] Streamed tool calls now more strictly follow OpenAI's format; ensures Vercel AI SDK compatibility (#8272)

[33mcommit 4ef41b84766670c1bd8079f58d35bf32b5bcb3ab[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Sun Sep 8 00:01:51 2024 -0400

    [Bugfix] Fix async postprocessor in case of preemption (#8267)

[33mcommit cfe712bf1aedbee4f26105737710ff80ae9d624e[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Sat Sep 7 14:03:16 2024 -0600

    [CI/Build] Use python 3.12 in cuda image (#8133)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit b962ee1470a019a72a1c17eddcf3a0471658a123[m
Author: sumitd2 <91451282+sumitd2@users.noreply.github.com>
Date:   Sat Sep 7 23:48:40 2024 +0530

    ppc64le: Dockerfile fixed, and a script for buildkite (#8026)

[33mcommit 36bf8150cc3a048d69d9d2196128462014b9599d[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sun Sep 8 01:45:44 2024 +0800

    [Model][VLM] Decouple weight loading logic for `Paligemma` (#8269)

[33mcommit e807125936a9db796746b67ba72c222b5c26582e[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sat Sep 7 16:38:23 2024 +0800

    [Model][VLM] Support multi-images inputs for InternVL2 models (#8201)

[33mcommit 9f68e00d27b0f8252549be3adbb47c5b735a8103[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Sep 7 16:02:39 2024 +0800

    [Bugfix] Fix broken OpenAI tensorizer test (#8258)

[33mcommit ce2702a92356b69ec1ea35ecd46263ddf98e8e2c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Sep 6 22:40:46 2024 -0700

    [tpu][misc] fix typo (#8260)

[33mcommit 795b662cffe79fa0fa9a3f13a65113abdb4f96a9[m
Author: Wei-Sheng Chin <wschin@outlook.com>
Date:   Fri Sep 6 20:18:16 2024 -0700

    Enable Random Prefix Caching in Serving Profiling Tool (benchmark_serving.py) (#8241)

[33mcommit 2f707fcb35c5bc4b9164cf2bbce0254a72f7348b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Sep 7 10:57:24 2024 +0800

    [Model] Multi-input support for LLaVA (#8238)

[33mcommit 41e95c5247c9703c3e11f3b563d8bba70ed31aca[m
Author: Kyle Mistele <kyle@mistele.com>
Date:   Fri Sep 6 21:49:01 2024 -0500

    [Bugfix] Fix Hermes tool call chat template bug (#8256)
    
    Co-authored-by: Kyle Mistele <kyle@constellate.ai>

[33mcommit 12dd715807ccbd7fafbb64d42571792db1cc6497[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Fri Sep 6 17:48:48 2024 -0700

    [misc] [doc] [frontend] LLM torch profiler support (#7943)

[33mcommit 29f49cd6e3d3c5658b92ea3e97138c1ab5cb6b30[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Sat Sep 7 01:02:05 2024 +0200

    [Model] Allow loading from original Mistral format (#8168)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 23f322297f33a50dd1fe0870665d0c4414fd78ab[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Fri Sep 6 18:29:03 2024 -0400

    [Misc] Remove `SqueezeLLM` (#8220)

[33mcommit 9db52eab3dc0b7b2cf30fa4399d569131e90c2d4[m
Author: rasmith <Randall.Smith@amd.com>
Date:   Fri Sep 6 17:26:09 2024 -0500

    [Kernel] [Triton] Memory optimization for awq_gemm and awq_dequantize, 2x throughput (#8248)

[33mcommit 1447c97e753919709b613590d7267c93d07d9382[m
Author: Alexey Kondratiev(AMD) <143633163+alexeykondrat@users.noreply.github.com>
Date:   Fri Sep 6 14:51:03 2024 -0400

    [CI/Build] Increasing timeout for multiproc worker tests (#8203)

[33mcommit de80783b6907eb084493a76ef9ec3e3941cc2087[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Fri Sep 6 09:18:35 2024 -0700

    [Misc] Use ray[adag] dependency instead of cuda (#7938)

[33mcommit e5cab71531360345e5b30b98dfcfec8087d6cddf[m
Author: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
Date:   Fri Sep 6 12:01:14 2024 -0400

    [Frontend] Add --logprobs argument to `benchmark_serving.py` (#8191)

[33mcommit baa5467547a758af35f442af6edfbc0fb73c83ce[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Sep 5 20:39:29 2024 -0700

    [BugFix] Fix Granite model configuration (#8216)

[33mcommit db3bf7c991cd1a0297d1a8ba501e59cfa226c337[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Thu Sep 5 18:10:33 2024 -0700

    [Core] Support load and unload LoRA in api server (#6566)
    
    Co-authored-by: Jee Jee Li <pandaleefree@gmail.com>

[33mcommit 2febcf2777c77de576ceb5c39cba1dbc2033d04d[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Thu Sep 5 13:25:29 2024 -0700

    [Documentation][Spec Decode] Add documentation about lossless guarantees in Speculative Decoding in vLLM (#7962)

[33mcommit 2ee45281a5012072f41573eb09e1f82985adc761[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Sep 5 11:09:46 2024 -0400

    Move verify_marlin_supported to GPTQMarlinLinearMethod (#8165)

[33mcommit 9da25a88aa35da4b5ad7da545e6189e08c5f52f4[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Thu Sep 5 06:48:10 2024 -0600

    [MODEL] Qwen Multimodal Support (Qwen-VL / Qwen-VL-Chat) (#8029)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 8685ba1a1ec08d2c14df924b6e2b499be14405e7[m
Author: manikandan.tm@zucisystems.com <94887255+Manikandan-Thangaraj-ZS0321@users.noreply.github.com>
Date:   Thu Sep 5 17:03:37 2024 +0530

    Inclusion of InternVLChatModel In PP_SUPPORTED_MODELS(Pipeline Parallelism) (#7860)

[33mcommit 288a938872cc3c6150a486aaa15a3b5dcadf42cc[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Sep 5 18:51:53 2024 +0800

    [Doc] Indicate more information about supported modalities (#8181)

[33mcommit e39ebf5cf5ec8f7449d633b6428333a99a206a1c[m
Author: Elfie Guo <164945471+elfiegg@users.noreply.github.com>
Date:   Wed Sep 4 22:12:26 2024 -0700

    [Core/Bugfix] Add query dtype as per FlashInfer API requirements. (#8173)

[33mcommit ba262c4e5aa9fa753c8cedfaea5c42941184a0db[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Sep 4 20:33:12 2024 -0700

    [ci] Mark LoRA test as soft-fail (#8160)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 4624d98dbdd6f29a3d8ba7a86d93bde730ef5f7d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Sep 4 20:31:48 2024 -0700

    [Misc] Clean up RoPE forward_native (#8076)

[33mcommit 1afc931987d0c0e12bb3fde7908e768222916385[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Wed Sep 4 17:35:36 2024 -0700

    [bugfix] >1.43 constraint for openai (#8169)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit e01c2beb7d1df1f388051f083a20ae9c0d552027[m
Author: Maureen McElaney <mmcelaney@users.noreply.github.com>
Date:   Wed Sep 4 19:50:13 2024 -0400

    [Doc] [Misc] Create CODE_OF_CONDUCT.md (#8161)

[33mcommit 32e7db25365415841ebc7c4215851743fbb1bad1[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Sep 4 16:34:27 2024 -0700

    Bump version to v0.6.0 (#8166)

[33mcommit 008cf886c9361e696f70a15a282d72b58686468a[m
Author: Harsha vardhan manoj Bikki <39381063+hbikki@users.noreply.github.com>
Date:   Wed Sep 4 16:33:43 2024 -0700

    [Neuron] Adding support for adding/ overriding neuron configuration a‚Ä¶ (#8062)
    
    Co-authored-by: Harsha Bikki <harbikh@amazon.com>

[33mcommit 77d9e514a2284d5d0bd34b1518b9483ae7d8a05a[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Sep 4 13:23:22 2024 -0700

    [MISC] Replace input token throughput with total token throughput (#8164)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit e02ce498be2e11a165803d4590588ba98f129797[m
Author: Kyle Mistele <kyle@mistele.com>
Date:   Wed Sep 4 15:18:13 2024 -0500

    [Feature] OpenAI-Compatible Tools API + Streaming for Hermes & Mistral models (#5649)
    
    Co-authored-by: constellate <constellate@1-ai-appserver-staging.codereach.com>
    Co-authored-by: Kyle Mistele <kyle@constellate.ai>

[33mcommit 561d6f8077c54c7af5dbf2ed92131ce9f7d9b56b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Sep 4 13:05:50 2024 -0700

    [CI] Change test input in Gemma LoRA test (#8163)

[33mcommit d1dec6424307a6070bf3ab1700633996f20ef248[m
Author: alexeykondrat <143633163+alexeykondrat@users.noreply.github.com>
Date:   Wed Sep 4 14:57:54 2024 -0400

    [CI/Build][ROCm] Enabling LoRA tests on ROCm (#7369)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 2ad2e5608eeede10683412bbbfaf30b3a68019dc[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Sep 4 11:53:25 2024 -0700

    [MISC] Consolidate FP8 kv-cache tests (#8131)

[33mcommit d3311562fbe740a883e7f03f0b59620587cabb29[m
Author: wnma <wnma3mz@gmail.com>
Date:   Wed Sep 4 18:55:37 2024 +0800

    [Bugfix] remove post_layernorm in siglip (#8106)

[33mcommit ccd72071911951a3eb73b52a1578c8e6e51130d7[m
Author: TimWang <7367474+haitwang-cloud@users.noreply.github.com>
Date:   Wed Sep 4 14:17:05 2024 +0800

    chore: Update check-wheel-size.py to read MAX_SIZE_MB from env (#8103)

[33mcommit 855c262a6bcbb392a6e312caa3489648aa3f4a47[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Sep 4 13:22:17 2024 +0800

    [Frontend] Multimodal support in offline chat (#8098)

[33mcommit 2be8ec6e71473573a9732460fcde9392cf52be45[m
Author: Peter Salas <peter@fixie.ai>
Date:   Tue Sep 3 21:38:21 2024 -0700

    [Model] Add Ultravox support for multiple audio chunks (#7963)

[33mcommit e16fa99a6ad5bae4aedfb76121d4e622d27f81c3[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Sep 3 22:12:41 2024 -0400

    [Misc] Update fbgemmfp8 to use `vLLMParameters` (#7972)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 61f4a93d1490f285b0dd3a536dd85a9f3f18ddd9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Sep 3 18:35:33 2024 -0700

    [TPU][Bugfix] Use XLA rank for persistent cache path (#8137)

[33mcommit d4db9f53c8a50a2b0788cf1e03b5b91f20de4313[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Sep 3 17:57:41 2024 -0700

    [Benchmark] Add `--async-engine` option to benchmark_throughput.py (#7964)

[33mcommit 2188a60c7e0e5a414a87a4f0fd798333b2e0f625[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Sep 3 17:21:44 2024 -0400

    [Misc] Update `GPTQ` to use `vLLMParameters` (#7976)

[33mcommit dc0b6066ab9dcdf290286e5ad2b630b462fc87e4[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Sep 3 14:11:42 2024 -0700

    [CI] Change PR remainder to avoid at-mentions (#8134)

[33mcommit 0af3abe3d3225449c907d75eb3d2ae4b83bd21a1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Sep 3 13:29:24 2024 -0700

    [TPU][Bugfix] Fix next_token_ids shape (#8128)

[33mcommit f1575dc99f68292e96bf0688c4dcd353c7d66f7f[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Sep 3 13:25:09 2024 -0700

    [ci] Fix GHA workflow  (#8129)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit c02638efb36007458b11710e0f7428cffac7cbe4[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Tue Sep 3 22:37:08 2024 +0300

    [CI/Build] make pip install vllm work in macos (for import only) (#8118)

[33mcommit 652c83b697ac64923fac9b253a3e09a2b653eb46[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Sep 3 12:28:25 2024 -0700

    [Misc] Raise a more informative exception in add/remove_logger (#7750)

[33mcommit 6d646d08a2e0e73e83e313a5ae470c1f9e4f200e[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Tue Sep 3 14:50:29 2024 -0400

    [Core] Optimize Async + Multi-step (#8050)

[33mcommit 95a178f86120f42d183b3af5ee1ce58ee05c8889[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Sep 3 11:32:27 2024 -0700

    [CI] Only PR reviewers/committers can trigger CI on PR (#8124)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit bd852f2a8b9e9129de69fa7349906a9115538d5a[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Tue Sep 3 10:49:18 2024 -0700

    [Performance] Enable chunked prefill and prefix caching together (#8120)
    
    Co-authored-by: Tao He <sighingnow@gmail.com>
    Co-authored-by: Juelianqvq <Juelianqvq@noreply.github.com>

[33mcommit ec266536b7c4d4d308566ac928a69fcb9ef94462[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue Sep 3 21:37:52 2024 +0800

    [Bugfix][VLM] Add fallback to SDPA for ViT model running on CPU backend (#8061)

[33mcommit 0fbc6696c28f41009d8493c57e74f5971d6f5026[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Sep 2 20:35:42 2024 -0700

    [Bugfix] Fix single output condition in output processor (#7881)

[33mcommit 6e36f4fa6ce64619b9ea94c88a157f5783a63a65[m
Author: wang.yuqi <noooop@126.com>
Date:   Tue Sep 3 05:20:12 2024 +0800

    improve chunked prefill performance
    
    [Bugfix] Fix #7592 vllm 0.5.4 enable_chunked_prefill throughput is slightly lower than 0.5.3~0.5.0. (#7874)

[33mcommit dd2a6a82e3f41b4673b1dbb24b2e99230ea96981[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Sep 2 23:48:56 2024 +0800

    [Bugfix] Fix internlm2 tensor parallel inference (#8055)

[33mcommit 4ca65a97638054ed04b37c2bf3e868d4c1209e9c[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Sep 2 20:43:26 2024 +0800

    [Core][Bugfix] Accept GGUF model without .gguf extension (#8056)

[33mcommit e2b2aa5a0fdd3e682dd1fbd62e2ba81b8aa054d2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Sep 1 23:09:46 2024 -0700

    [TPU] Align worker index with node boundary (#7932)

[33mcommit e6a26ed0376f39c0ae99ee1af1e390087fc81f8a[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Sun Sep 1 21:23:29 2024 -0700

    [SpecDecode][Kernel] Flashinfer Rejection Sampling (#7244)

[33mcommit f8d60145b4d954b7a110073f77dc91842155a3d8[m
Author: Shawn Tan <shawn@wtf.sg>
Date:   Sun Sep 1 21:37:18 2024 -0400

    [Model] Add Granite model (#7436)
    
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 5b86b19954d30acaebb24bc5441b184ae3fcf345[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Sep 1 14:46:57 2024 -0700

    [Misc] Optional installation of audio related packages (#8063)

[33mcommit 5231f0898e559671c6c8cc48efc53a859fce1841[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Aug 31 16:35:53 2024 -0700

    [Frontend][VLM] Add support for multiple multi-modal items (#8049)

[33mcommit 8423aef4c867818524e90b2e2e58730b6ee5592c[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Aug 31 15:44:03 2024 -0400

    [BugFix][Core] Multistep Fix Crash on Request Cancellation (#8059)

[33mcommit 4f5d8446ede9f85182126804c6b07a56e06fd3d1[m
Author: Nicol√≤ Lucchesi <nicolo.lucchesi@gmail.com>
Date:   Sat Aug 31 09:27:58 2024 +0200

    [Bugfix] Fix ModelScope models in v0.5.5 (#8037)

[33mcommit d05f0a9db2c32528f4aff7e741ff6caf21dd0802[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Aug 31 13:26:55 2024 +0800

    [Bugfix] Fix import error in Phi-3.5-MoE (#8052)

[33mcommit 622f8abff8e17a8274504cbbfb4b69c5724a0328[m
Author: Pavani Majety <pmajety@nvidia.com>
Date:   Fri Aug 30 22:18:50 2024 -0700

    [Bugfix] bugfix and add model test for flashinfer fp8 kv cache. (#8013)

[33mcommit 1248e8506a4d98b4f15cbfe729cf2af42fb4223a[m
Author: Wenxiang <8460860+wenxcs@users.noreply.github.com>
Date:   Sat Aug 31 03:42:57 2024 +0800

    [Model] Adding support for MSFT Phi-3.5-MoE (#7729)
    
    Co-authored-by: Your Name <you@example.com>
    Co-authored-by: Zeqi Lin <zelin@microsoft.com>
    Co-authored-by: Zeqi Lin <Zeqi.Lin@microsoft.com>

[33mcommit 2684efc4678eb46d1dc7fe4311365a99215e2dc6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Aug 30 09:01:26 2024 -0700

    [TPU][Bugfix] Fix tpu type api (#8035)

[33mcommit 058344f89a6594b560e2bb4925daed3f373c3fbc[m
Author: Kaunil Dhruv <dhruv.kaunil@gmail.com>
Date:   Fri Aug 30 08:21:02 2024 -0700

    [Frontend]-config-cli-args (#7737)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: Kaunil Dhruv <kaunil_dhruv@intuit.com>

[33mcommit 98cef6a2278750ce7578ee6d6ae91e53d01c77a5[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Aug 30 23:20:34 2024 +0800

    [Core] Increase default `max_num_batched_tokens` for multimodal models (#8028)

[33mcommit f97be32d1da4cfda933a0dbfbc681861f96390d9[m
Author: Jungho Christopher Cho <wjdgh6655@gmail.com>
Date:   Sat Aug 31 00:19:27 2024 +0900

    [VLM][Model] TP support for ViTs (#7186)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit afd39a4511111aa05fd58834191d46328aed5a27[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Aug 30 23:03:28 2024 +0800

    [Bugfix] Fix import error in Exaone model (#8034)

[33mcommit 2148441fd371faf3e90748b310fdb4500939e527[m
Author: Richard Liu <39319471+richardsliu@users.noreply.github.com>
Date:   Fri Aug 30 00:27:40 2024 -0700

    [TPU] Support single and multi-host TPUs on GKE (#7613)

[33mcommit dc13e993484cf23c337e93cac9b28e7195dbbbed[m
Author: Yohan Na <nayohan13@gmail.com>
Date:   Fri Aug 30 15:34:20 2024 +0900

    [MODEL] add Exaone model support (#7819)

[33mcommit 34a0e96d463d37cf85cee9c2cd01397034e97573[m
Author: Avshalom Manevich <12231371+avshalomman@users.noreply.github.com>
Date:   Fri Aug 30 11:11:39 2024 +0700

    [Kernel] changing fused moe kernel chunk size default to 32k (#7995)

[33mcommit 80c7b089b1189c5e2f40b3be250a118e9349a024[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Aug 29 19:35:29 2024 -0700

    [TPU] Async output processing for TPU (#8011)

[33mcommit 428dd1445ee3750099967084725849c4920721a5[m
Author: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
Date:   Thu Aug 29 22:19:08 2024 -0400

    [Core] Logprobs support in Multi-step (#7652)

[33mcommit 4abed65c5806d0514432d102f959a1c84d341171[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Aug 30 08:49:04 2024 +0800

    [VLM] Disallow overflowing `max_model_len` for multimodal models (#7998)

[33mcommit 0c785d344db23644139940d19d5c448754ef53d7[m
Author: Wei-Sheng Chin <wechi@microsoft.com>
Date:   Thu Aug 29 16:48:11 2024 -0700

    Add more percentiles and latencies (#7759)

[33mcommit 4664ceaad6f99ec7824859d1ac31b29502565a98[m
Author: chenqianfzh <51831990+chenqianfzh@users.noreply.github.com>
Date:   Thu Aug 29 16:09:08 2024 -0700

    support bitsandbytes 8-bit and FP4 quantized models (#7445)

[33mcommit 257afc37c5b3e4c6d491d105337387989b013aee[m
Author: Harsha vardhan manoj Bikki <39381063+hbikki@users.noreply.github.com>
Date:   Thu Aug 29 13:58:14 2024 -0700

    [Neuron] Adding support for context-lenght, token-gen buckets. (#7885)
    
    Co-authored-by: Harsha Bikki <harbikh@amazon.com>

[33mcommit 86a677de42e83940c4fd55daa0f48d974e5e2c53[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Thu Aug 29 16:46:55 2024 -0400

    [misc] update tpu int8 to use new vLLM Parameters (#7973)

[33mcommit d78789ac16870809d64378105f200049cae95112[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Aug 30 03:54:49 2024 +0800

    [Bugfix] Fix incorrect vocal embedding shards for GGUF model in tensor parallelism (#7954)

[33mcommit c334b1898b68812af73a6d491010d929ffdb9862[m
Author: kushanam <42385577+kushanam@users.noreply.github.com>
Date:   Thu Aug 29 12:15:04 2024 -0700

    extend cuda graph size for H200 (#7894)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 6b3421567d7af6075fcfaa85924514369ac9ef45[m
Author: Pavani Majety <pavanimajety@gmail.com>
Date:   Thu Aug 29 11:53:11 2024 -0700

    [Core][Kernels] Enable FP8 KV Cache with Flashinfer backend.  + BugFix for kv_cache_dtype=auto (#7985)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 3f60f2244e3ffec6198d7a41765918d1efd3bb96[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Thu Aug 29 14:18:26 2024 -0400

    [Core] Combine async postprocessor and multi-step (#7921)

[33mcommit f205c09854853172a446c92aa81eb7199da324ab[m
Author: Jonas M. K√ºbler <44084297+jmkuebler@users.noreply.github.com>
Date:   Thu Aug 29 07:18:13 2024 +0200

    [Bugfix] Unify rank computation across regular decoding and speculative decoding (#7899)

[33mcommit ef99a78760896316dd05f96683b8d8176bfacd7a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Aug 28 21:27:06 2024 -0700

    Revert "[Core][Kernels] Use FlashInfer backend for FP8 KV Cache when available." (#7982)

[33mcommit 74d5543ec589daaa4ac042d65d52dccf26ee3f2c[m
Author: Peter Salas <peter@fixie.ai>
Date:   Wed Aug 28 20:24:31 2024 -0700

    [VLM][Core] Fix exceptions on ragged NestedTensors (#7974)

[33mcommit a7f65c2be93f491771aca31106f790bf381c0bad[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Aug 28 17:32:26 2024 -0700

    [torch.compile] remove reset (#7975)

[33mcommit 4289cad37f345873f49638d82d83087718841da5[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Aug 28 17:22:43 2024 -0700

    [Frontend] Minor optimizations to zmq decoupled front-end (#7957)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic>

[33mcommit af59df0a108eb1f00d471c7fd2b70ce957095470[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Aug 28 19:19:17 2024 -0400

    Remove faulty Meta-Llama-3-8B-Instruct-FP8.yaml lm-eval test (#7961)

[33mcommit ce6bf3a2cff4860c5661cac2280e0a28bedb6440[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Aug 28 16:10:12 2024 -0700

    [torch.compile] avoid Dynamo guard evaluation overhead (#7898)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 3cdfe1f38b2c07a10a1681cd2d60c3bea1bae2f0[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Wed Aug 28 18:11:49 2024 -0400

    [Bugfix] Make torch registration of punica ops optional (#7970)

[33mcommit fdd9daafa3b31746ec8ec7c0d67ebc7efeb13f8f[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Thu Aug 29 01:06:52 2024 +0300

    [Kernel/Model] Migrate mamba_ssm and causal_conv1d kernels to vLLM (#7651)

[33mcommit 8c56e57defff17ab297f5493144ebc11447595b3[m
Author: Stas Bekman <stas00@users.noreply.github.com>
Date:   Wed Aug 28 13:54:23 2024 -0700

    [Doc] fix 404 link (#7966)

[33mcommit eeffde1ac01f575196655ad1cc8480b86967330b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Aug 28 13:10:21 2024 -0700

    [TPU] Upgrade PyTorch XLA nightly (#7967)

[33mcommit e5697d161c132cd50d8ce560ece5b10931d74965[m
Author: rasmith <Randall.Smith@amd.com>
Date:   Wed Aug 28 14:37:47 2024 -0500

    [Kernel] [Triton] [AMD] Adding Triton implementations awq_dequantize and awq_gemm to support AWQ (#7386)

[33mcommit b98cc28f91aadbb8b831611f3676da92f892211d[m
Author: Pavani Majety <pavanimajety@gmail.com>
Date:   Wed Aug 28 10:01:22 2024 -0700

    [Core][Kernels] Use FlashInfer backend for FP8 KV Cache when available. (#7798)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit ef9baee3c52f719df64a646db72b6c4ede8a29a0[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Aug 28 23:11:18 2024 +0800

    [Bugfix][VLM] Fix incompatibility between #7902 and #7230 (#7948)

[33mcommit 98c12cffe57be141b64d47c82e65b64948446699[m
Author: Stas Bekman <stas00@users.noreply.github.com>
Date:   Wed Aug 28 05:12:32 2024 -0700

    [Doc] fix the autoAWQ example (#7937)

[33mcommit f52a43a8b90f8c4d5ba63003cc9ae75701ad48d9[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Aug 28 01:27:07 2024 -0700

    [ci][test] fix pp test failure (#7945)

[33mcommit e3580537a41a46b0f3cd750b86b633c1857a8c90[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Aug 28 00:36:31 2024 -0700

    [Performance] Enable chunked prefill and prefix caching together (#7753)

[33mcommit f508e03e7f2d8aed897d8843e1ed1668e5c4ad7a[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Wed Aug 28 03:02:30 2024 -0400

    [Core] Async_output_proc: Add virtual engine support (towards pipeline parallel) (#7911)

[33mcommit 51f86bf48730c3766f39c15aecc1268780879835[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Aug 28 14:47:44 2024 +0800

    [mypy][CI/Build] Fix mypy errors (#7929)

[33mcommit c166e7e43e7bb398835d1933a69d106b47f6cc8d[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Tue Aug 27 23:13:45 2024 -0400

    [Bugfix] Allow ScalarType to be compiled with pytorch 2.3 and add checks for registering FakeScalarType and dynamo support. (#7886)

[33mcommit bc6e42a9b19364e07da9f279edd81796541d147d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 27 19:50:06 2024 -0700

    [hardware][rocm] allow rocm to override default env var (#7926)

[33mcommit fab5f53e2dbf8e076304d7f8a205370673fbcd02[m
Author: Peter Salas <peter@fixie.ai>
Date:   Tue Aug 27 18:53:56 2024 -0700

    [Core][VLM] Stack multimodal tensors to represent multiple images within each prompt (#7902)

[33mcommit 9c71c97ae24ae6f5209a475149808e25554cfe99[m
Author: Jonathan Berkhahn <jaberkha@us.ibm.com>
Date:   Tue Aug 27 16:11:14 2024 -0700

    [mypy] Enable mypy type checking for `vllm/core` (#7229)

[33mcommit 5340a2dccf06f502821b82db187a850ce566d07c[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Tue Aug 27 16:09:02 2024 -0700

    [Model] Add multi-image input support for LLaVA-Next offline inference (#7230)

[33mcommit 345be0e2445f82bb6bed166c205feeb4f4f73fc3[m
Author: Philipp Schmid <32632186+philschmid@users.noreply.github.com>
Date:   Wed Aug 28 00:07:53 2024 +0200

    [benchmark] Update TGI version (#7917)

[33mcommit fc911880cc505197a8eaa54d0d9c49edfa593b92[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Aug 27 18:07:09 2024 -0400

    [Kernel] Expand MoE weight loading + Add Fused Marlin MoE Kernel (#7766)
    
    Co-authored-by: ElizaWszola <eliza@neuralmagic.com>

[33mcommit ed6f002d3340888142cb67c13a37c060b51fa889[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 27 12:06:11 2024 -0700

    [cuda][misc] error on empty CUDA_VISIBLE_DEVICES (#7924)

[33mcommit b09c755be89edaaca7c9e010f423545f0cd014b4[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Aug 28 01:36:09 2024 +0800

    [Bugfix] Fix phi3v incorrect image_idx when using async engine (#7916)

[33mcommit 42e932c7d4c9f0c36227d7eb68fe7b71318bfce6[m
Author: alexeykondrat <143633163+alexeykondrat@users.noreply.github.com>
Date:   Tue Aug 27 13:09:13 2024 -0400

    [CI/Build][ROCm] Enabling tensorizer tests for ROCm (#7237)

[33mcommit 076169f603a44b3a3377e59bad62d1cfc62cf98a[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Wed Aug 28 01:07:02 2024 +0800

    [Hardware][Intel GPU] Add intel GPU pipeline parallel support. (#7810)

[33mcommit 9db642138b54ef3df81873eac9fe7e15fc2da584[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue Aug 27 23:28:30 2024 +0800

    [CI/Build][VLM] Cleanup multiple images inputs model test (#7897)

[33mcommit 6fc4e6e07a55559c3744212b4d562e20d024e661[m
Author: Patrick von Platen <patrick.v.platen@gmail.com>
Date:   Tue Aug 27 14:40:02 2024 +0200

    [Model] Add Mistral Tokenization to improve robustness and chat encoding (#7739)

[33mcommit 9606c7197df073e373ab9e716a62dd4c35398865[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Tue Aug 27 00:16:31 2024 -0700

    Revert #7509 (#7887)

[33mcommit 64cc64442546c829a28e6779e315b457edf76455[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Aug 26 21:33:58 2024 -0700

    [core][torch.compile] discard the compile for profiling (#7796)

[33mcommit 39178c7fbc6ab47b5448db101476c36d0ed38d7a[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Aug 26 21:33:17 2024 -0700

    [Tests] Disable retries and use context manager for openai client (#7565)

[33mcommit 2eedede87502be64f60962147513f3df6cb1bd01[m
Author: Megha Agarwal <16129366+megha95@users.noreply.github.com>
Date:   Mon Aug 26 20:53:20 2024 -0700

    [Core] Asynchronous Output Processor (#7049)
    
    Co-authored-by: Alexander Matveev <alexm@neuralmagic.com>

[33mcommit 015e6cc252450920411a6779fbb9e631c3698de1[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Mon Aug 26 20:09:34 2024 -0400

    [Misc] Update compressed tensors lifecycle to remove `prefix` from `create_weights` (#7825)

[33mcommit 760e9f71a839ddc2a05c47af1fea23eeefbc368e[m
Author: omrishiv <327609+omrishiv@users.noreply.github.com>
Date:   Mon Aug 26 15:13:13 2024 -0700

    [Bugfix] neuron: enable tensor parallelism (#7562)
    
    Signed-off-by: omrishiv <327609+omrishiv@users.noreply.github.com>

[33mcommit 05826c887b47dce9ca72f6186dcfda394a2e0766[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Aug 26 15:02:25 2024 -0700

    [misc] fix custom allreduce p2p cache file generation (#7853)

[33mcommit dd9857f5fae74d2fd8fc236419f736a4663db800[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Mon Aug 26 17:44:54 2024 -0400

    [Misc] Update `gptq_marlin_24` to use vLLMParameters (#7762)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 665304092de6d56aaccaadacfa497a7836d88e7b[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Mon Aug 26 15:16:15 2024 -0400

    [Misc] Update `qqq` to use vLLMParameters (#7805)

[33mcommit 2deb029d115dadd012ce5ea70487a207cb025493[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Mon Aug 26 11:24:53 2024 -0700

    [Performance][BlockManagerV2] Mark prefix cache block as computed after schedule (#7822)

[33mcommit 029c71de11bc3bcf84a1b3cf9d91e79ab6949799[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Aug 26 13:31:10 2024 +0800

    [CI/Build] Avoid downloading all HF files in `RemoteOpenAIServer` (#7836)

[33mcommit 0b769992ec1d780b3229c46152c6e647da113aa6[m
Author: ‚Ñçùï†ùïùùïùùï†ùï® ùïÑùïíùïü <hollowman@opensuse.org>
Date:   Mon Aug 26 06:16:38 2024 +0300

    [Bugfix]: Use float32 for base64 embedding (#7855)
    
    Signed-off-by: Hollow Man <hollowman@opensuse.org>

[33mcommit 1856aff4d66833b258ce64132413ab8a18cc18a6[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sun Aug 25 15:45:14 2024 -0700

    [Spec Decoding] Streamline batch expansion tensor manipulation (#7851)

[33mcommit 70c094ade6eb77396a309512f24ddbfafaf15b38[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Aug 25 14:30:09 2024 -0700

    [misc][cuda] improve pynvml warning (#7852)

[33mcommit 2059b8d9caf12072710a7d610dd80954ad7c047e[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sun Aug 25 23:53:09 2024 +0800

    [Misc] Remove snapshot_download usage in InternVL2 test (#7835)

[33mcommit 8aaf3d5347ad536de25869caa67b90e43f1ccd5b[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sun Aug 25 19:51:20 2024 +0800

    [Model][VLM] Support multi-images inputs for Phi-3-vision models  (#7783)

[33mcommit 80162c44b1d1e59a2c10f65b6adb9b0407439b1f[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Sat Aug 24 18:16:24 2024 -0700

    [Bugfix] Fix Phi-3v crash when input images are of certain sizes (#7840)

[33mcommit aab0fcdb63e322f717704e9d77199f63e036d59b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Aug 24 10:31:28 2024 -0700

    [ci][test] fix RemoteOpenAIServer (#7838)

[33mcommit ea9fa160e3b47e0b8aa273f3eb2be410bd1ccab5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Aug 24 01:03:27 2024 -0700

    [ci][test] exclude model download time in server start time (#7834)

[33mcommit 7d9ffa2ae102cbfae65035c511f8d3c8e5fab986[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Aug 24 00:51:38 2024 -0700

    [misc][core] lazy import outlines (#7831)

[33mcommit d81abefd2ee8e1f4b46b3660ebdaf7b8e19c573a[m
Author: Tyler Rockwood <rockwotj@gmail.com>
Date:   Sat Aug 24 01:07:24 2024 -0500

    [Frontend] add json_schema support from OpenAI protocol (#7654)

[33mcommit 8da48e4d95421cbd96fbdecdffed89a3d1aab218[m
Author: Pooya Davoodi <pooya.davoodi@parasail.io>
Date:   Fri Aug 23 23:04:22 2024 -0700

    [Frontend] Publish  Prometheus metrics in run_batch API (#7641)

[33mcommit 6885fde317433eec52e00c14329270d742f0630d[m
Author: Pooya Davoodi <pooya.davoodi@parasail.io>
Date:   Fri Aug 23 13:58:26 2024 -0700

    [Bugfix] Fix run_batch logger (#7640)

[33mcommit 9db93de20ca282feb4dfaabbc56032c9312bde7b[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Fri Aug 23 15:45:53 2024 -0400

    [Core] Add multi-step support to LLMEngine (#7789)

[33mcommit 09c7792610ada9f88bbf87d32b472dd44bf23cc2[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Aug 23 11:35:33 2024 -0700

    Bump version to v0.5.5 (#7823)

[33mcommit f1df5dbfd6782408228f39bdc0722fa465629f0f[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Fri Aug 23 14:30:52 2024 -0400

    [Misc] Update `marlin` to use vLLMParameters (#7803)

[33mcommit 35ee2ad6b9a850a25d94cab582de19de5bca6fbd[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 23 09:38:50 2024 -0700

    [github][misc] promote asking llm first (#7809)

[33mcommit e25fee57c2e69161bd261f5986dc5aeb198bbd42[m
Author: Maximilien de Bayser <mbayser@br.ibm.com>
Date:   Fri Aug 23 10:12:44 2024 -0300

    [BugFix] Fix server crash on empty prompt (#7746)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>

[33mcommit faeddb565d6a528d1cbd169e90bc538178fc2828[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Fri Aug 23 13:46:25 2024 +0800

    [misc] Add Torch profiler support for CPU-only devices (#7806)

[33mcommit fc5ebbd1d3453461ea6e00a78faf87c41d1aa625[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Fri Aug 23 11:06:54 2024 +0800

    [Hardware][Intel GPU] refactor xpu_model_runner for tp (#7712)

[33mcommit c01a6cb23144b67b473e569a25b6f9725bc3f85b[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu Aug 22 17:44:25 2024 -0700

    [Ray backend] Better error when pg topology is bad. (#7584)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit b903e1ba7fca15f0dc49ab49a9ec8107f625c048[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Thu Aug 22 15:50:21 2024 -0600

    [Frontend] error suppression cleanup (#7786)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit a15224642832acdddd757ddc95ed40a0ad1be33d[m
Author: Siyuan Liu <lsiyuan@google.com>
Date:   Thu Aug 22 13:51:23 2024 -0700

    [Misc] fix typo in triton import warning (#7794)

[33mcommit 666ad0aa16f0c656e48e58b4f31ffe956b484d3b[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Aug 22 13:10:55 2024 -0700

    [ci] Cleanup & refactor Dockerfile to pass different Python versions and sccache bucket via build args (#7705)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 15310b5101963818b76f1821e93887cb22f0aea6[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Aug 22 14:37:08 2024 -0400

    [Bugfix] Use LoadFormat values for `vllm serve --load-format` (#7784)

[33mcommit 57792ed469956c7e580f982d590fcacea882570b[m
Author: Peter Salas <peter@fixie.ai>
Date:   Thu Aug 22 10:02:06 2024 -0700

    [Doc] Fix incorrect docs from #7615 (#7788)

[33mcommit d3b5b98021ca2030a0056121122a8965f2328fa2[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Fri Aug 23 00:32:02 2024 +0800

    [Misc] Enhance prefix-caching benchmark tool (#6568)

[33mcommit cc0eaf12b1a94bc2fd8d497f6615202699fcf7da[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Thu Aug 22 07:33:48 2024 -0600

    [Bugfix] spec decode handle None entries in topk args in create_sequence_group_output (#7232)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 955b5191c966296e22cc0d9207d68665df90e2c9[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Thu Aug 22 08:36:18 2024 -0400

    [Misc] update fp8 to use `vLLMParameter` (#7437)

[33mcommit 55d63b1211af9bd3a71d88f82f3bd5804d83b2cd[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Aug 22 08:28:52 2024 -0400

    [Bugfix] Don't build machete on cuda <12.0 (#7757)

[33mcommit 4f419c00a621eac24f954f2b7670cbd22eb232a8[m
Author: Flex Wang <flex.wang@snowflake.com>
Date:   Thu Aug 22 05:25:04 2024 -0700

    Fix ShardedStateLoader for vllm fp8 quantization (#7708)

[33mcommit a3fce56b887cba61b8e05d50f01be4309ab2c42c[m
Author: Abhinav Goyal <abhinav.goyal@flipkart.com>
Date:   Thu Aug 22 15:12:24 2024 +0530

    [Speculative Decoding] EAGLE Implementation with Top-1 proposer (#6830)

[33mcommit b3856bef7df6e2f86e54a766eb83b4d77f98ee90[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Aug 22 01:14:13 2024 -0700

    [Misc] Use torch.compile for GemmaRMSNorm (#7642)

[33mcommit 8c6f694a79d7a607ef9ba1f865c610f15c3fc2a4[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Aug 22 00:54:15 2024 -0700

    [ci] refine dependency for distributed tests (#7776)

[33mcommit eeee1c3b1ae30a9714dffe7a58bdbed10b1e2e38[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Aug 21 21:31:49 2024 -0700

    [TPU] Avoid initializing TPU runtime in is_tpu (#7763)

[33mcommit aae74ef95c370df92584e08939a15707ea8a5d3f[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Aug 21 23:42:14 2024 -0400

    Revert "[Kernel]  Expand MoE weight loading + Add Fused Marlin MoE Kernel (#7527)" (#7764)

[33mcommit cde9183b40a88f4210a7e965a430ae860aba5f6d[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Wed Aug 21 20:18:11 2024 -0600

    [Bug][Frontend] Improve ZMQ client robustness (#7443)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit df1a21131d951ba8ee65363aeb9b9486f569aa4f[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Wed Aug 21 18:36:24 2024 -0700

    [Model] Fix Phi-3.5-vision-instruct 'num_crops' issue (#7710)

[33mcommit 7937009a7e82c3c4c9c7f48d11142bee5aac4a30[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Wed Aug 21 20:18:00 2024 -0400

    [Kernel] Replaced `blockReduce[...]` functions with `cub::BlockReduce` (#7233)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 9984605412de1171a72d955cfcb954725edd4d6f[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Wed Aug 21 19:47:36 2024 -0400

    [AMD][CI/Build] Disambiguation of the function call for ROCm 6.2 headers compatibility (#7477)
    
    Co-authored-by: Charlie Fu <Charlie.Fu@amd.com>

[33mcommit 7eebe8ccaa8bb9c37d59d00cbedcd5e67308acfe[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Aug 21 16:25:34 2024 -0700

    [distributed][misc] error on same VLLM_HOST_IP setting (#7756)

[33mcommit 8678a69ab51956031e3bb70bdf1a781a8652e67d[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Wed Aug 21 19:17:10 2024 -0400

    [Kernel]  Expand MoE weight loading + Add Fused Marlin MoE Kernel (#7527)
    
    Co-authored-by: ElizaWszola <eliza@neuralmagic.com>

[33mcommit 5844017285acda7060ffc62e3dcedc0775eb4fe2[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Wed Aug 21 15:52:40 2024 -0700

    [ci] [multi-step] narrow multi-step test dependency paths (#7760)

[33mcommit 1ca0d4f86bd6db76bd601df16647fed53e495a0a[m
Author: Peter Salas <peter@fixie.ai>
Date:   Wed Aug 21 15:49:39 2024 -0700

    [Model] Add UltravoxModel and UltravoxConfig (#7615)

[33mcommit dd53c4b023056cda6174cc32dc3d31bc01e8646a[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Wed Aug 21 15:39:26 2024 -0700

    [misc] Add Torch profiler support (#7451)
    
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 970dfdc01d3453c83066e6156278d70bade0350c[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Wed Aug 21 15:53:01 2024 -0400

    [Frontend] Improve Startup Failure UX (#7716)

[33mcommit 91f4522cbf85df0a65f619b25f6751edf2d5f0d6[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Wed Aug 21 11:49:19 2024 -0700

    [multi-step] Raise error if not using async engine (#7703)

[33mcommit 1b32e0264888200a0e6187496a816ef597a7f320[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Wed Aug 21 18:17:48 2024 +0000

    [Bugfix] Pass PYTHONPATH from setup.py to CMake (#7730)

[33mcommit f7e3b0c5aa2862d27b8872084c5ca934659ceef8[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Wed Aug 21 13:34:14 2024 -0400

    [Bugfix][Frontend] Fix Issues Under High Load With `zeromq` Frontend (#7394)
    
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit d3c002eadcbaabe1cc2e5fe94321cdc6383cd4e3[m
Author: Brian Li <brian14708@gmail.com>
Date:   Thu Aug 22 01:33:35 2024 +0800

    [Bugfix] chat method add_generation_prompt param (#7734)

[33mcommit 9b73a2f498e8bf8e18305a8afea84536e9330088[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Aug 21 12:23:22 2024 -0400

    [Spec Decoding] Use target model max length as default for draft model (#7706)

[33mcommit 6925cdbeea0d2061e47403cce10f015d99f00ab1[m
Author: Isotr0py <2037008807@qq.com>
Date:   Thu Aug 22 00:23:03 2024 +0800

    [Bugfix][Hardware][CPU] Fix `mm_limits` initialization for CPU backend (#7735)

[33mcommit 53328d7536b3e8ea4863e351b09e4284f5601cae[m
Author: LI MOU <142368437+learninmou@users.noreply.github.com>
Date:   Wed Aug 21 23:54:31 2024 +0800

    [BUG] fix crash on flashinfer backend with cudagraph disabled, when attention group_size not in [1,2,4,8] (#7509)

[33mcommit c75363fbc0ffd9d56bab452dd12adbf3628d73b4[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Aug 21 11:45:55 2024 -0400

    [BugFix] Avoid premature async generator exit and raise all exception variations (#7698)

[33mcommit dd3fa0e43055cc5dd8597b74afed7294132c79c5[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Wed Aug 21 13:41:17 2024 +0000

    [Bugfix] Mirror jinja2 in pyproject.toml (#7723)

[33mcommit baaedfdb2d3f1d70b7dbcde08b083abfe6017a92[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Aug 21 14:28:21 2024 +0800

    [mypy] Enable following imports for entrypoints (#7248)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: Fei <dfdfcai4@gmail.com>

[33mcommit 450664121277240b1c52611dbb7381ef2cc75355[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Aug 20 23:24:01 2024 -0700

    [Doc] Section for Multimodal Language Models (#7719)

[33mcommit 12e1c65bc937573f19ea53e51c18294611ba33d7[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Aug 21 14:18:57 2024 +0800

    [Model] Add AWQ quantization support for InternVL2 model (#7187)

[33mcommit b74a12580022039fc15fb54c7066cc13fdc96220[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 20 17:41:12 2024 -0700

    [ci] try to log process using the port to debug the port usage (#7711)

[33mcommit 66a9e713a70d71070c77342b85e020ce536f13c0[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Aug 20 17:37:39 2024 -0700

    [Core] Pipe `worker_class_fn` argument in Executor (#7707)

[33mcommit 9e51b6a626e6ddd16abbe6d198960d5d1cfbd063[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 20 17:12:44 2024 -0700

    [ci][test] adjust max wait time for cpu offloading test (#7709)

[33mcommit 6e4658c7aaa8020ebb183729d53baaf8310859ce[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Wed Aug 21 03:01:09 2024 +0800

    [Intel GPU] fix xpu not support punica kernel (which use torch.library.custom_op) (#7685)

[33mcommit 3b682179dd4844fa346ef5e77706880c4d0b09da[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Aug 20 11:50:45 2024 -0700

    [Core] Add `AttentionState` abstraction (#7663)

[33mcommit c6af027a35b657b20ec60adac77cb75264b65a98[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Tue Aug 20 13:17:47 2024 -0400

    [Misc] Add jinja2 as an explicit build requirement (#7695)

[33mcommit 2aa00d59ada908cbf58e241fb83b1a9b5c02f71b[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Tue Aug 20 20:02:21 2024 +0300

    [CI/Build] Pin OpenTelemetry versions and make errors clearer (#7266)
    
    [CI/Build] Pin OpenTelemetry versions and make a availability errors clearer (#7266)

[33mcommit c42590f97a8fd7bcc22137777f031eeee6df8187[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Wed Aug 21 00:54:10 2024 +0800

    [Hardware] [Intel GPU]  refactor xpu worker/executor (#7686)

[33mcommit aae6927be06dedbda39c6b0c30f6aa3242b84388[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue Aug 20 23:10:20 2024 +0800

    [VLM][Model] Add test for InternViT vision encoder (#7409)

[33mcommit 398521ad199d0ca8f822a98a004fef0e5914753a[m
Author: Ilya Lavrenov <ilya.lavrenov@intel.com>
Date:   Tue Aug 20 17:33:56 2024 +0400

    [OpenVINO] Updated documentation (#7687)

[33mcommit 5288c06aa03b100eab4f873452b65da941a1a232[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Tue Aug 20 09:09:33 2024 -0400

    [Kernel] (1/N) Machete - Hopper Optimized Mixed Precision Linear Kernel  (#7174)

[33mcommit b6f99a6ffe4c7471b32932a0d163fe0e7bbead5b[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Tue Aug 20 15:56:50 2024 +0800

    [Core] Refactor executor classes for easier inheritance (#7673)
    
    [Core] Refactor executor classes to make it easier to inherit GPUExecutor (#7673)

[33mcommit ad28a74beb8497a6961cfb39c63d6070712f1ef7[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 20 00:35:09 2024 -0700

    [misc][cuda] add warning for pynvml user (#7675)

[33mcommit e6d811dd13a0ad81a1efc67c97d8812e823db5a7[m
Author: jianyizh <jianyi.zhang@intel.com>
Date:   Tue Aug 20 15:26:09 2024 +0800

    [XPU] fallback to native implementation for xpu custom op (#7670)

[33mcommit c4be16e1a70d50b781038990087a717fd8834d4a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Aug 19 23:22:49 2024 -0700

    [misc] add nvidia related library in collect env (#7674)

[33mcommit 3d8a5f063d8a96ccfb8fc14d1d43b93cea0411a0[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Mon Aug 19 22:43:54 2024 -0700

    [CI] Organizing performance benchmark files (#7616)

[33mcommit f4fc7337bfaf5f10b8da4ba547e4009179348a26[m
Author: Zijian Hu <zijian.hu@scale.com>
Date:   Mon Aug 19 20:00:04 2024 -0700

    [Bugfix] support `tie_word_embeddings` for all models (#5724)

[33mcommit 0df7ec0b2d890799ca71e2f862fdff5fcc52cdc0[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Aug 19 19:55:04 2024 -0700

    [ci] Install Buildkite test suite analysis (#7667)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 312f7612328fb8db9fb2dd9f94f2ea021c035357[m
Author: Abhinav Goyal <agabohar@gmail.com>
Date:   Tue Aug 20 06:28:14 2024 +0530

    [Speculative Decoding] Fixing hidden states handling in batch expansion (#7508)

[33mcommit e54ebc2f8f9d78f3113fb2b531058977e6031609[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Aug 19 17:50:59 2024 -0700

    [doc] fix doc build error caused by msgspec (#7659)

[33mcommit 67e02fa8a405e1e1df0eb7428ad45eed20b0934b[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Mon Aug 19 18:43:09 2024 -0600

    [Bugfix] use StoreBoolean instead of type=bool for --disable-logprobs-during-spec-decoding (#7665)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 43735bf5e19eaf243b6edaa5af4c7561a14fc2f6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Aug 19 15:55:04 2024 -0700

    [TPU] Remove redundant input tensor cloning (#7660)

[33mcommit da115230fdde197abce793288b80da5223902861[m
Author: Andrew Song <40076917+a-ys@users.noreply.github.com>
Date:   Mon Aug 19 15:11:58 2024 -0700

    [Bugfix] Don't disable existing loggers (#7664)

[33mcommit 7601cb044ddfe920055f82ae9503729d4dde7259[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue Aug 20 05:30:14 2024 +0800

    [Core] Support tensor parallelism for GGUF quantization (#7520)

[33mcommit 47b65a550866c7ffbd076ecb74106714838ce7da[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Mon Aug 19 13:52:13 2024 -0700

    [core] Multi Step Scheduling (#7000)
    
    Co-authored-by: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>

[33mcommit dad961ef5ca3893b78224323ec943dce9f52f868[m
Author: Ali Panahi <64020589+c3-ali@users.noreply.github.com>
Date:   Mon Aug 19 13:47:00 2024 -0700

    [Bugfix] fix lora_dtype value type in arg_utils.py - part 2 (#5428)

[33mcommit 3ac50b47d0f718364d05b1bcb93743e15be6a37c[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Mon Aug 19 11:52:07 2024 -0700

    [MISC] Add prefix cache hit rate to metrics (#7606)

[33mcommit df845b2b46c3e30f5bd3e3be286285ed148323fc[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Aug 19 09:29:31 2024 -0700

    [Misc] Remove Gemma RoPE (#7638)

[33mcommit 1a36287b89f337057ebeb5d1bee30567e985b444[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Mon Aug 19 13:00:09 2024 +0800

    [Bugfix] Fix xpu build (#7644)

[33mcommit f710fb5265abf4e299c9e5b8a3391e71339da883[m
Author: Peng Guanwen <pg999w@outlook.com>
Date:   Mon Aug 19 11:24:03 2024 +0800

    [Core] Use flashinfer sampling kernel when available (#7137)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit ff7ec82c4dd6170ea8fedbd4d974c0a670e84c97[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Sun Aug 18 17:57:20 2024 -0700

    [Core] Optimize SPMD architecture with delta + serialization optimization (#7109)

[33mcommit 200a2ffa6bc6564ce5a86d48c13a4caae6201cbc[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Aug 18 17:18:12 2024 -0700

    [Misc] Refactor Llama3 RoPE initialization (#7637)

[33mcommit 40e1360bb6e9b299d604863b3be5ccbe9a3bee48[m
Author: Alex Brooks <alex.brooks@ibm.com>
Date:   Sun Aug 18 17:43:46 2024 -0600

    [CI/Build] Add text-only test for Qwen models  (#7475)
    
    Signed-off-by: Alex-Brooks <Alex.Brooks@ibm.com>

[33mcommit e3b318216d13225221ffbf03cc815648104e37c5[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Aug 18 16:19:48 2024 -0400

    [ Bugfix ] Fix Prometheus Metrics With `zeromq` Frontend (#7279)
    
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit ab7165f2c7ea358df969d68a0fb0ce9bb184a083[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Aug 18 01:15:10 2024 -0700

    [TPU] Optimize RoPE forward_native2 (#7636)

[33mcommit 0c2fa50b84dddd4866313ac37074255d29a94055[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Aug 18 00:18:53 2024 -0700

    [TPU] Use mark_dynamic only for dummy run (#7634)

[33mcommit ce143353c622318a9abf113bebee1cfebc274e0f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Aug 17 14:22:46 2024 -0700

    [TPU] Skip creating empty tensor (#7630)

[33mcommit bbf55c4805efba5f1d7094f5e2888b3ef26c0fd7[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Aug 17 13:30:55 2024 -0700

    [VLM] Refactor `MultiModalConfig` initialization and profiling (#7530)

[33mcommit 1ef13cf92f42a086d14a202a594d7dcae524e640[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Aug 18 03:02:14 2024 +0800

    [Misc]Fix BitAndBytes exception messages (#7626)

[33mcommit 832163b8754efe2c6d74fbecb6a87a4119410db4[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Aug 17 11:26:38 2024 -0700

    [ci][test] allow longer wait time for api server (#7629)

[33mcommit e73f76eec6b5aa69b065923c175610d10ccabd50[m
Author: Besher Alkurdi <42068063+mrbesher@users.noreply.github.com>
Date:   Sat Aug 17 21:11:09 2024 +0300

    [Model] Pipeline parallel support for JAIS (#7603)

[33mcommit d95cc0a55c55c914ad9fdb6a3a7ece282c334347[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 16 23:01:35 2024 -0700

    [core][misc] update libcudart finding (#7620)
    
    Co-authored-by: cjackal <44624812+cjackal@users.noreply.github.com>

[33mcommit 5bf45db7df3dc4ca634d41876f4b1f82b7e53c4c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 16 23:00:59 2024 -0700

    [ci][test] fix engine/logger test (#7621)

[33mcommit eed020f6730813b7d1d97e8d81333a85b70b2af0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 16 21:15:13 2024 -0700

    [misc] use nvml to get consistent device name (#7582)

[33mcommit 7c0b7ea2141246d2904fc8d8cf501411e81bb429[m
Author: Xander Johnson <xander@metasyn.pw>
Date:   Fri Aug 16 20:56:01 2024 -0700

    [Bugfix] add >= 1.0 constraint for openai dependency (#7612)

[33mcommit 4706eb628e0830f8ab4db5e9f5ede3bc4eee2b76[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri Aug 16 20:49:30 2024 -0700

    [aDAG] Unflake aDAG + PP tests (#7600)

[33mcommit bae888cb8e01b89ad58e3fdaf14f21c109c5fad7[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Fri Aug 16 20:44:05 2024 -0700

    [Bugfix] Clear engine reference in AsyncEngineRPCServer (#7618)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit 6bd19551b0fa8083e6ed1cb35f5375499d855fce[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Fri Aug 16 22:25:32 2024 -0500

    .[Build/CI] Enabling passing AMD tests. (#7610)

[33mcommit e6803499941333e30e7db984cc590f21fc284e7b[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Fri Aug 16 22:05:49 2024 -0400

    [Bugfix] Fix custom_ar support check (#7617)

[33mcommit 44f26a94664584f20458ae0ddf1a826b2d79a13c[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Aug 16 18:56:34 2024 -0400

    [Model] Align nemotron config with final HF state and fix lm-eval-small (#7611)

[33mcommit 37fd47e7803fedd9715abceee8bdb57070fc09f4[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Fri Aug 16 17:00:11 2024 -0400

    [Kernel] fix types used in aqlm and ggml kernels to support dynamo (#7596)

[33mcommit 7759ae958ffb9015cd28137c380ffdcbe7648511[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Fri Aug 16 16:59:49 2024 -0400

    [Kernel][Misc] dynamo support for ScalarType (#7594)

[33mcommit 9f698563564c57adb6b4a1ab99d0bb722d70dd5b[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Fri Aug 16 16:59:38 2024 -0400

    [Kernel] register punica functions as torch ops (#7591)

[33mcommit d4f0f17b025487e78525ba13133a161b20538d41[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Aug 16 16:59:27 2024 -0400

    [Doc] Update quantization supported hardware table (#7595)

[33mcommit b3f4e179350140d415f03e25261edf4b0b152ed4[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Aug 16 16:59:16 2024 -0400

    [Doc] Add docs for llmcompressor INT8 and FP8 checkpoints (#7444)

[33mcommit 93478b63d2c40a88e213125f11833ffb05d45da0[m
Author: Mahesh Keralapura <157427991+sfc-gh-mkeralapura@users.noreply.github.com>
Date:   Fri Aug 16 13:46:01 2024 -0700

    [Core] Fix tracking of model forward time in case of PP>1 (#7440)
    
    [Core] Fix tracking of model forward time to the span traces in case of PP>1 (#7440)

[33mcommit f366f6339b1dbd9176470489b99dae4fb454f5ce[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Fri Aug 16 11:41:56 2024 -0700

    [spec decode] [4/N] Move update_flash_attn_metadata to attn backend (#7571)
    
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 855866caa9c5f5356499d97d00745cae22d0cd39[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Aug 16 14:37:01 2024 -0400

    [Kernel] Add tuned triton configs for ExpertsInt8 (#7601)

[33mcommit 7fc23be81c55ca0570f551871a3adc994aaefc05[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Fri Aug 16 20:06:51 2024 +0300

    [Kernel] W8A16 Int8 inside FusedMoE  (#7415)

[33mcommit e837b624f25efe5d05412e95e18ed07ced880272[m
Author: Charlie Fu <Charlie.Fu@amd.com>
Date:   Fri Aug 16 12:06:30 2024 -0500

    [Feature][Hardware][Amd] Add fp8 Linear Layer for Rocm (#7210)

[33mcommit ec724a725eeeb6ad3b1d69815c9fb41e7f74997c[m
Author: fzyzcjy <5236035+fzyzcjy@users.noreply.github.com>
Date:   Sat Aug 17 00:17:50 2024 +0800

    support tqdm in notebooks (#7510)

[33mcommit 0e39a33c6d6dd25687db83c410b6210201880bdd[m
Author: Gordon Wong <gongdao123@gmail.com>
Date:   Sat Aug 17 00:05:18 2024 +0800

    [Bugfix][Hardware][AMD][Frontend] add quantization param to embedding checking method (#7513)

[33mcommit 6fc5b0f249396c6fb3a63b3175cd9892e7fedd9b[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Fri Aug 16 08:08:45 2024 -0700

    [CI] Fix crashes of performance benchmark  (#7500)

[33mcommit 9587b050fba00c3c35da05d3512bf7e351914a50[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Aug 15 22:48:07 2024 -0700

    [Core] Use uvloop with zmq-decoupled front-end (#7570)

[33mcommit 54bd9a03c4b2da0fd0b0e17b0552bbb0d517a081[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Aug 15 22:38:56 2024 -0700

    register custom op for flash attn and use from torch.ops (#7536)

[33mcommit 50b8d08dbd4493327e344bc627a0613947deba8f[m
Author: jon-chuang <9093549+jon-chuang@users.noreply.github.com>
Date:   Thu Aug 15 21:24:04 2024 -0700

    [Misc/Testing] Use `torch.testing.assert_close` (#7324)

[33mcommit e165528778d1bfeb8e9bd8a33d6cd64fb6c78e4e[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Aug 16 00:16:20 2024 -0400

    [CI] Move quantization cpu offload tests out of fastcheck (#7574)

[33mcommit 3b19e39dc59975c4240082a6b45f7c2a123b7164[m
Author: nunjunj <106306814+nunjunj@users.noreply.github.com>
Date:   Fri Aug 16 09:41:34 2024 +0700

    Chat method for offline llm (#5049)
    
    Co-authored-by: nunjunj <ray@g-3ff9f30f2ed650001.c.vllm-405802.internal>
    Co-authored-by: nunjunj <ray@g-1df6075697c3f0001.c.vllm-405802.internal>
    Co-authored-by: nunjunj <ray@g-c5a2c23abc49e0001.c.vllm-405802.internal>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit 4cd7d47fed0e4ab7c1b2149394ceb67f6635b1e8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Aug 15 19:39:04 2024 -0700

    [ci/test] rearrange tests and make adag test soft fail (#7572)

[33mcommit f878c8feb06b33fa68dd1bdd687637b326eccfde[m
Author: Grant Pinkert <gnpinkert@users.noreply.github.com>
Date:   Fri Aug 16 12:38:08 2024 +1000

    [Feature]: Add OpenAI server prompt_logprobs support #6508 (#7453)

[33mcommit b67ae00cdbbe1a58ffc8ff170f0c8d79044a684a[m
Author: shangmingc <csmthu@gmail.com>
Date:   Fri Aug 16 10:34:28 2024 +0800

    [Misc] Add quantization config support for speculative model. (#7343)

[33mcommit 9c8e2d11611ca5313710df06f215b41f05dde1b4[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Aug 15 21:26:19 2024 -0400

    [Bugfix][Harmless] Fix float16 dtype for model_is_embedding (#7566)

[33mcommit 21313e09e3f9448817016290da20d0db1adf3664[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Aug 15 16:10:22 2024 -0400

    [Bugfix] Fix default weight loading for scalars (#7534)

[33mcommit f4da5f7b6d296aabd00c2ed068cab4d3605ff80e[m
Author: PHILO-HE <feilong.he@intel.com>
Date:   Fri Aug 16 01:03:01 2024 +0800

    [Misc] Update dockerfile for CPU to cover protobuf installation (#7182)

[33mcommit 9c1f78d5d66c3630ad5f5e149eca6f84b2d254a2[m
Author: omrishiv <327609+omrishiv@users.noreply.github.com>
Date:   Thu Aug 15 09:44:14 2024 -0700

    [Bugfix] update neuron for version > 0.5.0 (#7175)
    
    Signed-off-by: omrishiv <327609+omrishiv@users.noreply.github.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit fc93e5614374688bddc432279244ba7fbf8169c2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Aug 15 00:02:29 2024 -0700

    [Bugfix][TPU] Correct env variable for XLA cache path (#7544)

[33mcommit 22b39e11f2eca7dd70bcef3760cd5da149412d00[m
Author: Kameshwara Pavan Kumar Mantha <25398886+pavanjava@users.noreply.github.com>
Date:   Thu Aug 15 04:08:37 2024 +0530

    llama_index serving integration documentation (#6973)
    
    Co-authored-by: pavanmantha <pavan.mantha@thevaslabs.io>

[33mcommit f55a9aea4573ed5282ee3221182993495ddc3709[m
Author: Kyle Sayers <kylesayrs@gmail.com>
Date:   Wed Aug 14 18:07:37 2024 -0400

    [Misc] Revert `compressed-tensors` code reuse (#7521)

[33mcommit 951fdd66d36ffed75a55e9bfa9f2221dce4fbcdc[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Aug 14 14:47:51 2024 -0700

    [TPU] Set per-rank XLA cache (#7533)

[33mcommit 2ecf7b175703de020943b33532baaf6a31f69d3a[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Wed Aug 14 12:32:45 2024 -0700

    [core] [3/N] multi-step args and sequence.py (#7452)

[33mcommit 3f674a49b5033a6ed778ab960e86e03cfa64aa1f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Aug 15 01:55:42 2024 +0800

    [VLM][Core] Support profiling with multiple multi-modal inputs per prompt (#7126)

[33mcommit 70b746efcf9a3ddcbe5afd34d8efa23671c1569e[m
Author: Wallas Henrique <wallashss@users.noreply.github.com>
Date:   Wed Aug 14 13:44:27 2024 -0300

    [Misc] Deprecation Warning when setting --engine-use-ray (#7424)
    
    Signed-off-by: Wallas Santos <wallashss@ibm.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 67d115db08a329bc37f84e37cbc8f7d24c195709[m
Author: jack <QwertyJack@users.noreply.github.com>
Date:   Thu Aug 15 00:15:19 2024 +0800

    [Bugfix][Frontend] Disable embedding API for chat models (#7504)
    
    Co-authored-by: jack <jack@alex>

[33mcommit d3d9cb6e4b8185b4e56e1dda92c6fc31cdc05de1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Aug 14 01:01:43 2024 -0700

    [ci] fix model tests (#7507)

[33mcommit c134a4640214e760a8480b6d80b2038bf9ba3a8e[m
Author: Chang Su <chang.s.su@oracle.com>
Date:   Tue Aug 13 22:31:44 2024 -0700

    Fix empty output when temp is too low (#2937)
    
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit 199adbb7cfb7e8185c9418de56db006f8cf1c294[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 13 21:52:58 2024 -0700

    [doc] update test script to include cudagraph (#7501)

[33mcommit dd164d72f31f95e19d84756a644811d0ca2c7c59[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Aug 14 11:37:30 2024 +0800

    [Bugfix][Docs] Update list of mock imports (#7493)

[33mcommit ea49e6a3c82bdd48f377efc79bfe44f37f13b3ad[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 13 19:27:46 2024 -0700

    [misc][ci] fix cpu test with plugins (#7489)

[33mcommit 97992802f3e6f9f317313f8afc15e2a37fc2722b[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Wed Aug 14 08:27:29 2024 +0800

    [CI/Build]Reduce the time consumption for LoRA tests (#7396)

[33mcommit 59edd0f1340a85d585a477fc687a16cfc5cf5276[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Aug 13 17:12:58 2024 -0700

    [Bugfix][CI] Import ray under guard (#7486)

[33mcommit a08df8322e2e5f27cb696bc2c0d8cdabe185878b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Aug 13 16:31:20 2024 -0700

    [TPU] Support multi-host inference (#7457)

[33mcommit 16422ea76f213f5b1035513b441245b19ca5bdce[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 13 16:24:17 2024 -0700

    [misc][plugin] add plugin system implementation (#7426)

[33mcommit 373538f973ac4ea93a4b675655b893bf495ac050[m
Author: Kyle Sayers <kylesayrs@gmail.com>
Date:   Tue Aug 13 19:05:15 2024 -0400

    [Misc] `compressed-tensors` code reuse (#7277)

[33mcommit 33e5d7e6b6d672eb7ecef038bbffc8b366f31220[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 13 15:40:17 2024 -0700

    [frontend] spawn engine process from api server process (#7484)

[33mcommit c5c77682648490a913d476c5b86e1c53a8e6755c[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Aug 13 14:28:36 2024 -0700

    Announce NVIDIA Meetup (#7483)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit b1e5afc3e7843e993d3f7d40e57f0fecb9d137b5[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Aug 13 17:08:20 2024 -0400

    [Misc] Update `awq` and `awq_marlin` to use `vLLMParameters` (#7422)

[33mcommit d3bdfd3ab9bac6bf1a88f717869bf9c06683d4b4[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Aug 13 14:57:45 2024 -0400

    [Misc] Update Fused MoE weight loading (#7334)

[33mcommit fb377d7e74228d477e270d8a8e53410db29ed755[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Aug 13 14:30:11 2024 -0400

    [Misc] Update `gptq_marlin` to use new vLLMParameters (#7281)

[33mcommit 181abbc27d812803d2ee945ea7407c64bca6c9f4[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Aug 13 14:28:14 2024 -0400

    [Misc] Update LM Eval Tolerance (#7473)

[33mcommit 00c3d68e45bad901989c1afe3c223225dc9a5d6d[m
Author: Peter Salas <peter.salas@gmail.com>
Date:   Tue Aug 13 10:39:33 2024 -0700

    [Frontend][Core] Add plumbing to support audio language models (#7446)

[33mcommit e20233d361b4e6a7cb8e37c6d7f85e9900527802[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Aug 13 01:37:08 2024 -0700

    Revert "[Doc] Update supported_hardware.rst (#7276)" (#7467)

[33mcommit d6e634f3d78649002460758f3964e4df0d39a546[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Aug 13 00:30:30 2024 -0700

    [TPU] Suppress import custom_ops warning (#7458)

[33mcommit 4d2dc5072b8cfaff0c02e504c79a72ee95d839a1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Aug 13 00:16:42 2024 -0700

    [hardware] unify usage of is_tpu to current_platform.is_tpu() (#7102)

[33mcommit 7025b11d949b4efeb2584690c35f919c77027368[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Aug 13 13:33:41 2024 +0800

    [Bugfix] Fix weight loading for Chameleon when TP>1 (#7410)

[33mcommit 5469146bcc7e24a74edd09360e22096c21d01cf5[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Aug 12 21:19:51 2024 -0700

    [ci] Remove fast check cancel workflow (#7455)

[33mcommit 97a6be95ba279c2bc9cdd8890506ec94e63b268d[m
Author: Andrew Wang <aw632@cornell.edu>
Date:   Mon Aug 12 19:29:34 2024 -0700

    [Misc] improve logits processors logging message (#7435)

[33mcommit 9ba85bc1527928f30ec56961520d7e07ee385167[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Aug 13 09:20:20 2024 +0800

    [mypy] Misc. typing improvements (#7417)

[33mcommit 198d6a289849bc64a17555e0cbb15a197a1229cb[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Mon Aug 12 17:57:16 2024 -0700

    [Core] Shut down aDAG workers with clean async llm engine exit (#7224)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit 774cd1d3bf7890c6abae6c7ace798c4a376b2b20[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Tue Aug 13 01:29:20 2024 +0200

    [CI/Build] bump minimum cmake version (#6999)

[33mcommit 91294d56e1b9e3e7e5cd8fa2ec4d45b126941598[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Mon Aug 12 23:07:20 2024 +0000

    [Bugfix] Handle PackageNotFoundError when checking for xpu version (#7398)

[33mcommit a046f86397c06af306d964ff40d0670bdc9c00a2[m
Author: jon-chuang <9093549+jon-chuang@users.noreply.github.com>
Date:   Mon Aug 12 15:47:41 2024 -0700

    [Core/Bugfix] Add FP8 K/V Scale and dtype conversion for prefix/prefill Triton Kernel (#7208)
    
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 4ddc4743d7ae93fca090d8485b31321abe3743e7[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Aug 13 05:14:14 2024 +0800

    [Core] Consolidate `GB` constant and enable float GB arguments (#7416)

[33mcommit 6aa33cb2ddd769e764a3312627cab5bffaa383cc[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Mon Aug 12 14:40:13 2024 -0400

    [Misc] Use scalar type to dispatch to different `gptq_marlin` kernels (#7323)

[33mcommit 1137f343aaccaa8d9dff92b3e70b432e93c9037a[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Aug 12 10:59:14 2024 -0700

    [ci] Cancel fastcheck when PR is ready (#7433)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 9b3e2edd30bda2926f38ec114ff82192e8993857[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Aug 12 10:56:52 2024 -0700

    [ci] Cancel fastcheck run when PR is marked ready (#7427)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 65950e8f587cf7e3b7307711103f275be2267e56[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Aug 12 10:18:03 2024 -0700

    [ci] Entrypoints run upon changes in vllm/ (#7423)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit cfba4def5d422dfbafbc21b8f695bdcb2295aa19[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Aug 12 09:58:28 2024 -0700

    [Bugfix] Fix logit soft cap in flash-attn backend (#7425)

[33mcommit d2bc4510a42c3a1f00a68c4387d28fb1991f7dcb[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Mon Aug 12 18:53:35 2024 +0200

    [CI/Build] bump Dockerfile.neuron image base, use public ECR (#6832)

[33mcommit 24154f8618aa5da695b18cbbd71704f59803ec6b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Aug 12 20:58:34 2024 +0800

    [Frontend] Disallow passing `model` as both argument and option (#7347)

[33mcommit e6e42e4b1759b8703bf6cb80aefa9c0ec35044f6[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Aug 12 01:16:06 2024 -0700

    [Core][VLM] Support image embeddings as input (#6613)

[33mcommit ec2affa8ae2664db88df2ff0248219e355d6629a[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Mon Aug 12 00:59:17 2024 -0700

    [Kernel] Flashinfer correctness fix for v0.1.3 (#7319)

[33mcommit 86ab567bae0698425095e28cce67e9a31a261b72[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Aug 11 19:41:52 2024 -0700

    [CI/Build] Minor refactoring for vLLM assets (#7407)

[33mcommit f020a6297e7539fdc5688fad366309fed5c0456a[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Aug 11 17:13:37 2024 -0700

    [Docs] Update readme (#7316)

[33mcommit 6c8e595710fb3fdcf868bf8bfa5863399b287b43[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Aug 11 15:40:48 2024 -0700

    [misc] add commit id in collect env (#7405)

[33mcommit 02b1988b9f2081e29189804669fc9c4c5257c0e0[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Mon Aug 12 00:38:17 2024 +0300

    [Doc] building vLLM with VLLM_TARGET_DEVICE=empty (#7403)

[33mcommit 386087970ac220ad675bd1ab7c0e4abb309d4e8a[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Sun Aug 11 23:09:44 2024 +0300

    [CI/Build] build on empty device for better dev experience (#4773)

[33mcommit c08e2b30862df5427843de76d8a619ea566600c1[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Sun Aug 11 08:50:08 2024 -0700

    [core] [2/N] refactor worker_base input preparation for multi-step (#7387)

[33mcommit 4fb7b52a2c0197699d74153a26bb8157ce7ab2c3[m
Author: Noam Gat <noamgat@gmail.com>
Date:   Sun Aug 11 15:11:50 2024 +0300

    Updating LM Format Enforcer version to v0.10.6 (#7189)

[33mcommit 90bab18f24dce1967282fbb1ebcd2c9aecc67d30[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Aug 10 18:12:22 2024 -0700

    [TPU] Use mark_dynamic to reduce compilation time (#7340)

[33mcommit 4c5d8e8ea91aa19415aa479d81e818913d51414c[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sun Aug 11 00:19:33 2024 +0800

    [Bugfix] Fix phi3v batch inference when images have different aspect ratio (#7392)

[33mcommit baa240252ed8d44ae51455e24ebe644220d52116[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Fri Aug 9 16:48:49 2024 -0700

    [Core] Fix edge case in chunked prefill + block manager v2 (#7380)

[33mcommit 999ef0b917aa00166e10bc4252de0463604265b3[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Aug 9 15:52:29 2024 -0700

    [Misc] Add numpy implementation of `compute_slot_mapping` (#7377)

[33mcommit 5c6c54d67a4d7d08f1db8bcc80612d44595d1b4f[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Fri Aug 9 17:23:46 2024 -0400

    [Bugfix] Fix `PerTensorScaleParameter` weight loading for fused models (#7376)

[33mcommit 933790c209fe73398a542d9fb31a138103ee3ccb[m
Author: Mahesh Keralapura <157427991+sfc-gh-mkeralapura@users.noreply.github.com>
Date:   Fri Aug 9 13:55:13 2024 -0700

    [Core] Add span metrics for model_forward, scheduler and sampler time (#7089)

[33mcommit 70d268a39947a8ea950f871f9345aad21f09715e[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Aug 9 10:00:00 2024 -0700

    [Bugfix] Fix ITL recording in serving benchmark (#7372)

[33mcommit 249b88228d1d371a5830c3394be010d51c7e5cbf[m
Author: Pooya Davoodi <pooyadavoodi@gmail.com>
Date:   Fri Aug 9 09:48:21 2024 -0700

    [Frontend] Support embeddings in the run_batch API (#7132)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 74af2bbd901d82c6bc2583515c4388722d451f07[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Fri Aug 9 12:35:49 2024 -0400

    [Bugfix] Fix reinit procedure in ModelInputForGPUBuilder (#7360)

[33mcommit fc7b8d1eefcbe837a56b7c080509417fe5167e6c[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Fri Aug 9 11:49:36 2024 -0400

    [Performance] e2e overheads reduction: Small followup diff (#7364)

[33mcommit 67abdbb42fdbb59c274130368981c0d0ac3539e3[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Aug 9 22:51:04 2024 +0800

    [VLM][Doc] Add `stop_token_ids` to InternVL example (#7354)

[33mcommit 07ab160741a486bbef23efbf26aaf2ea8a785ae1[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Fri Aug 9 17:07:06 2024 +0300

    [Model][Jamba] Mamba cache single buffer  (#6739)
    
    Co-authored-by: Mor Zusman <morz@ai21.com>

[33mcommit b4e9528f9569d6eb8c29624771a4058fe794cb5a[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Fri Aug 9 00:06:36 2024 -0700

    [Core] Streamline stream termination in `AsyncLLMEngine` (#7336)

[33mcommit 57b7be0e1c4e594c58a78297ab65fbb3ec206958[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Thu Aug 8 22:42:45 2024 -0700

    [Speculative decoding] [Multi-Step] decouple should_modify_greedy_probs_inplace (#6971)

[33mcommit 99b4cf5f23457b8c21e7e1b4d5d4384de867b521[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Thu Aug 8 23:08:46 2024 -0600

    [Bugfix] Fix speculative decoding with MLPSpeculator with padded vocabulary (#7218)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit e02ac5561748306186aaeaad6dad4c89484a2b45[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Fri Aug 9 00:34:28 2024 -0400

    [Performance] Optimize e2e overheads: Reduce python allocations (#7162)

[33mcommit 73388c07a42233a1010595edaab73a9e7ab8d9a4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Aug 8 20:24:58 2024 -0700

    [TPU] Fix dockerfile.tpu (#7331)

[33mcommit 7eb4a51c5f34a52427d170d0e654e0a346c6d69c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Aug 9 10:39:41 2024 +0800

    [Core] Support serving encoder/decoder models (#7258)

[33mcommit 0fa14907da70f3cbf9eb97d68d760b181a9a25a7[m
Author: Siyuan Liu <lsiyuan@google.com>
Date:   Thu Aug 8 18:35:49 2024 -0700

    [TPU] Add Load-time W8A16 quantization for TPU Backend (#7005)

[33mcommit 5923532e15b12832febe91ef5e9a4cef2786cefc[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Aug 8 13:59:57 2024 -0700

    Add Skywork AI as Sponsor (#7314)

[33mcommit a049b107e207db796817fb83c4536e0625531d54[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Fri Aug 9 04:42:58 2024 +0800

    [Misc] Temporarily resolve the error of BitAndBytes (#7308)

[33mcommit 8334c39f373b787a20eff8b7655363dd764dfe57[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Aug 9 04:42:44 2024 +0800

    [Bugfix] Fix new Llama3.1 GGUF model loading (#7269)

[33mcommit e90457674380f931bb95c0350af4ad83af568d72[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Thu Aug 8 21:24:52 2024 +0200

    [CI/Build] Dockerfile.cpu improvements (#7298)

[33mcommit e14fb22e59a1a9aa745b2a72211973838f6a5993[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Aug 8 14:22:49 2024 -0400

    [Doc] Put collect_env issue output in a <detail> block (#7310)

[33mcommit 782e53ab59308c8cdceba08527574e0e62acc95d[m
Author: Zach Zheng <zach.zheng96@gmail.com>
Date:   Thu Aug 8 10:43:30 2024 -0700

    [Bugfix][fast] Fix the get_num_blocks_touched logic (#6849)

[33mcommit 21b9c49aa37c7ba08590a99b0d4f15f86439c8f9[m
Author: Joe Runde <Joseph.Runde@ibm.com>
Date:   Thu Aug 8 10:47:48 2024 -0600

    [Frontend] Kill the server on engine death (#6594)
    
    Signed-off-by: Joe Runde <joe@joerun.de>
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit 5fb4a3f6785e3612bf1741f6e43a4184a37649c1[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Thu Aug 8 12:16:13 2024 -0400

    [Bugfix][Kernel] Increased atol to fix failing tests (#7305)

[33mcommit 757ac70a64b5a643b68281c0b65f72f847cedbd6[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Aug 8 22:02:41 2024 +0800

    [Model] Rename MiniCPMVQwen2 to MiniCPMV2.6 (#7273)

[33mcommit 6dffa4b0a6120159ef2fe44d695a46817aff65bc[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Thu Aug 8 00:02:27 2024 -0700

    [Bugfix] Fix LoRA with PP (#7292)

[33mcommit 48abee9e5492924a69551d859d66d98874d72d60[m
Author: Cherilyn Buren <88433283+NiuBlibing@users.noreply.github.com>
Date:   Thu Aug 8 14:17:29 2024 +0800

    [Frontend] remove max_num_batched_tokens limit for lora (#7288)

[33mcommit 746709642c81aa22926765aef67e086a15aef076[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Wed Aug 7 17:06:01 2024 -0700

    [Misc] Fix typos in scheduler.py (#7285)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit e53dfd3eafd9bd5cc217c3796c7d1911a88ec893[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Wed Aug 7 16:26:52 2024 -0700

    [Kernel] Fix Flashinfer Correctness (#7284)

[33mcommit 6d94420246f2d88137c04f357502a6a8c38a2e8e[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Aug 7 17:21:50 2024 -0400

    [Doc] Update supported_hardware.rst (#7276)

[33mcommit fc1493a01edf0ae6f50299daae15679e4c08d74c[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Aug 7 13:35:14 2024 -0700

    [FrontEnd] Make `merge_async_iterators` `is_cancelled` arg optional (#7282)

[33mcommit 311f743831f164f83361295b562f6cdb88ad3418[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Wed Aug 7 16:05:37 2024 -0400

    [Bugfix] Fix gptq failure on T4s (#7264)

[33mcommit 469b3bc538bcbdc1d9b7d30c415bdb0361853871[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Aug 7 11:34:25 2024 -0700

    [ci] Make building wheels per commit optional (#7278)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 5223199e03ac3729eb60043a1ef57156c8af1bc9[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Aug 7 14:23:12 2024 -0400

    [Bugfix][FP8] Fix dynamic FP8 Marlin quantization (#7219)

[33mcommit fde47d3bc2d51fa02d1132d541de52924a0b0838[m
Author: Maximilien de Bayser <maxdebayser@gmail.com>
Date:   Wed Aug 7 15:09:36 2024 -0300

    [BugFix] Fix frontend multiprocessing hang (#7217)
    
    Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>

[33mcommit 0e12cd67a8f84047e6d28084bfe94a8278e10218[m
Author: Stas Bekman <stas00@users.noreply.github.com>
Date:   Wed Aug 7 09:58:02 2024 -0700

    [Doc] add online speculative decoding example (#7243)

[33mcommit 80cbe10c59a3354d0fc7c841fdc6422fc64899aa[m
Author: Ilya Lavrenov <ilya.lavrenov@intel.com>
Date:   Wed Aug 7 20:49:10 2024 +0400

    [OpenVINO] migrate to latest dependencies versions (#7251)

[33mcommit b764547616e6ae1517929985400b1dc62cdbc3a3[m
Author: Isotr0py <2037008807@qq.com>
Date:   Thu Aug 8 00:32:07 2024 +0800

    [Bugfix] Fix input processor for InternVL2 model (#7164)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit ab0f5e2823d31c150c01fc30c146b6ea801d6bdd[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Wed Aug 7 12:29:27 2024 -0400

    Fixes typo in function name (#7275)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit 564985729abc267af281de11f737cfb29b5c0abb[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Wed Aug 7 12:24:56 2024 -0400

    [ BugFix ] Move `zmq` frontend to IPC instead of TCP (#7222)

[33mcommit 0f7052bc7e7c3301588705abf7c7fadf3db293a6[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Wed Aug 7 12:17:58 2024 -0400

    [Misc] Refactor linear layer weight loading; introduce `BasevLLMParameter` and `weight_loader_v2` (#5874)

[33mcommit 639159b2a665173bc7a81625887b8e76f85e2e32[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Aug 7 08:54:52 2024 -0700

    [distributed][misc] add specialized method for cuda platform (#7249)

[33mcommit 66d617e3437e62a6650ffcb85b3190669d37a468[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Aug 7 17:12:05 2024 +0800

    [Frontend] Gracefully handle missing chat template and fix CI failure (#7238)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 7b261092de3b008f7a2c218e338f4f8a025c93ee[m
Author: Atilla Akku≈ü <atiakkus10@gmail.com>
Date:   Wed Aug 7 10:32:16 2024 +0300

    [BUGFIX]: top_k is expected to be an integer. (#7227)

[33mcommit 2385c8f374dd2c9f1a42fdbb05eebfa78137474c[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Aug 6 23:43:03 2024 -0700

    [Doc] Mock new dependencies for documentation (#7245)

[33mcommit 9a3f49ae07f9627db02b2ee377accb76b65d1d1e[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Aug 6 22:21:41 2024 -0700

    [BugFix] Overhaul async request cancellation (#7111)

[33mcommit f9a56006497999a0ab8e32289f4fddabf2ed69bd[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Aug 6 21:34:26 2024 -0400

    [Bugfix] Fix GPTQ and GPTQ Marlin CPU Offloading (#7225)

[33mcommit fd95e026e0f9f50bacf1a63ef419df8bacfc99c0[m
Author: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
Date:   Tue Aug 6 16:51:47 2024 -0400

    [Core] Subclass ModelRunner to support cross-attention & encoder sequences (towards eventual encoder/decoder model support) (#4942)
    
    Co-authored-by: Andrew Feldman <afeld2012@gmail.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 660470e5a36b8e52083615ad7c85e9b4fd4c72ce[m
Author: xiaobochen123 <35516720+xiaobochen123@users.noreply.github.com>
Date:   Wed Aug 7 03:34:25 2024 +0800

    [Core] Optimize evictor-v2 performance (#7193)

[33mcommit 8d59dbb00044a588cab96bcdc028006ed922eb06[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Tue Aug 6 14:17:08 2024 -0400

    [Kernel] Add per-tensor and per-token AZP epilogues (#5941)
    
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>

[33mcommit 5c60c8c423197bcf20fdc5217d79b78532033f04[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Tue Aug 6 10:40:32 2024 -0700

    [SpecDecode] [Minor] Fix spec decode sampler tests (#7183)

[33mcommit 00afc7859072bdcaba30611c6563f2f7ac7104a3[m
Author: Katarzyna Papis <katarzyna.papis@intel.com>
Date:   Tue Aug 6 19:08:35 2024 +0200

    [Bugfix] add gguf dependency (#7198)
    
    Co-authored-by: katarzyna.papis <kpapis@kpapis-u20.sclab.intel.com>

[33mcommit 541c1852d37b9502fbc06253def70e901ca0c352[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Tue Aug 6 12:26:26 2024 -0400

    [ BugFix ] Fix ZMQ when `VLLM_PORT` is set (#7205)

[33mcommit a3bbbfa1d8c2f30581d37c6f30429d648bbbf87c[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Aug 6 11:16:53 2024 -0400

    [BugFix] Fix DeepSeek remote code (#7178)

[33mcommit 1f26efbb3a5e6dad0b98421dd697167c42a50629[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Aug 6 16:55:31 2024 +0800

    [Model] Support SigLIP encoder and alternative decoders for LLaVA models (#7153)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit 9118217f58c39040aa935b7c85250c7364ffa72d[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Tue Aug 6 09:57:25 2024 +0800

    [LoRA] Relax LoRA condition (#7146)

[33mcommit e3c664bfcb14a41e43ddb6078ed1464ae9b7852f[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Aug 5 17:39:22 2024 -0700

    [Build] Add initial conditional testing spec (#6841)

[33mcommit 360bd67cf0ea4a79a59c1aae736cc495a5a63ec5[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue Aug 6 07:54:23 2024 +0800

    [Core] Support loading GGUF model (#5191)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit ef527be06c4064f3a2753a3b2c7ede862fe459e8[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Mon Aug 5 16:41:27 2024 -0700

    [MISC] Use non-blocking transfer in prepare_input (#7172)

[33mcommit 89b8db6bb2ce2948073c21231f103c76456844da[m
Author: Jacob Schein <scheinjacob@gmail.com>
Date:   Mon Aug 5 16:35:47 2024 -0700

    [Bugfix] Specify device when loading LoRA and embedding tensors (#7129)
    
    Co-authored-by: Jacob Schein <jacobschein@Jacobs-MacBook-Pro-2.local>

[33mcommit 789937af2edb6c1ff847c3cbf0c773fb06602a5f[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Tue Aug 6 01:29:43 2024 +0200

    [Doc] [SpecDecode] Update MLPSpeculator documentation (#7100)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit dfb1a15dcb4c24bf7ff0ba7ddfc5d623ad519d7d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Aug 5 15:59:22 2024 -0700

    [ci][frontend] deduplicate tests (#7101)

[33mcommit 4db5176d9758b720b05460c50ace3c01026eb158[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Aug 5 14:39:48 2024 -0700

    bump version to v0.5.4 (#7139)

[33mcommit 4cf1dc39be80d81ddda9e7e55f4742a6bd57920c[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Aug 5 17:22:57 2024 -0400

    [Bugfix][CI/Build] Fix CUTLASS FetchContent (#7171)

[33mcommit 6e4852ce28ad57dc440067778464ac61e0621899[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Aug 5 16:00:01 2024 -0400

    [CI/Build] Suppress divide-by-zero and missing return statement warnings (#7001)

[33mcommit 8571ac4672c8b599338cb95e23dfd624016aab36[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Aug 5 15:13:43 2024 -0400

    [Kernel] Update CUTLASS to 3.5.1 (#7085)

[33mcommit 997cf78308d292b03c8a1e68d8d1a1f599551937[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Mon Aug 5 11:10:16 2024 -0700

    [Misc] Fix typo in GroupCoordinator.recv() (#7167)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit 57f560aa23077ed9def5952ab81a65bc080ae234[m
Author: Aditya Paliwal <aditya@x.ai>
Date:   Mon Aug 5 09:26:14 2024 -0700

    [BugFix] Use args.trust_remote_code (#7121)

[33mcommit 003f8ee1287f90a7e8aa9b9e7d6246ac74ebefbe[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Aug 5 08:41:03 2024 -0700

    [BugFix] Use IP4 localhost form for zmq bind (#7163)

[33mcommit e9630458c7b11732e147c120817c53420280d471[m
Author: Bongwon Jang <152451401+bong-furiosa@users.noreply.github.com>
Date:   Tue Aug 6 00:05:05 2024 +0900

    [SpecDecode] Support FlashInfer in DraftModelRunner (#6926)

[33mcommit 82a1b1a82b1fbb454c82a9ef95730b929c9b270c[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Mon Aug 5 01:46:44 2024 -0700

    [Speculative decoding] Add periodic log with time spent in proposal/scoring/verification (#6963)

[33mcommit c0d8f1636c58f5464e512eaabfed5aa29f2c5b7d[m
Author: Jungho Christopher Cho <wjdgh6655@gmail.com>
Date:   Mon Aug 5 15:22:12 2024 +0900

    [Model] SiglipVisionModel ported from transformers (#6942)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit cc08fc7225616aeb6709a2e75e5ac47ace124985[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Aug 5 11:40:51 2024 +0800

    [Frontend] Reapply "Factor out code for running uvicorn" (#7095)

[33mcommit 7b86e7c9cd6541abdf5d083b0a8a98ee667a91d1[m
Author: Alphi <52458637+HwwwwwwwH@users.noreply.github.com>
Date:   Mon Aug 5 09:23:17 2024 +0800

    [Model] Add multi-image support for minicpmv (#7122)
    
    Co-authored-by: hezhihui <hzh7269@modelbest.cn>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit f80ab3521ca2aa74e121e26a27b87da7a1065939[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Mon Aug 5 06:37:08 2024 +0800

    Clean up remaining Punica C information (#7027)

[33mcommit 16a1cc9bb2b4bba82d78f329e5a89b44a5523ac8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Aug 4 11:31:51 2024 -0700

    [misc][distributed] improve libcudart.so finding (#7127)

[33mcommit b1c9aa3daa7dcd981f0f77231b46883624b72dd0[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Sun Aug 4 16:13:18 2024 +0200

    [Bugfix] [SpecDecode] Default speculative_draft_tensor_parallel_size to 1 when using MLPSpeculator (#7105)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 179a6a36f2a585df49ce9c26701b1b9d894bd00e[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sun Aug 4 16:12:41 2024 +0800

    [Model]Refactor MiniCPMV (#7020)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 83c644fe7ecee05d3ebe5057acb6e008d7e81eb8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Aug 4 00:22:19 2024 -0700

    [core][misc] simply output processing with shortcut code path (#7117)

[33mcommit 9fadc7b7a03f798036d0e8710587870e13bae759[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Aug 3 22:03:46 2024 -0700

    [misc] add zmq in collect env (#7119)

[33mcommit 654bc5ca49bde0969bc95e4b1dbe7fabbb8f631c[m
Author: Yihuan Bu <88394319+kevinbu233@users.noreply.github.com>
Date:   Sat Aug 3 23:12:09 2024 -0400

    Support for guided decoding for offline LLM (#6878)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 825b044863a8e3af82a82a80cd2617486cc829ca[m
Author: Jeff Fialho <jefferson@fialhocoelho.com.br>
Date:   Sat Aug 3 20:01:38 2024 -0300

    [Frontend] Warn if user `max_model_len` is greater than derived `max_model_len` (#7080)
    
    Signed-off-by: Jefferson Fialho <jfialho@ibm.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 44dcb52e39ee6b2c9ef9e6497525e1e183c9d24b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Aug 3 10:44:53 2024 -0700

    [ci][test] finalize fork_new_process_for_each_test (#7114)

[33mcommit 67d745cc68d9ad31bf683a88f00a1aee9782f541[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Fri Aug 2 23:52:44 2024 -0700

    [CI] Temporarily turn off H100 performance benchmark (#7104)

[33mcommit 99d7cabd7b8b789e837a0682982fd7ec94a843b1[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Sat Aug 3 13:40:19 2024 +0800

    [LoRA]  ReplicatedLinear support LoRA (#7081)

[33mcommit fb2c1c86c196aa1531435d0c445fbea4c9dd4aa5[m
Author: Zach Zheng <zach.zheng96@gmail.com>
Date:   Fri Aug 2 22:38:15 2024 -0700

    [Bugfix] Fix block table for seqs that have prefix cache hits (#7018)

[33mcommit 0c25435daa0a399460a676e7c9b604bd23ea2d22[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sat Aug 3 13:36:14 2024 +0800

    [Model] Refactor and decouple weight loading logic for InternVL2 model (#7067)

[33mcommit a0d164567cd2a82d827c81a49a21e3f2c75a522d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 2 22:32:04 2024 -0700

    [ci][distributed] disable ray dag tests (#7099)

[33mcommit 04e55834254bf11770d544bbeebdbdb7731d9bbd[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 2 21:33:53 2024 -0700

    [ci][distributed] merge distributed test commands (#7097)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 8c025fa7030350a81bfeb665c99ad622667bdac0[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Aug 3 12:31:27 2024 +0800

    [Frontend] Factor out chat message parsing (#7055)

[33mcommit 69ea15e5cc823b2bc040921ce516807fb7357dd1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 2 21:05:16 2024 -0700

    [ci][distributed] shorten wait time if server hangs (#7098)

[33mcommit ed812a73fae77bb520b739cfeaad36dbd61e2b03[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Aug 2 21:27:28 2024 -0400

    [ Frontend ] Multiprocessing for OpenAI Server with `zeromq` (#6883)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>
    Co-authored-by: Joe Runde <Joseph.Runde@ibm.com>
    Co-authored-by: Joe Runde <joe@joerun.de>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 708989341ef6361a5981d890a0e2f1b794323458[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 2 16:18:45 2024 -0700

    [misc] add a flag to enable compile (#7092)

[33mcommit 22e718ff1a51930231d87c89d6c43676af59860b[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Fri Aug 2 15:50:00 2024 -0700

    [Misc] Revive to use loopback address for driver IP (#7091)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit 05308891e203329a733bcf29a3452b15b75b5eb4[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Fri Aug 2 13:55:40 2024 -0700

    [Core] Pipeline parallel with Ray ADAG (#6837)
    
    Support pipeline-parallelism with Ray accelerated DAG.
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>

[33mcommit a8d604ca2a2912b3a5352821c53c080383580df1[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Fri Aug 2 16:51:58 2024 -0400

    [Misc] Disambiguate quantized types via a new ScalarType (#6396)

[33mcommit b482b9a5b13ba7d126adabbedb3ba66f48d4d83b[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Aug 2 16:51:22 2024 -0400

    [CI/Build] Add support for Python 3.12 (#7035)

[33mcommit 806949514ab07a2d7218645022c22962696adf46[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 2 10:03:24 2024 -0700

    [ci] set timeout for test_oot_registration.py (#7082)

[33mcommit c16eaac5001d9e2bfb51c9812ec0c2b9e32b8d25[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Fri Aug 2 23:55:58 2024 +0800

    [Hardware][Intel CPU] Update torch 2.4.0 for CPU backend (#6931)

[33mcommit db35186391a2abfc6c91d703527dac20d2488107[m
Author: Peng Guanwen <pg999w@outlook.com>
Date:   Fri Aug 2 15:58:26 2024 +0800

    [Core] Comment out unused code in sampler (#7023)

[33mcommit 660dea1235bfe8987e4e9136ce70269084384b2f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Aug 2 00:14:21 2024 -0700

    [cuda][misc] remove error_on_invalid_device_count_status (#7069)

[33mcommit cf2a1a4d9d8168d2e8e7bef244c1dfec80780405[m
Author: Bongwon Jang <152451401+bong-furiosa@users.noreply.github.com>
Date:   Fri Aug 2 15:28:00 2024 +0900

    Fix tracing.py (#7065)

[33mcommit 252357793dd1fe9d30c34e68e4b8b2143a4c5138[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Aug 1 22:03:12 2024 -0700

    [ci][distributed] try to fix pp test (#7054)

[33mcommit 3bb4b1e4cd3d07c80a208d875b016631d91844f8[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Aug 2 10:49:43 2024 +0800

    [mypy] Speed up mypy checking (#7056)

[33mcommit 954f7305a106058815bd7e47f5b9d585d8764c05[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Thu Aug 1 18:44:16 2024 -0700

    [Kernel] Fix input for flashinfer prefill wrapper. (#7008)

[33mcommit 6ce01f30667bbae33f112152e07a3b66b841078f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Aug 1 18:29:52 2024 -0700

    [Performance] Optimize `get_seqs` (#7051)

[33mcommit 6a11fdfbb8d6701c7ad38648aead23d8cbe6aac5[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Aug 1 16:51:15 2024 -0400

    [CI/Build][Bugfix] Fix CUTLASS header-only line (#7034)

[33mcommit 805a8a75f2f17ee56c0882efcc34d35e1801cbee[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Aug 1 13:14:37 2024 -0700

    [Misc] Support attention logits soft-capping with flash-attn (#7022)

[33mcommit 562e580abc63cd6c1d39bd04d7a007ddefba7575[m
Author: omkar kakarparthi <75638701+okakarpa@users.noreply.github.com>
Date:   Thu Aug 1 15:12:37 2024 -0500

    Update run-amd-test.sh (#7044)

[33mcommit fc912e0886f5eaa584c1a65fad81c6c269f609a0[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Thu Aug 1 12:40:43 2024 -0700

    [Models] Support Qwen model with PP (#6974)
    
    Signed-off-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>

[33mcommit f4fd390f5de585fd94877158bea4e1b2d1920df3[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Aug 1 15:01:07 2024 -0400

    [Bugfix] Lower gemma's unloaded_params exception to warning (#7002)

[33mcommit fb3db616881d7225c4bbe64bb709ea6bcd6157f7[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Aug 1 15:00:51 2024 -0400

    [CI/Build] Remove sparseml requirement from testing (#7037)

[33mcommit 2dd34371a6054966d30971dae89b0c431d7f0f08[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Aug 2 03:00:28 2024 +0800

    [Bugfix] Fix RMSNorm forward in InternViT attention qk_layernorm (#6992)

[33mcommit 7e0861bd0bb25ea5ceaa3a513da4133fb828b5fe[m
Author: Sage Moore <sage@neuralmagic.com>
Date:   Thu Aug 1 11:11:24 2024 -0700

    [CI/Build] Update PyTorch to 2.4.0 (#6951)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit a72a424b3eac43a26d2214c0f2a7f91cc59f2f84[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Thu Aug 1 13:07:37 2024 -0500

    [Build/CI] Fixing Docker Hub quota issue. (#7043)

[33mcommit c8a7e93273ff4338d6f89f8a63ff16426ac240b8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jul 31 23:51:09 2024 -0700

    [core][scheduler] simplify and improve scheduler (#6867)

[33mcommit 3c10591ef2e78fbb6aa341195c4b24c36ae8b84d[m
Author: zifeitong <zifei.tong@parasail.io>
Date:   Wed Jul 31 21:13:34 2024 -0700

    [Bugfix] Set SamplingParams.max_tokens for OpenAI requests if not provided by user (#6954)

[33mcommit 0437492ea97f0650a8b2ca39121be8864625fd70[m
Author: Aurick Qiao <aurickq@users.noreply.github.com>
Date:   Wed Jul 31 20:15:42 2024 -0700

    PP comm optimization: replace send with partial send + allgather (#6695)
    
    Co-authored-by: Aurick Qiao <aurick.qiao@snowflake.com>

[33mcommit 630dd9e0aea166085a4c897e21a98ec752954265[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed Jul 31 20:49:11 2024 -0600

    [Bugfix][Model] Skip loading lm_head weights if using tie_word_embeddings (#6758)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 23993a7997ff927decaca60281871d5fdab11334[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jul 31 18:50:28 2024 -0700

    [Bugfix][TPU] Do not use torch.Generator for TPUs (#6981)

[33mcommit 1d2e7fb73f1205ae03e4ee3bcd3de566733bf582[m
Author: xuyi <xuyi@me.com>
Date:   Thu Aug 1 09:49:51 2024 +0800

    [Model] Pipeline parallel support for Qwen2 (#6924)

[33mcommit 7ecee3432110bae563c8756a66b54e5f08dc777d[m
Author: Jee Jee Li <pandaleefree@gmail.com>
Date:   Thu Aug 1 08:12:24 2024 +0800

    [Kernel][RFC] Refactor the punica kernel based on Triton (#5036)

[33mcommit 7eb0cb4a14ff3de84bf18fad8054d12ea8000c22[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Jul 31 16:34:26 2024 -0700

    Revert "[Frontend] Factor out code for running uvicorn" (#7012)
    
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>

[33mcommit a0dce9383ab7de0015060fb9fedadeb7d8ffdfb9[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jul 31 17:40:44 2024 -0400

    [Misc] Add compressed-tensors to optimized quant list (#7006)

[33mcommit 35e9c12bfaf8f273281af897b7208dfba53f103c[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Wed Jul 31 17:40:32 2024 -0400

    [Kernel] Tuned int8 Cutlass Kernels for SM75 (T4) (#6996)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 93548eb37e952a0af035dc524a3826cdcd78d6cf[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Wed Jul 31 17:40:22 2024 -0400

    [Kernel] Enable FP8 Cutlass for Ada Lovelace (#6950)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 460c1884e3cb781730f85cb5591a85d5864bdac8[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jul 31 15:47:46 2024 -0400

    [Bugfix] Support cpu offloading with fp8 quantization (#6960)

[33mcommit bd700134072d9513902b42f3ef20a7cd8a1c6377[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Jul 31 12:02:17 2024 -0700

    [MISC] Introduce pipeline parallelism partition strategies (#6920)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 2ee8d3ba55f1175162dbc8e70b76674197b127c6[m
Author: Avshalom Manevich <12231371+avshalomman@users.noreply.github.com>
Date:   Wed Jul 31 22:00:24 2024 +0300

    [Model] use FusedMoE layer in Jamba (#6935)

[33mcommit daed30c4a917c870f8fbddf45e3b027710c0842b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jul 31 23:46:17 2024 +0800

    [Bugfix] Fix feature size calculation for LLaVA-NeXT (#6982)

[33mcommit 2f4e108f75c817bf2f323e306db590e13d2863f6[m
Author: Alphi <52458637+HwwwwwwwH@users.noreply.github.com>
Date:   Wed Jul 31 22:39:19 2024 +0800

    [Bugfix] Clean up MiniCPM-V (#6939)
    
    Co-authored-by: hezhihui <hzh7269@modelbest.cn>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 6512937de1d7b4738938e0bb3004be86b6883729[m
Author: HandH1998 <1335248067@qq.com>
Date:   Wed Jul 31 21:55:21 2024 +0800

    Support W4A8 quantization for vllm (#5218)

[33mcommit c0644cf9cef0002485749defcaa02e3fec359d49[m
Author: Fei <dfdfcai4@gmail.com>
Date:   Wed Jul 31 01:16:01 2024 -0700

    [Bugfix] fix logit processor excceed vocab size issue (#6927)

[33mcommit 533d1932d23917f7a29ba04c6be5c8b2676b6969[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jul 31 00:19:28 2024 -0700

    [Bugfix][TPU] Set readonly=True for non-root devices (#6980)

[33mcommit 9f0e69b65350fad1d4a9c71ef58d6ae70eb635e8[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jul 31 10:49:48 2024 +0800

    [CI/Build] Fix mypy errors (#6968)

[33mcommit f230cc2ca6614dd4eecf3af9f12c3ddbcf83036e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jul 31 10:38:45 2024 +0800

    [Bugfix] Fix broadcasting logic for `multi_modal_kwargs` (#6836)

[33mcommit da1f7cc12a12ea4a744d26122e9a13ea4b3f4c7b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jul 31 10:38:03 2024 +0800

    [mypy] Enable following imports for some directories (#6681)

[33mcommit c32ab8be1ada40552e8a7c104a5de4830da2c7df[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Jul 30 17:53:21 2024 -0700

    [Speculative decoding] Add serving benchmark for llama3 70b + speculative decoding (#6964)

[33mcommit fb4f530bf5004a9afef1380cb0a84bfb98a89c63[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Jul 30 16:28:49 2024 -0700

    [CI] [nightly benchmark] Do not re-download sharegpt dataset if exists (#6706)

[33mcommit 79319cedfabbd7772234c238921e48d6549ece49[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Jul 30 16:28:05 2024 -0700

    [Nightly benchmarking suite] Remove pkill python from run benchmark suite (#6965)

[33mcommit 40c27a7cbb496ede63da9d636c07a1f315fd36e1[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Jul 30 14:59:48 2024 -0700

    [Build] Temporarily Disable Kernels and LoRA tests (#6961)

[33mcommit 6ca8031e7130f810ce7248286754a60044f65c73[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 30 14:32:12 2024 -0700

    [core][misc] improve free_finished_seq_groups (#6865)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit d7a299edaa5d23f3d7d5c98b53872a8ced9aad80[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Jul 30 16:37:01 2024 -0400

    [Kernel] Remove scaled_fp8_quant kernel padding footgun (#6842)

[33mcommit 052b6f8ca4041f90a1d6825342a4836befbcf478[m
Author: Sanger Steel <sangersteel@gmail.com>
Date:   Tue Jul 30 14:48:50 2024 -0400

    [Bugfix] Fix tensorizer memory profiling bug during testing (#6881)

[33mcommit 5895b24677ff7771fa414f611a241856e225e6ea[m
Author: Ilya Lavrenov <ilya.lavrenov@intel.com>
Date:   Tue Jul 30 22:33:01 2024 +0400

    [OpenVINO] Updated OpenVINO requirements and build docs (#6948)

[33mcommit cbbc904470668b9420e71595edeef76d673a2d59[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Jul 30 13:50:42 2024 -0400

    [Kernel] Squash a few more warnings (#6914)

[33mcommit 5cf9254a9cfd1611e5c2fcd1b5011b4bdb56947f[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Jul 30 10:40:08 2024 -0700

    [BugFix] Fix use of per-request seed with pipeline parallel (#6698)

[33mcommit f05840368335aa9c8184239d3c8bd986e44692f7[m
Author: fzyzcjy <5236035+fzyzcjy@users.noreply.github.com>
Date:   Wed Jul 31 00:14:03 2024 +0800

    [Doc] Super tiny fix doc typo (#6949)

[33mcommit c66c7f86aca956014d9ec6cc7a3e6001037e4655[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jul 30 02:20:57 2024 -0700

    [Bugfix] Fix PaliGemma MMP (#6930)

[33mcommit 6e063ea35b6fe3b6a9b87aae589725493849a632[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jul 30 02:06:29 2024 -0700

    [TPU] Fix greedy decoding (#6933)

[33mcommit af647fb8b3ea9d910f7d1bc104af8986d048a8e2[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Mon Jul 29 22:24:58 2024 -0400

    [Kernel] Tuned int8 kernels for Ada Lovelace (#6848)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 61a97c32f64641738d2cc623708f28046768224e[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Jul 29 21:26:07 2024 -0400

    [Kernel] Fix marlin divide-by-zero warnings (#6904)

[33mcommit 4fbf4aa128c5f5fee62d520dea9d3dfd10f33cdb[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Jul 29 17:03:45 2024 -0700

    [ci] GHA workflow to remove ready label upon "/notready" comment (#6921)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit aae6d36f7ebec2476f7a29ec72c91d7424bb66de[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Jul 29 20:01:17 2024 -0400

    [Kernel] Remove unused variables in awq/gemm_kernels.cu (#6908)

[33mcommit 9f69d8245a695918cb80c218a83c42e9fd409687[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Jul 29 16:37:27 2024 -0700

    [Frontend] New `allowed_token_ids` decoding request parameter (#6753)

[33mcommit 9a7e2d053405da076ff0975660e82c4bc08a62be[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Mon Jul 29 23:51:27 2024 +0200

    [Bugfix] Allow vllm to still work if triton is not installed. (#6786)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 7f8d612d24c66e9b5f8c0aa6cb562e853e9523a0[m
Author: Earthwalker <48991073+etwk@users.noreply.github.com>
Date:   Tue Jul 30 03:42:21 2024 +0800

    [TPU] Support tensor parallelism in async llm engine (#6891)

[33mcommit 60d1c6e584203b07df5020529d678e69baad84a3[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Jul 29 12:59:02 2024 -0400

    [Kernel] Fix deprecation function warnings squeezellm quant_cuda_kernel (#6901)

[33mcommit db9e5708a98b7209cf4465a0391139cf8fca7674[m
Author: Peng Guanwen <pg999w@outlook.com>
Date:   Tue Jul 30 00:47:31 2024 +0800

    [Core] Reduce unnecessary compute when logprobs=None (#6532)

[33mcommit 766435e660a786933392eb8ef0a873bc38cf0c8b[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Mon Jul 29 11:42:35 2024 -0400

    [Kernel] Tuned FP8 Kernels for Ada Lovelace (#6677)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 7cbd9ec7a9bfd4952ad522355b6bbb8e82b54fc9[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Jul 29 18:16:30 2024 +0800

    [Model] Initialize support for InternVL2 series models (#6514)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 3eeb148f467e3619e8890b1a5ebe86a173f91bc9[m
Author: Elsa Granger <6374697+zeyugao@users.noreply.github.com>
Date:   Sun Jul 28 23:13:49 2024 +0800

    [Misc] Pass cutlass_fp8_supported correctly in fbgemm_fp8 (#6871)

[33mcommit b1366a953498fde9c5e7ab91915367ebc69008b2[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sat Jul 27 18:05:17 2024 -0400

    Add Nemotron to PP_SUPPORTED_MODELS (#6863)

[33mcommit 75acdaa4b616c2e95c55a47d3158ceec9c72c503[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Sat Jul 27 17:52:33 2024 -0400

    [Kernel] Increase precision of GPTQ/AWQ Marlin kernel (#6795)

[33mcommit fad5576c58864a6c2cf528f67e60e03a949b3dac[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Jul 27 10:28:33 2024 -0700

    [TPU] Reduce compilation time & Upgrade PyTorch XLA version  (#6856)

[33mcommit f954d0715c8b68e780aac4a4f3ffd1ab56bebfcd[m
Author: Chenggang Wu <cgwu0530@gmail.com>
Date:   Sat Jul 27 09:24:46 2024 -0700

    [Docs] Add RunLLM chat widget (#6857)

[33mcommit 1ad86acf1789650e2ff27586e36a8159d52755dd[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jul 27 19:53:07 2024 +0800

    [Model] Initial support for BLIP-2 (#5920)
    
    Co-authored-by: ywang96 <ywang@roblox.com>

[33mcommit ecb33a28cb6c10ebf3b1aa139f72e759cacb8c15[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Jul 27 02:54:14 2024 -0700

    [CI/Build][Doc] Update CI and Doc for VLM example changes (#6860)

[33mcommit a57d75821c6177da75fdebf171d528eef5301961[m
Author: Wang Ran (Ê±™ÁÑ∂) <wrran@outlook.com>
Date:   Sat Jul 27 17:07:02 2024 +0800

    [bugfix] make args.stream work (#6831)

[33mcommit 925de97e05dd4709fcd80691cb37da5e582c22e8[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Jul 26 23:24:08 2024 -0700

    [Bugfix] Fix VLM example typo (#6859)

[33mcommit aa46953a20685377fc51dcde172114ddd7ffdc68[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Jul 26 22:44:13 2024 -0700

    [Misc][VLM][Doc] Consolidate offline examples for vision language models (#6858)
    
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit 593e79e7337f7fd9e92b7554dabdff96769dbf15[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Fri Jul 26 23:15:20 2024 -0600

    [Bugfix] torch.set_num_threads() in multiproc_gpu_executor (#6802)
    
    [Bugfix] Use torch.set_num_threads() to configure parallelism in multiproc_gpu_executor (#6802)
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit c53041ae3b8ded4ac4c3fc745be6bc695b9f0c78[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Sat Jul 27 05:47:33 2024 +0100

    [Doc] Add missing mock import to docs `conf.py` (#6834)

[33mcommit 52f07e3dec2b76045208f5cfea5670b85a719cc6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jul 26 20:54:27 2024 -0700

    [Hardware][TPU] Implement tensor parallelism with Ray (#5871)

[33mcommit 14dbd5a7674e5de2862c18adb711d9feecd35063[m
Author: Joe <g-eoj@users.noreply.github.com>
Date:   Fri Jul 26 20:47:50 2024 -0700

    [Model] H2O Danube3-4b (#6451)

[33mcommit ed94e4f427bce8611e198d051dbd3b0097b448e8[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Sat Jul 27 06:45:31 2024 +0300

    [Bugfix][Model] Jamba assertions and no chunked prefill by default for Jamba (#6784)

[33mcommit 3c3012398e4aecde9e40981d79a0576203158d24[m
Author: omrishiv <327609+omrishiv@users.noreply.github.com>
Date:   Fri Jul 26 20:20:16 2024 -0700

    [Doc] add VLLM_TARGET_DEVICE=neuron to documentation for neuron (#6844)
    
    Signed-off-by: omrishiv <327609+omrishiv@users.noreply.github.com>

[33mcommit ced36cd89b9c012eb066ef863b2d1ecf052f3e00[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jul 26 20:16:13 2024 -0700

    [ROCm] Upgrade PyTorch nightly version (#6845)

[33mcommit 969d03226514d99f43cf7d17d1e336231d91751a[m
Author: Sanger Steel <sangersteel@gmail.com>
Date:   Fri Jul 26 23:02:25 2024 -0400

    [Bugfix]: Fix Tensorizer test failures (#6835)

[33mcommit 55712941e57bcfd662db2905811d6e2807b9153f[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Fri Jul 26 22:27:44 2024 -0400

    [Bug Fix] Illegal memory access, FP8 Llama 3.1 405b  (#6852)

[33mcommit 981b0d567355063d5453e382a85970cae083c615[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jul 27 09:58:25 2024 +0800

    [Frontend] Factor out code for running uvicorn (#6828)

[33mcommit d09b94ca588c6de1e627194264357e14460ae2eb[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jul 26 18:45:57 2024 -0700

    [TPU] Support collective communications in XLA devices (#6813)

[33mcommit bb5494676f5f57f1cf7cf72598de5434a2a22865[m
Author: chenqianfzh <51831990+chenqianfzh@users.noreply.github.com>
Date:   Fri Jul 26 18:32:20 2024 -0700

    enforce eager mode with bnb quantization temporarily (#6846)

[33mcommit b5f49ee55beac7bb314fd8880bdb718ed117dacb[m
Author: Gurpreet Singh Dhami <143527450+gurpreet-dhami@users.noreply.github.com>
Date:   Fri Jul 26 20:26:45 2024 -0400

    Update README.md (#6847)

[33mcommit 150a1ffbfd3d0429d30fa5ab841f53903a0a8a62[m
Author: Zhanghao Wu <zhanghao.wu@outlook.com>
Date:   Fri Jul 26 17:39:10 2024 -0400

    [Doc] Update SkyPilot doc for wrong indents and instructions for update service (#4283)

[33mcommit 281977bd6eccade50be461f5a22cc51b74006976[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Jul 26 17:32:44 2024 -0400

    [Doc] Add Nemotron to supported model docs (#6843)

[33mcommit 3bbb4936dc5aa7737750410ab4b4647817dcf9a3[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Sat Jul 27 04:50:10 2024 +0800

    [Hardware] [Intel] Enable Multiprocessing and tensor parallel in CPU backend and update documentation  (#6125)

[33mcommit aa4867791ecd73a5f55b7bad4d9372954e661fe4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jul 26 12:39:49 2024 -0700

    [Misc][TPU] Support TPU in initialize_ray_cluster (#6812)

[33mcommit 71734f1bf263ed4877e928d7d9c4522d12e9c61f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jul 26 12:28:32 2024 -0700

    [Build/CI][ROCm] Minor simplification to Dockerfile.rocm (#6811)

[33mcommit 50704f52c4643777fb0e5dc99f6c048dd9f54f2d[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Jul 26 14:41:04 2024 -0400

    [Bugfix][Kernel] Promote another index to int64_t (#6838)

[33mcommit 07278c37ddd898d842bbddc382e4f67ac08dae35[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Jul 26 14:33:42 2024 -0400

    [Model] Support Nemotron models (Nemotron-3, Nemotron-4, Minitron) (#6611)

[33mcommit 85ad7e2d012edd87de9e84e93ed3204c80599695[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jul 25 21:48:05 2024 -0700

    [doc][debugging] add known issues for hangs (#6816)

[33mcommit 89a84b0bb7b30706a02836234a94493ea8f780bf[m
Author: Peng Guanwen <pg999w@outlook.com>
Date:   Fri Jul 26 12:31:31 2024 +0800

    [Core] Use array to speedup padding (#6779)

[33mcommit 084a01fd3544557990f8af8af6fd3c1185bae848[m
Author: Anthony Platanios <e.a.platanios@gmail.com>
Date:   Fri Jul 26 00:25:35 2024 -0400

    [Bugfix] [Easy] Fixed a bug in the multiprocessing GPU executor. (#6770)

[33mcommit 062a1d0fab111723ab768f94bdd48a6adc054007[m
Author: QQSong <ustcsqq@gmail.com>
Date:   Thu Jul 25 19:24:58 2024 -0700

    Fix ReplicatedLinear weight loading (#6793)

[33mcommit 2eb9f4ff262bb39859baebf8d2109abcdadee860[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Jul 25 18:08:33 2024 -0700

    [ci] Mark tensorizer as soft fail and separate from grouped test (#6810)
    
    [ci] Mark tensorizer test as soft fail and separate it from grouped test in fast check (#6810)
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 443c7cf4cf891e6957d4b31655e58cabceb5a2a7[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jul 25 17:44:09 2024 -0700

    [ci][distributed] fix flaky tests (#6806)

[33mcommit 1adddb14bf0e1a603581bca49e8d29e8bfb337dc[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu Jul 25 16:53:25 2024 -0700

    [Core] Fix ray forward_dag error mssg (#6792)

[33mcommit b7215de2c5fcdf8af96cf941556d63934ea8f353[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jul 25 16:47:55 2024 -0700

    [Docs] Publish 5th meetup slides (#6799)

[33mcommit f3ff63c3f45974986f13f60647a258b09913c420[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jul 25 15:38:32 2024 -0700

    [doc][distributed] improve multinode serving doc (#6804)

[33mcommit cd7edc4e8726d4b87e121f9ec671ecb6dd0c45d6[m
Author: Lucas Wilkinson <LucasWilkinson@users.noreply.github.com>
Date:   Thu Jul 25 18:05:09 2024 -0400

    [Bugfix] Fix empty (nullptr) channelwise  scales when loading wNa16 using compressed tensors (#6798)

[33mcommit 6a1e25b1514a25d3da96d0d78c4568f6e581e242[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Thu Jul 25 11:57:16 2024 -0700

    [Doc] Add documentations for nightly benchmarks (#6412)

[33mcommit 95db75de64bec34f4d80acff92c62d1cdfa94688[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Jul 25 13:40:01 2024 -0400

    [Bugfix] Add synchronize to prevent possible data race (#6788)
    
    Co-authored-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit 65b1f121c885f169da210946eddb0d52524677f1[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Jul 25 12:46:15 2024 -0400

    [Bugfix] Fix `kv_cache_dtype=fp8` without scales for FP8 checkpoints (#6761)

[33mcommit 889da130e747b1382268ed428352f2e73e51a30b[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Jul 25 09:46:04 2024 -0700

    [ Misc ] `fp8-marlin` channelwise via `compressed-tensors` (#6524)
    
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit b75e314fff29bdc94b2fb1dd78519e92f9520e65[m
Author: Alphi <52458637+HwwwwwwwH@users.noreply.github.com>
Date:   Fri Jul 26 00:42:49 2024 +0800

    [Bugfix] Add image placeholder for OpenAI Compatible Server of MiniCPM-V (#6787)
    
    Co-authored-by: hezhihui <hzh7269@modelbest.cn>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 316a41ac1de4e6e46933cadb39b9b7af65b01abd[m
Author: Chang Su <chang.s.su@oracle.com>
Date:   Wed Jul 24 22:48:07 2024 -0700

    [Bugfix] Fix encoding_format in examples/openai_embedding_client.py (#6755)

[33mcommit 0310029a2fc62171fae87155150326125e082a5a[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Thu Jul 25 01:34:11 2024 -0400

    [Bugfix] Fix awq_marlin and gptq_marlin flags (#6745)

[33mcommit 309aaef8255fb832bf674c6ed7d9d84211629421[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Jul 24 22:33:56 2024 -0700

    [Bugfix] Fix decode tokens w. CUDA graph (#6757)

[33mcommit 9e169a4c619c33ec4f9a14c5e971e3aa34bc4444[m
Author: Alphi <52458637+HwwwwwwwH@users.noreply.github.com>
Date:   Thu Jul 25 11:59:30 2024 +0800

    [Model] Adding support for MiniCPM-V (#4087)

[33mcommit 5689e256baf0c45148a01ad147abf11ad82c9690[m
Author: Evan Z. Liu <ezliu@users.noreply.github.com>
Date:   Wed Jul 24 18:51:00 2024 -0700

    [Frontend] Represent tokens with identifiable strings (#6626)

[33mcommit 740374d456a638df98ffbc7d9dab328752330e62[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jul 24 17:37:12 2024 -0700

    [core][distributed] fix zmq hang (#6759)

[33mcommit d88c458f44f5bc0d01215310f8abb5d63fa106d4[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Wed Jul 24 17:32:57 2024 -0400

    [Doc][AMD][ROCm]Added tips to refer to mi300x tuning guide for mi300x users (#6754)

[33mcommit 421e218b37bd98b52bb3737c5aacc5a60fd460c0[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jul 24 16:22:16 2024 -0400

    [Bugfix] Bump transformers to 4.43.2 (#6752)

[33mcommit 5448f67635570cee6fc23c7cd166e9d8f7595009[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Jul 24 12:17:12 2024 -0700

    [Core] Tweaks to model runner/input builder developer APIs (#6712)

[33mcommit 0e63494cf334497148ee4203b59e34b2dd53e50e[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Jul 24 11:36:52 2024 -0700

    Add fp8 support to `reshape_and_cache_flash` (#6667)

[33mcommit ee812580f7ae3969cf2550cc4dab31490bfea950[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Wed Jul 24 19:36:04 2024 +0200

    [Frontend] split run_server into build_server and run_server (#6740)

[33mcommit 40468b13faa1ebde366e7002c5752b59e1368d10[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Wed Jul 24 23:58:42 2024 +0800

    [Bugfix] Miscalculated latency lead to time_to_first_token_seconds inaccurate. (#6686)

[33mcommit 2cf0df3381b74f93dce3215bf5a043b5c47c55f4[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Jul 24 08:58:31 2024 -0700

    [Bugfix] Fix speculative decode seeded test (#6743)

[33mcommit 545146349c3c28282cbb60d503f06df473adc932[m
Author: LF Marques <luizfelipe.unesp@gmail.com>
Date:   Wed Jul 24 16:55:53 2024 +0100

    Adding f-string to validation error which is missing (#6748)

[33mcommit f4f8a9d892a357e341b90bc47a8d72ece62323d5[m
Author: liuyhwangyh <liuyhwangyh@163.com>
Date:   Wed Jul 24 20:04:46 2024 +0800

    [Bugfix]fix modelscope compatible issue (#6730)

[33mcommit b5708117060460fcc6ba6f58e0669d3c46d6339e[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Wed Jul 24 07:01:14 2024 -0500

    [Build/CI] Update run-amd-test.sh. Enable Docker Hub login. (#6711)

[33mcommit ccc4a73257b61d5f1249999f6a804d60c2d1a518[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jul 24 01:07:23 2024 -0700

    [Docs][ROCm] Detailed instructions to build from source (#6680)

[33mcommit 0a740a11ba055d6a2ae4786db6510684bfb7a887[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Jul 24 01:05:09 2024 -0700

    [Bugfix] Fix token padding for chameleon (#6724)

[33mcommit c882a7f5b3ce5c98efb52c911ea15ca565d10cd7[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Jul 24 00:34:22 2024 -0700

    [SpecDecoding] Update MLPSpeculator CI tests to use smaller model (#6714)

[33mcommit 5e8ca973ebd5584582923b8ed1d3d823769a80a5[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Tue Jul 23 18:49:44 2024 -0700

    [Bugfix] fix flashinfer cudagraph capture for PP (#6708)

[33mcommit 87525fab925edf549611a1a74a40699b0b5e316e[m
Author: dongmao zhang <deanraccoon@gmail.com>
Date:   Tue Jul 23 16:45:09 2024 -0700

    [bitsandbytes]: support read bnb pre-quantized model (#5753)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 2f808e69ab16a8775cd58849b15b465d4f11b92e[m
Author: Thomas Parnell <tom.parnell@gmail.com>
Date:   Wed Jul 24 01:05:05 2024 +0200

    [Bugfix] StatLoggers: cache spec decode metrics when they get collected. (#6645)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 01c16ede6b4fc2e07b6eb5a4f60a64a1f365e460[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Jul 23 18:45:12 2024 -0400

    [CI] Add smoke test for non-uniform AutoFP8 quantization (#6702)

[33mcommit 72fc7048032a9a12f42c76e60c0d8ca3673f0692[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 23 14:03:49 2024 -0700

    [build] relax wheel size limit (#6704)

[33mcommit 1bedf210e35f5a11df5e9dd51e82b0663f854cf4[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jul 23 13:47:48 2024 -0700

    Bump `transformers` version for Llama 3.1 hotfix and patch Chameleon  (#6690)

[33mcommit 507ef787d85dec24490069ffceacbd6b161f4f72[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Tue Jul 23 13:22:09 2024 -0600

    [Model] Pipeline Parallel Support for DeepSeek v2 (#6519)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 58f53034add8767c9e5d92431220faa409fa3dc2[m
Author: Yehoshua Cohen <61619195+yecohn@users.noreply.github.com>
Date:   Tue Jul 23 21:41:55 2024 +0300

    [Frontend] Add Usage data in each chunk for chat_serving. #6540 (#6652)

[33mcommit 0eb0757bef728c632be17e61a88cfa9dc1a760c4[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Jul 23 14:04:04 2024 -0400

    [Misc] Add ignored layers for `fp8` quantization (#6657)

[33mcommit 38c4b7e863570a045308af814c72f4504297222e[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Jul 23 10:08:59 2024 -0700

    Bump version to 0.5.3.post1 (#6696)

[33mcommit a112a84aadad40a69b85a07a5eb3f329498ea20e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jul 23 09:46:05 2024 -0700

    [BugFix] Fix RoPE error in Llama 3.1 (#6693)

[33mcommit 461089a21a5b00d6c6712e3bf371ce2d9cfa0860[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jul 23 09:27:58 2024 -0700

    [Bugfix] Fix a log error in chunked prefill (#6694)

[33mcommit 71950af726faa12bef0070a5d5d0305c503d7c35[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 23 08:55:33 2024 -0700

    [doc][distributed] fix doc argument order (#6691)

[33mcommit cb1362a8892d444294117b848547c76b80d6dc65[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jul 23 08:18:15 2024 -0700

    [Docs] Announce llama3.1 support (#6688)

[33mcommit bb2fc08072db2d96e547407b4301fb6ba141d9d6[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Jul 23 00:00:08 2024 -0700

    Bump version to v0.5.3 (#6674)

[33mcommit 3eda4ec780d572120ed02e9e94bcef383c3e0399[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Jul 22 23:59:42 2024 -0700

    support ignore patterns in model loader (#6673)

[33mcommit 22fa2e35cbbb76fde94412f565572d290027a3c3[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jul 22 23:50:48 2024 -0700

    [VLM][Model] Support image input for Chameleon  (#6633)

[33mcommit c5201240a4ffb40d014845088eb218b1512899e9[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 22 21:57:27 2024 -0700

    [misc] only tqdm for first rank (#6672)

[33mcommit 97234be0ec67f48ed5e65bc0290f329dfb33798e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jul 23 12:32:02 2024 +0800

    [Misc] Manage HTTP connections in one place (#6600)

[33mcommit c051bfe4eb77b82eba90504360bbd4e61d9e489a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 22 21:22:09 2024 -0700

    [doc][distributed] doc for setting up multi-node environment (#6529)
    
    [doc][distributed] add more doc for setting up multi-node environment (#6529)

[33mcommit 9e0b558a0923004758a9dc91f5d4920ded48b42a[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Jul 23 00:11:50 2024 -0400

    [Misc] Support FP8 kv cache scales from compressed-tensors (#6528)

[33mcommit e519ae097ac4c126d3d8b2f3bb5ee54f696cf8bc[m
Author: zhaotyer <89376832+zhaotyer@users.noreply.github.com>
Date:   Tue Jul 23 11:48:01 2024 +0800

    add tqdm when loading checkpoint shards (#6569)
    
    Co-authored-by: tianyi.zhao <tianyi.zhao@transwarp.io>
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 7c2749a4fdd92150940cc80c1027a1e173099a24[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 22 20:08:02 2024 -0700

    [misc] add start loading models for users information (#6670)

[33mcommit 729171ae58cce74753e628056bda2b6df6b65f4a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jul 22 20:03:13 2024 -0700

    [Misc] Enable chunked prefill by default for long context models (#6666)

[33mcommit c5e8330997dc3969818c6696a79820bcee44a702[m
Author: Cheng Li <pistasable@gmail.com>
Date:   Mon Jul 22 19:25:05 2024 -0700

    [Bugfix] Fix null `modules_to_not_convert`  in FBGEMM Fp8 quantization (#6665)

[33mcommit e0c15758b85827dcac78379e60ea975ebc0ec795[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Mon Jul 22 17:45:24 2024 -0700

    [Core] Modulize prepare input and attention metadata builder (#6596)

[33mcommit bdf5fd1386846281acb92cf6fd01addc9c43d7a8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jul 22 17:21:58 2024 -0700

    [Misc] Remove deprecation warning for beam search (#6659)

[33mcommit 5a96ee52a30dbcf18676b7c0d52493437fee8eec[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 22 16:26:29 2024 -0700

    [ci][build] add back vim in docker (#6661)

[33mcommit 42c7f66a386b2243dcd313feed7dec4e1d508167[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Mon Jul 22 15:42:40 2024 -0700

    [Core] Support dynamically loading Lora adapter from HuggingFace (#6234)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit 69d5ae38dc0dbc0b9074a344b4eb878c74c8c755[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Jul 22 14:20:41 2024 -0700

    [ci] Use different sccache bucket for CUDA 11.8 wheel build (#6656)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit fea59c7712eea40f09d36fa732f0b9a7024ea983[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Jul 22 16:08:30 2024 -0400

    [Bugfix][Kernel] Use int64_t for indices in fp8 quant kernels (#6649)

[33mcommit 739b61a348afa5da297a80ff15f4e39d6e524b53[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jul 23 01:13:53 2024 +0800

    [Frontend] Refactor prompt processing (#4028)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 89c1c6a196e80536bb392c422e7f34439b1f3104[m
Author: Jae-Won Chung <jwnchung@umich.edu>
Date:   Mon Jul 22 01:02:51 2024 -0400

    [Bugfix] Fix `vocab_size` field access in `llava_next.py` (#6624)

[33mcommit 42de2cefcbfc1e640f3337b36d5dddfd3133ef0e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Jul 21 18:43:11 2024 -0700

    [Misc] Add a wrapper for torch.inference_mode (#6618)

[33mcommit c9eef37f329c952df92d4c8f4aa23e616f183d04[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Jul 21 17:37:51 2024 -0700

    [Model] Initial Support for Chameleon (#5770)

[33mcommit 396d92d5e064d131422886482cb1b75e5b6538d9[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Sun Jul 21 19:41:42 2024 -0400

    [Kernel][Core] Add AWQ support to the Marlin kernel  (#6612)

[33mcommit 25e778aa169ec871ad65524c793bf9bd43f6885a[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Jul 22 07:07:58 2024 +0800

    [Model] Refactor and decouple phi3v image embedding (#6621)

[33mcommit b6df37f9431b44e3e8802448c95cbc6989c3716e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Jul 21 08:47:04 2024 -0700

    [Misc] Remove abused noqa (#6619)

[33mcommit 14f91fe67c2342f2fe859dc6a5c40810df0e1c61[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Sat Jul 20 23:58:58 2024 -0700

    [Spec Decode] Disable Log Prob serialization to CPU for spec decoding for both draft and target models. (#6485)

[33mcommit d7f4178dd99cdba8735d268ff470929de53ee2d5[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Jul 21 08:38:17 2024 +0800

    [Frontend] Move chat utils (#6602)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 082ecd80d58c6604f44c0196cb9db5bc4befd6d7[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Jul 20 19:25:56 2024 -0400

    [ Bugfix ] Fix AutoFP8 fp8 marlin (#6609)

[33mcommit f952bbc8ffccdd109b5bd8936655ce3fe3220807[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sat Jul 20 19:11:13 2024 -0400

    [Misc] Fix input_scale typing in w8a8_utils.py (#6579)

[33mcommit 9364f74eee2e8aab9e3c9cd6dea290018ef43b95[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Jul 20 14:50:10 2024 -0400

    [ Kernel ] Enable `fp8-marlin` for `fbgemm-fp8` models (#6606)

[33mcommit 06d6c5fe9fad0b798afe058c9e5e872193390456[m
Author: Matt Wong <156021403+mawong-amd@users.noreply.github.com>
Date:   Sat Jul 20 11:39:07 2024 -0500

    [Bugfix][CI/Build][Hardware][AMD] Fix AMD tests, add HF cache, update CK FA, add partially supported model notes (#6543)

[33mcommit 683e3cb9c4b25d10d507817cb0521883d29cc082[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Jul 20 12:36:57 2024 -0400

    [ Misc ] `fbgemm` checkpoints (#6559)

[33mcommit 9042d683620a7e3fa75c953fe9cca29086ce2b9a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jul 20 12:17:24 2024 +0800

    [Misc] Consolidate and optimize logic for building padded tensors (#6541)

[33mcommit 3f8d42c81fe8d3842a9e05c9f5d98290b7f79736[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Fri Jul 19 20:18:19 2024 -0600

    Pipeline Parallel: Guard for KeyErrors at request abort (#6587)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 7bd82002ae0e7ee8c4e5da0d43cfe0fd85372b4a[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Jul 19 18:25:06 2024 -0700

    [Core] Allow specifying custom Executor (#6557)

[33mcommit 2e26564259801dc6359c49bb044104d8d5373b57[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Fri Jul 19 21:15:26 2024 -0400

    [ Kernel ] FP8 Dynamic Per Token Quant - Add scale_ub (#6593)
    
    Co-authored-by: Varun Sundar Rabindranth <varun@neuralmagic.com>

[33mcommit e81522e8792443eabe23412bbec0bffd1157e9a2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jul 19 17:16:57 2024 -0700

    [build] add ib in image for out-of-the-box infiniband support (#6599)
    
    [build] add ib so that multi-node support with infiniband can be supported out-of-the-box (#6599)

[33mcommit 45ceb85a0c9032ea8bfa3d2526e3d7c1a09a48f0[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Fri Jul 19 19:38:21 2024 -0400

    [Docs] Update PP docs (#6598)

[33mcommit 4cc24f01b1f1a3e4fc0e740979ebecee0980fbe8[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jul 19 19:08:15 2024 -0400

    [ Kernel ] Enable Dynamic Per Token `fp8` (#6547)

[33mcommit 07eb6f19f3b0ee9f7adf6eb689607028aa40bfd5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jul 19 15:34:34 2024 -0700

    [bugfix][distributed] fix multi-node bug for shared memory (#6597)

[33mcommit f0bbfaf917edef99fe7817d607d56803695610ca[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Fri Jul 19 23:01:03 2024 +0200

    [Bugfix] [SpecDecode] AsyncMetricsCollector: update time since last collection (#6578)

[33mcommit 30efe41532b7cd7202d128ffedfc703c4039767f[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 19 12:14:11 2024 -0700

    [Docs] Update docs for wheel location (#6580)

[33mcommit 9ed82e7074a18e25680ab106fc846364ad97bc00[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Jul 19 12:10:56 2024 -0700

    [Misc] Small perf improvements (#6520)

[33mcommit 51f8aa90ad409cc77bfab208be7f5907bf7d5330[m
Author: Daniele <36171005+dtrifiro@users.noreply.github.com>
Date:   Fri Jul 19 19:16:27 2024 +0200

    [Bugfix][Frontend] remove duplicate init logger (#6581)

[33mcommit a5314e8698b7c0f20cf3facf921c54917c89a9ba[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Fri Jul 19 15:15:22 2024 +0200

    [Model] RowParallelLinear: pass bias to quant_method.apply  (#6327)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit a921e863921721ecae8250e0543aba1920c7c53a[m
Author: Woo-Yeon Lee <wooyeon0.lee@samsung.com>
Date:   Fri Jul 19 22:01:09 2024 +0900

    [BUGFIX] Raise an error for no draft token case when draft_tp>1 (#6369)

[33mcommit 6366efc67b0aedd2c1721c14385370e50b297fb3[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jul 19 11:55:13 2024 +0800

    [Bugfix][Frontend] Fix missing `/metrics` endpoint (#6463)

[33mcommit dbe55885541fcf27c0bc229df50b3ea3c53e38ce[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Jul 18 22:39:18 2024 -0400

    [ Misc ] non-uniform quantization via `compressed-tensors` for `Llama` (#6515)

[33mcommit d4201e06d5ec3384e06b20816ad6b2f1d1fb1441[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Fri Jul 19 04:22:08 2024 +0200

    [Bugfix] Make spec. decode respect per-request seed. (#6034)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit b5672a112c0e6c550f2dfa75c6cbe940a3f933bc[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Jul 18 19:15:52 2024 -0700

    [Core] Multiprocessing Pipeline Parallel support (#6130)
    
    Co-authored-by: Murali Andoorveedu <muralidhar.andoorveedu@centml.ai>

[33mcommit c5df56f88bc8a5a32a0534793f48182a333aeca4[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Jul 18 18:53:03 2024 -0700

    Add support for a rope extension method (#6553)

[33mcommit 1689219ebf01c750de492271832e27c39df38648[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Jul 18 20:29:25 2024 -0400

    [CI/Build] Build on Ubuntu 20.04 instead of 22.04 (#6517)

[33mcommit 4ffffccb7eca8a8911ab37b7e15e5d0210838ceb[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Jul 18 19:52:22 2024 -0400

    [Kernel] Implement fallback for FP8 channelwise using torch._scaled_mm (#6552)

[33mcommit f53b8f0d051a49402e5c4aef40764a7de8d5d50c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jul 18 16:41:06 2024 -0700

    [ci][test] add correctness test for cpu offloading (#6549)

[33mcommit 2d4733ba2d5dee17c42df84d5f5b21a360e5a323[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Jul 18 14:48:29 2024 -0700

    Fix PR comment bot (#6554)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 15c6a079b1ccea03587031c9d709fb9dce0a1d93[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Jul 18 16:31:50 2024 -0400

    [Model] Support Mistral-Nemo (#6548)

[33mcommit ecdb462c2493cf9fd095e624cdfd8d62842e2097[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Thu Jul 18 08:01:45 2024 -0700

    [ci] Reword Github bot comment  (#6534)

[33mcommit 58ca6632247cb738d069a585e1ec9a9d5e66da68[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Jul 18 10:39:12 2024 -0400

    [ Misc ] Improve Min Capability Checking in `compressed-tensors` (#6522)

[33mcommit 4634c8728b0fe30a0b2da22dd4a4c8d8a1d9213b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jul 18 01:34:16 2024 -0700

    [TPU] Refactor TPU worker & model runner (#6506)

[33mcommit c8a7d51c4982b7b425debe5473867d9983e728fd[m
Author: Noam Gat <noamgat@gmail.com>
Date:   Thu Jul 18 10:47:13 2024 +0300

    [Bugfix] Update flashinfer.py with PagedAttention forwards - Fixes Gemma2 OpenAI Server Crash (#6501)

[33mcommit e2fbaee7258810bcd43725e9ca7f1444a88f91f3[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Jul 18 00:13:30 2024 -0700

    [BugFix][Frontend] Use LoRA tokenizer in OpenAI APIs (#6227)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 8a74c68bd1ae48cb71e4c3bf9d7ff9a2ef8f9dae[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Jul 17 23:06:21 2024 -0700

    [Misc] Minor patch for draft model runner (#6523)

[33mcommit 61e592747c28c9fbd6861e48b825c796e09da02f[m
Author: Rui Qiao <161574667+ruisearch42@users.noreply.github.com>
Date:   Wed Jul 17 22:27:09 2024 -0700

    [Core] Introduce SPMD worker execution using Ray accelerated DAG (#6032)
    
    Signed-off-by: Rui Qiao <ruisearch42@gmail.com>
    Co-authored-by: Stephanie Wang <swang@cs.berkeley.edu>

[33mcommit d25877dd9b7a09d5f9552d9d185a86dc6497bc2f[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Jul 17 22:24:43 2024 -0700

    [BugFix] Avoid secondary error in ShmRingBuffer destructor (#6530)

[33mcommit 1c27d25fb57285d2c5bb6d17d70549ab4b8f45a7[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jul 17 20:54:35 2024 -0700

    [core][model] yet another cpu offload implementation (#6496)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 18fecc3559cad615fd8565d1a001557ec355f285[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Wed Jul 17 23:18:13 2024 -0400

    [ Kernel ] Fp8 Channelwise Weight Support (#6487)

[33mcommit b5af8c223c3d70557e7d73ba3c4c2e9d56fc9694[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Jul 17 19:26:04 2024 -0700

    [Model] Pipeline parallel support for Mixtral (#6516)

[33mcommit b5241e41d9fef56a89dcfda367a7eff87a07e3f7[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Wed Jul 17 21:38:35 2024 -0400

    [ Kernel ] FP8 Dynamic-Per-Token Quant Kernel (#6511)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit e76466dde2bc9525d55165ceaa600d298c7bf773[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Wed Jul 17 17:30:28 2024 -0400

    [Core] draft_model_runner: Implement prepare_inputs on GPU for advance_step (#6338)

[33mcommit 5f0b9933e63839e816b9736a65a3c55005df2cfe[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Jul 17 12:40:10 2024 -0700

    [Bugfix] Fix Ray Metrics API usage (#6354)

[33mcommit a38524f338a100bb0f0121c3aa24e8c4a9160d51[m
Author: milo157 <43028253+milo157@users.noreply.github.com>
Date:   Wed Jul 17 13:22:53 2024 -0400

    [DOC] - Add docker image to Cerebrium Integration (#6510)

[33mcommit 2fa4623d9e673faddb05018ac3f3d65780bb083d[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Jul 17 09:37:16 2024 -0700

    [Core] Refactor _prepare_model_input_tensors - take 2 (#6164)

[33mcommit a9a2e74d21d7ef893ff1b7d2c34f390ab3b7736c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jul 17 06:01:10 2024 -0700

    [Misc] Use `torch.Tensor` for type annotation (#6505)

[33mcommit e09ce759aa8d4fa41304df59b7e888fe12724d58[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jul 17 04:02:53 2024 -0700

    [TPU] Remove multi-modal args in TPU backend (#6504)

[33mcommit 5fa6e9876ed8212d74a71a7df7654fd4b94dd659[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Wed Jul 17 04:25:10 2024 -0400

    [Bugfix] Fix for multinode crash on 4 PP (#6495)
    
    Signed-off-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>

[33mcommit 5bf35a91e465278b51b0c98fa1b13beb8b04d431[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jul 17 15:43:21 2024 +0800

    [Doc][CI/Build] Update docs and tests to use `vllm serve` (#6431)

[33mcommit a19e8d372651abad75dc6a3939c18f23a1ae8d40[m
Author: shangmingc <csmthu@gmail.com>
Date:   Wed Jul 17 15:17:07 2024 +0800

    [Misc][Speculative decoding] Typos and typing fixes (#6467)
    
    Co-authored-by: caishangming.csm <caishangming.csm@alibaba-inc.com>

[33mcommit 10383887e03412196a2689b9398290719c4797bf[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Wed Jul 17 01:47:02 2024 -0400

    [ROCm] Cleanup Dockerfile and remove outdated patch (#6482)

[33mcommit 1d094fd7c0d72e7eaf3a2b65fff9f7de8d812a49[m
Author: Wushi Dong <33078715+wushidonguc@users.noreply.github.com>
Date:   Tue Jul 16 19:20:26 2024 -0700

    [Distributed][PP] only create embedding & lm head when necessary (#6455)
    
    original title: [Distributed][Model] Rank-based Component Creation for Pipeline Parallelism Memory Optimization

[33mcommit ce37be7ba05f21f2a8f3b792034195305ebe1b27[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 16 19:16:34 2024 -0700

    [misc][distributed] add seed to dummy weights (#6491)

[33mcommit 7f62077af5159c625fe3ad1c812e6c1a2b93ba3b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 16 17:35:52 2024 -0700

    [misc][distributed] improve tests (#6488)

[33mcommit 09c2eb85ddd3b2585979f4cd9cc97168d86718b6[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 16 15:44:22 2024 -0700

    [ci][distributed] add pipeline parallel correctness test (#6410)

[33mcommit 978aed53004b82877bd2af0f10afff1826d7194d[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Jul 16 18:31:32 2024 -0400

    [Kernel][Attention] Separate `Attention.kv_scale` into `k_scale` and `v_scale` (#6081)

[33mcommit 160e1d8c99567872ef3e683e87c09f96a3a2e7c4[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Tue Jul 16 13:37:10 2024 -0700

    [Misc] Log spec decode metrics (#6454)

[33mcommit 94162beb9f454403d68ec009bb5572ee560d7603[m
Author: Jiaxin Shan <seedjeffwan@gmail.com>
Date:   Tue Jul 16 10:11:04 2024 -0700

    [Doc] Fix the lora adapter path in server startup script (#6230)

[33mcommit c467dff24f5dfa0b8e4045c3d265c6e606e35f99[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jul 16 09:56:28 2024 -0700

    [Hardware][TPU] Support MoE with Pallas GMM kernel  (#6457)

[33mcommit 9f4ccec76135083c96d15fbbade5eda7a2321bf1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 16 09:45:30 2024 -0700

    [doc][misc] remind to cancel debugging environment variables (#6481)
    
    [doc][misc] remind users to cancel debugging environment variables after debugging (#6481)

[33mcommit 38ef94888afc0c2bccc2f18422d2b525d7649ac3[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jul 16 23:59:36 2024 +0800

    [CI/Build] Remove "boardwalk" image asset (#6460)

[33mcommit 2bb0489cb3367e46e201e84ab629df535544495b[m
Author: Peng Guanwen <pg999w@outlook.com>
Date:   Tue Jul 16 23:13:25 2024 +0800

    [Core] Use numpy to speed up padded token processing (#6442)

[33mcommit 7508a3dc34c2b7a5c5c971b13f15208d7dade442[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Tue Jul 16 15:55:15 2024 +0200

    [Misc] Fix typos in spec. decode metrics logging. (#6470)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 7a3d2a5b957063e911c25401c593dbc7798a5536[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Tue Jul 16 12:18:09 2024 +0000

    [Frontend] Support for chat completions input in the tokenize endpoint (#5923)

[33mcommit d97011512e5a816acbdb5bd8ffbf691dd227fe27[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jul 16 14:12:25 2024 +0800

    [CI/Build] vLLM cache directory for images (#6444)

[33mcommit 37d776606f7e434ac61758fd6601bb9df4ec505a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jul 15 21:04:58 2024 -0700

    [Docs] Announce 5th meetup (#6458)

[33mcommit d92b3c5cdef59533347ac714a70274f186943019[m
Author: Joe <g-eoj@users.noreply.github.com>
Date:   Mon Jul 15 18:54:15 2024 -0700

    [Bugfix][CI/Build] Test prompt adapters in openai entrypoint tests (#6419)

[33mcommit 9ad32dacd9c4697ca06e841bd1bc97b58d2c7b3d[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Tue Jul 16 04:32:55 2024 +0300

    [BugFix][Model] Jamba - Handle aborted requests, Add tests and fix cleanup bug (#6425)
    
    Co-authored-by: Mor Zusman <morz@ai21.com>

[33mcommit d6f3b3d5c4d5638bb1f778c1dc021b382673bdea[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Jul 15 18:26:11 2024 -0700

    Pin sphinx-argparse version (#6453)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 4552e37b55e3b8d7ba54d05945ac06b680964db6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jul 15 14:31:16 2024 -0700

    [CI/Build][TPU] Add TPU CI test (#6277)
    
    Co-authored-by: kevin <kevin@anyscale.com>

[33mcommit ec9933f4a5d3f13f43d6c30f7f59d33127de961d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jul 15 12:02:14 2024 -0700

    [Misc] Add CustomOp Interface to UnquantizedFusedMoEMethod (#6289)

[33mcommit 3dee97b05fc5487fe66513a7c299605ed17561a8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jul 15 11:58:10 2024 -0700

    [Docs] Add Google Cloud to sponsor list (#6450)

[33mcommit 4cf256ae7f8b0be8f06f6b85821e55d4f5bdaa13[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 15 10:32:35 2024 -0700

    [misc][distributed] fix pp missing layer condition (#6446)

[33mcommit 64fdc08c72f1ba923d7a4f76858fcad3551282a5[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Jul 15 10:27:40 2024 -0700

    bump version to v0.5.2 (#6433)

[33mcommit 4ef95b0f0677f95d8181837bbeebca7fca5a2bb2[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Mon Jul 15 19:14:49 2024 +0200

    [Bugfix] use float32 precision in samplers/test_logprobs.py for comparing with HF  (#6409)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit eaec4b915347d839b0e99bcd57475730a715492c[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Mon Jul 15 19:12:47 2024 +0200

    [Bugfix] Add custom Triton cache manager to resolve MoE MP issue  (#6140)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>
    Co-authored-by: Chih-Chieh-Yang <chih.chieh.yang@ibm.com>

[33mcommit a63a4c634174de7a6b966dd6996f9f8d2ae86827[m
Author: Pernekhan Utemuratov <bestkhang@gmail.com>
Date:   Mon Jul 15 10:10:26 2024 -0700

    [Misc] Use 0.0.9 version for flashinfer (#6447)
    
    Co-authored-by: Pernekhan Utemuratov <pernekhan@deepinfra.com>

[33mcommit c8fd97f26d05aff5a4603177c75aaccf4e6de11b[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Jul 15 13:05:52 2024 -0400

    [Kernel] Use CUTLASS kernels for the FP8 layers with Bias (#6270)

[33mcommit 94b82e8c18f0d38d85171cc8667f763c8078a835[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 15 09:45:51 2024 -0700

    [doc][distributed] add suggestion for distributed inference (#6418)

[33mcommit 6ae1597ddf5ac51a6eae6b012c5399de22cb9d28[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jul 15 02:29:51 2024 -0700

    [VLM] Minor space optimization for `ClipVisionModel` (#6436)

[33mcommit 22e79ee8f3930c39f40f6a1529e41594a607c6b4[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Jul 14 23:33:25 2024 -0700

    [doc][misc] doc update (#6439)

[33mcommit de199163140974876d4416e936934ad621b2eb0c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jul 15 13:39:15 2024 +0800

    [Bugfix] Convert image to RGB by default (#6430)

[33mcommit 69672f116cf83dbcfd2d470a959dfe123df4d301[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Jul 14 21:20:51 2024 -0700

    [core][distributed] simplify code to support pipeline parallel (#6406)

[33mcommit 44874a0bf970ae55c487a1dc09b25bd308872f7c[m
Author: DefTruth <31974251+DefTruth@users.noreply.github.com>
Date:   Mon Jul 15 12:16:51 2024 +0800

    [Doc] add env docs for flashinfer backend (#6437)

[33mcommit b47008b4d29acb39503a65991c75a68361abc0b0[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Sun Jul 14 21:06:09 2024 -0700

    [BugFix] BatchResponseData body should be optional (#6345)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 9bfece89fdbe745730c6bb510ba043c698f79870[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Jul 14 20:36:16 2024 -0700

    Add FUNDING.yml (#6435)

[33mcommit 32c9d7f7650842cc20b2e66a4125ffe126619c50[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Jul 14 19:37:35 2024 -0700

    Report usage for beam search (#6404)

[33mcommit ccb20db8bd2abb302a8dc0fbc0901f284df9b3f5[m
Author: Fish <45708320+lxline@users.noreply.github.com>
Date:   Mon Jul 15 10:27:01 2024 +0800

    [Bugfix] Benchmark serving script used global parameter 'args' in function 'sample_random_requests' (#6428)

[33mcommit a754dc2cb964c78fd9da514aa0b87a0241e97d1f[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Jul 14 21:54:46 2024 -0400

    [CI/Build] Cross python wheel (#6394)

[33mcommit 61e85dbad87cc1a0b2a838274a758012062747a6[m
Author: Robert Cohn <rscohn2@gmail.com>
Date:   Sun Jul 14 20:10:11 2024 -0400

    [Doc] xpu backend requires running setvars.sh (#6393)

[33mcommit dbfe254eda918bc3cc52cf448d518824ad6593b9[m
Author: Ethan Xu <70482605+EthanqX@users.noreply.github.com>
Date:   Sun Jul 14 15:36:43 2024 -0700

    [Feature] vLLM CLI (#5090)
    
    Co-authored-by: simon-mo <simon.mo@hey.com>

[33mcommit 73030b7dae676f730ea43652af056501584ecbfe[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Jul 14 17:38:42 2024 -0400

    [ Misc ] Enable Quantizing All Layers of DeekSeekv2 (#6423)

[33mcommit ccd3c045710323102ebd9eab6d2e192c0fd6e509[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Jul 14 07:16:21 2024 -0700

    [ci][build] fix commit id (#6420)
    
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit 9dad5cc85902f419aea5320dd49a827621ed5668[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sun Jul 14 09:37:19 2024 -0400

    [Kernel] Turn off CUTLASS scaled_mm for Ada Lovelace (#6384)

[33mcommit 6ef3bf912cfb878ff57cf395c4e5908fd9b2a42b[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Sun Jul 14 02:58:09 2024 -0500

    Remove unnecessary trailing period in spec_decode.rst (#6405)

[33mcommit 540c0368b14ddd8d3efac0b182761bf6600f104f[m
Author: Isotr0py <2037008807@qq.com>
Date:   Sun Jul 14 13:27:14 2024 +0800

    [Model] Initialize Fuyu-8B support (#3924)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit fb6af8bc086328ca6659e72d11ffd4309ce4de22[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Jul 13 23:03:58 2024 -0400

    [ Misc ] Apply MoE Refactor to Deepseekv2 To Support Fp8 (#6417)

[33mcommit eeceadaecc80cc51c4e9ddae0cb99a33d379452d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Jul 13 11:52:22 2024 -0700

    [Misc] Add deprecation warning for beam search (#6402)

[33mcommit babf52dade78ff3b1bea6cb6e9f4151dfd630251[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Jul 13 06:21:37 2024 -0400

    [ Misc ] More Cleanup of Marlin (#6359)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic.com>

[33mcommit 9da4aad44b7878032ef2bb32eb1b4e1ab86f8351[m
Author: Noam Gat <noamgat@gmail.com>
Date:   Sat Jul 13 13:09:12 2024 +0300

    Updating LM Format Enforcer version to v10.3 (#6411)

[33mcommit 41708e50341c82668fd25ebc7777470cba6f5303[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jul 12 21:51:48 2024 -0700

    [ci] try to add multi-node tests (#6280)
    
    Signed-off-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>
    Co-authored-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>

[33mcommit d80aef37764feda51e21065de9c669785fe1d94a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jul 12 19:36:53 2024 -0700

    [Docs] Clean up latest news (#6401)

[33mcommit e1684a766ad3f2f1531c273fa8a056fc14c4c71e[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Sat Jul 13 03:30:54 2024 +0200

    [Bugfix] Fix hard-coded value of x in context_attention_fwd (#6373)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit a27f87da3429eafbbaf4f5372bf458ae40e30618[m
Author: Saliya Ekanayake <esaliya@gmail.com>
Date:   Fri Jul 12 17:48:23 2024 -0700

    [Doc] Fix Typo in Doc (#6392)
    
    Co-authored-by: Saliya Ekanayake <esaliya@d-matrix.ai>

[33mcommit 16ff6bd58ca20b008eaf7491d5422dfd80737570[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Fri Jul 12 16:34:37 2024 -0700

    [ci] Fix wording for GH bot (#6398)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit f8f9ff57ee365891fe9f54cd46df65cc9d5ccca0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jul 12 15:59:47 2024 -0700

    [Bugfix][TPU] Fix megacore setting for v5e-litepod (#6397)

[33mcommit 6bc9710f6e623adaa05b462171454f0bf543e9b0[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 12 15:52:43 2024 -0700

    Fix release pipeline's dir permission (#6391)

[33mcommit 111fc6e7ecb8e5eb665606cf79209495e874479b[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Jul 12 18:52:15 2024 -0400

    [Misc] Add generated git commit hash as `vllm.__commit__` (#6386)

[33mcommit 75f64d8b94d012ea37dddde1058ce17e55001a4a[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Jul 12 14:33:33 2024 -0700

    [Bugfix] Fix illegal memory access in FP8 MoE kernel (#6382)

[33mcommit 21b2dcedabb84332a73e8cda3886a6988c52a7df[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 12 14:08:04 2024 -0700

    Fix release pipeline's -e flag (#6390)

[33mcommit 07b35af86d984e529e4099b0d348b71ad820c23d[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 12 14:03:39 2024 -0700

    Fix interpolation in release pipeline (#6389)

[33mcommit bb1a784b05cde68a2a657431c4ab21839ca4c756[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 12 14:00:57 2024 -0700

    Fix release-pipeline.yaml (#6388)

[33mcommit d719ba24c5b4e669bf51b49293cab09f2ce7361c[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 12 13:56:59 2024 -0700

    Build some nightly wheels by default (#6380)

[33mcommit aa48e502fba074a3c3afeeba0267d0f9e9f205db[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Jul 12 12:04:26 2024 -0700

    [MISC] Upgrade dependency to PyTorch 2.3.1 (#5327)

[33mcommit 4dbebd03cc0ba514174648c65250ec3faac8ef69[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Fri Jul 12 11:36:26 2024 -0700

    [ci] Add GHA workflows to enable full CI run (#6381)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit b75bce1008fba05ae6e0dcb8060a61015a3c0129[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Fri Jul 12 09:58:38 2024 -0700

    [ci] Add grouped tests & mark tests to run by default for fastcheck pipeline (#6365)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit b039cbbce37c1e6a1fdb284a41bd27cfef1b3783[m
Author: Yihuan Bu <88394319+kevinbu233@users.noreply.github.com>
Date:   Fri Jul 12 12:55:39 2024 -0400

    [Misc] add fixture to guided processor tests (#6341)

[33mcommit f9d25c251907bc8be9b9c712adaf8d3ce631226e[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Fri Jul 12 11:42:24 2024 -0500

    [Build/CI] Checking/Waiting for the GPU's clean state (#6379)

[33mcommit 024ad87cdc00bb44beed409dbd90c4490284d73e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jul 12 23:22:18 2024 +0800

    [Bugfix] Fix dtype mismatch in PaliGemma (#6367)

[33mcommit aea19f0989667968465087338b568694f61c6391[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jul 12 11:11:29 2024 -0400

    [ Misc ] Support Models With Bias in `compressed-tensors` integration (#6356)

[33mcommit f7160d946a0a07703e72d81ba9ecf3913f192605[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Jul 12 01:40:07 2024 -0700

    [Misc][Bugfix] Update transformers for tokenizer issue (#6364)

[33mcommit 6047187cd854eef114bd70c76469d5a839a07ef4[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jul 12 01:06:09 2024 -0400

    [ Misc ] Remove separate bias add (#6353)

[33mcommit b6c16cf8ff8d558ec943f1f17342c2c081f3f5af[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Fri Jul 12 00:30:46 2024 -0400

    [ROCm][AMD] unify CUDA_VISIBLE_DEVICES usage in cuda/rocm (#6352)

[33mcommit d26a8b3f1fb53ec35008a83690ca7339c13ecd4e[m
Author: adityagoel14 <aditya.goel@amd.com>
Date:   Fri Jul 12 00:26:26 2024 -0400

    [CI/Build] (2/2) Switching AMD CI to store images in Docker Hub (#6350)

[33mcommit d59eb98489103877e9476ef5263305aa3e3f9e23[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Jul 11 22:47:17 2024 -0400

    [Model][Phi3-Small] Remove scipy from blocksparse_attention (#6343)

[33mcommit adf32e0a0f58edafe0c71b5c235848a487be2a71[m
Author: Helena Kloosterman <helena.kloosterman@intel.com>
Date:   Fri Jul 12 04:47:00 2024 +0200

    [Bugfix] Fix usage stats logging exception warning with OpenVINO (#6349)

[33mcommit 2b0fb534813e9835077403723a484b7c03d47259[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jul 11 19:35:17 2024 -0700

    [distributed][misc] be consistent with pytorch for libcudart.so (#6346)
    
    [distributed][misc] keep consistent with how pytorch finds libcudart.so (#6346)

[33mcommit d6ab5289976fe219f943a7df4fb3a0ba1cb31a00[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Thu Jul 11 18:32:06 2024 -0700

    [Misc] Remove flashinfer warning, add flashinfer tests to CI (#6351)

[33mcommit 7ed6a4f0e1b39499675edf1dd6079d4bf21eb0fe[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Jul 11 18:02:29 2024 -0400

    [ BugFix ] Prompt Logprobs Detokenization (#6223)
    
    Co-authored-by: Zifei Tong <zifeitong@gmail.com>

[33mcommit a4feba929b61f287ae0b7407c3d615c6dec193d6[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Thu Jul 11 13:28:38 2024 -0700

    [CI/Build] Add nightly benchmarking for tgi, tensorrt-llm and lmdeploy (#5362)

[33mcommit 2d23b42d9255f724f955a1cf91ed78c983854737[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jul 11 11:38:40 2024 -0700

    [doc] update pipeline parallel in readme (#6347)

[33mcommit 1df43de9bb2cceecdc0dc2dc5c650a327aeabe0f[m
Author: xwjiang2010 <87673679+xwjiang2010@users.noreply.github.com>
Date:   Thu Jul 11 10:21:10 2024 -0700

    [bug fix] Fix llava next feature size calculation. (#6339)
    
    Signed-off-by: Xiaowei Jiang <xwjiang2010@gmail.com>

[33mcommit 52b7fcb35a6f8b57429431e929884c05d8266023[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Jul 11 09:17:07 2024 -0700

    Benchmark: add H100 suite (#6047)

[33mcommit b675069d7486129dbed7847f420b7a927691f16b[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu Jul 11 11:40:11 2024 -0400

    [ Misc ] Refactor Marlin Python Utilities (#6082)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic.com>

[33mcommit 55f692b46ef35ed4a9e199dfe60a9eefe800e4b0[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Thu Jul 11 17:40:20 2024 +0300

    [BugFix] get_and_reset only when scheduler outputs are not empty (#6266)

[33mcommit 8a1415cf776b2b902f6429ecfc325877b57cbefe[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Thu Jul 11 16:05:59 2024 +0200

    [Bugfix] GPTBigCodeForCausalLM: Remove lm_head from supported_lora_modules. (#6326)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>
    Co-authored-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 546b101fa05043feb470513a778c31114ea3aa05[m
Author: pushan <62173185+pushan01@users.noreply.github.com>
Date:   Thu Jul 11 21:46:31 2024 +0800

    [BugFix]: fix engine timeout due to request abort (#6255)
    
    Signed-off-by: yatta zhang <ytzhang01@foxmail.com>
    Signed-off-by: zhangyuntao.dev <zhangyuntao.dev@bytedance.com>
    Co-authored-by: zhangyuntao.dev <zhangyuntao.dev@bytedance.com>

[33mcommit 3963a5335bb4106f2ecd1139527e3568d2151933[m
Author: aniaan <hi@aniaan.dev>
Date:   Thu Jul 11 17:39:07 2024 +0800

    [Misc] refactor(config): clean up unused code (#6320)

[33mcommit c4774eb8418864390341d35103aa747fc411b59c[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Jul 11 00:04:05 2024 -0700

    [Bugfix] Fix snapshot download in serving benchmark (#6318)

[33mcommit fc17110bbef4e78703abffac51133a2fb71e9f79[m
Author: Lim Xiang Yang <xiangyang95@gmail.com>
Date:   Thu Jul 11 12:37:11 2024 +0800

    [BugFix]: set outlines pkg version (#6262)

[33mcommit 439c84581aaf45917c6f77805a3511f1efc052bb[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Thu Jul 11 12:15:29 2024 +0800

    [Doc] Update description of vLLM support for CPUs (#6003)

[33mcommit 99ded1e1c4dc00baa77beae74602ebafe4921176[m
Author: daquexian <daquexian566@gmail.com>
Date:   Thu Jul 11 01:05:26 2024 +0100

    [Doc] Remove comments incorrectly copied from another project (#6286)

[33mcommit 997df46a32f3b2c2debe3e17730895cef0d94d2a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jul 10 16:39:02 2024 -0700

    [Bugfix][Neuron] Fix soft prompt method error in NeuronExecutor (#6313)

[33mcommit ae151d73be479e9c0caa2fdfc30b17f073018ef3[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Wed Jul 10 16:02:47 2024 -0700

    [Speculative Decoding] Enabling bonus token in speculative decoding for KV cache based models (#5765)

[33mcommit 44cc76610d0b23ce5d609867f6dae7e033dee818[m
Author: sangjune.park <park12sj@gmail.com>
Date:   Thu Jul 11 02:03:32 2024 +0900

    [Bugfix] Fix OpenVINOExecutor abstractmethod error (#6296)
    
    Signed-off-by: sangjune.park <sangjune.park@navercorp.com>

[33mcommit b422d4961a3052c5b4bcfc3747a1ad55acfe7eb8[m
Author: Benjamin Muskalla <bmuskalla@github.com>
Date:   Wed Jul 10 16:15:55 2024 +0200

    [CI/Build] Enable mypy typing for remaining folders (#6268)

[33mcommit c38eba304674fdf9da4d881e46f103440e22a153[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Wed Jul 10 15:04:07 2024 +0200

    [Bugfix] MLPSpeculator: Use ParallelLMHead in tie_weights=False case. (#6303)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit e72ae80b06405ea92b703c8979f046d68e970c94[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jul 10 06:03:16 2024 -0700

    [Bugfix] Support 2D input shape in MoE layer (#6287)

[33mcommit 8a924d2248dedb620eb9a32ca5c9f97ab525aaf5[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jul 10 14:55:34 2024 +0800

    [Doc] Guide for adding multi-modal plugins (#6205)

[33mcommit 5ed3505d827658fe4f71f30fecf93a66baabfe26[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jul 9 19:30:56 2024 -0700

    [Bugfix][TPU] Add prompt adapter methods to TPUExecutor (#6279)

[33mcommit da78caecfa7f6137efc3e08388f4db102650ac45[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 9 18:49:11 2024 -0700

    [core][distributed] zmq fallback for broadcasting large objects (#6183)
    
    [core][distributed] add zmq fallback for broadcasting large objects (#6183)

[33mcommit 2416b26e119b9d1932ba30790ecaddfac1ae4143[m
Author: Abhinav Goyal <abhinav.goyal@flipkart.com>
Date:   Wed Jul 10 07:04:02 2024 +0530

    [Speculative Decoding] Medusa Implementation with Top-1 proposer (#4978)

[33mcommit d3a245138acb358c7e1e5c5dcf4dcb3c2b48c8ff[m
Author: Baoyuan Qi <qibaoyuan@126.com>
Date:   Wed Jul 10 07:43:24 2024 +0800

    [Bugfix]fix and needs_scalar_to_array logic check (#6238)
    
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>

[33mcommit 673dd4cae9340e78dd5c05843e41c38133aa29a6[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Tue Jul 9 16:24:58 2024 -0700

    [Docs] Docs update for Pipeline Parallel (#6222)
    
    Signed-off-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 4d6ada947c7e6379b6857bc9a9a1203679d32039[m
Author: Swapnil Parekh <swapnilbp100@gmail.com>
Date:   Tue Jul 9 16:26:36 2024 -0400

    [CORE] Adding support for insertion of soft-tuned prompts (#4645)
    
    Co-authored-by: Swapnil Parekh <swapnilp@ibm.com>
    Co-authored-by: Joe G <joseph.granados@h2o.ai>
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit a0550cbc80f504aa2da80b573c22204f686a0389[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Jul 9 12:56:56 2024 -0700

    Add support for multi-node on CI (#5955)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 08c5bdecae5c5186c39a1d1ff444c3bf01f7fa0e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jul 9 02:56:06 2024 -0700

    [Bugfix][TPU] Fix outlines installation in TPU Dockerfile (#6256)

[33mcommit 5d5b4c5fe524c3b62453bba7ad4434a27c81317a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jul 9 00:21:37 2024 -0700

    [Bugfix][TPU] Add missing None to model input (#6245)

[33mcommit 70c232f85a9e83421a4d9ca95e6384364271f2bc[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 8 21:31:44 2024 -0700

    [core][distributed] fix ray worker rank assignment (#6235)

[33mcommit a3c9435d93fb7609977da5d90f839b9987c8b264[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 8 20:02:15 2024 -0700

    [hardware][cuda] use device id under CUDA_VISIBLE_DEVICES for get_device_capability (#6216)

[33mcommit 4f0e0ea131ef40654faa26fa21196031754df53a[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Jul 8 13:38:03 2024 -0700

    Add FlashInfer to default Dockerfile (#6172)

[33mcommit ddc369fba147046f5044aaddbb867b5333f7068c[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Mon Jul 8 21:25:51 2024 +0300

    [Bugfix] Mamba cache Cuda Graph padding (#6214)

[33mcommit 185ad31f37541ac205b55f446bfd71542f83075a[m
Author: Eric <ericperfectttt@gmail.com>
Date:   Tue Jul 9 02:23:24 2024 +0800

    [Bugfix] use diskcache in outlines _get_guide  #5436  (#6203)

[33mcommit 543aa4857362ff385af8a9f496392b8831c42833[m
Author: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
Date:   Mon Jul 8 13:12:15 2024 -0400

    [Kernel] Correctly invoke prefill & decode kernels for cross-attention (towards eventual encoder/decoder model support) (#4888)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit f7a8fa39d828136d0b8bbdd20c262602e5543ffd[m
Author: Avshalom Manevich <12231371+avshalomman@users.noreply.github.com>
Date:   Mon Jul 8 18:00:38 2024 +0300

    [Kernel] reloading fused_moe config on the last chunk (#6210)

[33mcommit 717f4bcea036a049e86802b3a05dd6f7cd17efc8[m
Author: Haichuan <1778876540@qq.com>
Date:   Mon Jul 8 15:52:06 2024 +0800

    Feature/add benchmark testing (#5947)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 16620f439db1f2cc91b5582b59fc8845cbb02881[m
Author: kczimm <4733573+kczimm@users.noreply.github.com>
Date:   Sun Jul 7 21:32:57 2024 -0500

    do not exclude `object` field in CompletionStreamResponse (#6196)

[33mcommit 3b08fe2b13ced7fe76abe17c99614dd36e4b4788[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Jul 7 15:11:12 2024 -0700

    [misc][frontend] log all available endpoints (#6195)
    
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit abfe705a02160db53f4b0cf90c7b016f04291b9c[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Jul 7 16:42:11 2024 -0400

    [ Misc ] Support Fp8 via `llm-compressor` (#6110)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic>

[33mcommit 333306a252a0ef42ef07b11b64df6ff1ac2e2d6d[m
Author: Haichuan <1778876540@qq.com>
Date:   Sun Jul 7 15:42:13 2024 +0800

    add benchmark for fix length input and output (#5857)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 6206dcb29eb99b3eebf5f00c97a5690c9b7df4f1[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Jul 6 18:25:50 2024 -0700

    [Model] Add PaliGemma (#5189)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 9389380015b80c109b899a08840132780b9b3fc0[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jul 6 17:18:59 2024 +0800

    [Doc] Move guide for multimodal model and other improvements (#6168)

[33mcommit 175c43eca4e6a50e160c386c6668ae4645c0b5d1[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Jul 5 22:59:36 2024 -0700

    [Doc] Reorganize Supported Models by Type (#6167)

[33mcommit bc96d5c330e079fa501eee05e97bf15009c9a094[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 5 17:19:53 2024 -0700

    Move release wheel env var to Dockerfile instead (#6163)

[33mcommit f0250620dd2e33087293cf89b96db854767b939b[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 5 16:24:31 2024 -0700

    Fix release wheel build env var (#6162)

[33mcommit 2de490d60f281c8d4b182bf5551d27c141bd742d[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 5 14:51:25 2024 -0700

    Update wheel builds to strip debug (#6161)

[33mcommit 79d406e9183aa12cdef6f1876eb9a15385662587[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 5 12:44:40 2024 -0700

    [Docs] Fix readthedocs for tag build (#6158)

[33mcommit abad5746a71dc87fb2b1d43cae645dcda79b64a2[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jul 5 12:04:51 2024 -0700

    bump version to v0.5.1 (#6157)

[33mcommit e58294ddf23107d93987c00611d63a20e3cfe771[m
Author: JGSweets <JGSweets@users.noreply.github.com>
Date:   Fri Jul 5 12:41:01 2024 -0500

    [Bugfix] Add verbose error if scipy is missing for blocksparse attention (#5695)

[33mcommit f1e15da6fe20ff17d5b8c28f37487cee38f08b83[m
Author: jvlunteren <161835099+jvlunteren@users.noreply.github.com>
Date:   Fri Jul 5 19:37:09 2024 +0200

    [Frontend] Continuous usage stats in OpenAI completion API (#5742)

[33mcommit 0097bb1829310577262e2a79ae8b498765b39225[m
Author: Christian Rohmann <frittentheke@users.noreply.github.com>
Date:   Fri Jul 5 18:49:47 2024 +0200

    [Bugfix] Use templated datasource in grafana.json to allow automatic imports (#6136)
    
    Signed-off-by: Christian Rohmann <christian.rohmann@inovex.de>

[33mcommit ea4b5704833cb31377bcbc2f00959f6c09909099[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jul 5 13:49:38 2024 +0800

    [VLM] Cleanup validation and update docs (#6149)

[33mcommit a41357e941b81067cd053e94da41adae470990df[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Jul 4 18:29:47 2024 -0700

    [VLM] Improve consistency between feature size calculation and dummy data for profiling (#6146)

[33mcommit ae96ef8fbd6fe8905f8ea0d3a3f9ff1738dbcbe5[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jul 5 07:37:23 2024 +0800

    [VLM] Calculate maximum number of multi-modal tokens by model (#6121)

[33mcommit 69ec3ca14cf3d0b278672196ad6de9875fe95cbb[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Thu Jul 4 16:35:51 2024 -0700

    [Kernel][Model] logits_soft_cap for Gemma2 with flashinfer (#6051)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 81d7a50f2402ef5b622ac8d3a081994a1a4641b0[m
Author: Yuan <yuan.zhou@intel.com>
Date:   Fri Jul 5 06:22:12 2024 +0800

    [Hardware][Intel CPU] Adding intel openmp tunings in Docker file (#6008)
    
    Signed-off-by: Yuan Zhou <yuan.zhou@intel.com>

[33mcommit 27902d42beeeb5828ef3243d5455a3b9af3317b3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jul 4 09:57:09 2024 -0700

    [misc][doc] try to add warning for latest html (#5979)

[33mcommit 56b325e977435af744f8b3dca7af0ca209663558[m
Author: Gregory Shtrasberg <156009573+gshtras@users.noreply.github.com>
Date:   Thu Jul 4 01:19:38 2024 -0400

    [ROCm][AMD][Model]Adding alibi slopes support in ROCm triton flash attention and naive flash attention (#6043)
    
    Co-authored-by: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>

[33mcommit 3dd507083f4d8416d5fed9827e91d22f29b0b723[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jul 4 09:58:18 2024 +0800

    [CI/Build] Cleanup VLM tests (#6107)

[33mcommit 0ed646b7aa3b434b2fcb6f6b6e725570879cb89e[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Wed Jul 3 17:52:29 2024 -0700

    [Distributed][Core] Support Py39 and Py38 for PP (#6120)
    
    Signed-off-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>

[33mcommit 1dab9bc8a9192a6081821c3a6b6c4aee3b7912c3[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed Jul 3 17:56:59 2024 -0600

    [Bugfix] set OMP_NUM_THREADS to 1 by default for multiprocessing (#6109)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 3de6e6a30e33406c2b3bb81fb5a82a2966cebd87[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jul 3 16:40:31 2024 -0700

    [core][distributed] support n layers % pp size != 0 (#6115)

[33mcommit 966fe72141e8365721840b7ababfb78601c23ead[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jul 3 15:52:04 2024 -0700

    [doc][misc] bump up py version in installation doc (#6119)

[33mcommit 62963d129e84d0a0904ee62dbab067a29216e7bf[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Wed Jul 3 18:50:08 2024 -0400

    [ Misc ] Clean Up `CompressedTensorsW8A8` (#6113)

[33mcommit d9e98f42e434d1f1a0f8ceed363047060aca6262[m
Author: xwjiang2010 <87673679+xwjiang2010@users.noreply.github.com>
Date:   Wed Jul 3 15:14:16 2024 -0700

    [vlm] Remove vision language config. (#6089)
    
    Signed-off-by: Xiaowei Jiang <xwjiang2010@gmail.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 3c6325f0fcfc46e573a107c9435abba6b6a617e8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jul 3 14:41:32 2024 -0700

    [core][distributed] custom allreduce when pp size > 1 (#6117)

[33mcommit 47f0954af0a5aefd0db19875f6bdcbe933d055a9[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jul 3 13:38:00 2024 -0400

    [Kernel] Expand FP8 support to Ampere GPUs using FP8 Marlin (#5975)

[33mcommit 7cd2ebb0251fd1fd0eec5c93dac674603a22eddd[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Jul 3 00:32:35 2024 -0700

    [Bugfix] Fix `compute_logits` in Jamba (#6093)

[33mcommit f1c78138aa28e58eeaafa4791788fe6ceddf1dd8[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Jul 3 00:13:56 2024 -0700

    [Doc] Fix Mock Import (#6094)

[33mcommit 3a86b54fb00bde01da2680bf3cfd989b6b21511c[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jul 2 23:41:23 2024 -0700

    [VLM][Frontend] Proper Image Prompt Formatting from OpenAI API (#6091)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit f666207161e5ecc2cd6ebab93c5a62cf44f30641[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 2 23:37:29 2024 -0700

    [misc][distributed] error on invalid state (#6092)

[33mcommit d830656a9722bfc719426ce6bdd13b3d9d456304[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Jul 2 23:09:40 2024 -0700

    [BugFix] Avoid unnecessary Ray import warnings (#6079)

[33mcommit d18bab3587e6804aaa74f93fb1d55ab5766f75a3[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Wed Jul 3 13:31:25 2024 +0900

    [CI] Fix base url doesn't strip "/" (#6087)

[33mcommit 9831aec49fd541a8fe6cb65f0c3a65b03eccffe0[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jul 3 11:34:00 2024 +0800

    [Core] Dynamic image size support for VLMs (#5276)
    
    Signed-off-by: Xiaowei Jiang <xwjiang2010@gmail.com>
    Co-authored-by: Xiaowei Jiang <xwjiang2010@gmail.com>
    Co-authored-by: ywang96 <ywang@roblox.com>
    Co-authored-by: xwjiang2010 <87673679+xwjiang2010@users.noreply.github.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit 482045ee77a49d69ab9464d9d727960890d950f1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jul 2 20:12:22 2024 -0700

    [hardware][misc] introduce platform abstraction (#6080)

[33mcommit 9d6a8daa87e2e0af3ff45d03d08ad5a94ec089a8[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Wed Jul 3 02:11:29 2024 +0300

    [Model] Jamba support (#4115)
    
    Signed-off-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>
    Co-authored-by: Erez Schwartz <erezs@ai21.com>
    Co-authored-by: Mor Zusman <morz@ai21.com>
    Co-authored-by: tomeras91 <57313761+tomeras91@users.noreply.github.com>
    Co-authored-by: Tomer Asida <tomera@ai21.com>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>
    Co-authored-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>

[33mcommit ee93f4f92acbd9759a9af80747bc2a4459f07639[m
Author: Qubitium-ModelCloud <qubitium@modelcloud.ai>
Date:   Wed Jul 3 06:25:17 2024 +0800

    [CORE] Quantized lm-head Framework (#4442)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic.com>
    Co-authored-by: ZX <zx@lbx.dev>

[33mcommit 7c008c51a9aa4c0d53d09ab3a1ba61ecec354565[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Tue Jul 2 17:54:35 2024 -0400

    [ Misc ] Refactor MoE to isolate Fp8 From Mixtral (#5970)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 4d26d806e1eeff9f90351008e8e36bcf0d35678f[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Tue Jul 2 16:14:22 2024 -0400

    Update conftest.py (#6076)

[33mcommit c5832d2ae9431a1672d547c232ec46b1a9051ff0[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Tue Jul 2 10:58:08 2024 -0700

    [Core] Pipeline Parallel Support (#4412)
    
    Signed-off-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>

[33mcommit 15aba081f33e6d048422df6dcdb94301d08d13e6[m
Author: Sirej Dua <sirejdua@gmail.com>
Date:   Tue Jul 2 07:20:29 2024 -0700

    [Speculative Decoding] MLPSpeculator Tensor Parallel support (1/2) (#6050)
    
    Co-authored-by: Sirej Dua <sirej.dua@databricks.com>
    Co-authored-by: Sirej Dua <Sirej Dua>

[33mcommit 31354e563f077888ff1efb8ba4dad530cbdadd32[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jul 2 18:53:16 2024 +0800

    [Doc] Reinstate doc dependencies (#6061)

[33mcommit 98d6682cd1f27fa48bf915d3fd3e1eb1ee3014c4[m
Author: xwjiang2010 <87673679+xwjiang2010@users.noreply.github.com>
Date:   Tue Jul 2 00:57:09 2024 -0700

    [VLM] Remove `image_input_type` from VLM config (#5852)
    
    Signed-off-by: Xiaowei Jiang <xwjiang2010@gmail.com>
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 2c37540aa6af89f0ece874d831dff3bf62edf486[m
Author: danieljannai21 <100521221+danieljannai21@users.noreply.github.com>
Date:   Tue Jul 2 09:01:57 2024 +0300

    [Frontend] Add template related params to request (#5709)

[33mcommit 3476ed0809ec91a3457da0cb90543133a4f4b519[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Mon Jul 1 23:10:37 2024 -0400

    [Core] Optimize block_manager_v2 vs block_manager_v1 (to make V2 default)  (#5602)

[33mcommit 54600709b6d419fb243ce718a48ab7d40f5c3eb7[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Tue Jul 2 01:40:02 2024 +0200

    [Model] Changes to MLPSpeculator to support tie_weights and input_scale (#5965)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>
    Co-authored-by: Joshua Rosenkranz <jmrosenk@us.ibm.com>

[33mcommit e373853e12c890964e21fa0ac9b46fee48fa7c76[m
Author: James Whedbee <jamesw@telnyx.com>
Date:   Mon Jul 1 18:39:10 2024 -0500

    [Frontend] Relax api url assertion for openai benchmarking (#6046)

[33mcommit c87ebc3ef9ae6e8d6babbca782510ff924b3abc7[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Jul 1 16:17:58 2024 -0700

    [BugFix] Ensure worker model loop is always stopped at the right time (#5987)

[33mcommit c4059ea54ff36e62b03f1a88baa41ca72dc695e4[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Jul 1 16:08:58 2024 -0700

    [Bugfix] Add explicit `end_forward` calls to flashinfer (#6044)

[33mcommit 8e0817c262da5c104f651a0ce4ac9ee0cd76f4ce[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jul 1 15:09:11 2024 -0700

    [Bugfix][Doc] Fix Doc Formatting (#6048)

[33mcommit 83bdcb6ac32f22f20fd3a60ba67064a0b462801d[m
Author: ning.zhang <10524065+llmpros@users.noreply.github.com>
Date:   Mon Jul 1 14:11:36 2024 -0700

    add FAQ doc under 'serving' (#5946)

[33mcommit 12a59959ed3a78a50f9b48b0ec6ccd6c862b22b4[m
Author: Avshalom Manevich <12231371+avshalomman@users.noreply.github.com>
Date:   Tue Jul 2 00:08:29 2024 +0300

    [Bugfix] adding chunking mechanism to fused_moe to handle large inputs (#6029)

[33mcommit dec6fc6f3bc56a487af4d8d23e18dd227360ef98[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Jul 1 13:12:40 2024 -0700

    [Bugfix] Use RayActorError for older versions of Ray in  RayTokenizerGroupPool (#6039)

[33mcommit 8893130b63e6b2778b5d3db4dbc83ff6206ba44a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 1 10:50:56 2024 -0700

    [doc][misc] further lower visibility of simple api server (#6041)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit bb6032683687b817b026a38c5a8729c2cd861246[m
Author: zhyncs <me@zhyncs.com>
Date:   Tue Jul 2 01:20:33 2024 +0800

    [Misc] update benchmark backend for scalellm (#6018)

[33mcommit 4050d646e5221a516c93384b047e10b22d7167e7[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jul 1 09:52:43 2024 -0700

    [doc][misc] remove deprecated api server in doc (#6037)

[33mcommit d76084c12f0400a8f8364883a841405c903b61f6[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Mon Jul 1 12:40:45 2024 -0400

    [ CI ] Re-enable Large Model LM Eval (#6031)

[33mcommit 80ca1e6a3a28a0373dc00c5b4fe956c16de952fa[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Mon Jul 1 00:33:05 2024 -0700

    [Speculative Decoding 2/2 ] Integrate typical acceptance sampler into Spec Decode Worker (#5348)

[33mcommit 614aa5120303ab09be78fb1db669da198cc43b02[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Jun 30 20:07:34 2024 -0700

    [misc][cuda] use nvml to avoid accidentally cuda initialization (#6007)

[33mcommit af9ad46fca6e594797b83e5ecb2e1f31ca5e9fac[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Jun 30 19:06:27 2024 -0400

    [ Misc ] Refactor w8a8 to use `process_weights_after_load` (Simplify Weight Loading) (#5940)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic>

[33mcommit 7836fdcc11aef8c4494a4470522c685c2190eddc[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Sun Jun 30 16:15:16 2024 -0400

    [Misc] Fix `get_min_capability` (#5971)

[33mcommit deacb7ec44cd816648eb856959472f1fef01f883[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun Jun 30 14:56:56 2024 -0400

    [ CI ] Temporarily Disable Large LM-Eval Tests (#6005)
    
    Co-authored-by: rshaw@neuralmagic.com <rshaw@neuralmagic>

[33mcommit f5e73c9f1bfcffdac4ec97f038443c053ee6fed8[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Mon Jul 1 02:11:15 2024 +0900

    [Lora] Use safetensor keys instead of adapter_config.json to find unexpected modules.  (#5909)
    
    Co-authored-by: sang <sangcho@anyscale.com>

[33mcommit c6c240aa0a2d4bed821282a07d50f6710cd99eed[m
Author: llmpros <10524065+llmpros@users.noreply.github.com>
Date:   Sun Jun 30 08:53:00 2024 -0700

    [Frontend]: Support base64 embedding (#5935)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 2be6955a3fd596b33be92a2927f55ee0779a4690[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Jun 30 01:06:13 2024 -0700

    [ci][distributed] fix device count call
    
    [ci][distributed] fix some cuda init that makes it necessary to use spawn (#5991)

[33mcommit 9d47f64eb6f35e42840b1e4ca6dc68167014abcd[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Jun 30 12:58:49 2024 +0800

    [CI/Build] [3/3] Reorganize entrypoints tests (#5966)

[33mcommit cff6a1fec15dba524c162d20a4e8de4df2b0a3d5[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun Jun 30 11:44:25 2024 +0800

    [CI/Build] Reuse code for checking output consistency (#5988)

[33mcommit bcc6a09b63aeb3efce964b54a756d431e580aebc[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat Jun 29 18:18:31 2024 -0700

    [CI/Build] Temporarily Remove Phi3-Vision from TP Test (#5989)

[33mcommit 9def10664e8b54dcc5c6114f2895bc9e712bf182[m
Author: Matt Wong <156021403+mawong-amd@users.noreply.github.com>
Date:   Sat Jun 29 14:47:58 2024 -0500

    [Bugfix][CI/Build][Hardware][AMD] Install matching torchvision to fix AMD tests (#5949)

[33mcommit 75aa1442dbc76c43804e8dd528eff1aae3b45d1e[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Jun 29 13:04:30 2024 -0400

    [ CI/Build ] LM Eval Harness Based CI Testing (#5838)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic>

[33mcommit 99397da5349226c553debfd37469a6de724d3f24[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jun 29 23:45:54 2024 +0800

    [CI/Build] Add TP test for vision models (#5892)

[33mcommit 8dbfcd35bf2313dedc9e947a991b6e0044248589[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Jun 29 09:12:58 2024 -0400

    [ CI/Build ] Added E2E Test For Compressed Tensors (#5839)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>
    Co-authored-by: Robert Shaw <rshaw@neuralmagic>

[33mcommit f7dac83d95ae38973b425a8bb2d3a3df9fe9a9c2[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Sat Jun 29 06:04:20 2024 -0700

    [Kernel] Raise an exception in MoE kernel if the batch size is larger then 65k (#5939)

[33mcommit 7c01f706418d593b3cf23d2ec9110dca7151c539[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Sat Jun 29 05:47:53 2024 -0700

    [Core] Optimize `SequenceStatus.is_finished` by switching to IntEnum (#5974)

[33mcommit 51e971d39e1272f1c5b070a5da6b38ccfa92fc14[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jun 29 19:19:02 2024 +0800

    [Bugfix] Support `eos_token_id` from `config.json` (#5954)

[33mcommit 329df38f1a931215062d7b43660ceee1f83c0ab5[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Jun 28 23:34:29 2024 -0700

    [Misc] Update Phi-3-Vision Example (#5981)
    
    Co-authored-by: Cyrus Leung <cyrus.tl.leung@gmail.com>

[33mcommit 580353da93ee0d96a19964241e16f92e6a6d6142[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jun 28 20:10:21 2024 -0700

    [Bugfix] Fix precisions in Gemma 1 (#5913)

[33mcommit ba4994443afc6a8249ed726c5ebd09b2c57a3b00[m
Author: Joe Runde <joe@joerun.de>
Date:   Fri Jun 28 20:48:25 2024 -0600

    [Kernel] Add punica dimensions for Granite 3b and 8b (#5930)
    
    Signed-off-by: Joe Runde <joe@joerun.de>

[33mcommit 906a19cdb06b390f3dde287b06a3fe26c03a45e5[m
Author: William Lin <SolitaryThinker@users.noreply.github.com>
Date:   Fri Jun 28 19:36:06 2024 -0700

    [Misc] Extend vLLM Metrics logging API (#5925)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit c4bca740e8498987184466d2f85ed43f1e1feb80[m
Author: mcalman <68564154+mcalman@users.noreply.github.com>
Date:   Fri Jun 28 22:34:42 2024 -0400

    [Bugfix] fix missing last itl in openai completions benchmark (#5926)

[33mcommit 7f83f40dee2e92ff005d44a262a3cf42c87c2082[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jun 28 18:55:17 2024 -0700

    [Bugfix][TPU] Fix pad slot id (#5977)

[33mcommit 54814fd85b5182fc140febfebbb2560420d2ed2a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jun 28 18:14:16 2024 -0700

    [Bugfix][TPU] Fix TPU sampler output (#5978)

[33mcommit 7041de43849fda7c8e931f0726f3db2a0d8015a4[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Fri Jun 28 15:28:49 2024 -0700

    [Kernel] Flashinfer for prefill & decode, with Cudagraph support for decode (#4628)
    
    Co-authored-by: LiuXiaoxuanPKU <llilyliupku@gmail.com>, bong-furiosa <bongwon.jang@furiosa.ai>

[33mcommit 6a62cb82ccace1209f7b8bbec95025e047a95ded[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jun 28 17:46:30 2024 -0400

    [Bugfix] Fix Engine Failing After Invalid Request - AsyncEngineDeadError (#5963)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic>

[33mcommit 5d2a1a9cf0f47ac4f1676c17a835a05d4b4e4175[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Jun 28 17:34:56 2024 -0400

    Unmark more files as executable (#5962)

[33mcommit 4bf35ed9ae3cb2ee2efd8f5b9ced620ca9836240[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Jun 28 17:12:40 2024 -0400

    [Bugfix] Only add `Attention.kv_scale` if kv cache quantization is enabled (#5936)

[33mcommit be0b3af9e068418726fa2b1dccef966e39024fd5[m
Author: wangding zeng <155410488+zwd003@users.noreply.github.com>
Date:   Sat Jun 29 04:24:57 2024 +0800

    Support Deepseek-V2 (#4650)
    
    Co-authored-by: Philipp Moritz <pcmoritz@gmail.com>

[33mcommit 2cd402e1692417b7645e4ece11bc2ab91072f47c[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jun 28 14:43:49 2024 -0400

    [ Bugfix ] Enabling Loading Models With Fused QKV/MLP on Disk with FP8 (#5921)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic>

[33mcommit b185230744ae36a612527a9864c27f685acc6ef3[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jun 28 13:49:57 2024 -0400

    [ Misc ] Remove `fp8_shard_indexer` from Col/Row Parallel Linear (Simplify Weight Loading) (#5928)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic>

[33mcommit 6a2d659d28a9f9f3edbfbae138915d147a9fe79c[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Jun 28 13:10:34 2024 -0400

    [Bugfix] Fix compute datatype for cutlass 3.x epilogues (#5931)

[33mcommit b2c620230a6efdc590b06b10f8e89f42362a150a[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Jun 28 09:17:51 2024 -0700

    [Spec Decode] Introduce DraftModelRunner (#5799)

[33mcommit b90d8cd832669b9ad7c48cd9a431e80836778b56[m
Author: xwjiang2010 <87673679+xwjiang2010@users.noreply.github.com>
Date:   Fri Jun 28 08:20:22 2024 -0700

    [Distributed] Make it clear that % should not be in tensor dict keys. (#5927)
    
    Signed-off-by: Xiaowei Jiang <xwjiang2010@gmail.com>

[33mcommit 3b752a6555a67bb4863ea821fc30fdda38b27355[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jun 28 22:59:18 2024 +0800

    [CI/Build] [2/3] Reorganize entrypoints tests (#5904)

[33mcommit ec1ad0046c6cf356443ff05a63f88a8d650844df[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Fri Jun 28 16:42:17 2024 +0200

    [Bugfix] Better error message for MLPSpeculator when `num_speculative_tokens` is set too high (#5894)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 57f09a419c04ecec4718ea9d5be1e6f4a8cc336e[m
Author: Ilya Lavrenov <ilya.lavrenov@intel.com>
Date:   Fri Jun 28 17:50:16 2024 +0400

    [Hardware][Intel] OpenVINO vLLM backend (#5379)

[33mcommit 593263440967a8065d528acb3ff88274fc22c778[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Jun 28 09:36:12 2024 -0400

    Unmark fused_moe config json file as executable (#5960)

[33mcommit 5cbe8d155c33a75934782019c06860467a3efa97[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jun 28 20:09:56 2024 +0800

    [Core] Registry for processing model inputs (#5214)
    
    Co-authored-by: ywang96 <ywang@roblox.com>

[33mcommit 0d0e3a42ac80eb41fc50f139fe31fde8e0b5bf8e[m
Author: Isotr0py <2037008807@qq.com>
Date:   Fri Jun 28 20:03:41 2024 +0800

    [Bugfix][Hardware][Intel CPU] Fix unpassed multi_modal_kwargs for CPU runner (#5956)

[33mcommit 74d55c065b104f816fca9c177e044415802796a1[m
Author: xwjiang2010 <87673679+xwjiang2010@users.noreply.github.com>
Date:   Fri Jun 28 00:29:13 2024 -0700

    [VLM][BugFix] Make sure that `multi_modal_kwargs` can broadcast properly with ring buffer. (#5905)
    
    Signed-off-by: Xiaowei Jiang <xwjiang2010@gmail.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit f136da15e154b25c7eb3221772a85a15811f0318[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jun 27 21:12:13 2024 -0700

    [Hardware][TPU] Optimize KV cache swapping (#5878)

[33mcommit c3dde367f16111b8968948a1f8e1a26bdac6ffdd[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Thu Jun 27 15:41:08 2024 -0500

    [Kernel][ROCm][AMD] fused_moe Triton configs v2 for mi300X (#5932)

[33mcommit 64e8d2a783ac976f1b8e84a795f6a607820d6485[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jun 27 13:34:55 2024 -0700

    [core][misc] remove logical block (#5882)

[33mcommit 79c92c7c8aa6a881421e2007ab216a819f61bc9b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jun 27 13:33:56 2024 -0700

    [Model] Add Gemma 2 (#5908)

[33mcommit 736ed388492c5c10deb7522637a94c041f163f48[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Jun 27 11:43:04 2024 -0700

    [CI/Build] Fix Args for `_get_logits_warper` in Sampler Test (#5922)

[33mcommit 365791ff81181d0d08b719cc6ff976889f6e3288[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Jun 27 11:31:11 2024 -0700

    [BugFix] Fix `min_tokens` behaviour for multiple eos tokens (#5849)

[33mcommit 691e29ecf356d2646f74c622d957ec43dbf95c3a[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Jun 27 10:59:33 2024 -0700

    [BugFix] Fix `MLPSpeculator` handling of `num_speculative_tokens` (#5876)

[33mcommit 3fd02bda51ee7cf07e0375994ac1f34b6d1b981b[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jun 27 10:07:07 2024 -0700

    [doc][misc] add note for Kubernetes users (#5916)

[33mcommit 98cf2ed678580326ffc39c987304c61cb0ce4981[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jun 28 00:08:10 2024 +0800

    [Model][Bugfix] Implicit model flags and reenable Phi-3-Vision (#5896)

[33mcommit e9d32d077da2f914c965a66dd2fdfc77c50d117f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jun 27 20:43:17 2024 +0800

    [CI/Build] [1/3] Reorganize entrypoints tests (#5526)

[33mcommit 2061f0b8a7f1a01683c4045096a092eedf6387a4[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Jun 27 01:29:24 2024 -0700

    [Bugfix] Fix img_sizes Parsing in Phi3-Vision (#5888)

[33mcommit 96354d6a2967a63eb5c0e56a2da2ead512ff1067[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jun 27 16:03:04 2024 +0800

    [Model] Add base class for LoRA-supported models (#5018)

[33mcommit d12af207d24fda5ba6cea08caa1073f9d4413938[m
Author: xwjiang2010 <87673679+xwjiang2010@users.noreply.github.com>
Date:   Thu Jun 27 00:15:24 2024 -0700

    [VLM][Bugfix] Make sure that `multi_modal_kwargs` is broadcasted properly (#5880)
    
    Signed-off-by: Xiaowei Jiang <xwjiang2010@gmail.com>

[33mcommit 6eabc6cb0e022a3f57fbf115ce53dc8bcba66840[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jun 27 14:20:01 2024 +0800

    [Doc] Add note about context length in Phi-3-Vision example (#5887)

[33mcommit 2110557dabe8a18b811116c1ae9fdf75fbe27df6[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Jun 26 21:12:10 2024 -0700

    [BugFix] Fix cuda graph for MLPSpeculator (#5875)
    
    Co-authored-by: Abhinav Goyal <abhinav.goyal@flipkart.com>

[33mcommit b9e84259e9083fe6a157ac0cf4834d89afcbaa6a[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Jun 26 17:57:16 2024 -0700

    [Misc] Add example for LLaVA-NeXT (#5879)

[33mcommit 294104c3f9ab471d2d571b6a6eda266af3824d6a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jun 26 14:57:12 2024 -0700

    [doc] update usage of env var to avoid conflict (#5873)

[33mcommit 38a1674abbba38344543170cb552e88e7f619167[m
Author: Chip Kerchner <49959681+ChipKerchner@users.noreply.github.com>
Date:   Wed Jun 26 17:53:04 2024 -0400

    Support CPU inference with VSX PowerPC ISA (#5652)

[33mcommit f5c8628fdc78bf9ca70206ef41175030fb67e870[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 26 13:42:40 2024 -0700

    [Bugfix][TPU] Fix CPU cache allocation (#5869)

[33mcommit cbc53b6b8d87b29949ce13d504750f63714df532[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 26 11:07:49 2024 -0700

    [Hardware][TPU] Support parallel sampling & Swapping (#5855)

[33mcommit c54269d967f2546868d9a52a10c110adc8f9822a[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Wed Jun 26 16:54:22 2024 +0000

    [Frontend] Add tokenize/detokenize endpoints (#5054)

[33mcommit 5bfd1bbc9831fed39632f071f16bb62373ec1249[m
Author: Luka Govediƒç <ProExpertProg@users.noreply.github.com>
Date:   Wed Jun 26 11:16:00 2024 -0400

    [Kernel] Adding bias epilogue support for `cutlass_scaled_mm` (#5560)
    
    Co-authored-by: Chih-Chieh-Yang <7364402+cyang49@users.noreply.github.com>
    Co-authored-by: Lucas Wilkinson <lwilkinson@neuralmagic.com>

[33mcommit 6984c02a2735d4d08426d2c426c34b6d73bee89e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jun 26 16:02:34 2024 +0800

    [CI/Build] Refactor image test assets (#5821)

[33mcommit 3439c5a8e3a1cdab9bf7c4430455ace06be1f28d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 26 00:58:23 2024 -0700

    [Bugfix][TPU] Fix KV cache size calculation (#5860)

[33mcommit 6806998bf9c7f24d710d9017c901e9e9a30757d5[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 26 00:15:22 2024 -0700

    [Bugfix] Fix embedding to support 2D inputs (#5829)

[33mcommit 515080ad2fd93cc8e363ff43b90a9df18cfd71ff[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jun 25 21:56:02 2024 -0700

    [bugfix][distributed] fix shm broadcast when the queue size is full (#5801)

[33mcommit 3aa7b6cf66890c042ebecf9e8094f4f5e3dbf96e[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jun 25 20:34:25 2024 -0700

    [Misc][Doc] Add Example of using OpenAI Server with VLM (#5832)

[33mcommit dda4811591fdb90d263bc9b8ac522436369aef13[m
Author: Stephanie Wang <swang@cs.berkeley.edu>
Date:   Tue Jun 25 20:30:03 2024 -0700

    [Core] Refactor Worker and ModelRunner to consolidate control plane communication (#5408)
    
    Signed-off-by: Stephanie Wang <swang@cs.berkeley.edu>
    Signed-off-by: Stephanie <swang@anyscale.com>
    Co-authored-by: Stephanie <swang@anyscale.com>

[33mcommit 82079729ccd0830ce77fcc5fd7ea2be3bf81ccaf[m
Author: aws-patlange <90803007+aws-patlange@users.noreply.github.com>
Date:   Tue Jun 25 19:52:10 2024 -0700

    [Bugfix] Fix assertion in NeuronExecutor (#5841)

[33mcommit c2a8ac75e03aec19dad397a8e64377d37c67239a[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Wed Jun 26 01:04:08 2024 +0100

    [CI/Build] Add E2E tests for MLPSpeculator (#5791)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit f178e56c68d97e3a29a8a885a09dd61f8d534732[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jun 25 16:58:23 2024 -0700

    [Hardware][TPU] Raise errors for unsupported sampling params (#5850)

[33mcommit dd793d1de59b5efad25f4794b68cb935824c7a11[m
Author: Matt Wong <156021403+mawong-amd@users.noreply.github.com>
Date:   Tue Jun 25 17:56:15 2024 -0500

    [Hardware][AMD][CI/Build][Doc] Upgrade to ROCm 6.1, Dockerfile improvements, test fixes (#5422)

[33mcommit bc34937d68e9715d8416457539fb528301cf6269[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jun 25 15:25:52 2024 -0700

    [Hardware][TPU] Refactor TPU backend (#5831)

[33mcommit dd248f76756adba4a1637b882e79ab639f957feb[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Jun 25 15:23:35 2024 -0400

    [Misc] Update `w4a16` `compressed-tensors` support to include `w8a16` (#5794)

[33mcommit d9b34baeddc7f48a526dc610429a3c8670b3b339[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Jun 25 15:18:03 2024 -0400

    [CI/Build] Add unit testing for FlexibleArgumentParser (#5798)

[33mcommit c18ebfdd71d16eb18617676b0b1d82ebde0027f0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jun 25 12:10:28 2024 -0700

    [doc][distributed] add both gloo and nccl tests (#5834)

[33mcommit 67882dbb44186d781ab6db9eaec08f6616dc86bd[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Jun 25 10:15:10 2024 -0700

    [Core] Add fault tolerance for `RayTokenizerGroupPool` (#5748)

[33mcommit 7b993143014c95844b380a5b05eebd14ad77b7aa[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Wed Jun 26 00:41:36 2024 +0800

    [Misc] Remove useless code in cpu_worker (#5824)

[33mcommit 2ce5d6688bae64e467640b05e73af2888e93afcf[m
Author: Woo-Yeon Lee <wooyeonlee0@gmail.com>
Date:   Tue Jun 25 18:56:06 2024 +0900

     [Speculative Decoding] Support draft model on different tensor-parallel size than target model (#5414)

[33mcommit f23871e9eead900d6146961ca894f5bc91f30f5e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jun 25 16:25:03 2024 +0800

    [Doc] Add notice about breaking changes to VLMs (#5818)

[33mcommit e9de9dd551ac595a9f3825fcd1507deceef4f332[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Jun 24 21:09:02 2024 -0700

    [ci] Remove aws template (#5757)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit ba991d5c84adbc0685075af88333c688ddb06011[m
Author: Chang Su <chang.s.su@oracle.com>
Date:   Mon Jun 24 16:01:19 2024 -0700

    [Bugfix] Fix FlexibleArgumentParser replaces _ with - for actual args (#5795)

[33mcommit 1744cc99ba9bdefea8f3f798cf51ed650b81a98e[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Jun 24 13:48:55 2024 -0400

    [Doc] Add Phi-3-medium to list of supported models (#5788)

[33mcommit e72dc6cb3507d914eec8dfd0d5c7b9478f6a8ccc[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Jun 24 13:26:17 2024 -0400

    [Doc] Add "Suggest edit" button to doc pages (#5789)

[33mcommit c2462129521a64b62ace77b28641d2e3bec5831c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jun 24 00:37:42 2024 -0700

    [doc][faq] add warning to download models for every nodes (#5783)

[33mcommit edd5fe5fa29b8f9cc5fa37a30cc7211e0ff37067[m
Author: Isotr0py <2037008807@qq.com>
Date:   Mon Jun 24 12:11:53 2024 +0800

    [Bugfix] Add phi3v resize for dynamic shape and fix torchvision requirement (#5772)

[33mcommit 5d4d90536fa24c032bb91ae629b7b4958e045b03[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Sun Jun 23 17:42:28 2024 -0400

    [Distributed] Add send and recv helpers (#5719)

[33mcommit 6c916ac8a80d1b2f4e0d0113a67767dc254a3598[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Mon Jun 24 02:37:11 2024 +0530

    [BugFix] [Kernel] Add Cutlass2x fallback kernels (#5744)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 832ea88fcb4819037b685fb47b3a0de37f2804d3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Jun 22 10:00:43 2024 -0700

    [core][distributed] improve shared memory broadcast (#5754)

[33mcommit 8c00f9c15d13aed34b129b31c32a227be230e218[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jun 21 23:09:40 2024 -0700

    [Docs][TPU] Add installation tip for TPU (#5761)

[33mcommit 0cbc1d2b4ff9e3afa32ffd2d5d308c136c2d15e3[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jun 21 22:25:14 2024 -0700

    [Bugfix] Fix pin_lora error in TPU executor (#5760)

[33mcommit ff9ddbceee63efba6ba1f8d4dc66a92f1191da04[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Fri Jun 21 20:33:12 2024 -0700

    [Misc] Remove #4789 workaround left in vllm/entrypoints/openai/run_batch.py (#5756)

[33mcommit 9c62db07ed8ee28d9f1a0e6ac215446d49532008[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Sat Jun 22 10:07:08 2024 +0800

    [Model] Support Qwen-VL and Qwen-VL-Chat models with text-only inputs (#5710)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit cf90ae01237018f70573f69c599d26648ff7740b[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Sat Jun 22 08:09:34 2024 +0800

    [CI][Hardware][Intel GPU] add Intel GPU(XPU) ci pipeline (#5616)

[33mcommit f5dda63eb5fcb5624b93fa5f09da01d5372bbce4[m
Author: rohithkrn <rohith.nallamaddi@gmail.com>
Date:   Fri Jun 21 15:42:46 2024 -0700

    [LoRA] Add support for pinning lora adapters in the LRU cache (#5603)

[33mcommit 7187507301aa8361407e04be42d0d50680891493[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jun 21 14:04:26 2024 -0700

    [ci][test] fix ca test in main (#5746)

[33mcommit f1e72cc19a21928400b63743d5fe164ec8ed30e8[m
Author: zhyncs <me@zhyncs.com>
Date:   Sat Jun 22 03:15:48 2024 +0800

    [BugFix] exclude version 1.15.0 for modelscope (#5668)

[33mcommit 5b15bde5399cbcb1052bfb49584f81ed300cd4ac[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri Jun 21 12:44:29 2024 -0400

    [Doc] Documentation on supported hardware for quantization methods (#5745)

[33mcommit bd620b01fb74d5269ca6fc0fd32f66bfb205a358[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Jun 20 23:39:40 2024 -0700

    [Kernel][CPU] Add Quick `gelu` to CPU (#5717)

[33mcommit d9a252bc8e8a2741d8a2997032a94208fb8f29d9[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jun 20 22:12:35 2024 -0700

    [Core][Distributed] add shm broadcast (#5399)
    
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 67005a07bc0991211ba2acccb3e56c72a47f9def[m
Author: Jee Li <pandaleefree@163.com>
Date:   Fri Jun 21 12:46:28 2024 +0800

    [Bugfix] Add  fully sharded layer for QKVParallelLinearWithLora (#5665)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit c35e4a3dd74fa5952b04354a3c7cfd0ed09e2eb0[m
Author: Chang Su <chang.s.su@oracle.com>
Date:   Thu Jun 20 21:45:34 2024 -0700

    [BugFix] Fix test_phi3v.py (#5725)

[33mcommit 1f5674218f968dec625d0995fe5cd5d626db9188[m
Author: Jinzhen Lin <linjinzhen@hotmail.com>
Date:   Fri Jun 21 08:55:41 2024 +0800

    [Kernel] Add punica dimension for Qwen2 LoRA (#5441)

[33mcommit b12518d3cf4326dfcd10a09780913b86c19fcf1a[m
Author: Joshua Rosenkranz <joshua.rosenkranz@gmail.com>
Date:   Thu Jun 20 20:23:12 2024 -0400

    [Model] MLPSpeculator speculative decoding support (#4947)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>
    
    Co-authored-by: Thomas Parnell <tpa@zurich.ibm.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>
    Co-authored-by: Davis Wertheimer <Davis.Wertheimer@ibm.com>

[33mcommit 6c5b7af1525a2013d7b1806dd6c0c9a53404be6d[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jun 20 17:06:34 2024 -0700

    [distributed][misc] use fork by default for mp (#5669)

[33mcommit 8065a7e220cca1dd53107da85b6f3932ac9e25e8[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Jun 20 19:00:13 2024 -0400

    [Frontend] Add FlexibleArgumentParser to support both underscore and dash in names (#5718)

[33mcommit 3f3b6b21500bce2061cae33706bd47c8b6663771[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Jun 20 14:36:10 2024 -0400

    [Bugfix] Fix the CUDA version check for FP8 support in the CUTLASS kernels (#5715)

[33mcommit a7dcc62086ea751b46b4821c2811cf8ac83711bf[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Thu Jun 20 19:03:21 2024 +0530

    [Kernel] Update Cutlass int8 kernel configs for SM80 (#5275)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit ad137cd1112ab9b17ac36fc123fc7806a1d7473d[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Jun 20 04:52:09 2024 -0700

    [Model] Port over CLIPVisionModel for VLMs (#5591)

[33mcommit 111af1fa2c4fdb2d83b466935a327b1a5009874a[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Thu Jun 20 12:07:08 2024 +0530

    [Kernel] Update Cutlass int8 kernel configs for SM90 (#5514)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 1b2eaac3165dc78d4ef51231722735ca9cf37304[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Jun 19 23:10:47 2024 -0700

    [Bugfix][Doc] FIx Duplicate Explicit Target Name Errors (#5703)

[33mcommit 3730a1c832bca5ca8128aec3c7659304895edf2e[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jun 20 10:09:21 2024 +0800

    [Misc] Improve conftest (#5681)

[33mcommit 949e49a6857080e36ecd62f6e193754290c7c43c[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Jun 19 16:30:03 2024 -0700

    [ci] Limit num gpus if specified for A100 (#5694)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 4a30d7e3ccae6e977d728e2157aaa11ac0fed549[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Wed Jun 19 18:06:44 2024 -0400

    [Misc] Add per channel support for static activation quantization; update w8a8 schemes to share base classes (#5650)

[33mcommit e83db9e7e3d776cd9b059a49024f3950ef579b41[m
Author: Rafael Vasquez <rafvasq21@gmail.com>
Date:   Wed Jun 19 18:01:45 2024 -0400

    [Doc] Update docker references (#5614)
    
    Signed-off-by: Rafael Vasquez <rafvasq21@gmail.com>

[33mcommit 78687504f7eb6d7523bff15b1bca8c9cbb74656a[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Wed Jun 19 13:57:12 2024 -0700

    [Bugfix] AsyncLLMEngine hangs with asyncio.run (#5654)

[33mcommit d571ca010813c5532c646ee74c1a2c9e1e78e12a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jun 19 13:16:04 2024 -0700

    [ci][distributed] add tests for custom allreduce (#5689)

[33mcommit afed90a0344b1b0ce6aae46efc630adb489ec769[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jun 19 14:41:42 2024 -0400

    [Frontend][Bugfix] Fix preemption_mode -> preemption-mode for CLI arg in arg_utils.py (#5688)

[33mcommit 3ee5c4bca514ee95592a018fae95e050fd6763c0[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Jun 19 07:42:13 2024 -0700

    [ci] Add A100 queue into AWS CI template (#5648)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit e9c2732b976612b6362635be2984f03bfabc20ec[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jun 19 22:37:33 2024 +0800

    [CI/Build] Add tqdm to dependencies (#5680)

[33mcommit d8714530d11603a159a46ea0dde299f95807cfde[m
Author: DearPlanet <junsong.zhang2021.work@outlook.com>
Date:   Wed Jun 19 18:19:08 2024 +0800

    [Misc]Add param max-model-len in benchmark_latency.py (#5629)

[33mcommit 7d46c8d37864993162bbeb61dc19b5ad6043646d[m
Author: Isotr0py <2037008807@qq.com>
Date:   Wed Jun 19 17:58:32 2024 +0800

    [Bugfix] Fix sampling_params passed incorrectly in Phi3v example (#5684)

[33mcommit da971ec7a5b35f33981cff9ca50064d3166953f9[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jun 19 05:38:26 2024 -0400

    [Model] Add FP8 kv cache for Qwen2 (#5656)

[33mcommit 3eea74889fe29534808bae41fca251e0e74c0962[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jun 19 01:05:00 2024 -0700

    [misc][distributed] use 127.0.0.1 for single-node (#5619)

[33mcommit f758aed0e851687e919a4ee09ab872ee2c8fe159[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Wed Jun 19 02:21:29 2024 -0400

    [Bugfix][CI/Build][AMD][ROCm]Fixed the cmake build bug which generate garbage on certain devices (#5641)

[33mcommit e5150f2c281f052df42121ae60827156abe57173[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Wed Jun 19 08:03:55 2024 +0200

    [Bugfix] Added test for sampling repetition penalty bug. (#5659)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 59a1eb59c9cb383e5ea36d7253f81ff2ea7766cc[m
Author: Shukant Pal <SukantK2002@outlook.com>
Date:   Tue Jun 18 18:46:38 2024 -0700

    [Bugfix] Fix Phi-3 Long RoPE scaling implementation (#5628)

[33mcommit 6820724e51079120251c8522afd385ca64abc948[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Jun 18 20:33:25 2024 -0400

    [Bugfix] Fix w8a8 benchmarks for int8 case (#5643)

[33mcommit b23ce9203235488e080434108d3504d54b24e867[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Tue Jun 18 19:48:49 2024 -0400

    [Bugfix] Fix CUDA version check for mma warning suppression (#5642)

[33mcommit 2bd231a7b7787407ccba36f966603578842d03f7[m
Author: milo157 <43028253+milo157@users.noreply.github.com>
Date:   Tue Jun 18 18:56:59 2024 -0400

    [Doc] Added cerebrium as Integration option (#5553)

[33mcommit 8a173382c80d6730e1bbc81f932ac3721ab2cd9d[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Tue Jun 18 23:18:37 2024 +0200

    [Bugfix] Fix for inconsistent behaviour related to sampling and repetition penalties  (#5639)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 07feecde1a69859d565786a7ad64c0f604f17b28[m
Author: sergey-tinkoff <167607910+sergey-tinkoff@users.noreply.github.com>
Date:   Tue Jun 18 21:01:21 2024 +0300

    [Model] LoRA support added for command-r (#5178)

[33mcommit 19091efc44c6f9b1e008dc5469c63a1f01684745[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Jun 18 11:00:36 2024 -0700

    [ci] Setup Release pipeline and build release wheels with cache (#5610)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 95db455e7f337e99ffafd0b14367a7cbc11dca43[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Tue Jun 18 12:45:05 2024 -0400

    [Misc] Add channel-wise quantization support for w8a8 dynamic per token activation quantization (#5542)

[33mcommit 7879f24dcce75665d83865ee8281f2ef1bbb7e74[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Tue Jun 18 19:17:03 2024 +0300

    [Misc] Add OpenTelemetry support (#4687)
    
    This PR adds basic support for OpenTelemetry distributed tracing.
    It includes changes to enable tracing functionality and improve monitoring capabilities.
    
    I've also added a markdown with print-screens to guide users how to use this feature. You can find it here

[33mcommit 13db4369d9ab3158a01192d60c744c6523961824[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Tue Jun 18 07:26:20 2024 -0700

    [ci] Deprecate original CI template (#5624)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 4ad7b53e59b6600d050581329dfaba0222b13ae5[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jun 18 06:10:04 2024 -0700

    [CI/Build][Misc] Update Pytest Marker for VLMs (#5623)

[33mcommit f0cc0e68e3ceef6fe43f78bf36df88e6cad28766[m
Author: Chang Su <chang.s.su@oracle.com>
Date:   Tue Jun 18 05:12:19 2024 -0700

    [Misc] Remove import from transformers logging (#5625)

[33mcommit db5ec52ad7dc69dbe8dd9ba25fe8f2c6ce35a4cf[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jun 18 00:21:05 2024 -0700

    [bugfix][distributed] improve p2p capability test (#5612)
    
    [bugfix][distributed] do not error if two processes do not agree on p2p capability (#5612)

[33mcommit 114d7270ffc2e5a66e0974b0d6d913c7f990afa7[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Mon Jun 17 21:37:18 2024 -0700

    [CI] Avoid naming different metrics with the same name in performance benchmark (#5615)

[33mcommit 32c86e494a49dff8d1d4b10c5922a36daa6e8faf[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jun 18 11:58:30 2024 +0800

    [Misc] Fix typo (#5618)

[33mcommit 8eadcf0b90f126cf9b23f9583a53b19b6b58fd87[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jun 17 20:54:57 2024 -0700

    [misc][typo] fix typo (#5620)

[33mcommit 5002175e801703c5b8a1411b490f6ff6c1747c8e[m
Author: Joe Runde <joe@joerun.de>
Date:   Mon Jun 17 21:54:11 2024 -0600

    [Kernel] Add punica dimensions for Granite 13b (#5559)
    
    Signed-off-by: Joe Runde <Joseph.Runde@ibm.com>

[33mcommit daef218b5595a8c744ee143223f4f0544619ea9f[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue Jun 18 10:34:33 2024 +0800

    [Model] Initialize Phi-3-vision support (#4986)

[33mcommit fa9e3852290ecb6eaae45befbd629bb060f57fb7[m
Author: sroy745 <142070531+sroy745@users.noreply.github.com>
Date:   Mon Jun 17 19:29:09 2024 -0700

    [Speculative Decoding 1/2 ] Add typical acceptance sampling as one of the sampling techniques in the verifier (#5131)

[33mcommit 26e1188e51aca3b76184671d804a8b17c294b610[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Mon Jun 17 16:16:10 2024 -0700

    [Fix] Use utf-8 encoding in entrypoints/openai/run_batch.py (#5606)

[33mcommit a3e8a05d4c1b79dd44eb92bb6f57eb40c3fbdb21[m
Author: Bruce Fontaine <bruce@2.7182.net>
Date:   Mon Jun 17 15:26:41 2024 -0700

    [Bugfix] Fix KV head calculation for MPT models when using GQA (#5142)

[33mcommit e441bad674e6dca076a145ca63f72100318c51e5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jun 17 15:08:05 2024 -0700

    [Optimization] use a pool to reuse LogicalTokenBlock.token_ids (#5584)

[33mcommit 1b44aaf4e3559e4e321f32715b08f1aa7e4f3d50[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jun 17 14:35:04 2024 -0700

    [bugfix][distributed] fix 16 gpus local rank arrangement (#5604)

[33mcommit 9e4e6fe2073ff5e4a747d5ce2a08d321268b7254[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Mon Jun 17 11:41:08 2024 -0700

    [CI] the readability of benchmarking and prepare for dashboard (#5571)
    
    [CI] Improve the readability of performance benchmarking results and prepare for upcoming performance dashboard (#5571)

[33mcommit ab66536dbfedff4ffcbb6dc9f9a21d0a9ac0ec91[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Tue Jun 18 02:36:10 2024 +0800

    [CI/BUILD] Support non-AVX512 vLLM building and testing (#5574)

[33mcommit 728c4c8a063c25e7a20d6eda20a3f30873bda4c6[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Tue Jun 18 02:01:25 2024 +0800

    [Hardware][Intel GPU] Add Intel GPU(XPU) inference backend (#3814)
    
    Co-authored-by: Jiang Li <jiang1.li@intel.com>
    Co-authored-by: Abhilash Majumder <abhilash.majumder@intel.com>
    Co-authored-by: Abhilash Majumder <30946547+abhilash1910@users.noreply.github.com>

[33mcommit 1f12122b1714c855c02699775bcd2fb2b34f2577[m
Author: zhyncs <me@zhyncs.com>
Date:   Tue Jun 18 00:40:35 2024 +0800

    [Misc] use AutoTokenizer for benchmark serving when vLLM not installed (#5588)

[33mcommit 890d8d960bb441b4ac46588492db7f16b6da78d7[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Mon Jun 17 12:32:48 2024 -0400

    [Kernel] `compressed-tensors` marlin 24 support (#5435)

[33mcommit 9e74d9d003d546c17dca472c3f4b48be651f1d7c[m
Author: Charles Riggins <liqianchen123@foxmail.com>
Date:   Tue Jun 18 00:05:33 2024 +0800

    Correct alignment in the seq_len diagram. (#5592)
    
    Co-authored-by: Liqian Chen <liqian.chen@deeplang.ai>

[33mcommit 9333fb8eb9ed6a62d33ef4d56d589f83a0f19233[m
Author: Amit Garg <gargamit@microsoft.com>
Date:   Mon Jun 17 09:04:14 2024 -0700

    [Model] Rename Phi3 rope scaling type (#5595)

[33mcommit e2b85cf86a522e734a38b1d0314cfe9625003ef9[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Sun Jun 16 23:48:06 2024 -0700

    Fix w8a8 benchmark and add Llama-3-8B (#5562)

[33mcommit 845a3f26f9706acafe8fa45ae452846d8cc3b97f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Jun 16 19:08:01 2024 -0700

    [Doc] add debugging tips for crash and multi-node debugging (#5581)

[33mcommit f07d5133202c08899eb5f51134af0f43b7791a33[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Jun 16 16:07:01 2024 -0700

    [build][misc] limit numpy version (#5582)

[33mcommit 4a6769053ab2616f7f490e6ec5b8241e76ef0c2a[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sun Jun 16 10:07:34 2024 -0400

    [CI][BugFix] Flip is_quant_method_supported condition (#5577)

[33mcommit f31c1f90e381967d25591a8928782d8a6a13693e[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Sun Jun 16 00:48:02 2024 -0700

    Add basic correctness 2 GPU tests to 4 GPU pipeline (#5518)

[33mcommit 3ce2c050dd919542ef5355635edf71349ea597f2[m
Author: zifeitong <zifei.tong@parasail.io>
Date:   Sat Jun 15 16:57:54 2024 -0700

    [Fix] Correct OpenAI batch response format (#5554)

[33mcommit 1c0afa13c57766641e75172ff1cac2e09f79a3b9[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sat Jun 15 16:30:51 2024 -0700

    [BugFix] Don't start a Ray cluster when not using Ray (#5570)

[33mcommit d919ecc771ece6995a949c3d4284c534a2bd0890[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Sat Jun 15 13:38:16 2024 -0400

    add gptq_marlin test for bug report https://github.com/vllm-project/vllm/issues/5088 (#5145)

[33mcommit e691918e3bd75a05bc473c77577c494aa6442640[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Sat Jun 15 23:59:36 2024 +0900

    [misc] Do not allow to use lora with chunked prefill. (#5538)
    
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit 81fbb3655f37e2b3ccbe0e17276c5d813b886417[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jun 15 19:29:42 2024 +0800

    [CI/Build] Test both text and token IDs in batched OpenAI Completions API (#5568)

[33mcommit 0e9164b40abdb30f1929edb44b56894c9e26c31d[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jun 15 12:45:31 2024 +0800

    [mypy] Enable type checking for test directory (#5017)

[33mcommit 1b8a0d71cf5aa1a43c14478ec90538c3fbe1b315[m
Author: leiwen83 <leiwen83@users.noreply.github.com>
Date:   Sat Jun 15 08:23:56 2024 +0800

    [Core][Bugfix]: fix prefix caching for blockv2 (#5364)
    
    Signed-off-by: Lei Wen <wenlei03@qiyi.com>
    Co-authored-by: Lei Wen <wenlei03@qiyi.com>

[33mcommit bd7efe95d03773c65fa7dc1e122f3ce0e079a542[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jun 14 19:18:22 2024 -0500

    Add ccache to amd (#5555)

[33mcommit f5bb85b435e6fe3db57fae1e25e09914015ef957[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jun 14 14:47:45 2024 -0700

    [Core][Distributed] improve p2p cache generation (#5528)

[33mcommit 28c145eb5755902505c066dc3b1e5315572cc6e7[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jun 14 14:40:09 2024 -0700

    [Bugfix] Fix typo in Pallas backend (#5558)

[33mcommit e2afb03c92a06700d296a2e7f6565d4a4f05168c[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Fri Jun 14 22:28:11 2024 +0200

    [Bugfix] Enable loading FP8 checkpoints for gpt_bigcode models  (#5460)
    
    Signed-off-by: Thomas Parnell <tpa@zurich.ibm.com>

[33mcommit 6e2527a7cb94fa9154e34a42b95c1e4eb9a83e01[m
Author: Sanger Steel <sangersteel@gmail.com>
Date:   Fri Jun 14 14:27:57 2024 -0400

    [Doc] Update documentation on Tensorizer (#5471)

[33mcommit cdab68dcdb7a68b46b8138f73cdd6ac26ff6d9c0[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jun 14 13:17:21 2024 -0500

    [Docs] Add ZhenFund as a Sponsor (#5548)

[33mcommit d1c3d7d1398c26fa5afd4583a58fceca76555c2a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jun 14 10:59:28 2024 -0700

    [misc][distributed] fix benign error in `is_in_the_same_node` (#5512)

[33mcommit 77490c6f2f1e99982d2553832a42980bbdee820c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jun 15 01:04:42 2024 +0800

    [Core] Remove duplicate processing in async engine (#5525)

[33mcommit 48f589e18b8b6758dbfb6bb23b2994430893b477[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jun 14 10:02:23 2024 -0700

    [mis] fix flaky test of test_cuda_device_count_stateless (#5546)

[33mcommit 348616ac4b72e2acc6e9a60ae94cf0f7fc29ac31[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Jun 14 13:02:00 2024 -0400

    [Kernel] Suppress mma.sp warning on CUDA 12.5 and later (#5401)

[33mcommit 15985680e2278610e873cc07ec72fa514ace72e9[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Jun 14 13:01:46 2024 -0400

    [ Misc ] Rs/compressed tensors cleanup (#5432)
    
    Co-authored-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: Dipika Sikka <dipikasikka1@gmail.com>

[33mcommit d74674bbd978fad7f27a252650249bc2550f3e92[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Sat Jun 15 00:47:44 2024 +0800

    [Misc] Fix arg names (#5524)

[33mcommit 703475f6c2771600acc27eba76f6a750f54aae50[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Jun 14 12:30:15 2024 -0400

    [Kernel] Fix CUTLASS 3.x custom broadcast load epilogue (#5516)

[33mcommit d47af2bc0208d50ed36ae877876c1d2eafdc933a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Jun 15 00:27:30 2024 +0800

    [CI/Build] Disable LLaVA-NeXT CPU test (#5529)

[33mcommit 319ad7f1d386699e94f629341c9988a926821f24[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Thu Jun 13 22:36:20 2024 -0700

    [CI/Build][Misc] Add CI that benchmarks vllm performance on those PRs with `perf-benchmarks` label (#5073)
    
    Co-authored-by: simon-mo <simon.mo@hey.com>

[33mcommit 0f0d8bc065f3608e7657a9696f5d2d7c0d6722d1[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Jun 13 21:42:06 2024 -0500

    bump version to v0.5.0.post1 (#5522)

[33mcommit 55d6361b13ae6328de809f57a69b719c1600040a[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Fri Jun 14 10:02:53 2024 +0800

    [Misc] Fix arg names in quantizer script (#5507)

[33mcommit cd9c0d65d98f86fbd2235ee41b80107097a57f77[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Fri Jun 14 07:22:24 2024 +0800

    [Hardware][Intel] Support CPU inference with AVX2 ISA (#5452)

[33mcommit 50eed24d252965a81ce50b64fd387d60fb1f4f6e[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Thu Jun 13 16:06:49 2024 -0700

    Add `cuda_device_count_stateless` (#5473)

[33mcommit e38042d4af1ddb390c3dd9340250de25bee37c62[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Jun 13 16:38:05 2024 -0400

    [Kernel] Disable CUTLASS kernels for fp8 (#5505)

[33mcommit 33e3b372429232cea44266d866906effaa705a10[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Jun 13 16:37:48 2024 -0400

    [CI/Build] Disable test_fp8.py (#5508)

[33mcommit 1696efe6c91a82e1aca5b49f4bc7899802115981[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jun 13 12:09:16 2024 -0700

    [misc] fix format.sh (#5511)

[33mcommit 6b0511a57bdba85efe2b4d5588dd16280c8fdc78[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Thu Jun 13 11:22:50 2024 -0700

    Revert "[Core] Remove unnecessary copies in flash attn backend" (#5478)

[33mcommit a8fda4f66131e211ac1e64f6b1d74123e0347a1c[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Thu Jun 13 11:22:41 2024 -0700

    Seperate dev requirements into lint and test (#5474)

[33mcommit 30299a41fa78c7bf485aca7ef8ad584ca340a64d[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Thu Jun 13 11:22:30 2024 -0700

    [MISC] Remove FP8 warning (#5472)
    
    Co-authored-by: Philipp Moritz <pcmoritz@gmail.com>

[33mcommit 85657b56071b7c21586d88389c6e817f11c69e04[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu Jun 13 14:22:19 2024 -0400

    [Kernel] Factor out epilogues from cutlass kernels (#5391)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>
    Co-authored-by: zifeitong <zifei.tong@parasail.io>
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>

[33mcommit 0ce7b952f8eafdb13a7b6de3af53157c7aae98d4[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jun 14 02:22:07 2024 +0800

    [Doc] Update LLaVA docs (#5437)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 39873476f8a1cf97bdf5651b4535ae60358ff15b[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jun 14 02:21:53 2024 +0800

    [CI/Build] Simplify OpenAI server setup in tests (#5100)

[33mcommit 03dccc886ef7e5d0dd67512f3e9748ee00c21fb2[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Jun 14 02:21:39 2024 +0800

    [Misc] Add vLLM version getter to utils (#5098)

[33mcommit a65634d3ae8928284b3923a46bff89731cb1792e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jun 13 10:18:26 2024 -0700

    [Docs] Add 4th meetup slides (#5509)

[33mcommit 80aa7e91fcd547a7a1396f71b9bdce18e5c92245[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Fri Jun 14 00:33:14 2024 +0800

    [Hardware][Intel] Optimize CPU backend and add more performance tips (#4971)
    
    Co-authored-by: Jianan Gu <jianan.gu@intel.com>

[33mcommit bd43973522ea17be50e10fbb222a22f673c8067e[m
Author: wenyujin333 <wuyou.wuyou@alibaba-inc.com>
Date:   Fri Jun 14 00:01:10 2024 +0800

    [Kernel] Tune Qwen2MoE kernel configurations with tp2,4 (#5497)
    
    Tune Qwen2-57B-A14B configs based on #4921
    
    Throughput Performance
    command: python benchmarks/benchmark_throughput.py --model=Qwen/Qwen2-57B-A14B-Instruct --input-len 1000 --output-len 50 -tp 2
    
    A100 GPU
    
    benchmark       no config       w/ PR
    tp=2    10.53 requests/s, 11058.17 tokens/s     12.47 requests/s, 13088.57 tokens/s
    tp=4    17.77 requests/s, 18662.95 tokens/s     20.20 requests/s, 21212.32 tokens/s

[33mcommit 23ec72fa032b3d81a5ea9eb0f7c607f1d6e7949a[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Jun 13 11:18:08 2024 -0400

    [CI/Build][REDO] Add is_quant_method_supported to control quantization test configurations (#5466)

[33mcommit c2637a613b6140dc16fecd5a1b0f5a9e1d0932ff[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Thu Jun 13 10:19:56 2024 -0400

    [Kernel] `w4a16` support for `compressed-tensors` (#5385)
    
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>

[33mcommit 88407532e7ec2dd3313f6cb3a31d8dd1fa868178[m
Author: Wang, Yi <yi.a.wang@intel.com>
Date:   Thu Jun 13 11:16:41 2024 +0800

    [Bugfix]if the content is started with ":"(response of ping), client should i‚Ä¶ (#5303)
    
    Signed-off-by: Wang, Yi A <yi.a.wang@intel.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 916d219d62e9e4005e10be23f81d881afdb8d6d0[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Jun 12 17:58:12 2024 -0700

    [ci] Use sccache to build images (#5419)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit ea3890a5f0314e49d69afca45fe706504cb14029[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jun 12 17:27:08 2024 -0700

    [Core][Distributed] code deduplication in tp&pp with coordinator(#5293)
    
    [Core][Distributed] add coordinator to reduce code duplication in tp and pp (#5293)

[33mcommit 2135cacb457b7daf1143c8465ab72650eaa4dd7e[m
Author: Isotr0py <2037008807@qq.com>
Date:   Thu Jun 13 07:20:18 2024 +0800

    [Bugfix] Fix wrong multi_modal_input format for CPU runner (#5451)

[33mcommit 7d19de2e9c9a94658c36b55011b803a7991d0335[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jun 12 18:42:12 2024 -0400

    [Frontend] Add "input speed" to tqdm postfix alongside output speed (#5425)

[33mcommit 94a07bbdd813a0121d01a852ab03fb2430e73548[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jun 12 17:59:44 2024 -0400

    [Bugfix] Fix typo in scheduler.py (requeset -> request) (#5470)

[33mcommit b8d4dfff9c29ad6e02bce1fc79c089120b2d34d6[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jun 13 05:49:31 2024 +0800

    [Doc] Update debug docs (#5438)

[33mcommit 622d45128c02e5296e1177481c65199754eab396[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Jun 12 14:46:35 2024 -0700

    [misc] add hint for AttributeError (#5462)

[33mcommit 51602eefd38250325e541abd28f051ffd7676c3f[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed Jun 12 15:13:52 2024 -0600

     [Frontend] [Core] Support for sharded tensorized models (#4990)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>
    Co-authored-by: Sanger Steel <sangersteel@gmail.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 5cc50a531f720758025c8493ee85a56272277a54[m
Author: Arthur Kim <kimdwkimdw@gmail.com>
Date:   Thu Jun 13 06:08:52 2024 +0900

    [Bugfix] TYPE_CHECKING for MultiModalData (#5444)

[33mcommit 5985e3427dc4a10b8483fd08013fa8df563f04fb[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Jun 12 14:07:26 2024 -0700

    [Kernel] Vectorized FP8 quantize kernel (#5396)
    
    Inspired by #5146, this PR improves FP8 quantize kernel by vectorizing data transfer to better utilize memory bandwidth. Microbenchmark shows that this improved kernel can achieve 1.0x-1.5x speedup (especially when hidden size is large).
    
    In details, we applied 3 optimizations:
    
    - Use inverted scale so that most divisions are changed to multiplications.
    - Unroll the loop by 4 times to improve ILP.
    - Use vectorized 4 to transfer data between HBM and SRAM.

[33mcommit 8b82a89997826af8e0e4ecfaaed60f3b28b1baed[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Wed Jun 12 14:00:18 2024 -0700

    [ci] Add AMD, Neuron, Intel tests for AWS CI and turn off default soft fail for GPU tests (#5464)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit c3c2903e72c6e85a81ff6de8b879f4c82e8ad364[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Thu Jun 13 03:58:53 2024 +0800

    [Bugfix] Add device assertion to TorchSDPA (#5402)

[33mcommit 1a8bfd92d5f35d638e3cfc8c4cd1779aeda0adfb[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 12 11:53:03 2024 -0700

    [Hardware] Initial TPU integration (#5292)

[33mcommit 847cdcca1c94b12e6c118dbf863e4b111d1b4fd2[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu Jun 13 02:06:14 2024 +0900

    [CI] Upgrade codespell version. (#5381)

[33mcommit e3c12bf6d22999cfbe267a7c788f6875340616cd[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Jun 12 12:03:24 2024 -0500

    Revert "[CI/Build] Add `is_quant_method_supported` to control quantization test configurations" (#5463)

[33mcommit 3dd6853bc8c4fb8bbaf507c1699e5cbe8fa356ad[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jun 12 12:58:02 2024 -0400

    [CI/Build] Add `is_quant_method_supported` to control quantization test configurations (#5253)

[33mcommit 8f89d72090da70895d77d32248ea8504f7daba50[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jun 11 11:12:13 2024 -0700

    [Doc] add common case for long waiting time (#5430)

[33mcommit 99dac099ab5205d40bfaf5cf5652884b8764a400[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Jun 11 11:10:41 2024 -0700

    [Core][Doc] Default to multiprocessing for single-node distributed case (#5230)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit c4bd03c7c5672b6a5d3d6839339853e04fe15127[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jun 11 10:53:59 2024 -0700

    [Core][Distributed] add same-node detection (#5369)

[33mcommit dcbf4286afbff55d836b1c69bd2b4705f0082ddb[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Tue Jun 11 17:42:26 2024 +0000

    [Frontend] Customizable RoPE theta (#5197)

[33mcommit 00e6a2dc535c89ac7c92551ef9b92acd8664df02[m
Author: Ali Panahi <64020589+c3-ali@users.noreply.github.com>
Date:   Tue Jun 11 10:40:23 2024 -0700

    [Bugfix] fix lora_dtype value type in arg_utils.py (#5398)

[33mcommit 2e02311a1b33b4fc21179813c56b444f1be10d53[m
Author: Junichi Sato <junichi.sato@sbintuitions.co.jp>
Date:   Wed Jun 12 02:38:07 2024 +0900

    [Bugfix] Fix `MultiprocessingGPUExecutor.check_health` when world_size == 1 (#5254)

[33mcommit 89ec06c33b9b3e64a6562a82049de44cbf7f9e09[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Jun 11 10:31:56 2024 -0700

    [Docs] [Spec decode] Fix docs error in code example (#5427)

[33mcommit 9fde251bf0b5262ce31eec78f851346b32f684da[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Tue Jun 11 10:24:59 2024 -0700

    [Doc] Add an automatic prefix caching section in vllm documentation (#5324)
    
    Co-authored-by: simon-mo <simon.mo@hey.com>

[33mcommit 4c2ffb28ffe7270b49ac7cf5324978950a28e7e1[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Jun 11 10:15:40 2024 -0700

    [Speculative decoding] Initial spec decode docs (#5400)

[33mcommit 246598a6b1e22616630b7f1bf11bd9bcb31dc860[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Tue Jun 11 17:28:50 2024 +0900

    [CI] docfix (#5410)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>
    Co-authored-by: ywang96 <ywang@roblox.com>

[33mcommit 8bab4959bea640f8f81ca59eb06b1f056ac23111[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jun 11 00:37:56 2024 -0700

    [Misc] Remove VLLM_BUILD_WITH_NEURON env variable (#5389)

[33mcommit 3c4cebf751a6d2ff9ada2f8234bab17ba7283e09[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Jun 11 00:20:28 2024 -0700

    [Doc][Typo] Fixing Missing Comma (#5403)

[33mcommit d8f31f2f8b3486c6767a8db29d881fa8cda620fa[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jun 10 23:21:43 2024 -0700

    [Doc] add debugging tips (#5409)

[33mcommit 640052b0698d64d03806c98bc118a425afc53eff[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jun 11 13:36:46 2024 +0800

    [Bugfix][Frontend] Cleanup "fix chat logprobs" (#5026)

[33mcommit 351d5e7b8253d754b2a951152cd48927c4c1629d[m
Author: maor-ps <154728172+maor-ps@users.noreply.github.com>
Date:   Tue Jun 11 05:30:31 2024 +0300

    [Bugfix] OpenAI entrypoint limits logprobs while ignoring server defined --max-logprobs (#5312)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit a008629807b45c2b015d4e0bc7c4186cecbb642f[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Jun 10 19:29:02 2024 -0700

    [Misc] Various simplifications and typing fixes (#5368)

[33mcommit 76477a93b78896179c96af71dce7e2bb95a16955[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Jun 10 18:58:07 2024 -0700

    [ci] Fix Buildkite agent path (#5392)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 77c87beb0647d52b7d1bfbe335913e52e93148bf[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Jun 10 20:55:12 2024 -0400

    [Doc] Add documentation for FP8 W8A8 (#5388)

[33mcommit 114332b88e499f03a5af6fa9fc3633492352af52[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Jun 10 17:56:06 2024 -0500

    Bump version to v0.5.0 (#5384)

[33mcommit cb77ad836f0ee8572c0f3d6f08fa993b2565a55b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 10 13:17:19 2024 -0700

    [Docs] Alphabetically sort sponsors (#5386)

[33mcommit 856c990041bf6cf4b2397401d4b18531382ecb50[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jun 10 09:53:50 2024 -0700

    [Docs] Add Docs on Limitations of VLM Support (#5383)

[33mcommit c5602f0baa8fa42df11853a0d422bc140cf04c9a[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Jun 10 09:22:34 2024 -0700

    [ci] Mount buildkite agent on Docker container to upload benchmark results (#5330)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit f7f9c5f97b4dd206a3cd9c65729a1c807ac82f50[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Jun 10 09:21:11 2024 -0700

    [ci] Use small_cpu_queue for doc build (#5331)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 2c0d9335942a76bdc72e3c51dadfc7397bc79cea[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jun 10 23:38:47 2024 +0800

    [Bugfix] Fix LLaVA-NeXT (#5380)

[33mcommit 774d1035e4000fe3a40e01ccbf017a0f763fd6f2[m
Author: Itay Etelis <92247226+Etelis@users.noreply.github.com>
Date:   Mon Jun 10 17:22:09 2024 +0300

    [Feature][Frontend]:  Continued `stream_options` implementation also in CompletionRequest (#5319)

[33mcommit 6b29d6fe709b91346be102a697bfaea386ed9107[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jun 10 20:47:15 2024 +0800

    [Model] Initial support for LLaVA-NeXT (#4199)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 0bfa1c4f133737a59bcb94e85ca80f2f4cd68038[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jun 10 19:38:49 2024 +0800

    [Misc] Improve error message when LoRA parsing fails (#5194)

[33mcommit c81da5f56dd613d5378078866e4810452d50d6ed[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Jun 10 02:51:02 2024 -0700

    [misc][typo] fix typo (#5372)

[33mcommit 68bc81703e2c41f38b1696269ce912cacb384e60[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Jun 10 02:13:39 2024 -0700

    [Frontend][Misc] Enforce Pixel Values as Input Type for VLMs in API Server (#5374)

[33mcommit 5884c2b454d9a6e16646e949d7308a4cfae3ac12[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Sun Jun 9 23:49:46 2024 -0400

    [Misc] Update to comply with the new `compressed-tensors` config (#5350)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit 45f92c00cf1752ae27b4e8a08a560abf08cc6cd2[m
Author: Bla_ckB <50193121+BlackBird-Coding@users.noreply.github.com>
Date:   Mon Jun 10 06:23:14 2024 +0700

    [Bugfix] Fix KeyError: 1 When Using LoRA adapters (#5164)

[33mcommit 5467ac319636245ded483b31967ac43e543c5fa3[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Sun Jun 9 16:23:30 2024 -0400

    [Kernel][Misc] Use TORCH_LIBRARY instead of PYBIND11_MODULE for custom ops (#5047)

[33mcommit 5d7e3d0176e0dbcf144c64b7d14d996c55e36c50[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Jun 8 20:50:14 2024 -0700

    [mis][ci/test] fix flaky test in test_sharded_state_loader.py (#5361)
    
    [mis][ci/test] fix flaky test in tests/test_sharded_state_loader.py (#5361)

[33mcommit 0373e1837e1a85c595fa9fc67c775bc6cbe105a2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Jun 8 19:14:43 2024 -0700

    [Core][CUDA Graph] add output buffer for cudagraph (#5074)
    
    [Core][CUDA Graph] add output buffer for cudagraph to reduce memory footprint (#5074)

[33mcommit c09dade2a263b6f684d2fbf390c9c1c64761e953[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sat Jun 8 13:54:05 2024 -0400

    [Misc][Breaking] Change FP8 checkpoint format from act_scale -> input_scale (#5353)

[33mcommit 8ea5e44a435e8731fd6f5ba4c329dd112752532a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Jun 8 01:59:20 2024 -0700

    [CI/Test] improve robustness of test (vllm_runner) (#5357)
    
    [CI/Test] improve robustness of test by replacing del with context manager (vllm_runner) (#5357)

[33mcommit 9fb900f90cbb5614c3e7d67446325ad8b7ac04b2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Jun 7 22:31:32 2024 -0700

    [CI/Test] improve robustness of test (hf_runner) (#5347)
    
    [CI/Test] improve robustness of test by replacing del with context manager (hf_runner) (#5347)

[33mcommit c96fc067479453b02e92d9378eeeaebb6b3816de[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Fri Jun 7 22:13:12 2024 -0400

    [ROCm][AMD] Use pytorch sdpa math backend to do naive attention (#4965)

[33mcommit b3376e5c76c199acb216addec7c32ac5299bef31[m
Author: Benjamin Kitor <bkitor@gmail.com>
Date:   Fri Jun 7 18:20:16 2024 -0700

    [Misc] Add args for selecting distributed executor to benchmarks (#5335)

[33mcommit e69ded7d1c8a4f6ed26e64090bdc050c06cde3b9[m
Author: Cheng Li <pistasable@gmail.com>
Date:   Fri Jun 7 17:42:05 2024 -0700

    [Bug Fix] Fix the support check for FP8 CUTLASS  (#5352)
    
    Bug description:
    With torch 2.4.0.dev20240603+cu121,
    cutlass_fp8_supported outputs False, and the (capability, version) before the comparison is (90, 11111111112)
    
    This PR fixes the support check for FP8 CUTLASS ( cutlass_fp8_supported) which was introduced in https://github.com/vllm-project/vllm/pull/5183.

[33mcommit 767c727a81ae9ec570d30d55b7afc783775d5a05[m
Author: Calvinn Ng <39899397+Calvinnncy97@users.noreply.github.com>
Date:   Sat Jun 8 05:10:21 2024 +0800

    fix DbrxFusedNormAttention missing cache_config (#5340)
    
    Co-authored-by: team <calvinn.ng@ahrefs.com>

[33mcommit 6840a716104c8c17303b938673c2ac019e541700[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Sat Jun 8 05:09:13 2024 +0800

    [Misc] Remove unused cuda_utils.h in CPU backend (#5345)

[33mcommit 7a9cb294ae317b28a60165b34c8398c762869a74[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Jun 7 11:23:32 2024 -0700

    [Frontend] Add OpenAI Vision API Support (#5237)
    
    Co-authored-by: DarkLight1337 <tlleungac@connect.ust.hk>

[33mcommit ca3ea51bde6c22d0afb3aa0a3fdba6d568095a0a[m
Author: Dipika Sikka <dipikasikka1@gmail.com>
Date:   Fri Jun 7 12:36:26 2024 -0400

    [Kernel] Dynamic Per-Token Activation Quantization (#5037)
    
    Co-authored-by: Varun Sundar Rabindranath <varunsundar08@gmail.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit dc49fb892ca32cb364dfc39d711ab84d3b35a28f[m
Author: limingshu <61349199+JamesLim-sy@users.noreply.github.com>
Date:   Fri Jun 7 21:35:42 2024 +0800

    Addition of lacked ignored_seq_groups in _schedule_chunked_prefill (#5296)

[33mcommit 18a277b52dd2a64ee4c0111fc8cda126031e5889[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Jun 7 03:01:56 2024 -0700

    Remove Ray health check (#4693)

[33mcommit 8d75fe48ca5f46b7af0f5201d8500b9604eed769[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri Jun 7 04:42:35 2024 -0400

    [Kernel] Switch fp8 layers to use the CUTLASS kernels (#5183)
    
    Switching from torch._scaled_mm to vLLM's cutlass fp8 kernels when supported as we are seeing 5-15% improvement in e2e performance on neuralmagic/Meta-Llama-3-8B-Instruct-FP8
    
    see https://docs.google.com/spreadsheets/d/1GiAnmzyGHgZ6zL_LDSTm35Bdrt4A8AaFEurDlISYYA4/ for some quick e2e benchmarks and #5144 for comparisons across different GEMM sizes.

[33mcommit 388596c91437a51d428a447594e9faec340c29b2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Jun 6 22:15:11 2024 -0700

    [Misc][Utils] allow get_open_port to be called for multiple times (#5333)

[33mcommit baa15a9ec320a6b90222df0aaed13b89e3bafc9c[m
Author: Itay Etelis <92247226+Etelis@users.noreply.github.com>
Date:   Fri Jun 7 06:29:24 2024 +0300

    [Feature][Frontend]: Add support for `stream_options` in `ChatCompletionRequest` (#5135)

[33mcommit 15063741e30881d7a982c3436c3299a0551327dc[m
Author: Jie Fu (ÂÇÖÊù∞) <jiefu@tencent.com>
Date:   Fri Jun 7 11:17:21 2024 +0800

    [Misc] Missing error message for custom ops import (#5282)

[33mcommit ccdc490dda3f534c63c1faf29a638e65594d0dc3[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Thu Jun 6 19:07:57 2024 -0700

    [Core] Change LoRA embedding sharding to support loading methods (#5038)

[33mcommit a31cab7556f540b558b0b454b4a4b9b438542566[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Thu Jun 6 18:12:00 2024 -0700

    [Core] Avoid copying prompt/output tokens if no penalties are used (#5289)

[33mcommit 828da0d44e9124d949909477d6018fc08469a31e[m
Author: Matthew Goldey <matthew.goldey@gmail.com>
Date:   Thu Jun 6 16:48:13 2024 -0400

    [Frontend] enable passing multiple LoRA adapters at once to generate() (#5300)

[33mcommit abe855d63774c44e69048dfd188f0333db581d4b[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Thu Jun 6 09:29:29 2024 -0700

    [Kernel] Retune Mixtral 8x22b configs for FP8 on H100 (#5294)

[33mcommit 4efff036f0dfeee21e82044e9b6e63b861b817a3[m
Author: liuyhwangyh <liuyhwangyh@163.com>
Date:   Fri Jun 7 00:28:10 2024 +0800

    Bugfix: fix broken of download models from modelscope (#5233)
    
    Co-authored-by: mulin.lyh <mulin.lyh@taobao.com>

[33mcommit 89c920785f97821fd81547048a82c7c2a4f7a2c2[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu Jun 6 18:17:18 2024 +0800

    [CI/Build] Update vision tests (#5307)

[33mcommit 7b0a0dfb22907505441f8a4a5eb882cbca4d2acf[m
Author: Breno Faria <breno@veltefaria.de>
Date:   Thu Jun 6 01:49:12 2024 +0200

    [Frontend][Core] Update Outlines Integration from `FSM` to `Guide` (#4109)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>
    Co-authored-by: Breno Faria <breno.faria@intrafind.com>

[33mcommit 3a6ae1d33c7a8ef28b6dfa978f53b4fdcdbaaca6[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Jun 5 17:49:27 2024 -0500

    [CI] Disable flash_attn backend for spec decode (#5286)

[33mcommit 8f1729b829795c2c98152fef8857c5e7b8c4e648[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Jun 5 17:25:18 2024 -0500

    [Docs] Add Ray Summit CFP (#5295)

[33mcommit 6a7c7711a2588ca4a5e713e5335122988f8c0a55[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 5 15:19:02 2024 -0700

    [Misc] Skip for logits_scale == 1.0 (#5291)

[33mcommit 0f83ddd4d71ce1a80cfcaff085b40fef83d1a750[m
Author: Alex Wu <alexanderwu@berkeley.edu>
Date:   Wed Jun 5 15:18:12 2024 -0700

    [Bugfix][Frontend/Core] Don't log exception when AsyncLLMEngine gracefully shuts down. (#5290)

[33mcommit 065aff6c16bd563acc449b1dae6a99256cfbdeb8[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed Jun 5 18:16:56 2024 -0400

    [Bugfix] Make EngineArgs use named arguments for config construction (#5285)

[33mcommit 3d33e372a14614b13a793f374e59bddb3027527e[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Jun 5 14:53:16 2024 -0700

    [BugFix] Fix log message about default max model length (#5284)

[33mcommit faf71bcd4b11b6d350431f432af08ccd9f30016f[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Jun 5 14:53:05 2024 -0700

    [Speculative Decoding] Add `ProposerWorkerBase` abstract class (#5252)

[33mcommit f270a3953770547d5f8783320897870fcd031884[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Jun 5 13:02:56 2024 -0500

    [Docs] Add Sequoia as sponsors (#5287)

[33mcommit 51a08e7d8f0f11411d380c007ab606fc2d5e3cf9[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Wed Jun 5 10:59:14 2024 -0700

    [Kernel] Re-tune Mixtral MoE configurations for FP8 on H100 (#5238)

[33mcommit eb8fcd266686570a1cfdcda4af73af0e27b0f3d8[m
Author: DriverSong <31926998+DriverSong@users.noreply.github.com>
Date:   Thu Jun 6 01:59:02 2024 +0800

    [BugFix] Apply get_cached_tokenizer to the tokenizer setter of LLM (#5207)
    
    Co-authored-by: qiujiawei9 <qiujiawei9@jd.com>

[33mcommit 5563a4dea86e62a560c8c99537ce614d5de894e0[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed Jun 5 10:58:50 2024 -0700

    [Model] Correct Mixtral FP8 checkpoint loading (#5231)

[33mcommit ccd4f129e8ad95191b3c8d6d0e935382b10c5164[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Jun 5 13:44:15 2024 -0400

    [Kernel] Add GPU architecture guards to the CUTLASS w8a8 kernels to reduce binary size (#5157)
    
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 02cc3b51a7f2af012a8f17f0d836529d57012eee[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed Jun 5 13:17:51 2024 -0400

    [misc] benchmark_serving.py -- add ITL results and tweak TPOT results (#5263)

[33mcommit d5b1eb081e193c54ac21390a0f6ba7013e4f3b11[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Jun 5 11:42:08 2024 -0500

    [CI] Add nightly benchmarks (#5260)

[33mcommit f0a500545f97d026c3873e8dc0043e06e42ae61c[m
Author: tomeras91 <57313761+tomeras91@users.noreply.github.com>
Date:   Wed Jun 5 19:32:58 2024 +0300

    [Frontend] OpenAI API server: Add `add_special_tokens` to ChatCompletionRequest (default False) (#5278)

[33mcommit c65146e75e71f72bdb93542efdc40c87caccb42e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 5 09:18:59 2024 -0700

    [Misc] Fix docstring of get_attn_backend (#5271)

[33mcommit 41ca62cf03b31deb68dbc14e4a92a1d4579de08b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 5 09:18:19 2024 -0700

    [Misc] Add CustomOp interface for device portability (#5255)

[33mcommit 974fc9b8455ec6c210534c176fd7d1245ca43261[m
Author: zifeitong <zifei.tong@parasail.io>
Date:   Tue Jun 4 19:37:28 2024 -0700

    [Bugfix] Fix prompt_logprobs when SamplingParams.detokenize is set to True (#5226)

[33mcommit fee4dcc33ad3fb3988bfdf89aceef04c462ae1ce[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Jun 4 15:29:09 2024 -0700

    [Misc] update collect env (#5261)

[33mcommit 650a4cc55ef5515a14aed12ea4e069462716b2d9[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Jun 4 15:52:28 2024 -0400

    [Misc] Add transformers version to collect_env.py (#5259)

[33mcommit 9ca62d866827dd5ef990540477a90403298200c5[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Jun 4 13:34:53 2024 -0500

    [CI] mark AMD test as softfail to prevent blockage (#5256)

[33mcommit 45c35f0d58f4508bf43bd6af1d3d0d0ec0c915e6[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Wed Jun 5 01:26:40 2024 +0800

    [CI/Build] Reducing CPU CI execution time (#5241)

[33mcommit 9ba093b4f4f914a8557eb7e4bf961d84420671a5[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Jun 5 01:09:19 2024 +0800

    [CI/Build] Simplify model loading for `HfRunner` (#5251)

[33mcommit 27208be66e6529d016358d15fe87e95810698227[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jun 4 09:58:47 2024 -0700

    [Kernel] Add back batch size 1536 and 3072 to MoE tuning (#5242)

[33mcommit 87d5abef756e959fd05dcaa6d5c00d07c34e1fe8[m
Author: Jie Fu (ÂÇÖÊù∞) <fujie_email@sina.com>
Date:   Wed Jun 5 00:57:51 2024 +0800

    [Bugfix] Fix a bug caused by pip install setuptools>=49.4.0 for CPU backend (#5249)

[33mcommit ec784b2526219cd96159a52074ab8cd4e684410a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue Jun 4 12:01:46 2024 +0800

    [CI/Build] Add inputs tests (#5215)

[33mcommit a58f24e590c1c4be2d1398f62f119a795e79d833[m
Author: zifeitong <zifei.tong@parasail.io>
Date:   Mon Jun 3 20:55:50 2024 -0700

    [Bugfix] Fix torch.compile() error when using MultiprocessingGPUExecutor (#5229)

[33mcommit f42a006b15e876a2a7cb24614ece780bde6d1e3d[m
Author: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
Date:   Mon Jun 3 23:32:57 2024 -0400

    [Bugfix]: During testing, use pytest monkeypatch for safely overriding the env var that indicates the vLLM backend (#5210)

[33mcommit 3a434b07edc42a7466fb1ac536f3beb9470f9416[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 3 20:06:59 2024 -0700

    [Kernel] Enhance MoE benchmarking & tuning script (#4921)

[33mcommit bd0e7802e09e40060b857b85227fd93a6a739467[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jun 3 19:36:41 2024 -0700

    [Bugfix] Add warmup for prefix caching example (#5235)

[33mcommit 06b2550cbb56f4a538f43c56addf20f4d2d19cad[m
Author: Toshiki Kataoka <tos.lunar@gmail.com>
Date:   Tue Jun 4 09:59:30 2024 +0900

    [Bugfix] Support `prompt_logprobs==0` (#5217)

[33mcommit f775a07e30fdeafc14f53fe502b262b00540dd71[m
Author: Breno Faria <breno@veltefaria.de>
Date:   Tue Jun 4 01:25:29 2024 +0200

    [FRONTEND] OpenAI `tools` support named functions (#5032)

[33mcommit 4f0d17c05cdb220f2f45a20e956f766dec29acbc[m
Author: Kevin H. Luu <kevin@anyscale.com>
Date:   Mon Jun 3 16:16:43 2024 -0700

    New CI template on AWS stack (#5110)
    
    Signed-off-by: kevin <kevin@anyscale.com>

[33mcommit 10c38e3e46d95a02576c92c25d5b3e88e3c6e282[m
Author: Kaiyang Chen <48289729+Kaiyang-Chen@users.noreply.github.com>
Date:   Tue Jun 4 04:37:11 2024 +0800

    [Misc]: Implement CPU/GPU swapping in BlockManagerV2 (#3834)

[33mcommit cafb8e06c5ffa359ac7fa4b53795e6eaa1a200c7[m
Author: Yuan <yuan.zhou@intel.com>
Date:   Tue Jun 4 01:39:50 2024 +0800

    [CI/BUILD] enable intel queue for longer CPU tests (#4113)

[33mcommit cbb2f59cc853731f5607ac0130bb6cdebfdc89c7[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Mon Jun 3 12:52:30 2024 -0400

    [Kernel] Pass a device pointer into the quantize kernel for the scales (#5159)

[33mcommit 0ab278ca31028a7623098b3c7d615ad350663d05[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Jun 3 09:39:31 2024 -0700

    [Core] Remove unnecessary copies in flash attn backend (#5138)

[33mcommit 7a64d24aad69e4d2548aa0bf528d9fe63428ab01[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jun 3 13:56:41 2024 +0800

    [Core] Support image processor (#4197)

[33mcommit dfbe60dc62409f03aa9eebc70ab2582ae64f0e1f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon Jun 3 07:05:50 2024 +0800

    [Misc] Simplify code and fix type annotations in `conftest.py` (#5118)

[33mcommit a66cf40b205d57ac1b5dc96b6bb6f8e813b18316[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Sun Jun 2 16:13:26 2024 -0500

    [Kernel][ROCm][AMD] enable fused topk_softmax kernel for moe layer (#4927)
    
    This PR enables the fused topk_softmax kernel used in moe layer for HIP

[33mcommit f790ad3c50f050778af1fd31170746b7c68ca2fc[m
Author: Avinash Raj <avistylein3105@gmail.com>
Date:   Sun Jun 2 13:36:13 2024 +0530

    [Frontend][OpenAI] Support for returning max_model_len on /v1/models response (#4643)

[33mcommit ed59a7ed23c6e91096ea82b03037e40b14b5375c[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat Jun 1 21:21:53 2024 -0500

    Update test_ignore_eos (#4898)

[33mcommit 044793d8df6aeb5326b5992d0e60aa4457760e8a[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Jun 1 19:35:41 2024 -0400

    [BugFix] Prevent `LLM.encode` for non-generation Models  (#5184)
    
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit c2d6d2f960176491e0499656409f30b947ee8027[m
Author: Daniil Arapov <59310708+Delviet@users.noreply.github.com>
Date:   Sun Jun 2 01:53:52 2024 +0300

    [Bugfix]: Fix issues related to prefix caching example (#5177) (#5180)

[33mcommit 8279078e218833b357f7c5076850e3688714d570[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sat Jun 1 15:40:25 2024 -0700

    [Bugfix] Remove deprecated @abstractproperty (#5174)

[33mcommit b9c0605a8e7d558f595bd59ba6e6c95578dc0f1e[m
Author: chenqianfzh <51831990+chenqianfzh@users.noreply.github.com>
Date:   Sat Jun 1 13:51:10 2024 -0700

    [Feature][Kernel] Support bitsandbytes quantization and QLoRA (#4776)

[33mcommit 37464a0f745a0204da7443d2a6ef4b8f65e5af12[m
Author: Nadav Shmayovits <45605409+NadavShmayo@users.noreply.github.com>
Date:   Sat Jun 1 20:18:50 2024 +0300

    [Bugfix] Fix call to init_logger in openai server (#4765)

[33mcommit c35407282878cb3a42860d584a4d9eb6aed82299[m
Author: Ye Cao <952129620@qq.com>
Date:   Sun Jun 2 01:11:22 2024 +0800

    [Minor] Fix the path typo in loader.py: save_sharded_states.py -> save_sharded_state.py  (#5151)
    
    Signed-off-by: Ye Cao <caoye.cao@alibaba-inc.com>

[33mcommit f081c3ce4b020fb094e33575d178345c477ab0c6[m
Author: Varun Sundar Rabindranath <varunsundar08@gmail.com>
Date:   Sat Jun 1 14:16:07 2024 +0530

    [Kernel] Update Cutlass fp8 configs (#5144)
    
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>

[33mcommit 260d119e864edbf023b1be7fa446a08bbea11f80[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Sat Jun 1 02:45:32 2024 -0400

    [Kernel] Refactor CUTLASS kernels to always take scales that reside on the GPU (#5137)

[33mcommit a360ff80bb34f9dfcd21cf880c2030daa2d6b3a3[m
Author: Daniele <d.trifiro@me.com>
Date:   Sat Jun 1 06:06:45 2024 +0200

    [CI/Build] CMakeLists: build all extensions' cmake targets at the same time (#5034)

[33mcommit 1197e02141df1a7442f21ff6922c98ec0bba153e[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Fri May 31 20:21:38 2024 -0400

    [Build] Guard against older CUDA versions when building CUTLASS 3.x kernels (#5168)

[33mcommit 657579113f714c2e74bca373ecfb6c2c245b4101[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Fri May 31 17:20:19 2024 -0700

    [Doc] Add checkmark for GPTBigCodeForCausalLM LoRA support (#5171)

[33mcommit e9899fb7a4d9e032198d26ef84f1dd2cfd9621aa[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri May 31 14:29:19 2024 -0700

    [Model] Enable FP8 QKV in MoE and refine kernel tuning script (#5039)

[33mcommit a377f0bd5e1fa0ca069e3dbf28f4de5af64d0bb1[m
Author: functionxu123 <1229853312@qq.com>
Date:   Fri May 31 13:14:50 2024 +0800

    [Misc]: optimize eager mode host time (#4196)
    
    Co-authored-by: xuhao <xuhao@cambricon.com>

[33mcommit e9d3aa04f6e55e2bb540f0810da97ddd0deebb13[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri May 31 00:00:26 2024 -0500

    Revert "[Kernel] Marlin_24: Ensure the mma.sp instruction is using the ::ordered_metadata modifier (introduced with PTX 8.5)" (#5149)

[33mcommit a22dea54d3e80bf069cfeed8002a193ef8b18e1b[m
Author: SnowDist <quxingwei25@gmail.com>
Date:   Fri May 31 10:24:41 2024 +0800

    [Model] Support MAP-NEO model (#5081)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 533c2177925ba19934eab0095a50d0a783185e6b[m
Author: simon-mo <simon.mo@hey.com>
Date:   Fri May 31 02:13:01 2024 +0000

    Fix cutlass sm_90a vesrion in CMakeList

[33mcommit 6d21fa1cadf1e623e302eb04c15e4927febc8cf1[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Thu May 30 22:02:11 2024 -0400

    [Kernel] Marlin_24: Ensure the mma.sp instruction is using the ::ordered_metadata modifier (introduced with PTX 8.5) (#5136)

[33mcommit b35be5403f3cf8631aefe02a35d97013657e2e47[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu May 30 17:04:37 2024 -0700

    [Bugfix] Avoid Warnings in SparseML Activation Quantization (#5120)

[33mcommit 45a1a69b9841a4cb7cc70788cf7dea1a2d3ec3d6[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu May 30 16:37:16 2024 -0500

    [Build] Disable sm_90a in cu11 (#5141)

[33mcommit 87a658c81219568fc30081d9cc11327238160563[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu May 30 13:13:46 2024 -0500

    Bump version to v0.4.3 (#5046)

[33mcommit 429d89720e41901c3c0499a8ed3ad5be693cc945[m
Author: Chansung Park <deep.diver.csp@gmail.com>
Date:   Fri May 31 02:11:07 2024 +0900

    add doc about serving option on dstack (#3074)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit a9bcc7afb23d208efaa1b47549fa93eaa1d9d6cf[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri May 31 00:59:23 2024 +0800

    [Doc] Use intersphinx and update entrypoints docs (#5125)

[33mcommit d79d9eaaff90801668613a4e3d5d8a0004963f21[m
Author: Hyunsung Lee <ita9naiwa@gmail.com>
Date:   Thu May 30 22:56:19 2024 +0900

    [Misc] remove duplicate definition of `seq_lens_tensor` in model_runner.py (#5129)

[33mcommit f758505c736ce53a13567852594c3e05215bb6b2[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu May 30 06:29:48 2024 -0700

    [CI/Build] increase wheel size limit to 200 MB (#5130)

[33mcommit d910816c7356f4decd56eefb80e963b476cdf3e5[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu May 30 05:58:37 2024 -0700

    [Bugfix] Automatically Detect SparseML models (#5119)

[33mcommit 87d41c849d2cde9279fb08a3a0d97123e3d8fe2f[m
Author: Breno Faria <breno@veltefaria.de>
Date:   Thu May 30 11:52:14 2024 +0200

    [BUGFIX] [FRONTEND] Correct chat logprobs (#5029)
    
    Co-authored-by: Breno Faria <breno.faria@intrafind.com>

[33mcommit e07aff9e52342dc82b73c803ba69601242801bc4[m
Author: omkar kakarparthi <75638701+okakarpa@users.noreply.github.com>
Date:   Wed May 29 22:27:39 2024 -0500

    [CI/Build] Docker cleanup functionality for amd servers  (#5112)
    
    Co-authored-by: Alexey Kondratiev <alexey.kondratiev@amd.com>
    Co-authored-by: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
    Co-authored-by: Alexei V. Ivanov <alexei.ivanov@amd.com>
    Co-authored-by: omkarkakarparthi <okakarpa>

[33mcommit 5bf185a1c48fdca524dd76aec4a1424b3a09c9a1[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Wed May 29 20:30:18 2024 -0400

    [Bugfix] gptq_marlin: Ensure g_idx_sort_indices is not a Parameter (#5108)

[33mcommit 4fbcb0f27e78df75de47c0248ce6901cd081c8ff[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed May 29 16:51:18 2024 -0700

    [Doc][Build] update after removing vllm-nccl (#5103)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit 7c3604fb68031da36567151a9bdfe69e04de44b8[m
Author: Itay Etelis <92247226+Etelis@users.noreply.github.com>
Date:   Thu May 30 02:13:22 2024 +0300

    [Bugfix] logprobs is not compatible with the OpenAI spec #4795 (#5031)

[33mcommit b1c255630db60e08c394964b8ed6c0154d31a29f[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu May 30 07:05:01 2024 +0800

    [Core] Avoid the need to pass `None` values to `Sequence.inputs` (#5099)

[33mcommit eb6c50cdc2bfb58591bd524ff08c8016e7c0411a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu May 30 07:02:54 2024 +0800

    [Bugfix][CI/Build] Fix codespell failing to skip files in `git diff` (#5097)

[33mcommit eecd864388cba75421215411d42bde1c328fa518[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu May 30 07:02:25 2024 +0800

    [Bugfix][CI/Build] Fix test and improve code for `merge_async_iterators` (#5096)

[33mcommit ae495c74eab390e52bcade098ee8313679fa8802[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Thu May 30 01:26:33 2024 +0300

    [Doc]Replace deprecated flag in readme (#4526)

[33mcommit 4238bc82f24d5887784b04a353ed93e2360623b4[m
Author: afeldman-nm <156691304+afeldman-nm@users.noreply.github.com>
Date:   Wed May 29 12:09:13 2024 -0400

    [Core] Cross-attention KV caching and memory-management (towards eventual encoder/decoder model support) (#4837)

[33mcommit 594392d27a0dc3b1df84246afb46cc229946c0f3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed May 29 04:29:07 2024 -0700

    [Core][Distributed] improve p2p access check (#4992)

[33mcommit 18c1f16d86d5130ca989d32a3f05142a6652ba0d[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed May 29 15:16:41 2024 +0800

    [Bugfix] Fix arguments passed to `Sequence` in stop checker test (#5092)

[33mcommit 5bd3c650721cc5de451f034bcbed37d1a1a4116c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue May 28 22:13:52 2024 -0700

    [Core][Optimization] remove vllm-nccl (#5091)

[33mcommit 616e600e0b092050213e79fd2a10baabb30dcf6d[m
Author: Marut Pandya <pandyamarut@gmail.com>
Date:   Tue May 28 17:16:18 2024 -0700

    [Misc] add gpu_memory_utilization arg (#5079)
    
    Signed-off-by: pandyamarut <pandyamarut@gmail.com>

[33mcommit dfba529b4024fba9ce1346467318b35e8f2fa9d9[m
Author: Junichi Sato <junichi.sato@sbintuitions.co.jp>
Date:   Wed May 29 09:15:35 2024 +0900

    [Bugfix] Remove the last EOS token unless explicitly specified (#5077)

[33mcommit 5ae5ed1e6047d4095149e26526a618be0529a118[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed May 29 04:29:31 2024 +0800

    [Core] Consolidate prompt arguments to LLM engines (#4328)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 290f4ada2bf42174a53ae6aab2873e115c8ae11b[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue May 28 12:29:09 2024 -0500

    [Docs] Add Dropbox as sponsors (#5089)

[33mcommit dd8de11f0a15f9ef48cd1dcac02dd8e2a8bcb494[m
Author: Divakar Verma <137818590+divakar-amd@users.noreply.github.com>
Date:   Tue May 28 11:03:23 2024 -0500

    [Kernel][ROCm][AMD] Add fused_moe Triton configs for MI300X (#4951)
    
    This PR adds Triton kernel configs for the MoE kernel for MI300X

[33mcommit 9ba415588aeda8d99bda8889f90010f0d7330e89[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Tue May 28 08:32:42 2024 -0700

    [BugFix] Fix Embedding Models with TP>1 (#5075)

[33mcommit d4f398590786f0015d474b03a3d078db1e7d1be2[m
Author: Micha≈Ç Moskal <michal@moskal.me>
Date:   Mon May 27 19:07:07 2024 -0700

    [Core] Sliding window for block manager v2 (#4545)
    
    Co-authored-by: Ruth Evans <ruthevans@Ruths-MacBook-Pro.local>

[33mcommit 890aa93d275a2b75313629614ab9ed278a13f6d7[m
Author: Isotr0py <2037008807@qq.com>
Date:   Tue May 28 07:41:43 2024 +0800

    [Model] Add support for falcon-11B (#5069)

[33mcommit fbdb7b3ee2c3f7b58841c12b52ed4c83f508babb[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Mon May 27 22:26:14 2024 +0000

    [Core] Allow AQLM on Pascal (#5058)

[33mcommit 1102bef2195a102c6a5489a28329e543a600b4d8[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon May 27 15:18:17 2024 -0700

    [Bugfix / Core] Prefix Caching Guards (merged with main) (#4846)
    
    Co-authored-by: rsnm2 <rshaw@neuralmagic.com>
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>

[33mcommit f17a1a8f9665bb237a3dddda7dc93f259e5e81e0[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sat May 25 10:28:16 2024 -0700

    [Misc] Make Serving Benchmark More User-friendly (#5044)

[33mcommit d5a16977729928a2ceafb5ec8764081f40f7cdff[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Sat May 25 10:00:14 2024 -0700

    [Dynamic Spec Decoding] Minor fix for disabling speculative decoding (#5000)

[33mcommit 325c119961698c27d8d11d61d019a6d57c814c51[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri May 24 23:49:49 2024 -0700

    [Misc] add logging level env var (#5045)

[33mcommit 8e192ff967b44b186ea02d30e49fddf656fdfe50[m
Author: Eric Xihui Lin <xihuil.silence@gmail.com>
Date:   Sat May 25 01:00:52 2024 -0400

    [Kernel][Backend][Model] Blocksparse flash attention kernel and Phi-3-Small model (#4799)
    
    Co-authored-by: beagleski <yunanzhang@microsoft.com>
    Co-authored-by: bapatra <bapatra@microsoft.com>
    Co-authored-by: Barun Patra <codedecde@users.noreply.github.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit e64fde4b013cb8bb2321f59ba78aca50b02071cb[m
Author: leiwen83 <leiwen83@users.noreply.github.com>
Date:   Sat May 25 01:07:09 2024 +0800

    [Core][Bugfix]: fix prefix caching for blockv2 (#4764)
    
    Co-authored-by: Lei Wen <wenlei03@qiyi.com>

[33mcommit 919770957f26d71a5a6eda7a1a7443dfeb5ba0ee[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri May 24 14:28:27 2024 +0200

    [Bugfix] Fix Mistral v0.3 Weight Loading (#5005)
    
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 6a50f4cafaf9f734b3f6ad11e6af38838aa3baf8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu May 23 16:21:54 2024 -0700

    [Doc] add ccache guide in doc (#5012)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit e3470f87538ec86d1094ac4747519c6300213088[m
Author: Elisei Smirnov <61423871+kezouke@users.noreply.github.com>
Date:   Fri May 24 01:04:24 2024 +0300

    [Core]: Option To Use Prompt Token Ids Inside Logits Processor (#4985)
    
    Co-authored-by: Elisei Smirnov <el.smirnov@innopolis.university>

[33mcommit a1242324c99ff8b1e29981006dfb504da198c7c3[m
Author: Dipika Sikka <ds3822@columbia.edu>
Date:   Thu May 23 17:29:18 2024 -0400

    [Kernel] Initial Activation Quantization Support (#4525)
    
    Co-authored-by: Varun Sundar Rabindranath <varunsundar08@gmail.com>
    Co-authored-by: Varun Sundar Rabindranath <varun@neuralmagic.com>

[33mcommit 5eda2ea02a01b2457f4d6ac2a217f2fa8a2e5d5f[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Thu May 23 09:54:48 2024 -0700

    [Core][1/N] Support send/recv in PyNCCL Groups (#4988)
    
    Signed-off-by: Muralidhar Andoorveedu <muralidhar.andoorveedu@centml.ai>

[33mcommit 2ba80bed2732edf42b1014ea4e34757849fc93d0[m
Author: Letian Li <lotianmail@gmail.com>
Date:   Thu May 23 17:08:58 2024 +0100

    [Bugfix] Update Dockerfile.cpu to fix NameError: name 'vllm_ops' is not defined (#5009)

[33mcommit 606625329648e6eff1883e23040adfad82f219cf[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Thu May 23 02:39:27 2024 -0400

    Marlin 24 prefill performance improvement (about 25% better on average) (#4983)

[33mcommit ee3eea0a1b2c690557455d97074d8829d5a98320[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed May 22 15:55:56 2024 -0700

    [Misc] Take user preference in attention selector (#4960)

[33mcommit a36de682d4283c60777bc3022ed3ce71cd90b904[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Wed May 22 15:26:56 2024 -0700

    [Minor] Fix small typo in llama.py: QKVParallelLinear -> QuantizationConfig (#4991)

[33mcommit eb6d3c264d0cd8e44dec16bca7947fbe96415ce9[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed May 22 14:17:27 2024 -0700

    [Core] Eliminate parallel worker per-step task scheduling overhead (#4894)

[33mcommit 97b030005c7f5cde7c1b97c718a8841db7d6220b[m
Author: raywanb <112235519+raywanb@users.noreply.github.com>
Date:   Thu May 23 04:58:59 2024 +0800

    [Model] LoRA gptbigcode implementation (#3949)

[33mcommit a3a73ab0696b6692f3eecf80271a01fa97bd001d[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed May 22 13:28:20 2024 -0700

    [Misc] Load FP8 kv-cache scaling factors from checkpoints (#4893)
    
    The 2nd PR for #4532.
    
    This PR supports loading FP8 kv-cache scaling factors from a FP8 checkpoint (with .kv_scale parameter).

[33mcommit 8674f9880e2d8574c2adc759027e0f27dc9b95de[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Wed May 22 10:10:43 2024 -0400

    [Kernel] Fixup for CUTLASS kernels in CUDA graphs (#4954)
    
    Pass the CUDA stream into the CUTLASS GEMMs, to avoid future issues with CUDA graphs

[33mcommit c74c913bfbefc5d7a1302557eb35cdcbecd91f67[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Wed May 22 22:02:58 2024 +0900

    [misc] remove comments that were supposed to be removed (#4977)

[33mcommit 5f6d10c14c17122e6d711a4829ee0ca672e07f6f[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Wed May 22 03:18:41 2024 -0400

    [CI/Build] Enforce style for C++ and CUDA code with `clang-format` (#4722)

[33mcommit 9b9a10d6cb89f18e054daa66f25cb8f17c723b2c[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Wed May 22 05:32:35 2024 +0000

    [Frontend] Dynamic RoPE scaling (#4638)

[33mcommit 99eff67ba9155b5fec9a9abd939e3a29a1b42dce[m
Author: Isotr0py <41363108+Isotr0py@users.noreply.github.com>
Date:   Wed May 22 03:33:25 2024 +0800

    [Bugfix][Kernel] Add head size check for attention backend selection (#4944)

[33mcommit 14772eeb8e8ec76e5e70142d12a7332fcec28ccb[m
Author: Kante Yin <kerthcet@gmail.com>
Date:   Wed May 22 00:30:52 2024 +0800

    [Bugfix] Fix flag name for  `max_seq_len_to_capture` (#4935)
    
    Signed-off-by: kerthcet <kerthcet@gmail.com>

[33mcommit 757b62c49560baa6f294310a53032348a0d95939[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue May 21 12:06:10 2024 -0400

    [CI/Build] Codespell ignore `build/` directory (#4945)

[33mcommit e941f885843d4bcd239f805a9267729e9631556f[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue May 21 00:17:25 2024 -0700

    [Docs] Add acknowledgment for sponsors (#4925)

[33mcommit f12c3b5b3d076a67662b76d215fd875fd6cdf6d7[m
Author: Isotr0py <41363108+Isotr0py@users.noreply.github.com>
Date:   Tue May 21 13:24:17 2024 +0800

    [Model] Add Phi-2 LoRA support (#4886)

[33mcommit d130b573a0162173002b97e2112c6c1c10d0ca8e[m
Author: HUANG Fei <hzhwcmhf@gmail.com>
Date:   Tue May 21 13:22:22 2024 +0800

    [Model] add rope_scaling support for qwen2 (#4930)

[33mcommit 65ae8c2c8f52e0c98e4e26ad1255772d888592a6[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon May 20 17:48:32 2024 -0700

    [Core] Fix scheduler considering "no LoRA" as "LoRA" (#4897)

[33mcommit c3af44722cff56bba5fc912c8e16d9de02dfb532[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Mon May 20 13:16:57 2024 -0700

    [Doc]Add documentation to benchmarking script when running TGI (#4920)

[33mcommit 1937e29848c8de8634c5421612d57863aa0e2a51[m
Author: Aurick Qiao <aurickq@users.noreply.github.com>
Date:   Mon May 20 14:46:12 2024 -0400

    [Core] Sharded State Loader download from HF (#4889)

[33mcommit f0eecee6106774e1e0f9b31c7438cde77654df52[m
Author: Mor Zusman <mor.zusmann@gmail.com>
Date:   Mon May 20 21:44:25 2024 +0300

    [Bugfix] Fix dummy weight for fp8 (#4916)
    
    Allow dummy load format for fp8,
    torch.uniform_ doesn't support FP8 at the moment
    
    Co-authored-by: Mor Zusman <morz@ai21.com>

[33mcommit 943e72ca56974b4d8b5a141182e717d2abd3a819[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Mon May 20 13:29:28 2024 -0500

    [Build/CI] Enabling AMD Entrypoints Test (#4834)
    
    Co-authored-by: Alexey Kondratiev <alexey.kondratiev@amd.com>

[33mcommit 546a97ef691f242c899a5e0906d0e75f42694e95[m
Author: Wenwei Zhang <40779233+ZwwWayne@users.noreply.github.com>
Date:   Tue May 21 01:45:06 2024 +0800

    [Misc]: allow user to specify port in distributed setting (#4914)

[33mcommit da5a0b539d6a5fe0c0195513a797814d2c267540[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Mon May 20 10:55:34 2024 -0400

    Remove marlin warning (#4918)

[33mcommit 6287537a0c970bda1fc8b31f2bde1bcf2d26e151[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon May 20 16:11:25 2024 +0800

    [Model] LLaVA model refactor (#4910)

[33mcommit b57e6c59491ea7d60af413ad4a6455812b9c6c50[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 19 18:11:30 2024 -0700

    [Kernel] Add flash-attn back (#4907)

[33mcommit 27ce85476e6b170c5c90c65ac5c3268911135766[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Sun May 19 11:37:34 2024 -0400

    [Kernel] Add marlin_24 unit tests (#4901)

[33mcommit f68470e803df575f294e67167b4b83adfe004cfa[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sun May 19 15:13:33 2024 +0800

    [Bugfix][Model] Add base class for vision-language models (#4809)

[33mcommit 2e9a2227ecee8990f0552518fc40dba67f1026b3[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Sat May 18 16:05:23 2024 +0900

    [Lora] Support long context lora  (#4787)
    
    Currently we need to call rotary embedding kernel for each LoRA, which makes it hard to serve multiple long context length LoRA. Add batched rotary embedding kernel and pipe it through.
    
    It replaces the rotary embedding layer to the one that is aware of multiple cos-sin-cache per scaling factors.
    
    Follow up of https://github.com/vllm-project/vllm/pull/3095/files

[33mcommit c0724fc9150329d42abaf2f0f77dc8ca91d48acb[m
Author: alexeykondrat <143633163+alexeykondrat@users.noreply.github.com>
Date:   Sat May 18 01:09:11 2024 -0400

    [ROCm][Hardware][AMD] Adding Navi21 to fallback to naive attention if Triton is not used (#4658)

[33mcommit 86b45ae065e8c5e4a5f2af3ee1dc19a261c58775[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri May 17 14:58:52 2024 -0400

    [Bugfix] Relax tiktoken to >= 0.6.0 (#4890)

[33mcommit c5711ef98519de25d1f51121f7848a13f2891fc1[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri May 17 10:52:11 2024 -0700

    [Doc] Update Ray Data distributed offline inference example (#4871)

[33mcommit 48d5985a088c6e13e9ad9b0c7a0ce846e30b529f[m
Author: eigenLiu <33959526+eigen2017@users.noreply.github.com>
Date:   Sat May 18 00:43:19 2024 +0800

    Sync huggingface modifications of qwen Moe model (#4774)

[33mcommit 33e0823de583819f39e88c39ea3f7dd4e07c3990[m
Author: Jinzhen Lin <linjinzhen@hotmail.com>
Date:   Fri May 17 17:43:34 2024 +0800

    [Bugfix] fix rope error when load models with different dtypes  (#4835)

[33mcommit 26148120b3c05704409a425d017f0a51fca3b7cc[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Thu May 16 22:58:25 2024 -0500

    [Build/CI] Extending the set of AMD tests with Regression, Basic Correctness, Distributed, Engine, Llava Tests (#4797)

[33mcommit 0150a1063029f0238c25bc5a2ea0943b9650d522[m
Author: bofeng huang <bofenghuang7@gmail.com>
Date:   Fri May 17 03:47:22 2024 +0200

    [Frontend] OpenAI API server: Do not add bos token by default when encoding (#4688)

[33mcommit 8e7fb5d43ae74e0a75a7da940a63c7891208d268[m
Author: Kante Yin <kerthcet@gmail.com>
Date:   Fri May 17 07:37:29 2024 +0800

    Support to serve vLLM on Kubernetes with LWS (#4829)
    
    Signed-off-by: kerthcet <kerthcet@gmail.com>

[33mcommit 9a31a817a85ac4249bf82dd8b6f90ef6b8e81fef[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu May 16 15:42:29 2024 -0700

    [Bugfix] Fix FP8 KV cache support (#4869)

[33mcommit 2060e93659f1f63a3d2a76aee61559ccb1fe732e[m
Author: Tyler Michael Smith <tyler@neuralmagic.com>
Date:   Thu May 16 18:32:50 2024 -0400

    [Kernel] Add w8a8 CUTLASS kernels (#4749)

[33mcommit 8435b207af398cb6cec961f8ac8e1d8bb5164b3e[m
Author: Silencio <19430328+Silencioo@users.noreply.github.com>
Date:   Fri May 17 02:16:09 2024 +0800

    [Kernel] Add punica dimension for Qwen1.5-32B LoRA (#4850)
    
    Co-authored-by: Silencio <silencio@adsl-99-6-187-6.dsl.irvnca.sbcglobal.net>

[33mcommit 10fa9eea21ae757d17c1369afa6172598db3be92[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu May 16 11:07:41 2024 -0700

    [Misc] remove old comments (#4866)

[33mcommit e08188081be890f72a8d3dda66e7e1ce0a45216c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu May 16 10:59:52 2024 -0700

    [Core][Distributed] remove graph mode  function (#4818)

[33mcommit b5853f99639afd82cb18f131dce7f8c41eda74bd[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Thu May 16 13:46:52 2024 -0400

    [ROCm][AMD][Bugfix] adding a missing triton autotune config (#4845)

[33mcommit f09edd8a25d54c48eb804abe391e98d0b85b9ea2[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu May 16 10:02:56 2024 -0700

    Add JSON output support for benchmark_latency and benchmark_throughput (#4848)

[33mcommit 6979ade3840703d055402e78168194644e3cbdd8[m
Author: Alexander Matveev <59768536+alexm-neuralmagic@users.noreply.github.com>
Date:   Thu May 16 12:56:15 2024 -0400

    Add GPTQ Marlin 2:4 sparse structured support (#4790)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic.com>

[33mcommit 9216b9cc38e8753de442877863ad651425902e1f[m
Author: Pierre Dulac <dulacpier@gmail.com>
Date:   Thu May 16 18:42:21 2024 +0200

    [Bugfix] Bypass authorization API token for preflight requests (#4862)

[33mcommit 5e0391c0406ec225b2c58bc22d5be864a432fe40[m
Author: Alex Wu <alexanderwu@berkeley.edu>
Date:   Thu May 16 11:42:41 2024 -0400

    [Frontend] Separate OpenAI Batch Runner usage from API Server (#4851)

[33mcommit dbc0754ddfc33e60454ec4a9cdba945f172a39ef[m
Author: Alex Wu <alexanderwu@berkeley.edu>
Date:   Thu May 16 11:42:17 2024 -0400

    [docs] Fix typo in examples filename openi -> openai (#4864)

[33mcommit 99caa4910651754f3f68de518ca42349c8c424d1[m
Author: Jinzhen Lin <linjinzhen@hotmail.com>
Date:   Thu May 16 21:55:29 2024 +0800

    [Kernel] add bfloat16 support for gptq marlin kernel (#4788)

[33mcommit 5c342570d7e4c73bfaa4c4057174b92117d322bb[m
Author: alexm-nm <59768536+alexm-nm@users.noreply.github.com>
Date:   Thu May 16 09:36:49 2024 -0400

    Add marlin unit tests and marlin benchmark script (#4815)

[33mcommit 973617ae02a4e8e6190674cf1cdb0c0803b65ae6[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Thu May 16 00:53:51 2024 -0700

    [Speculative decoding][Re-take] Enable TP>1 speculative decoding (#4840)
    
    Co-authored-by: Cade Daniel <edacih@gmail.com>
    Co-authored-by: Cade Daniel <cade@anyscale.com>

[33mcommit 30e754390c2a8a7198f472386d35ee1ec9443e4a[m
Author: Aurick Qiao <aurickq@users.noreply.github.com>
Date:   Thu May 16 01:11:54 2024 -0400

    [Core] Implement sharded state loader (#4690)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 52f8107cf2e5b3cc1a6a4a96c22b24505f02df01[m
Author: Alex Wu <itswu.alex@gmail.com>
Date:   Wed May 15 19:13:36 2024 -0400

    [Frontend] Support OpenAI batch file format (#4794)
    
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>

[33mcommit fc0d9dfc3afcea2e23649ef8eb8bbe0446682813[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu May 16 05:58:46 2024 +0800

    [Frontend] Re-enable custom roles in Chat Completions API (#4758)

[33mcommit 361c461a128a5df2faefeb70ffa98e61e4feda55[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed May 15 11:38:49 2024 -0700

    [Doc] Highlight the fourth meetup in the README (#4842)

[33mcommit a5675d348b126e53928e139d1ed5b2c00a0044e8[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Wed May 15 07:22:09 2024 -0700

    [Bugfix] Properly set distributed_executor_backend in ParallelConfig (#4816)

[33mcommit e9cdd2b1e20beb1c21c55441d0e6a4ed86f4e292[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed May 15 14:38:40 2024 +0800

    [CI/Build] Further decouple HuggingFace implementation from ours during tests (#4166)

[33mcommit 65bf2ac165734fb6339210c4b2b8ce68d2391b77[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Wed May 15 14:00:10 2024 +0900

    [Core][2/N] Model runner refactoring part 2. Combine prepare prefill / decode to a single API (#4681)
    
    This PR combines prepare_prompt and prepare_decode into a single API. This PR also coelsce the attn metadata for prefill/decode to a single class and allow to slice them when running attn backend.
    
    It also refactors subquery_start_loc which was not refactored in the previous PR

[33mcommit 8a7cc254a064b8d42bf4de7a9c3f29552240dfd9[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Wed May 15 11:52:45 2024 +0900

    Revert "[Kernel] Use flash-attn for decoding (#3648)" (#4820)
    
    Lora 3 & 4 test seems to have illegal memory access failure after this commit;
    
    [2024-05-14 23:51:18,182 E 22 22] logging.cc:101: Unhandled exception: N3c105ErrorE. what(): CUDA error: an illegal memory access was encountered
    <br class="Apple-interchange-newline">
    Exmaple: https://buildkite.com/vllm/ci/builds/7382#018f793d-1527-4e1c-ab59-c3a34ec55241
    
    This reverts commit 1356df5.
    
    FILL IN THE PR DESCRIPTION HERE
    
    FIX #xxxx (link existing issues this PR will resolve)

[33mcommit 29bc01bf3bc26642e4cee15ebd36a6ce5799326d[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue May 14 15:33:06 2024 -0700

    Add 4th meetup announcement to readme (#4817)

[33mcommit 676a99982fe9aabe72fd52a91e08988a653a7359[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue May 14 10:38:59 2024 -0700

    [Core] Add MultiprocessingGPUExecutor (#4539)
    
    Co-authored-by: SAHIL SUNEJA <suneja@us.ibm.com>

[33mcommit dc72402b5785a6ffadff59d4e018661278d4b028[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed May 15 00:57:08 2024 +0800

    [Bugfix][Doc] Fix CI failure in docs (#4804)
    
    This PR fixes the CI failure introduced by #4798.
    
    The failure originates from having duplicate target names in reST, and is fixed by changing the ref targets to anonymous ones. For more information, see this discussion.
    
    I have also changed the format of the links to be more distinct from each other.

[33mcommit ccb63a8245bceb9e6ba260eeef41b54ca8bdb370[m
Author: Kuntai Du <kuntai@uchicago.edu>
Date:   Tue May 14 05:34:33 2024 -0700

    [Core][Hash][Automatic Prefix caching] Accelerating the hashing function by avoiding deep copies (#4696)

[33mcommit c579b750a083931ad03ecac898aca5ad67c6c59c[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon May 13 18:48:00 2024 -0700

    [Doc] Add meetups to the doc (#4798)

[33mcommit 4bfa7e7f75eb5b1a397c93aeea1dea1afa867b2a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue May 14 08:47:42 2024 +0800

    [Doc] Add API reference for offline inference (#4710)

[33mcommit ac1fbf7fd2d1fdddc7b4953eeb3acae35c62766f[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon May 13 16:23:54 2024 -0700

    [Doc] Shorten README by removing supported model list (#4796)

[33mcommit 33d3914b1e6d85a855da1a69193030c1915cb6f9[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Mon May 13 16:00:27 2024 -0700

    [Bugfix] Fix dynamic FP8 quantization for Mixtral (#4793)

[33mcommit 1356df53bd5d6877358aff3d2bbd95f28f8009a4[m
Author: Stephen Krider <72541272+skrider@users.noreply.github.com>
Date:   Mon May 13 15:50:33 2024 -0700

    [Kernel] Use flash-attn for decoding (#3648)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: LiuXiaoxuanPKU <lilyliupku@gmail.com>

[33mcommit ce532ff45c8008c7157eb448860c13bcdd44823f[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Mon May 13 15:00:13 2024 -0700

    [Speculative decoding] Improve n-gram efficiency (#4724)

[33mcommit 8bc68e198c4c90ddc2e54fa76eb81c2c714bb1cd[m
Author: Sanger Steel <sangersteel@gmail.com>
Date:   Mon May 13 17:57:07 2024 -0400

    [Frontend] [Core] perf: Automatically detect vLLM-tensorized model, update `tensorizer` to version 2.9.0 (#4208)

[33mcommit 0fca3cdcf265cd375bca684d951702b6b7adf65a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon May 13 10:47:25 2024 -0700

    [Misc] Enhance attention selector (#4751)

[33mcommit e7c46b9527c9a50253657fd0078a0b1f23560ce4[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Mon May 13 23:50:44 2024 +0900

    [Scheduler] Warning upon preemption and Swapping (#4647)
    
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>

[33mcommit 350f9e107f0c00e59be1b970f96395494ed68b48[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Mon May 13 22:50:09 2024 +0800

    [CI/Build] Move `test_utils.py` to `tests/utils.py` (#4425)
    
    Since #4335 was merged, I've noticed that the definition of ServerRunner in the tests is the same as in the test for OpenAI API. I have moved the class to the test utilities to avoid code duplication. (Although it only has been repeated twice so far, I will add another similar test suite in #4200 which would duplicate the code a third time)
    
    Also, I have moved the test utilities file (test_utils.py) to under the test directory (tests/utils.py), since none of its code is actually used in the main package. Note that I have added __init__.py to each test subpackage and updated the ray.init() call in the test utilities file in order to relative import tests/utils.py.

[33mcommit 702bee461f448b0186eb9d673baad29fd923c884[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun May 12 17:47:59 2024 -0700

    [Core][Distributed] refactor custom allreduce to support multiple tp groups (#4754)

[33mcommit a7be4d00725db5ae4f738f70c3a89fd9dedaf7ec[m
Author: Swapnil Parekh <swapnilbp100@gmail.com>
Date:   Sun May 12 20:47:47 2024 -0400

    [CORE] Improvement in ranks code (#4718)

[33mcommit a709e87a4f35c1637d2bbea4bc2c9e5fe7fd70b5[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sun May 12 20:46:31 2024 -0400

    [CI/Build] Tweak Marlin Nondeterminism Issues (#4713)

[33mcommit 6eaccb7353cfe84d77981da726f6d82a8aefd2be[m
Author: Yikang Shen <yikang.shn@gmail.com>
Date:   Sun May 12 00:27:24 2024 -0400

    [Model] Add support for IBM Granite Code models (#4636)

[33mcommit e254497b66dcd87038969b0ad34d34425edfc5fe[m
Author: Chang Su <chang.s.su@oracle.com>
Date:   Sat May 11 11:30:37 2024 -0700

    [Model][Misc] Add e5-mistral-7b-instruct and Embedding API (#3734)

[33mcommit 4e12131089f192334f6e09c8fe5cd85af1e25327[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri May 10 15:14:40 2024 -0700

    [Core][Test] fix function name typo in custom allreduce (#4750)

[33mcommit fcc2994be657a897dd0732928754749048520b28[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri May 10 16:01:01 2024 -0600

    [CI] Nits for bad initialization of SeqGroup in testing (#4748)

[33mcommit 2e7796f2cf4537dd3b08d5de3aa8349f5db1a168[m
Author: heeju-kim2 <157340754+heeju-kim2@users.noreply.github.com>
Date:   Sat May 11 02:36:25 2024 +0900

    [Speculative decoding] CUDA graph support (#4295)
    
    Co-authored-by: Cade Daniel <edacih@gmail.com>

[33mcommit 706588a77d2099b118f53a53ef2dd7f8c2de9ffc[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Fri May 10 23:00:56 2024 +0800

    [Bugfix] Fix CLI arguments in OpenAI server docs (#4729)

[33mcommit 6a0f617210dfba76f3db4db1155d1f1489609133[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri May 10 23:54:32 2024 +0900

    [Core] Fix circular reference which leaked llm instance in local dev env (#4737)
    
    Storing exception frame is extremely prone to circular refernece because it contains the reference to objects.
    
    When tensorizer is not installed, it leaks llm instance because error frame has references to various modules which cause circular reference problem.
    
    I also found spec decoding has a circular reference issue, and I solved it using weakref.proxy.

[33mcommit dac6a3f6ed14ea4061b672f9290bfdf8bcdd996d[m
Author: Steve Grubb <ausearch.1@gmail.com>
Date:   Fri May 10 09:37:05 2024 -0400

    [Misc] Apply a couple g++ cleanups (#4719)

[33mcommit 64b77dfd7e1378853ec7b189f3d7d0e51ce18855[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Fri May 10 20:52:48 2024 +0800

    [Core]fix type annotation for `swap_blocks` (#4726)

[33mcommit 51d4094fda63b1d738f55ae9dd75d354b9c1143c[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu May 9 22:13:23 2024 -0700

    chunked-prefill-doc-syntax (#4603)
    
    Fix the docs: https://docs.vllm.ai/en/latest/models/performance.html
    
    Co-authored-by: sang <rkooo567@gmail.com>

[33mcommit e965d4618430db94fed73d4305c44c9147e47150[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Fri May 10 12:42:38 2024 +0800

    [Misc] Keep only one implementation of the create_dummy_prompt function. (#4716)

[33mcommit 208b71bcc1b94df1fdd2fc10da3e04c706340188[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu May 9 19:48:43 2024 -0700

    [Core][Distributed] refactor pynccl (#4591)
    
    [Core][Distributed] refactor pynccl to hold multiple communicators (#4591)

[33mcommit c83310174055bb124ea2197885b652efd59b7a0f[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Thu May 9 17:04:17 2024 -0700

    [Kernel] Refactor FP8 kv-cache with NVIDIA float8_e4m3 support (#4535)

[33mcommit 379da6dcb5f5d062d0452b2fc23291e5113dcf04[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Thu May 9 16:38:07 2024 -0700

    [Kernel] [FP8] Improve FP8 linear layer performance (#4691)
    
    This PR improves the FP8 performance of linear layers, which had been lacking before (#4118 (comment) and #4118 (comment)).
    
    We noticed that CUBLASLt can find a better algorithm if the first dimension of the matrix is greater than 16. So this PR enlarges matrices appropriately during quantization. This improves FP8 performance and removes the performance regression vs. FP16, in many cases exceeding FP16 performance.
    
    Here are benchmarks on llama3 70b (ITL numbers for 1000 input and 50 output tokens at fixed qps and at TP 4), all FP8 measurements are for dynamic quantization:
    
    qps = 1: 24 ms (FP8, this PR), 32 ms (FP8, previous main), 26 ms (FP16)
    qps = 2: 26 ms (FP8, this PR), 34ms (FP8, previous main), 28 ms (FP16)
    qps = 4: 33 ms (FP8, this PR), 44 ms (FP8, previous main), 36 ms (FP16)
    qps = 6: 46 ms (FP8, this PR), 56 ms (FP8, previous main), 54 ms (FP16)
    qps = 8: 85 ms (FP8, this PR), 85 ms (FP8, previous main), 138 ms (FP16)

[33mcommit ebce310b7433e050086f52ca48571807df467f50[m
Author: Hao Zhang <152229491+sfc-gh-hazhang@users.noreply.github.com>
Date:   Thu May 9 15:37:14 2024 -0700

    [Model] Snowflake arctic model implementation (#4652)
    
    Co-authored-by: Dash Desai <1723932+iamontheinet@users.noreply.github.com>
    Co-authored-by: Aurick Qiao <qiao@aurick.net>
    Co-authored-by: Aurick Qiao <aurick.qiao@snowflake.com>
    Co-authored-by: Aurick Qiao <aurickq@users.noreply.github.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit be0c5180ac0832a0b285d0845d458798bb3f0f4f[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu May 9 14:36:25 2024 -0400

    [Bugfix] Add logs for all model dtype casting (#4717)

[33mcommit cea64430f615ff90c67ff8375ec86562913c5500[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Thu May 9 11:10:13 2024 -0600

    [Bugfix] Update grafana.json (#4711)

[33mcommit a3c124570a66f746ba09faabe2e14851386b395a[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri May 10 00:53:14 2024 +0800

    [Bugfix] Fix CLI arguments in OpenAI server docs (#4709)

[33mcommit ff5abcd7463211251bcf19916ae3b45d762f48d4[m
Author: kliuae <17350011+kliuae@users.noreply.github.com>
Date:   Fri May 10 00:19:50 2024 +0800

    [ROCm] Add support for Punica kernels on AMD GPUs (#3140)
    
    Co-authored-by: miloice <jeffaw99@hotmail.com>

[33mcommit 0ee535b2945d042cbb1fc6e63fd3fddd94d491f2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu May 9 09:04:59 2024 -0700

    [Misc] Set block size at initialization & Fix test_model_runner (#4705)

[33mcommit 190bc838e17196733526896bf2861f8d05bd3f43[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu May 9 00:17:17 2024 -0700

    [Misc] Remove unnecessary ModelRunner imports (#4703)

[33mcommit f12b20deccbc6c8bb5cdeac053d75178341c66c1[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Thu May 9 13:48:33 2024 +0800

    [Frontend] Move async logic outside of constructor (#4674)

[33mcommit 16bc0a098f6d34050637c3336183fb6966300dd5[m
Author: Mahmoud Ashraf <hassouna97.ma@gmail.com>
Date:   Thu May 9 08:02:31 2024 +0300

    [Frontend] add tok/s speed metric to llm class when using tqdm (#4400)
    
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit e288df0632d5bdde76c20bed8310b46d35b8e5ac[m
Author: alexm-nm <59768536+alexm-nm@users.noreply.github.com>
Date:   Wed May 8 20:14:31 2024 -0400

    [Bugfix] Fine-tune gptq_marlin configs to be more similar to marlin (#4626)

[33mcommit 8b9241be3a0020724e145bf600d9710b3d59b167[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Wed May 8 16:24:46 2024 -0700

    [Speculative decoding] [Bugfix] Fix overallocation in ngram + spec logprobs (#4672)

[33mcommit f942efb5a3712498b8b583d2d9345f98d15f22f0[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Wed May 8 14:44:00 2024 -0700

    [Dynamic Spec Decoding] Auto-disable by the running queue size (#4592)
    
    Co-authored-by: Cade Daniel <edacih@gmail.com>

[33mcommit 89579a201f2c84b512f0e1006ac2ea0d979803ab[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 8 13:15:34 2024 -0700

    [Misc] Use vllm-flash-attn instead of flash-attn (#4686)

[33mcommit 230c4b38c10148c3fbbbb67cd1046766d73c865a[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed May 8 13:14:02 2024 -0700

    [CI/Test] fix swap test for multi gpu (#4689)

[33mcommit 20cfcdec998b39f5dbb0dc89efe4122f95f5cb16[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed May 8 12:07:05 2024 -0700

    [Core][Optimization] change python dict to pytorch tensor for blocks to swap (#4659)

[33mcommit ad932a221d2a4c1e6355021bb9e9c47f7a179e51[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed May 8 10:33:18 2024 -0700

    [Core] Faster startup for LoRA enabled models (#4634)

[33mcommit 5510cf0e8a6a3ee56daefb86b145c7f2a000817f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 8 09:59:31 2024 -0700

    [Misc] Add `get_name` method to attention backends (#4685)

[33mcommit 0f9a6e3d229cade0ae9a53a4f69a38f52e430bd0[m
Author: DefTruth <31974251+DefTruth@users.noreply.github.com>
Date:   Thu May 9 00:19:58 2024 +0800

    [Bugfix][Kernel] allow non-power-of-2 for prefix prefill with alibi  (#4573)

[33mcommit f6a593093ac201c286e99a849091801a88d83622[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu May 9 00:44:35 2024 +0900

    [CI] Make mistral tests pass (#4596)

[33mcommit d7740ea4dcee4ab75d7d6eef723f33cae957b288[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu May 9 00:42:28 2024 +0900

    [Core] Optimize sampler get_logprobs (#4594)

[33mcommit cc466a32903d53d0ceca459b766d74ad668c8f87[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue May 7 19:34:47 2024 -0700

    [Core][Distributed] support cpu&device in broadcast tensor dict (#4660)
    
    [Core][Distributed] support both cpu and device tensor in broadcast tensor dict (#4660)

[33mcommit 8344f7742b794ca6ec9bcb891c178cd0551f23d0[m
Author: leiwen83 <leiwen83@users.noreply.github.com>
Date:   Wed May 8 02:40:18 2024 +0800

    [Bug fix][Core] fixup ngram not setup correctly (#4551)
    
    Co-authored-by: Lei Wen <wenlei03@qiyi.com>
    Co-authored-by: Cade Daniel <edacih@gmail.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit 469f85c7829c301b6dec48725951b5501c18d611[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue May 7 11:06:32 2024 -0700

    [Core][Optimization] change copy-on-write from dict[int, list] to list (#4648)

[33mcommit 10760da8003824e208c94fb2bfcdb6fdd0f4edda[m
Author: Austin Veselka <50646302+FurtherAI@users.noreply.github.com>
Date:   Tue May 7 12:59:07 2024 -0500

    [Bugfix] Fixed error in slice_lora_b for MergedQKVParallelLinearWithLora (#4609)

[33mcommit 478aed5827169ef3ee07fdab42a935532a9ff68d[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Tue May 7 11:23:17 2024 -0500

    [Build/CI] Fixing 'docker run' to re-enable AMD CI tests. (#4642)

[33mcommit 63575bc2e197b85ce1c911421ff30c5459e35e9c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon May 6 21:30:27 2024 -0700

    [Core][Optimization] change python dict to pytorch tensor (#4607)

[33mcommit a98187cf7227695819e199e2e3ad35be0a9a84f3[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Mon May 6 17:39:28 2024 -0700

    [Kernel] Make static FP8 scaling more robust (#4570)
    
    Previously FP8 static scaling works if the scales are overestimating the maxima of all activation tensors during computation. However this will not always be the case even if the scales were calibrated very carefully. For example, with the activations in my checkpoint
    
    https://huggingface.co/pcmoritz/Mixtral-8x7B-v0.1-fp8-act-scale
    
    (which was calibrated on https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k), I'm getting the following mostly random performance on MMLU:
    
    |      Groups      |Version|Filter|n-shot|Metric|Value |   |Stderr|
    |------------------|-------|------|-----:|------|-----:|---|-----:|
    |mmlu              |N/A    |none  |     0|acc   |0.2295|¬±  |0.0035|
    | - humanities     |N/A    |none  |     5|acc   |0.2421|¬±  |0.0062|
    | - other          |N/A    |none  |     5|acc   |0.2398|¬±  |0.0076|
    | - social_sciences|N/A    |none  |     5|acc   |0.2171|¬±  |0.0074|
    | - stem           |N/A    |none  |     5|acc   |0.2125|¬±  |0.0073|
    With the fix in this PR where the scaled activations are clamped between [-std::numeric_limits<c10::Float8_e4m3fn>::max(), std::numeric_limits<c10::Float8_e4m3fn>::max()] to make sure there are no NaNs, the performance is
    
    |      Groups      |Version|Filter|n-shot|Metric|Value |   |Stderr|
    |------------------|-------|------|-----:|------|-----:|---|-----:|
    |mmlu              |N/A    |none  |     0|acc   |0.7008|¬±  |0.0036|
    | - humanities     |N/A    |none  |     5|acc   |0.6453|¬±  |0.0065|
    | - other          |N/A    |none  |     5|acc   |0.7692|¬±  |0.0072|
    | - social_sciences|N/A    |none  |     5|acc   |0.8083|¬±  |0.0070|
    | - stem           |N/A    |none  |     5|acc   |0.6115|¬±  |0.0083|
    This is not perfect yet but is getting very close to the FP16 / dynamic activation scale performance.

[33mcommit bd99d226295776011f4ea4831498a7103bc4e43b[m
Author: Noam Gat <noamgat@gmail.com>
Date:   Tue May 7 02:51:59 2024 +0300

    Update lm-format-enforcer to 0.10.1 (#4631)

[33mcommit 19cb4716ee700e5d8baa64d7cf14fb5da3737f6d[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Mon May 6 16:18:57 2024 -0700

    [CI] Add retry for agent lost (#4633)

[33mcommit e186d37cb135107a09cd684e4fa2cf30c0ce6f28[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon May 6 15:23:36 2024 -0700

    [CI] use ccache actions properly in release workflow (#4629)

[33mcommit 323f27b9048713cdbab31995265975842a937167[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Tue May 7 00:31:05 2024 +0800

    [Bugfix] Fix `asyncio.Task` not being subscriptable (#4623)

[33mcommit 0650e5935b0f6af35fb2acf71769982c47b804d7[m
Author: zhaoyang-star <zhaoyangstar@foxmail.com>
Date:   Mon May 6 07:58:55 2024 +0800

    Disable cuda version check in vllm-openai image (#4530)

[33mcommit c7f2cf2b7f67bce5842fedfdba508440fe257375[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat May 4 21:28:58 2024 -0700

    [CI] Reduce wheel size by not shipping debug symbols (#4602)

[33mcommit 8d8357c8ed1f3ddb6a0e8f3287ec669a13d77df1[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat May 4 17:09:49 2024 -0700

    bump version to v0.4.2 (#4600)

[33mcommit 43029870694de0789a10ab49f181f1cba6ec741a[m
Author: DearPlanet <149305930+DearPlanet@users.noreply.github.com>
Date:   Sun May 5 06:39:34 2024 +0800

    [Bugfix] Fix inappropriate content of model_name tag in Prometheus metrics (#3937)

[33mcommit 021b1a2ab7497769dae8a67ea3467e4bafb474c5[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat May 4 13:44:36 2024 -0700

    [CI] check size of the wheels (#4319)

[33mcommit 2a052011ca473a9dc8160f3daa1f5f63a2ad1fe3[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Sat May 4 14:45:16 2024 -0400

    [Kernel] Support MoE Fp8 Checkpoints for Mixtral (Static Weights with Dynamic/Static Activations) (#4527)
    
    Follow on to #4332 to enable FP8 checkpoint loading for Mixtral and supersedes #4436.
    
    This PR enables the following checkpoint loading features for Mixtral:
    
    Supports loading fp8 checkpoints for Mixtral, such as this "nm-testing/Mixtral-8x7B-Instruct-v0.1-FP8" test model
    Supports static or dynamic activation quantization with static weight quantization (all per tensor)
    Supports different scales for each expert weight
    Supports Fp8 in QKV layer
    Notes:
    
    The Expert Gate/Router always runs at half / full precision for now.
    If there are different weight scales between QKV layer (for separate QKV weights), they are re-quantized using layer.weight_scale.max() so we can have a single gemm for performance.

[33mcommit 36fb68f94792a8cec8df5b58bab7ab4d4d6158b4[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Sat May 4 16:18:00 2024 +0900

    [Doc] Chunked Prefill Documentation (#4580)

[33mcommit bc8ad68455ce41ba672764f4a53df5a87d1dbe99[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri May 3 17:47:07 2024 -0700

    [Misc][Refactor] Introduce ExecuteModelData (#4540)

[33mcommit 344bf7cd2d66a8b13f216f61c7a6d5d70576a498[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri May 3 15:55:56 2024 -0700

    [Misc] add installation time env vars (#4574)

[33mcommit ab502751117d3785384b9c33ee88e0aff93bbf05[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Fri May 3 15:52:01 2024 -0700

    [Speculative decoding] Support target-model logprobs (#4378)

[33mcommit 43c413ec570e94869ee7b7d275de720219a34357[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Fri May 3 15:51:27 2024 -0700

    [Kernel] Use flashinfer for decoding (#4353)
    
    Co-authored-by: LiuXiaoxuanPKU <llilyliupku@gmail.com>

[33mcommit f8e7adda21810104382bdf3febe3ea02c72f7348[m
Author: Sebastian Schoennenbeck <schoennenbeck@gmail.com>
Date:   Fri May 3 20:04:14 2024 +0200

    Fix/async chat serving (#2727)

[33mcommit 7e65477e5e737927c2f07c913ede0763134504a3[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Fri May 3 13:32:21 2024 -0400

    [Bugfix] Allow "None" or "" to be passed to CLI for string args that default to None (#4586)

[33mcommit 3521ba4f2554bcf246a95a9fb2d1b80990a6835b[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Sat May 4 02:20:12 2024 +0900

    [Core][Model runner refactoring 1/N] Refactor attn metadata term (#4518)

[33mcommit 2d7bce9cd5981db146b18a8a95c5a7e0480687bd[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu May 2 22:13:49 2024 -0700

    [Doc] add env vars to the doc (#4572)

[33mcommit ce3f1eedf8e7e015054a166f17205eb3206e4625[m
Author: DefTruth <31974251+DefTruth@users.noreply.github.com>
Date:   Fri May 3 12:48:08 2024 +0800

    [Misc] remove chunk detected debug logs (#4571)

[33mcommit 808632d3b4effd3c0807325b529d0354894c31b1[m
Author: Yang, Bo <pop.atry@gmail.com>
Date:   Thu May 2 18:35:18 2024 -0700

    [BugFix] Prevent the task of `_force_log` from being garbage collected (#4567)

[33mcommit 344a5d0c332c3945caf336fd1d21f450f1455e6c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu May 2 17:32:33 2024 -0700

    [Core][Distributed] enable allreduce for multiple tp groups (#4566)

[33mcommit 0f8a91401c89ac0a8018def3756829611b57727f[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri May 3 06:31:20 2024 +0900

    [Core] Ignore infeasible swap requests. (#4557)

[33mcommit 9b5c9f9484858279a937498ebf9239a9df67f61f[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Thu May 2 14:29:07 2024 -0500

    [CI/Build] AMD CI pipeline with extended set of tests. (#4267)
    
    Co-authored-by: simon-mo <simon.mo@hey.com>

[33mcommit 32881f3f3106e17d2fd52d8ac00217a0f0b2476a[m
Author: Micha≈Ç Moskal <michal@moskal.me>
Date:   Thu May 2 11:23:37 2024 -0700

    [kernel] fix sliding window in prefix prefill Triton kernel (#4405)
    
    Co-authored-by: SangBin Cho <rkooo567@gmail.com>

[33mcommit 5b8a7c1cb0f1bb81266bae98944c055a8abb1a68[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu May 2 11:13:25 2024 -0700

    [Misc] centralize all usage of environment variables (#4548)

[33mcommit 1ff0c73a79b0c2788b12bd83523b74c01d414480[m
Author: Mark McLoughlin <markmc@redhat.com>
Date:   Thu May 2 18:52:51 2024 +0100

    [BugFix] Include target-device specific requirements.txt in sdist (#4559)

[33mcommit 5ad60b0cbd0a396eb3f1fda6bbf2c95aff6d5ecf[m
Author: Hu Dong <itechbear@gmail.com>
Date:   Fri May 3 01:50:25 2024 +0800

    [Misc] Exclude the `tests` directory from being packaged (#4552)

[33mcommit fb087af52e3834d98250a455355a3ef329663168[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri May 3 02:47:41 2024 +0900

    [mypy][7/N] Cover all directories (#4555)

[33mcommit 7038e8b80303bf6128acbe508dec910183a1be56[m
Author: alexm-nm <59768536+alexm-nm@users.noreply.github.com>
Date:   Thu May 2 12:56:22 2024 -0400

    [Kernel] Support running GPTQ 8-bit models in Marlin (#4533)

[33mcommit 2a85f9300733c09ec90819bc6df4bff8f103fd67[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed May 1 21:28:21 2024 -0700

    [Core][Distributed] enable multiple tp group (#4512)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit cf8cac8c701079a3fda068ffd1cd6f72a490aa6d[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu May 2 12:01:00 2024 +0900

    [mypy][6/N] Fix all the core subdirectory typing (#4450)
    
    Co-authored-by: Cade Daniel <edacih@gmail.com>

[33mcommit 5e401bce17ae9b327020ade6ba0ddceea2853451[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Thu May 2 05:57:12 2024 +0300

    [CI]Add regression tests to ensure the async engine generates metrics (#4524)

[33mcommit 0d62fe58dbb58cfe4132005ce7ff37319d66981d[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu May 2 11:24:13 2024 +0900

    [Bug fix][Core] assert num_new_tokens == 1 fails when SamplingParams.n is not 1 and max_tokens is large & Add tests for preemption (#4451)

[33mcommit b8afa8b95a4eee008a9b72440620113e5bfbe962[m
Author: Danny Guinther <dguinther@neuralmagic.com>
Date:   Wed May 1 20:34:40 2024 -0400

    [MISC] Rework logger to enable pythonic custom logging configuration to be provided (#4273)

[33mcommit 826b82a260ebb1ea7edd04a3278d5fb9b103a76e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 1 16:47:59 2024 -0700

    [Misc] Fix expert_ids shape in MoE (#4517)

[33mcommit c9d852d601ce1a02f6748ab62db8694c22772583[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Wed May 1 16:30:52 2024 -0700

    [Misc] Remove Mixtral device="cuda" declarations (#4543)
    
    Remove the device="cuda" declarations in mixtral as promised in #4343

[33mcommit 6ef09b08f88b675f84b7140238286e5d4c5304c8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed May 1 15:23:06 2024 -0700

    [Core][Distributed] fix pynccl del error (#4508)

[33mcommit 3a922c1e7ee6753f41c6cc9d6d47d3b2d0110447[m
Author: Roy <jasonailu87@gmail.com>
Date:   Thu May 2 04:08:14 2024 +0800

    [Bugfix][Core] Fix and refactor logging stats (#4336)

[33mcommit c47ba4aaa94d067bbb0437526cae9a33c698c717[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Wed May 1 19:31:22 2024 +0000

    [Bugfix] Add validation for seed (#4529)

[33mcommit 24bb4fe432fffeccf7a27270ee70aff1b1b8a89a[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Wed May 1 11:47:38 2024 -0700

    [Kernel] Update fused_moe tuning script for FP8 (#4457)
    
    This PR updates the tuning script for the fused_moe kernel to support FP8 and also adds configurations for TP4. Note that for the configuration I removed num_warps and num_stages for small batch sizes since that improved performance and brought the benchmarks on par with the numbers before in that regime to make sure this is a strict improvement over the status quo.
    
    All the numbers below are for mistralai/Mixtral-8x7B-Instruct-v0.1, 1000 input and 50 output tokens.
    
    Before this PR (with static activation scaling):
    
    qps = 1: 9.8 ms ITL, 0.49s e2e latency
    qps = 2: 9.7 ms ITL, 0.49s e2e latency
    qps = 4: 10.1 ms ITL, 0.52s e2e latency
    qps = 6: 11.9 ms ITL, 0.59s e2e latency
    qps = 8: 14.0 ms ITL, 0.70s e2e latency
    qps = 10: 15.7 ms ITL, 0.79s e2e latency
    
    After this PR (with static activation scaling):
    
    qps = 1: 9.8 ms ITL, 0.49s e2e latency
    qps = 2: 9.7 ms ITL, 0.49s e2e latency
    qps = 4: 10.2 ms ITL, 0.53s e2e latency
    qps = 6: 11.9 ms ITL, 0.59s e2e latency
    qps = 8: 11.9 ms ITL, 0.59s e2e latency
    qps = 10: 12.1 ms ITL, 0.61s e2e latency

[33mcommit a657bfc48a11d87de146629a7b6c03e9ccfbc3fc[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed May 1 11:41:59 2024 -0700

    [Core] Add `multiproc_worker_utils` for multiprocessing-based workers (#4357)

[33mcommit 24750f4cadd15a2b3a52f982e39eb9803749efbc[m
Author: leiwen83 <leiwen83@users.noreply.github.com>
Date:   Thu May 2 02:20:32 2024 +0800

    [Core] Enable prefix caching with block manager v2 enabled (#4142)
    
    Co-authored-by: Lei Wen <wenlei03@qiyi.com>
    Co-authored-by: Sage Moore <sagemoore@utexas.edu>

[33mcommit b38e42fbca978d62cc8330bdcf8da91c72cb2ebc[m
Author: leiwen83 <leiwen83@users.noreply.github.com>
Date:   Thu May 2 02:13:03 2024 +0800

    [Speculative decoding] Add ngram prompt lookup decoding (#4237)
    
    Co-authored-by: Lei Wen <wenlei03@qiyi.com>

[33mcommit 8b798eec75cde6eb6fe65b5d673dd9bd4eaef799[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed May 1 12:01:50 2024 -0600

    [CI/Build][Bugfix] VLLM_USE_PRECOMPILED should skip compilation (#4534)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit 69909126a7f6fb1e3254dc0dec87dc6e78e1a0e2[m
Author: sasha0552 <admin@sasha0552.org>
Date:   Wed May 1 17:41:17 2024 +0000

    [Bugfix] Use random seed if seed is -1 (#4531)

[33mcommit e491c7e053e5d774f321612b3a400ca2fb424d32[m
Author: FrŒ±n√ßois <francois.paupier@gmail.com>
Date:   Wed May 1 19:14:16 2024 +0200

    [Doc] update(example model): for OpenAI compatible serving (#4503)

[33mcommit 4dc8026d8614185ece28dd3fcd82aa0dabb4f79c[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Wed May 1 12:14:13 2024 -0400

    [Bugfix] Fix 307 Redirect for `/metrics` (#4523)

[33mcommit a88bb9b032d75aad74b2e1bd3d97b8e8a24e8b9d[m
Author: AnyISalIn <anyisalin@gmail.com>
Date:   Thu May 2 00:11:03 2024 +0800

    [Bugfix] Fix the fp8 kv_cache check error that occurs when failing to obtain the CUDA version. (#4173)
    
    Signed-off-by: AnyISalIn <anyisalin@gmail.com>

[33mcommit 6f1df80436c46175e09f660a99075a5eba3a2273[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Wed May 1 21:45:42 2024 +0900

    [Test] Add ignore_eos test  (#4519)

[33mcommit d6f4bd7cddc9546c38568c92c3772d22940a09f2[m
Author: Jee Li <pandaleefree@163.com>
Date:   Wed May 1 12:18:14 2024 +0800

    [Misc]Add customized information for models (#4132)

[33mcommit c3845d82dc3d1831714898114f87d9c103e2dd41[m
Author: Robert Caulk <rob.caulk@gmail.com>
Date:   Wed May 1 05:48:39 2024 +0200

    Allow user to define whitespace pattern for outlines (#4305)

[33mcommit a822eb3413087062a38cea495564ec4a7093c3e5[m
Author: PastelÔºÅ <1627301104@qq.com>
Date:   Wed May 1 11:41:32 2024 +0800

    [Misc] fix typo in block manager (#4453)

[33mcommit f458112e8afdb01bd3cb2e435db314c6bc227973[m
Author: harrywu <63134210+HarryWu99@users.noreply.github.com>
Date:   Wed May 1 11:21:39 2024 +0800

    [Misc][Typo] type annotation fix (#4495)

[33mcommit 2e240c69a9874743abc8b0b681e8c13d675beda3[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Apr 30 18:06:34 2024 -0700

    [Core] Centralize GPU Worker construction (#4419)

[33mcommit ee37328da085af14f89ad1af8eb2c359ae2f46a1[m
Author: fuchen.ljl <yjqqqqdx_01@163.com>
Date:   Wed May 1 08:42:09 2024 +0800

    Unable to find Punica extension issue during source code installation (#4494)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 6ad58f42c59eaee0a57c89f1feb08757524b93cf[m
Author: fuchen.ljl <yjqqqqdx_01@163.com>
Date:   Wed May 1 07:38:50 2024 +0800

    fix_tokenizer_snapshot_download_bug (#4493)

[33mcommit dd1a50a8bc520b0e52ce7914f0263ebd576c197f[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Wed May 1 07:33:33 2024 +0800

    [Bugfix][Minor] Make ignore_eos effective  (#4468)

[33mcommit 715c2d854d56f2026c31f126a90e6e7859434a50[m
Author: Alpay Ariyak <98838263+alpayariyak@users.noreply.github.com>
Date:   Tue Apr 30 19:32:13 2024 -0400

    [Frontend] [Core] Tensorizer: support dynamic `num_readers`, update version (#4467)

[33mcommit a494140433be496a0321999955acf7e6387986b3[m
Author: Florian Greinacher <florian@greinacher.de>
Date:   Wed May 1 01:28:46 2024 +0200

    [Frontend] Support complex message content for chat completions endpoint (#3467)
    
    Co-authored-by: Lily Liu <lilyliupku@gmail.com>
    Co-authored-by: Cyrus Leung <tlleungac@connect.ust.hk>

[33mcommit 111815d482ba2b724541994da12736615101ef5e[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Tue Apr 30 17:46:12 2024 -0400

    [Kernel] Support Fp8 Checkpoints (Dynamic + Static) (#4332)
    
    Co-authored-by: Philipp Moritz <pcmoritz@gmail.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: mgoin <michael@neuralmagic.com>
    Co-authored-by: Tyler Michael Smith <tyler@neuralmagic.com>
    Co-authored-by: Cody Yu <hao.yu.cody@gmail.com>

[33mcommit b31a1fb63c98fa1c64666aaae15579439af60d95[m
Author: Prashant Gupta <prashantgupta@us.ibm.com>
Date:   Tue Apr 30 10:41:59 2024 -0700

    [Doc] add visualization for multi-stage dockerfile (#4456)
    
    Signed-off-by: Prashant Gupta <prashantgupta@us.ibm.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 4bb53e2dde809ea5727b8cac95a080893733a1ef[m
Author: leiwen83 <leiwen83@users.noreply.github.com>
Date:   Wed May 1 01:12:59 2024 +0800

    [BugFix] fix num_lookahead_slots missing in async executor (#4165)
    
    Co-authored-by: Lei Wen <wenlei03@qiyi.com>

[33mcommit 26f2fb51133c85ad8a57a87c8037f750dda757f4[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Tue Apr 30 12:14:47 2024 +0000

    [Core]Refactor gptq_marlin ops (#4466)

[33mcommit fa32207842f1ed5a966372ed0513914bff8426c4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Apr 29 22:05:40 2024 -0700

    [Bugfix][Kernel] Fix compute_type for MoE kernel (#4463)

[33mcommit d627a3d837976a23f89ba808f5ef6908fdb65bfa[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Mon Apr 29 20:05:47 2024 -0400

    [Misc] Upgrade to `torch==2.3.0` (#4454)

[33mcommit f4f921b7f12c67d3c4b7575caf5ddd9bd4b0b787[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Apr 29 13:52:22 2024 -0700

    [Core][Distributed] use cpu group to broadcast metadata in cpu (#4444)

[33mcommit ac5ccf0156e1772f3ea89c205704a31219442c55[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Apr 29 12:50:01 2024 -0700

    [CI] hotfix: soft fail neuron test (#4458)

[33mcommit 73c8d677e57e42374bcfb2271b8f1cf7f2c0a486[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Mon Apr 29 12:35:34 2024 -0400

    [Kernel] Marlin Expansion: Support AutoGPTQ Models with Marlin (#3922)
    
    Co-authored-by: alexm <alexm@neuralmagic.com>
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit df29793dc73a83f3c86c19de967adffda1a28a93[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Mon Apr 29 11:01:26 2024 +0900

    [mypy][5/N] Support all typing on model executor (#4427)

[33mcommit 03dd7d52bfcc4f21ba964a0cfc3fb6e7a47fb242[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Apr 28 16:32:07 2024 -0700

    [CI] clean docker cache for neuron (#4441)

[33mcommit bf480c53027cb009427581af0100de75ac7a2e5f[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Mon Apr 29 01:59:33 2024 +0300

    Add more Prometheus metrics (#2764)
    
    Co-authored-by: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
    Co-authored-by: Robert Shaw <rshaw@neuralmagic.com>

[33mcommit 9c7306ac114da3e31a5ff040a76f6c640354cce8[m
Author: DefTruth <31974251+DefTruth@users.noreply.github.com>
Date:   Sun Apr 28 18:58:30 2024 +0800

    [Misc] fix typo in llm_engine init logging (#4428)

[33mcommit 4ea1f9678dd93f02424ab3de2149f83a490e6c6f[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Apr 27 14:35:33 2024 -0400

    [BugFix] Resolved Issues For LinearMethod --> QuantConfig (#4418)

[33mcommit ba4be44c32761d30f1e17656b863d2cc078af9e4[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sat Apr 27 11:17:45 2024 -0700

    [BugFix] Fix return type of executor execute_model methods (#4402)

[33mcommit d6e520e1700f78de2d5efdb8607a76cbab61182e[m
Author: Prashant Gupta <prashantgupta24@gmail.com>
Date:   Sat Apr 27 09:59:55 2024 -0700

    [Core] Support offline use of local cache for models (#4374)
    
    Signed-off-by: Prashant Gupta <prashantgupta@us.ibm.com>
    Co-authored-by: Travis Johnson <tjohnson31415@gmail.com>

[33mcommit 81661da7b2d446cff7065fd6b34f1b7051098d24[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sat Apr 27 09:52:46 2024 -0700

    [BugFix] Fix `min_tokens` when `eos_token_id` is None (#4389)
    
    Co-authored-by: DefTruth <31974251+deftruth@users.noreply.github.com>

[33mcommit dfea17314827845d55dabb03ebe905f58e6682e4[m
Author: Ruoyu Qin <qry6909@163.com>
Date:   Sun Apr 28 00:48:37 2024 +0800

    [Bugfix] Abort requests when the connection to /v1/completions is interrupted (#4363)

[33mcommit 7134303cbbb7c82cdfcb0c87d59bb48fe6ad642b[m
Author: Roy <jasonailu87@gmail.com>
Date:   Sat Apr 27 19:30:08 2024 +0800

    [Bugfix][Core] Fix get decoding config from ray (#4335)

[33mcommit 3da24c2df735354ccb463650c29cca8ce506fa07[m
Author: Caio Mendes <caioctmendes@gmail.com>
Date:   Sat Apr 27 07:08:15 2024 -0300

    [Model] Phi-3 4k sliding window temp. fix (#4380)

[33mcommit eefeb16464af5f3a61e3052d1a4128480bff7f47[m
Author: Austin Veselka <50646302+FurtherAI@users.noreply.github.com>
Date:   Sat Apr 27 02:03:48 2024 -0500

    [Kernel] Full Tensor Parallelism for LoRA Layers (#3524)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit 18d23f642af9c56f45ccf684a22f386fc54c6ead[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Sat Apr 27 02:37:40 2024 -0400

    [ROCm][Hardware][AMD] Enable group query attention for triton FA (#4406)

[33mcommit 87f545ba6fdbbbe9813736fc398874563e2604a7[m
Author: Roy <jasonailu87@gmail.com>
Date:   Sat Apr 27 13:45:02 2024 +0800

    [Misc] Fix logger format typo (#4396)

[33mcommit 8947bc3c156963dfc66e7ca1e4c436506ed6a512[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Sat Apr 27 13:08:24 2024 +0800

    [Frontend][Bugfix] Disallow extra fields in OpenAI API (#4355)

[33mcommit 12628d3c787efd3483aaa74b5ae4175b28fd5805[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Fri Apr 26 21:49:59 2024 -0700

    [Kernel] Optimize FP8 support for MoE kernel / Mixtral via static scales (#4343)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 258a2c58d08fc7a242556120877a89404861fbce[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Fri Apr 26 21:14:26 2024 -0700

    [Core] Introduce `DistributedGPUExecutor` abstract class (#4348)

[33mcommit aba47be3fef57f37196a91f899068506b9075f4f[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Apr 26 15:47:45 2024 -0700

    [Misc] add RFC issue template (#4401)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit a62aaf1df558d69658a42c1ab749368ab0325f35[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Apr 26 13:41:14 2024 -0700

    [Misc][Refactor] Generalize linear_method to be quant_method (#4373)

[33mcommit 603ad8481594321ceae7d54e2c0050b3638c6502[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri Apr 26 22:02:02 2024 +0900

    [Core] Refactoring sampler and support prompt logprob for chunked prefill  (#4309)

[33mcommit a88081bf768fcc1c662e4f588bd01ca9ddcc6aad[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri Apr 26 16:16:58 2024 +0900

    [CI] Disable non-lazy string operation on logging (#4326)
    
    Co-authored-by: Danny Guinther <dguinther@neuralmagic.com>

[33mcommit 2f30e7c72fca61c8225654880ee1ef89cad1690c[m
Author: Norman Mu <normster@users.noreply.github.com>
Date:   Thu Apr 25 22:36:01 2024 -0700

    [Frontend] Add --log-level option to api server (#4377)

[33mcommit a74dee9b62d10767eb0580f196f5e508e9e80a2d[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Fri Apr 26 10:10:48 2024 +0800

    [Bugfix] Fix parameter name in `get_tokenizer` (#4107)

[33mcommit cf29b7eda47d5a8c5fe6a7a53490271da8520563[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Thu Apr 25 21:12:25 2024 -0400

    [ROCm][Hardware][AMD][Doc] Documentation update for ROCm (#4376)
    
    Co-authored-by: WoosukKwon <woosuk.kwon@berkeley.edu>

[33mcommit efffb63f584c1ce4fdcf4e7b7fd0bfc8b33a733a[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Apr 25 16:45:12 2024 -0700

    [Core] Move function tracing setup to util function (#4352)

[33mcommit 15e7c675b0dc36109c7b591f856f102e96493a94[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Apr 25 16:32:48 2024 -0700

    [Core] Add `shutdown()` method to `ExecutorBase` (#4349)

[33mcommit b6dcb4d44281a9e85cafcfa6376c373d02286779[m
Author: Roy <jasonailu87@gmail.com>
Date:   Fri Apr 26 03:43:32 2024 +0800

    [Misc] Fix flash attention backend log  (#4368)

[33mcommit b5b4a398a794e3276729a525e58eaa92f5fc0212[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri Apr 26 04:13:50 2024 +0900

    [Mypy] Typing lora folder (#4337)

[33mcommit f4bc4de1b1a1bd33bd3ec7dea3377eb75884250a[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Thu Apr 25 19:03:56 2024 +0000

    [Core]refactor aqlm quant ops  (#4351)

[33mcommit bd7a8eef25cd85be7eb9f2a94fd752d27ee7dce3[m
Author: Caio Mendes <caioctmendes@gmail.com>
Date:   Thu Apr 25 14:32:00 2024 -0300

    [Doc] README Phi-3 name fix. (#4372)
    
    Co-authored-by: Caio Mendes <caiocesart@microsoft.com>

[33mcommit 7ee82bef1e71febc28757807f5df8191bb36d88e[m
Author: Alexei-V-Ivanov-AMD <156011006+Alexei-V-Ivanov-AMD@users.noreply.github.com>
Date:   Thu Apr 25 11:37:20 2024 -0500

    [CI/Build] Adding functionality to reset the node's GPUs before processing. (#4213)

[33mcommit fbf152d976e655f8734561452a1036e63081ccfd[m
Author: Isotr0py <41363108+Isotr0py@users.noreply.github.com>
Date:   Fri Apr 26 00:35:56 2024 +0800

    [Bugfix][Model] Refactor OLMo model to support new HF format in transformers 4.40.0 (#4324)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 479d69fad0538f04cb22bf13e76ff91cfeb8a4e5[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Apr 24 23:52:22 2024 -0700

    [Core] Move ray_utils.py from `engine` to `executor` package (#4347)

[33mcommit 96e90fdeb3c4ebacfe24513556afccb918722b7c[m
Author: Caio Mendes <caioctmendes@gmail.com>
Date:   Thu Apr 25 00:06:57 2024 -0300

    [Model] Adds Phi-3 support (#4298)

[33mcommit a395a638c2f18d549e7d01655cf7a6dbee566f91[m
Author: zifeitong <zifeitong@gmail.com>
Date:   Wed Apr 24 14:10:24 2024 -0700

    [Misc] Use public API in benchmark_throughput (#4300)

[33mcommit 2768884ac4a026609efceef92edea55839af0c30[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Apr 24 14:09:44 2024 -0700

    [Doc] Add note for docker user (#4340)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit aae08249acca69060d0a8220cab920e00520932c[m
Author: alexm-nm <59768536+alexm-nm@users.noreply.github.com>
Date:   Wed Apr 24 13:35:01 2024 -0400

    [Bugfix] Fix marlin kernel crash on H100 (#4218)
    
    This PR addresses the Marlin kernel H100 crash that was reported here: neuralmagic#187.
    The reason for the crash was the inline PTX assembly that introduced the async_copy with streaming behavior. The solution is to use the more standard PTX for async_copy (without the fractional L2 policy for "evict_first"). There is no performance difference between standard async_copy PTX and the previous one.

[33mcommit 7923dcad12edae7dcfd6e0cf7ce2984b3bcecf0f[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Apr 24 09:49:13 2024 -0700

    [Misc] Update ShareGPT Dataset Sampling in Serving Benchmark (#4279)

[33mcommit 3cd9b5bb2d4a0d5eed07186ae140f5dc8f839708[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Apr 24 09:00:20 2024 -0700

    [Core][Distributed] use existing torch.cuda.device (#4318)
    
    [Core][Distributed] use existing torch.cuda.device context manager (#4318)

[33mcommit 468d761b32e3b3c5d64eeaa797e54ab809b7e50c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Apr 23 18:54:33 2024 -0700

    [Misc] Reduce supported Punica dtypes (#4304)

[33mcommit e4bf860a54a302ccb2d80489368d5df686e46923[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Apr 23 18:33:12 2024 -0700

    [CI][Build] change pynvml to nvidia-ml-py (#4302)

[33mcommit 91f50a6fe240b2c92a99e171bb11d083f82e4a84[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Apr 23 18:32:19 2024 -0700

    [Core][Distributed] use cpu/gloo to initialize pynccl (#4248)

[33mcommit 79a268c4ab2cbf44280eebd998b8efc383bac216[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Tue Apr 23 21:26:33 2024 -0400

    [BUG] fixed fp8 conflict with aqlm (#4307)
    
    Fixes fp8 iterface which broke in AQLM merge.

[33mcommit eace8bf0b9118877c390e6d490502214c39db132[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Tue Apr 23 18:18:23 2024 -0700

    [Kernel] FP8 support for MoE kernel / Mixtral (#4244)
    
    This PR is the first step towards fixing https://github.com/vllm-project/vllm/pull/3208
    
    It implements dynamic per-tensor scaling (see https://github.com/vllm-project/vllm/pull/4118), so users do not need to compute activation scales on a calibration dataset and they also don't need to convert their model checkpoints. It is enough to specify the `quantization="fp8"` argument. You can try out the PR like this:
    
    ```python
    from vllm import LLM, SamplingParams
    
    prompts = [
        "Hello, my name is",
        "The president of the United States is",
        "The capital of France is",
        "The future of AI is",
    ]
    sampling_params = SamplingParams(temperature=0.8, top_p=0.95)
    
    llm = LLM(model="mistralai/Mixtral-8x7B-Instruct-v0.1", tensor_parallel_size=2, quantization="fp8")
    
    outputs = llm.generate(prompts, sampling_params)
    
    # Print the outputs.
    for output in outputs:
        prompt = output.prompt
        generated_text = output.outputs[0].text
        print(f"Prompt: {prompt!r}, Generated text: {generated_text!r}")
    ```
    
    **Performance**: For this PR, the focus is on making the code clean (while still trying to get reasonable performance), there is a bunch of optimizations that we will submit as a follow up PR that significantly improve the performance (similar to the numbers in https://github.com/vllm-project/vllm/pull/3954). With this PR, the results are as follows:
    
    <img width="725" alt="Screenshot 2024-04-21 at 1 31 50 PM" src="https://github.com/vllm-project/vllm/assets/113316/d8fe1118-07a0-4d4e-8530-37a77d465a03">
    
    
    **Accuracy**: The accuracy with this PR on MMLU on `mistralai/Mixtral-8x7B-v0.1` is as follows:
    
    ```
    |      Groups      |Version|Filter|n-shot|Metric|Value |   |Stderr|
    |------------------|-------|------|-----:|------|-----:|---|-----:|
    |mmlu              |N/A    |none  |     0|acc   |0.7018|¬±  |0.0036|
    | - humanities     |N/A    |none  |     5|acc   |0.6472|¬±  |0.0065|
    | - other          |N/A    |none  |     5|acc   |0.7673|¬±  |0.0072|
    | - social_sciences|N/A    |none  |     5|acc   |0.8099|¬±  |0.0070|
    | - stem           |N/A    |none  |     5|acc   |0.6131|¬±  |0.0083|
    ```
    this compares favorably with the fp16 results which are
    ```
    |      Groups      |Version|Filter|n-shot|Metric|Value |   |Stderr|
    |------------------|-------|------|-----:|------|-----:|---|-----:|
    |mmlu              |N/A    |none  |     0|acc   |0.7020|¬±  |0.1313|
    | - humanities     |N/A    |none  |     5|acc   |0.6425|¬±  |0.1349|
    | - other          |N/A    |none  |     5|acc   |0.7744|¬±  |0.1038|
    | - social_sciences|N/A    |none  |     5|acc   |0.8131|¬±  |0.0695|
    | - stem           |N/A    |none  |     5|acc   |0.6108|¬±  |0.1383|
    ```
    
    Happy hacking!

[33mcommit 1e8f4252aa163041094a8fedbb701a98d7087d7c[m
Author: Cyrus Leung <tlleungac@connect.ust.hk>
Date:   Wed Apr 24 02:19:03 2024 +0800

    [Bugfix][Frontend] Raise exception when file-like chat template fails to be opened (#4292)

[33mcommit 2b7949c1c2e34de41d9cfc84dd0e377cc6bd58c2[m
Author: James Fleming <jaemz@alum.mit.edu>
Date:   Tue Apr 23 13:59:33 2024 -0400

    AQLM CUDA support (#3287)
    
    Co-authored-by: mgoin <michael@neuralmagic.com>

[33mcommit 62b5166bd4c458c3a8f6eda89d3ef9db14a4c2c8[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Apr 23 09:51:41 2024 -0700

    [CI] Add ccache for wheel builds job (#4281)

[33mcommit d86285a4a4b79b883620d2878c0b52b22ad4c640[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Apr 23 09:45:52 2024 -0700

    [Core][Logging] Add last frame information for better debugging (#4278)

[33mcommit d87f39e9a9dd149f5dd7a58b4d98b21f713827b6[m
Author: DefTruth <31974251+DefTruth@users.noreply.github.com>
Date:   Wed Apr 24 00:28:35 2024 +0800

    [Bugfix] Add init_cached_hf_modules to RayWorkerWrapper (#4286)

[33mcommit d3c8180ac4143f4affd2ef26855058e96b72b5f5[m
Author: Jack Gordley <jgordley99@gmail.com>
Date:   Tue Apr 23 12:06:29 2024 +0100

    [Bugfix] Fixing max token error message for openai compatible server (#4016)

[33mcommit 62b8aebc6f06b5c8fafa1f27893cd4f9bb11fa8b[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Apr 23 01:02:36 2024 -0700

    [Speculative decoding 7/9] Speculative decoding end-to-end correctness tests. (#3951)

[33mcommit 050f285ff6e7bbe898ee751770b2571972166bef[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Tue Apr 23 17:02:11 2024 +0900

    [Core] Scheduling optimization 2 (#4280)

[33mcommit 8f2ea22bde67161895152e7f7ad602ac96ea326e[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Apr 23 00:49:08 2024 -0700

    [Core] Some simplification of WorkerWrapper changes (#4183)

[33mcommit 0ae11f78ab89556d5d867abb98f8a132f7507269[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Tue Apr 23 13:32:44 2024 +0900

    [Mypy] Part 3 fix typing for nested directories for most of directory (#4161)

[33mcommit 34128a697ed2dd4d88a9829f35445fbfc5b85c64[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Tue Apr 23 02:53:01 2024 +0100

    Fix `autodoc` directives (#4272)
    
    Co-authored-by: Harry Mellor <hmellor@oxts.com>

[33mcommit c1b4e4157c0b4154f950adaea85a259fc629c758[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Apr 22 17:21:48 2024 -0700

    [Core][Distributed] use absolute path for library file (#4271)

[33mcommit ceaf4ed0030c7816537359b8efc750474149ce0f[m
Author: Zhanghao Wu <zhanghao.wu@outlook.com>
Date:   Mon Apr 22 15:34:31 2024 -0700

    [Doc] Update the SkyPilot doc with serving and Llama-3 (#4276)

[33mcommit ad8d696a99ca1eee19f1404e16e8e82df592ff85[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Tue Apr 23 06:11:06 2024 +0900

    [Core] Scheduler perf fix (#4270)

[33mcommit 3d925165f2b18379640a63fbb42de95440d63b64[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Mon Apr 22 17:36:54 2024 +0100

    Add example scripts to documentation (#4225)
    
    Co-authored-by: Harry Mellor <hmellor@oxts.com>

[33mcommit 15436806912d7ad9371c8bcf6a46857590c107d2[m
Author: alexm-nm <59768536+alexm-nm@users.noreply.github.com>
Date:   Mon Apr 22 12:10:48 2024 -0400

    [Bugfix] Ensure download_weights_from_hf(..) inside loader is using the revision parameter (#4217)

[33mcommit 077f0a2e8a873340b1a2cf54d6c9043754eb7514[m
Author: Tao He <sighingnow@gmail.com>
Date:   Mon Apr 22 17:19:51 2024 +0800

    [Frontend] Enable support for CPU backend in AsyncLLMEngine. (#3993)
    
    Signed-off-by: Tao He <sighingnow@gmail.com>

[33mcommit e73ed0f1c624f85d348c0709c256a0ae6627986b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Apr 22 00:54:16 2024 -0700

    [Bugfix] Fix type annotations in CPU model runner (#4256)

[33mcommit 296cdf8ac7853b671d10f3df094288ea4f35bb38[m
Author: Isotr0py <41363108+Isotr0py@users.noreply.github.com>
Date:   Mon Apr 22 15:44:16 2024 +0800

    [Misc] Add vision language model support to CPU backend (#3968)

[33mcommit 747b1a7147515c08491ef4aa1b23ea23329966ed[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Apr 21 23:04:16 2024 -0700

    [Core][Distributed] fix _is_full_nvlink detection (#4233)

[33mcommit 95e5b087cfed33bf20891852b2d7a0cac2341519[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Mon Apr 22 00:57:24 2024 -0400

    [AMD][Hardware][Misc][Bugfix] xformer cleanup and light navi logic and CI fixes and refactoring (#4129)

[33mcommit a37d815b83849b5a96a182929dd6f3bd35f68fb8[m
Author: GeauxEric <yunding.eric@gmail.com>
Date:   Sun Apr 21 15:06:46 2024 -0700

    Make initialization of tokenizer and detokenizer optional (#3748)
    
    Co-authored-by: Yun Ding <yunding@nvidia.com>
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 7f2593b164c2ff115ba4fb9ce95fe63bdd824b85[m
Author: xiaoji <44150358+YeFD@users.noreply.github.com>
Date:   Mon Apr 22 00:57:08 2024 +0800

    [Doc]: Update the doc of adding new models (#4236)

[33mcommit fe7d648fe56c138811e9b2b02937b55a84830454[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Sun Apr 21 17:15:28 2024 +0100

    Don't show default value for flags in `EngineArgs` (#4223)
    
    Co-authored-by: Harry Mellor <hmellor@oxts.com>

[33mcommit cc74b2b232070f74d8765a5eefa49ae93ee45490[m
Author: Noam Gat <noamgat@gmail.com>
Date:   Sat Apr 20 11:33:16 2024 +0300

    Updating lm-format-enforcer version and adding links to decoding libraries in docs (#4222)

[33mcommit 91528575ec0e6fd251bac08973a3abf23d4c318c[m
Author: nunjunj <106306814+nunjunj@users.noreply.github.com>
Date:   Sat Apr 20 00:11:57 2024 -0700

    [Frontend] multiple sampling params support  (#3570)

[33mcommit a22cdea371bb26b4bdba112d4602736b48ca4a3a[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Fri Apr 19 21:28:57 2024 -0700

    [Kernel][FP8] Initial support with dynamic per-tensor scaling (#4118)
    
    Provide an initial support to FP8 computation. This PR is inspired by HuggingFace TGI: huggingface/text-generation-inference#1726
    
    This feature can be enabled with --quantization fp8 or -q fp8 when launching an engine.
    
    Algorithm:
    We still load a model checkpoint in FP16/BF16. After the weights are loaded, Fp8LinearMethod calculates the per-tensor scaling factor of weights and quantizes the weights accordingly. The scaling factor will then be stored for future use. Meanwhile, the per-tensor scaling factor for activations is calculated in every forward pass.
    
    Initial Results:
    Currently tested Mistral-7B on 1xH100. With prompt length ~5 and decoding length 128:
    
    BF16: 1.47s
    FP8: 1.66s
    I'll try to use larger models and try to find more performance bottleneck. Meanwhile, you're welcome to try this code.

[33mcommit 682789d4026429a04cc32acb88064265441080dd[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Sat Apr 20 04:51:33 2024 +0100

    Fix missing docs and out of sync `EngineArgs` (#4219)
    
    Co-authored-by: Harry Mellor <hmellor@oxts.com>

[33mcommit 138485a82de50f90536ea0a650dd2f6bba1927e9[m
Author: Ayush Rautwar <42046470+ayusher@users.noreply.github.com>
Date:   Fri Apr 19 23:49:22 2024 -0400

    [Bugfix] Add fix for JSON whitespace (#4189)
    
    Co-authored-by: Ubuntu <ubuntu@ip-172-31-13-147.ec2.internal>

[33mcommit bc9df1571b8002738eb8db70a07f552e32feb75f[m
Author: Chirag Jain <jain.chirag925@gmail.com>
Date:   Sat Apr 20 05:43:56 2024 +0530

    Pass `tokenizer_revision` when getting tokenizer in openai serving (#4214)

[33mcommit 15b86408a89d5b998409e7fbe7850e937cc837da[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Apr 19 12:44:51 2024 -0700

    [Misc] add nccl in collect env (#4211)

[33mcommit 7be4f5628fc9999bf8a6025edd8f098353e0724b[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Fri Apr 19 18:08:26 2024 +0300

    [Bugfix][Core] Restore logging of stats in the async engine (#4150)

[33mcommit 8f20fc04bf7384089395caa021766cd352d0cf0b[m
Author: Uranus <109661872+UranusSeven@users.noreply.github.com>
Date:   Fri Apr 19 16:18:33 2024 +0800

    [Misc] fix docstrings (#4191)
    
    Co-authored-by: Zhong Wang <wangzhong@infini-ai.com>

[33mcommit 221d93ecbf51102df69deaf153d35df6d93370f6[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Apr 19 01:00:22 2024 -0700

    Bump version of 0.4.1 (#4177)

[33mcommit d17c8477f1fb337ea9fcf439bcab4d323058c1b4[m
Author: Jee Li <pandaleefree@163.com>
Date:   Fri Apr 19 15:59:54 2024 +0800

    [Bugfix] Fix LoRA loading check (#4138)
    
    Co-authored-by: simon-mo <simon.mo@hey.com>

[33mcommit a134ef6f5e6c24d3cd459c63557e5db276db25b2[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Apr 18 21:13:36 2024 -0700

    Support eos_token_id from generation_config.json (#4182)

[33mcommit 8a7a3e4436d7284df4c0913f074d77d640a9c6c3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Apr 18 16:15:12 2024 -0700

    [Core] add an option to log every function call to for debugging hang/crash in distributed inference (#4079)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 8f9c28fd40a9daa744d08cacb0bd5ac2247a97d1[m
Author: Adam Tilghman <agt@ucsd.edu>
Date:   Thu Apr 18 15:32:47 2024 -0700

    [Bugfix] Fix CustomAllreduce nvlink topology detection (#3974)
    
    [Bugfix] Fix CustomAllreduce pcie nvlink topology detection (#3974) (#4159)

[33mcommit cd2f63fb362b2c53b993e7edf6565ab6a5f9f260[m
Author: Liangfu Chen <liangfc@amazon.com>
Date:   Thu Apr 18 15:26:01 2024 -0700

    [CI/CD] add neuron docker and ci test scripts (#3571)

[33mcommit 87fa80c91f5b24a2ee1805b80c3eca8fd6600cd5[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Apr 18 14:36:39 2024 -0700

    [Misc] Bump transformers to latest version (#4176)

[33mcommit e1bb2fd52dea0bbc772bdf35fd27664c5daec7b2[m
Author: James Whedbee <jamesw@telnyx.com>
Date:   Thu Apr 18 16:12:55 2024 -0500

    [Bugfix] Support logprobs when using guided_json and other constrained decoding fields (#4149)

[33mcommit 705578ae14b648782a8a321dd0903c163bd77375[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Apr 18 10:55:48 2024 -0700

    [Docs] document that Meta Llama 3 is supported (#4175)

[33mcommit e8cc7967ff8a6f8432747a9e87ab451d36e1ff57[m
Author: Micha≈Ç Moskal <michal@moskal.me>
Date:   Thu Apr 18 00:51:28 2024 -0700

    [Bugfix][Kernel] allow non-power-of-two head sizes in prefix prefill (#4128)

[33mcommit 53b018edcbc601f0eea9f65f13a9a9620c4be8dc[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Apr 18 03:21:55 2024 -0400

    [Bugfix] Get available quantization methods from quantization registry (#4098)

[33mcommit 66ded030677c7a0ca696f8d64e41637f4a358c00[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Thu Apr 18 08:16:26 2024 +0100

    Allow model to be served under multiple names (#2894)
    
    Co-authored-by: Alexandre Payot <alexandrep@graphcore.ai>

[33mcommit 6dc1fc9cfed74f63f3e90c60e4d6ad7065bd4529[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Apr 17 22:28:52 2024 -0700

    [Core] nccl integrity check and test (#4155)
    
    [Core] Add integrity check during initialization; add test for it (#4155)

[33mcommit 533d2a1f3962c45ddebbdeb0ff1cb7cd54d5e771[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu Apr 18 09:28:43 2024 +0900

    [Typing] Mypy typing part 2 (#4043)
    
    Co-authored-by: SangBin Cho <sangcho@sangcho-LT93GQWG9C.local>

[33mcommit a53222544c6385ee314a26fdf42eb14f5b4e5ad9[m
Author: Shoichi Uchinami <s.uchinami@gmail.com>
Date:   Thu Apr 18 02:02:45 2024 +0900

    [Kernel] Add punica dimension for Swallow-MS-7B LoRA (#4134)

[33mcommit fe3b5bbc23a99533bc7d4a94ae073828ed025974[m
Author: Elinx <xizzuli@163.com>
Date:   Wed Apr 17 19:07:23 2024 +0800

    [Bugfix] fix output parsing error for trtllm backend (#4137)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 8438e0569eaf8496aa3d41deb808f2c831b64ecf[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Apr 17 01:34:33 2024 -0700

    [Core] RayWorkerVllm --> WorkerWrapper to reduce duplication (#4024)
    
    [Core] replace narrow-usage RayWorkerVllm to general WorkerWrapper to reduce code duplication (#4024)

[33mcommit 11d652bd4f6f81d09638399885099b78a4e3b9c8[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Apr 16 22:53:26 2024 -0700

    [CI] Move CPU/AMD tests to after wait (#4123)

[33mcommit d150e4f89f9da5b093511227449ad940a9a82a52[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Apr 16 17:56:01 2024 -0700

    [Misc] [CI] Fix CI failure caught after merge (#4126)

[33mcommit e95cd879598b834f85e70ebcd23db316ae430540[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Apr 16 13:09:21 2024 -0700

    [Speculative decoding 6/9] Integrate speculative decoding with LLMEngine  (#3894)

[33mcommit 69e1d2fb6922b2d388bae41286d8867976cbd6c6[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Apr 16 11:34:39 2024 -0700

    [Core] Refactor model loading code (#4097)

[33mcommit 05434764cd99990035779cf9a4ed86623b528825[m
Author: Noam Gat <noamgat@gmail.com>
Date:   Tue Apr 16 08:54:57 2024 +0300

    LM Format Enforcer Guided Decoding Support (#3868)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 4e7ee664e201442e24e2298a36a5264b98691626[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Tue Apr 16 14:24:53 2024 +0900

    [Core] Fix engine-use-ray broken  (#4105)

[33mcommit 37e84a403d6d11b670a42e84153204cd8b76b849[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Tue Apr 16 06:47:31 2024 +0900

    [Typing] Fix Sequence type GenericAlias only available after Python 3.9. (#4092)

[33mcommit 4695397dcfef693a0a10f1eb8bf77ea905c54829[m
Author: Ricky Xu <xuchen727@hotmail.com>
Date:   Mon Apr 15 14:24:45 2024 -0700

    [Bugfix] Fix ray workers profiling with nsight  (#4095)

[33mcommit d619ae2d19c41d9aa8f68fa0e5e32cc410dc2522[m
Author: Sanger Steel <sangersteel@gmail.com>
Date:   Mon Apr 15 16:28:25 2024 -0400

    [Doc] Add better clarity for tensorizer usage (#4090)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit eb46fbfda25348422918c4a876e17aef05fc5e34[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Apr 15 13:05:09 2024 -0700

    [Core] Simplifications to executor classes (#4071)

[33mcommit 0003e9154bf1091d0de7ca7a6c7f1253df1eca5b[m
Author: Li, Jiang <jiang1.li@intel.com>
Date:   Mon Apr 15 23:35:55 2024 +0800

    [Misc][Minor] Fix CPU block num log in CPUExecutor. (#4088)

[33mcommit e11e2007368b22fce05b9ecdf00dd48eda471f9e[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Apr 14 21:50:08 2024 -0700

    [Bugfix] Fix filelock version requirement (#4075)

[33mcommit 8db1bf32f8924403c6a845b5ce71ba0f14beb038[m
Author: Roy <jasonailu87@gmail.com>
Date:   Mon Apr 15 08:43:54 2024 +0800

    [Misc] Upgrade triton to 2.2.0 (#4061)

[33mcommit aceb17cf2d629175a484c3d9df355f44bd334cb3[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Apr 14 14:35:55 2024 -0700

    [Docs] document that mixtral 8x22b is supported (#4073)

[33mcommit 563c54f760f870ae44c7662c8a9ec3a223a3c4c4[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sun Apr 14 22:12:42 2024 +0100

    [BugFix] Fix tensorizer extra in setup.py (#4072)

[33mcommit 2cd6b4f3625466eb5849bcfd7a6fb316735adab8[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Apr 13 23:40:21 2024 -0700

    [Core] avoid too many cuda context by caching p2p test (#4021)

[33mcommit 711a000255eac3e034f0b73aa5cc62b45201a571[m
Author: Sanger Steel <sangersteel@gmail.com>
Date:   Sat Apr 13 20:13:01 2024 -0400

    [Frontend] [Core] feat: Add model loading using `tensorizer` (#3476)

[33mcommit 989ae2538df211ca3a31f77ac8e106c5c97c6e53[m
Author: Jee Li <pandaleefree@163.com>
Date:   Sat Apr 13 22:55:05 2024 +0800

    [Kernel] Add punica dimension for Baichuan-13B (#4053)

[33mcommit 0a430b4ae2763c2f161e3bfb1529acf4685f7caa[m
Author: zspo <songpo.zhang@foxmail.com>
Date:   Sat Apr 13 22:54:03 2024 +0800

    [Bugfix] fix_small_bug_in_neuron_executor (#4051)

[33mcommit ec8e3c695f2dce080bde569746180300e91084a3[m
Author: zspo <songpo.zhang@foxmail.com>
Date:   Sat Apr 13 22:52:36 2024 +0800

    [Bugfix] fix_log_time_in_metrics (#4050)

[33mcommit 98afde19fc273b1e6a695990b93ec07157b856f1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Apr 13 07:12:53 2024 -0700

    [Core][Distributed] improve logging for init dist (#4042)

[33mcommit 5c2e66e4871917c5d59cc4a8b89ef53e690e9bd9[m
Author: Dylan Hawk <51147702+dylanwhawk@users.noreply.github.com>
Date:   Fri Apr 12 21:07:04 2024 -0700

    [Bugfix] More type hint fixes for py 3.8 (#4039)

[33mcommit 546e7211684a28bbe53088961b4cf5123e235760[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Apr 12 18:43:37 2024 -0700

    [CI/Test] expand ruff and yapf for all supported python version (#4037)

[33mcommit b8aacac31a4e2e03381fdaef6f1e4bbb895f3b64[m
Author: Jee Li <pandaleefree@163.com>
Date:   Sat Apr 13 07:56:37 2024 +0800

    [Bugfix] Fix LoRA bug (#4032)

[33mcommit d04973ad5446fe05c06035f6b2d99402fc3ac7bf[m
Author: Bellk17 <Kyletbell@ymail.com>
Date:   Fri Apr 12 16:41:26 2024 -0700

    Fix triton compilation issue (#3984)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit fbb9d9eef48a29e0ea821bbf399e4bf9a08d6ac1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Apr 12 16:40:39 2024 -0700

    [Core] fix custom allreduce default value (#4040)

[33mcommit 09473ee41c0a22c4d18936ea7eb2328071c19308[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Sat Apr 13 06:35:50 2024 +0900

    [mypy] Add mypy type annotation part 1 (#4006)

[33mcommit d4ec9ffb9574988132d927fd1615180522877262[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Fri Apr 12 13:56:04 2024 -0700

    [Misc] Fix typo in scheduler.py (#4022)

[33mcommit 96b6a6d790115d04bb87d410f3bdd5d7d85b43f1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Apr 12 12:35:44 2024 -0700

    [Bugfix] fix type hint for py 3.8 (#4036)

[33mcommit 36729bac1303b655b816b77f45b17237bfafd692[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Sat Apr 13 01:56:57 2024 +0900

    [Test] Test multiple attn backend for chunked prefill.  (#4023)

[33mcommit 7fd3949a0b1c6cd0dcd7066aca48d9d589f2f68e[m
Author: Cyrus Leung <cyrus.tl.leung@gmail.com>
Date:   Fri Apr 12 13:30:54 2024 +0800

    [Frontend][Core] Move `merge_async_iterators` to utils (#4026)

[33mcommit 1096717ae9e0b414ad625c1a12354dd1d949ffb1[m
Author: Jee Li <pandaleefree@163.com>
Date:   Fri Apr 12 12:02:44 2024 +0800

    [Core] Support LoRA on quantized models (#4012)

[33mcommit c2b4a1bce9a7707179cdfab2fb498c20b2b221e6[m
Author: Michael Feil <63565275+michaelfeil@users.noreply.github.com>
Date:   Thu Apr 11 17:17:21 2024 -0700

    [Doc] Add typing hints / mypy types cleanup (#3816)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit e46a60aa4c90cf3dfd9b90782f2eeabbda935eef[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Apr 11 23:34:12 2024 +0100

    [BugFix] Fix handling of stop strings and stop token ids (#3672)

[33mcommit 1e96c3341a4e055ae392085fecc7a672295b71c2[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Thu Apr 11 15:18:57 2024 -0700

    Add extra punica sizes to support bigger vocabs (#4015)

[33mcommit 95e7d4a97cd64f8c6dc226ec0bbceebef6458701[m
Author: Dylan Hawk <51147702+dylanwhawk@users.noreply.github.com>
Date:   Thu Apr 11 15:15:50 2024 -0700

    Fix echo/logprob OpenAI completion bug (#3441)
    
    Co-authored-by: Dylan Hawk <dylanwawk@gmail.com>

[33mcommit 559eb852f83fe7867390dd2986b4f93a6572cf10[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Apr 11 14:00:48 2024 -0700

    [Core] init_distributed_environment align with init_process_group(#4014)
    
    [Core][Distributed] make init_distributed_environment compatible with init_process_group (#4014)

[33mcommit a10d3056da644c31e4ebf95a2b6ad65a626a7350[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Thu Apr 11 13:35:51 2024 -0700

    [Core] Set `linear_weights` directly on the layer (#3977)

[33mcommit 8afca50889bad6ad987c523c48c31fc52fcb72e4[m
Author: bigPYJ1151 <jiang1.li@intel.com>
Date:   Fri Apr 12 02:56:49 2024 +0800

    [Hardware][Intel] Isolate CPUModelRunner and ModelRunner for better maintenance (#3824)

[33mcommit 08ccee1e830d39ecdb3c6cf382c843dbf5ae830e[m
Author: fuchen.ljl <yjqqqqdx_01@163.com>
Date:   Thu Apr 11 23:59:26 2024 +0800

    punica fix-bgmv-kernel-640 (#4007)

[33mcommit c1dc547129f5faaa2ca5ba557145b8ec8838693c[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Apr 11 07:50:00 2024 -0700

    [Kernel] Fused MoE Config for Mixtral 8x22 (#4002)

[33mcommit f3d0bf7589d6e63a691dcbb9d1db538c184fde29[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Apr 10 20:33:02 2024 -0700

    [Doc][Installation] delete python setup.py develop (#3989)

[33mcommit e9da5a40c63ce7f8a85438d3c7d919b46e7939f5[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Thu Apr 11 03:26:07 2024 +0000

    [Misc] Add indirection layer for custom ops  (#3913)

[33mcommit e42df7227d18e2b96785f8ee52053663ade05b63[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu Apr 11 12:09:50 2024 +0900

    [Test] Add xformer and flash attn tests (#3961)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit caada5e50aa16cd5f59bd7889128a83588ca1f99[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Apr 10 18:48:26 2024 -0700

    [Core][Model] torch.compile for layernorm in commandr (#3985)
    
    [Core][Model] Use torch.compile to accelerate layernorm in commandr (#3985)

[33mcommit 67b4221a61ace91a79aff507df0a95a01978300e[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu Apr 11 09:56:48 2024 +0900

    [Core][5/N] Fully working chunked prefill e2e (#3884)

[33mcommit 63e7176f265be43dcc425f5ab4ab45c90234f5c3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Apr 10 15:33:30 2024 -0700

    [Core][Refactor] move parallel_utils into vllm/distributed (#3950)
    
    [WIP][Core][Refactor] move vllm/model_executor/parallel_utils into vllm/distributed and vllm/device_communicators (#3950)

[33mcommit 934d3662f716d60abfb04cf9fdd6d20f6e75f140[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed Apr 10 16:28:25 2024 -0600

    [Bugfix] handle hf_config with architectures == None (#3982)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 92cd2e2f21e8ec65b2cb635a9f15de38157a1359[m
Author: FrŒ±n√ßois <francois.paupier@gmail.com>
Date:   Wed Apr 10 20:05:52 2024 +0200

    [Doc] Fix getting stared to use publicly available model (#3963)

[33mcommit e4c4072c94b346053768691451566c56664e26a7[m
Author: Daniel E Marasco <dmarasco@users.noreply.github.com>
Date:   Wed Apr 10 13:15:51 2024 -0400

    [Bugfix] Remove key sorting for `guided_json` parameter in OpenAi compatible Server (#3945)

[33mcommit e35397468f36a857b8d2b7d92a472265e1c500cc[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Apr 10 10:03:02 2024 -0700

    [Doc] Add doc to state our model support policy (#3948)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit 8b317c6dd09ce566f4b4abeb446585ac75262cce[m
Author: James Whedbee <jamesw@telnyx.com>
Date:   Wed Apr 10 10:12:00 2024 -0500

    [Model][AMD] ROCm support for 256 head dims for Gemma (#3972)

[33mcommit bd3c144e0b8e82c9b3c5c40c6d557fe8665de5a3[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Apr 10 07:37:17 2024 -0700

    [Bugfix][ROCm] Add numba to Dockerfile.rocm (#3962)

[33mcommit 0258b7a94b08321ca01cf170f867b67c1920af87[m
Author: Travis Johnson <tsjohnso@us.ibm.com>
Date:   Wed Apr 10 02:39:56 2024 -0600

    [Bugfix] handle prompt_logprobs in _apply_min_tokens_penalty (#3876)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>

[33mcommit b3104b2a10ab7cb7532442177ae0d0c40acf9d03[m
Author: ËÉ°ËØëÊñá <1020030101@qq.com>
Date:   Wed Apr 10 15:09:36 2024 +0800

    [Bugfix] Fix logits processor when prompt_logprobs is not None (#3899)

[33mcommit c2e00af523b0638dcca68c9a42a9187449841ced[m
Author: zhaotyer <89376832+zhaotyer@users.noreply.github.com>
Date:   Wed Apr 10 12:49:11 2024 +0800

    [Bugfix]  fix utils.py/merge_dict func TypeError: 'type' object is not subscriptable (#3955)
    
    Co-authored-by: tianyi_zhao <tianyi.zhao@transwarp.io>

[33mcommit c013d32c758699fbe5804af1b9d9408acd6cb8b7[m
Author: Zedong Peng <zedongpeng1@gmail.com>
Date:   Wed Apr 10 12:30:03 2024 +0800

    [Benchmark] Add cpu options to bench scripts (#3915)

[33mcommit 11dd6ebb8950a66c371f6fa5d2489eb01fc4f6d5[m
Author: Jee Li <pandaleefree@163.com>
Date:   Wed Apr 10 10:47:15 2024 +0800

    [Misc] Avoid loading incorrect LoRA config (#3777)

[33mcommit 6c0b04515fee7b402a6febde1467581825bb2164[m
Author: Juan Villamizar <100237675+jpvillam-amd@users.noreply.github.com>
Date:   Tue Apr 9 17:10:47 2024 -0500

    [ROCm][Hardware][AMD] Use Triton Kernel for default FA on ROCm (#3643)
    
    Co-authored-by: jpvillam <jpvillam@amd.com>
    Co-authored-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit e23a43aef8bc51c5201658775445f529324ed728[m
Author: Junichi Sato <jsato8094@gmail.com>
Date:   Wed Apr 10 04:11:31 2024 +0900

    [Bugfix] Fix KeyError on loading GPT-NeoX (#3925)

[33mcommit e7c7067b45c9f604e0c68015ee6e0fe345288111[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Apr 9 11:44:15 2024 -0700

    [Misc] [Core] Implement RFC "Augment BaseExecutor interfaces to enable hardware-agnostic speculative decoding" (#3837)

[33mcommit 6d592eb430a37a7f8f5f9beb2dbc014bf3aa76bc[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Apr 9 01:49:02 2024 -0700

    [Core] separate distributed_init from worker (#3904)

[33mcommit d036198e23345f3c25438f082396f7487028e8b6[m
Author: Roy <jasonailu87@gmail.com>
Date:   Tue Apr 9 06:17:21 2024 +0800

    [BugFix][Model] Fix commandr RoPE max_position_embeddings (#3919)

[33mcommit 59a6abf3c99ee4fed5312d357f6ecbf857f24433[m
Author: Matt Wong <156021403+mawong-amd@users.noreply.github.com>
Date:   Mon Apr 8 14:31:02 2024 -0700

    [Hotfix][CI/Build][Kernel] CUDA 11.8 does not support layernorm optimizations (#3782)

[33mcommit bc0c0192d13ca6ea4aeea4725f752a89483895bc[m
Author: Kiran R <kiranr8k@gmail.com>
Date:   Tue Apr 9 01:12:35 2024 +0530

    [Bugfix] Enable Proper `attention_bias` Usage in Llama Model Configuration (#3767)
    
    Co-authored-by: roy <jasonailu87@gmail.com>

[33mcommit f46864d68dfb46ff88f574e6844f10fdb14cd3b5[m
Author: egortolmachev <150433814+egortolmachev@users.noreply.github.com>
Date:   Mon Apr 8 17:59:38 2024 +0300

    [Bugfix] Added Command-R GPTQ support (#3849)
    
    Co-authored-by: Egor Tolmachev <t333ga@gmail.com>

[33mcommit b4543c8f6bf67a7f1a0d6d0fd6cf5697c7eeaabb[m
Author: ywfang <47963924+SUDA-HLT-ywfang@users.noreply.github.com>
Date:   Mon Apr 8 18:28:36 2024 +0800

    [Model] add minicpm (#3893)

[33mcommit 0ce0539d4750f9ebcd9b19d7085ca3b934b9ec67[m
Author: Isotr0py <41363108+Isotr0py@users.noreply.github.com>
Date:   Sun Apr 7 22:54:13 2024 +0800

    [Bugfix] Fix Llava inference with Tensor Parallelism. (#3883)

[33mcommit 2f1928354903ae0c6edfe76cc90081eb513ead2c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Apr 6 19:14:06 2024 -0700

    [Core] latency optimization (#3890)

[33mcommit 95baec828f3ee046074dace1d88202a920b7dc15[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Apr 6 17:11:41 2024 -0700

    [Core] enable out-of-tree model register (#3871)

[33mcommit e4be7d70bbac47b2c309caa20e68fc43e05e0550[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Apr 6 14:32:30 2024 -0700

    [CI/Benchmark] add more iteration and use median for robust latency benchmark (#3889)

[33mcommit 54951ac4bfb7f4224cb8f5ffc89b214c950107d8[m
Author: Isotr0py <41363108+Isotr0py@users.noreply.github.com>
Date:   Sat Apr 6 03:02:09 2024 +0800

    [Bugfix] Fix incorrect output on OLMo models in Tensor Parallelism (#3869)

[33mcommit 18de88348954b7e535a62c0b7e55004f253e9f21[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Sat Apr 6 02:17:58 2024 +0900

    [Chunked Prefill][4/n] Chunked prefill scheduler. (#3853)

[33mcommit 1d7c940d74f4923f7507725598bcd08f0f1dbd2d[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Fri Apr 5 19:15:42 2024 +0200

    Add option to completion API to truncate prompt tokens (#3144)

[33mcommit cfaf49a1673c872d2a06560346efb13695f82f35[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Apr 5 00:39:17 2024 -0700

    [Misc] Define common requirements (#3841)

[33mcommit 9edec652e2adfee7c06483271f5df4b1be1bfddc[m
Author: Noam Gat <noamgat@gmail.com>
Date:   Fri Apr 5 09:46:01 2024 +0300

    [Bugfix] Fixing requirements.txt (#3865)

[33mcommit e0dd4d358969144dae3592fd265dea002579a600[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Thu Apr 4 21:57:33 2024 -0700

    [Misc] Fix linter issues in examples/fp8/quantizer/quantize.py (#3864)

[33mcommit e5043a3e7505aefc59636f7df129dc168da4a7d2[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Thu Apr 4 21:54:16 2024 -0700

    [Misc] Add pytest marker to opt-out of global test cleanup (#3863)

[33mcommit d03d64fd2e22f1a48e7b78c66d7644e6b6230fb7[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Apr 4 21:53:16 2024 -0700

    [CI/Build] refactor dockerfile & fix pip cache
    
    [CI/Build] fix pip cache with vllm_nccl & refactor dockerfile to build wheels (#3859)

[33mcommit 78107fa0911567f131cbad810872ae25594a4506[m
Author: Sean Gallen <sjgallen@gmail.com>
Date:   Thu Apr 4 23:52:01 2024 -0500

    [Doc]Add asynchronous engine arguments to documentation. (#3810)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit c391e4b68e6694986f24ccd620d7bf07c237ab60[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Apr 4 16:52:12 2024 -0700

    [Core] improve robustness of pynccl (#3860)

[33mcommit 9117f892f0e4d3b0f07bf0b9b409321bc743dabc[m
Author: Saurabh Dash <111897126+saurabhdash2512@users.noreply.github.com>
Date:   Fri Apr 5 02:01:49 2024 +0530

    [Model] Cohere CommandR+ (#3829)

[33mcommit db2a6a41e206abecf4128aba25117fcaf7bebe12[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Thu Apr 4 12:49:49 2024 -0700

    [Hardware][CPU] Update cpu torch to match default of 2.2.1 (#3854)

[33mcommit ca81ff5196b2fa82b7a9d553cd6e30eab9e72aca[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Apr 4 10:26:19 2024 -0700

    [Core] manage nccl via a pypi package & upgrade to pt 2.2.1 (#3805)

[33mcommit b7782002e1da25de77e0b1890ff8b72dd4df917c[m
Author: TianYu GUO <guoty9@mail2.sysu.edu.cn>
Date:   Thu Apr 4 17:56:22 2024 +0800

    [Benchmark] Refactor sample_requests in benchmark_throughput (#3613)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit 819a309c0fcf84d9b023a96d6836e7501309d6b1[m
Author: Chang Su <csu272@usc.edu>
Date:   Thu Apr 4 00:41:05 2024 -0700

    [Bugfix] Fix args in benchmark_serving (#3836)
    
    Co-authored-by: Roger Wang <ywang@roblox.com>

[33mcommit aabe8f40f2d82da49f5fd542e80cae03550dd441[m
Author: Matthias Gerstgrasser <matthias@gerstgrasser.net>
Date:   Wed Apr 3 21:52:18 2024 -0700

    [Core] [Frontend] Make detokenization optional (#3749)
    
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 498eb5cfa3b482c715a710c548a430ad140d109c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Apr 3 21:33:08 2024 -0700

    [Bugfix] Add kv_scale input parameter to CPU backend (#3840)

[33mcommit 537ee25f43afbb51be6984a9ce781f28fafaf373[m
Author: Michael Feil <63565275+michaelfeil@users.noreply.github.com>
Date:   Wed Apr 3 21:02:43 2024 -0700

    [Core] Enable hf_transfer by default if available (#3817)

[33mcommit 294f8f6665b1731d1a8786e518d9862f7a7043df[m
Author: Tao He <sighingnow@gmail.com>
Date:   Thu Apr 4 11:31:46 2024 +0800

    [BugFix] Pass tokenizer_config to local_tokenizer_group (#3754)
    
    Signed-off-by: Tao He <sighingnow@gmail.com>

[33mcommit b95047f2dad3cc4d64e6f4d76974e3c55917c5ee[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Apr 3 15:46:10 2024 -0700

    [Misc] Publish 3rd meetup slides (#3835)

[33mcommit 2ff767b51301e07d1e0ad5887eb26e104e2b3a8a[m
Author: Adrian Abeyta <adabeyta@amd.com>
Date:   Wed Apr 3 16:15:55 2024 -0500

    Enable scaled FP8 (e4m3fn) KV cache on ROCm (AMD GPU) (#3290)
    
    Co-authored-by: Gregory Shtrasberg <Gregory.Shtrasberg@amd.com>
    Co-authored-by: HaiShaw <hixiao@gmail.com>
    Co-authored-by: AdrianAbeyta <Adrian.Abeyta@amd.com>
    Co-authored-by: Matthew Wong <Matthew.Wong2@amd.com>
    Co-authored-by: root <root@gt-pla-u18-08.pla.dcgpu>
    Co-authored-by: mawong-amd <156021403+mawong-amd@users.noreply.github.com>
    Co-authored-by: ttbachyinsda <ttbachyinsda@outlook.com>
    Co-authored-by: guofangze <guofangze@kuaishou.com>
    Co-authored-by: Michael Goin <mgoin64@gmail.com>
    Co-authored-by: jacobthebanana <50071502+jacobthebanana@users.noreply.github.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 3dcb3e8b9838cbbef83ce326b1a35b31a3cf14f2[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu Apr 4 06:13:49 2024 +0900

    [3/N] Refactor scheduler for chunked prefill scheduling (#3550)

[33mcommit c64cf38673780544087af5ad5d3baf879a29220b[m
Author: Michael Feil <63565275+michaelfeil@users.noreply.github.com>
Date:   Wed Apr 3 00:31:43 2024 -0700

    [Doc] Update contribution guidelines for better onboarding (#3819)

[33mcommit 76b889bf1d101c4e5c9a17b9e1a7f8e2df43e306[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Tue Apr 2 23:11:10 2024 -0700

    [Doc] Update README.md (#3806)

[33mcommit c9b506dad43c1439fd9aa5c1dd358d03967a7790[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Apr 2 23:06:25 2024 -0700

    [BugFix] Use different mechanism to get vllm version in `is_cpu()` (#3804)

[33mcommit 5757d90e26464d4582e36b55a2a0f34aec408e7f[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Apr 2 17:40:57 2024 -0700

    [Speculative decoding] Adding configuration object for speculative decoding (#3706)
    
    Co-authored-by: Lily Liu <lilyliupku@gmail.com>

[33mcommit a3c226e7eb19b976a937e745f3867eb05f809278[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Apr 2 12:57:04 2024 -0700

    [CI/Build] 0.4.0.post1, fix sm 7.0/7.5 binary (#3803)

[33mcommit b321d4881b273b2b7085093816443a718c62d24a[m
Author: Michael Goin <michael@neuralmagic.com>
Date:   Tue Apr 2 12:35:31 2024 -0700

    [Bugfix] Add `__init__.py` files for `vllm/core/block/` and `vllm/spec_decode/` (#3798)

[33mcommit ad6eca408bc515391992db0f8becaa78e23d1150[m
Author: leiwen83 <leiwen83@users.noreply.github.com>
Date:   Wed Apr 3 02:56:26 2024 +0800

    Fix early CUDA init via get_architecture_class_name import (#3770)
    
    Signed-off-by: Lei Wen <wenlei03@qiyi.com>
    Co-authored-by: Lei Wen <wenlei03@qiyi.com>

[33mcommit 205b94942e97f668c01d8f4b476da36277df4c59[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Tue Apr 2 11:54:33 2024 -0700

    [CI/Build] fix TORCH_CUDA_ARCH_LIST in wheel build (#3801)

[33mcommit 3bec41f41a28c0d51111b49e0db712009cf0439f[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Tue Apr 2 09:49:37 2024 -0700

    [Doc] Fix vLLMEngine Doc Page (#3791)

[33mcommit 0739b1947f4081b0edafc7951134a928e39302e7[m
Author: A-Mahla <89754740+A-Mahla@users.noreply.github.com>
Date:   Tue Apr 2 10:20:28 2024 +0200

    [Frontend][Bugfix] allow using the default middleware with a root path (#3788)
    
    Co-authored-by: A-Mahla <>

[33mcommit 77a6572aa5e752b28383768ffcd151cf93e3925f[m
Author: bigPYJ1151 <jiang1.li@intel.com>
Date:   Tue Apr 2 13:50:53 2024 +0800

    [HotFix] [CI/Build] Minor fix for CPU backend CI (#3787)

[33mcommit 0e3f06fe9ccfb59cb89c353b6ef81110fa0854c9[m
Author: bigPYJ1151 <jiang1.li@intel.com>
Date:   Tue Apr 2 13:07:30 2024 +0800

    [Hardware][Intel] Add CPU inference backend (#3634)
    
    Co-authored-by: Kunshang Ji <kunshang.ji@intel.com>
    Co-authored-by: Yuan Zhou <yuan.zhou@intel.com>

[33mcommit eb69d68804840b1108608316fe643e6a74ae44d0[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Mon Apr 1 17:49:51 2024 -0700

    [Misc] [CI/Build] Speed up block manager CPU-only unit tests ~10x by opting-out of GPU cleanup (#3783)

[33mcommit 7d4e1b85e78574acb5c682fa9fe1d3dfa5f092d7[m
Author: Qubitium <417764+Qubitium@users.noreply.github.com>
Date:   Tue Apr 2 07:32:01 2024 +0800

    [Misc] Add support for new autogptq checkpoint_format (#3689)
    
    Co-authored-by: Robert Shaw <rshaw@neuralmagic.com>

[33mcommit 93deb0b38f8c11a67fc559957661ceac7172dbfb[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Mon Apr 1 15:55:24 2024 -0700

    [Speculative decoding 4/9] Lookahead scheduling for speculative decoding (#3250)

[33mcommit ccb58b23e698ed0bd3f4a850366211622463f109[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Apr 1 15:24:30 2024 -0700

    [Misc] Fix Benchmark TTFT Calculation for Chat Completions (#3768)

[33mcommit 49782fcb769eb4f04a3cf5179c1e6c13ab633ce1[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Apr 1 13:22:06 2024 -0700

    [Misc] Some minor simplifications to detokenization logic (#3670)
    
    Some simplifications made for clarity.
    
    Also moves detokenization-related functions from tokenizer.py to detokenizer.py.

[33mcommit f03cc667a09bce92e09365893603f7ec0d87c9f2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Apr 1 03:15:48 2024 -0700

    [Misc] Minor fixes in requirements.txt (#3769)

[33mcommit 563c1d7ec56aa0f9fdc28720f3517bf9297f5476[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Sat Mar 30 21:18:34 2024 -0500

    [CI/Build] Make Marlin Tests Green (#3753)

[33mcommit 9c82a1bec3a177ff2d611c092c19d25cabd90bb0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sat Mar 30 16:34:38 2024 -0700

    [Doc] Update installation doc (#3746)
    
    [Doc] Update installation doc for build from source and explain the dependency on torch/cuda version (#3746)
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit b6d103542c654fb63013a1e45a586d654ae36a2a[m
Author: mawong-amd <156021403+mawong-amd@users.noreply.github.com>
Date:   Sat Mar 30 14:26:38 2024 -0700

    [Kernel] Layernorm performance optimization (#3662)

[33mcommit 51c31bc10ca7c48b580cd58fcd741ba4d6db4447[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Mar 29 18:53:08 2024 -0700

    CMake build elf without PTX (#3739)

[33mcommit 3ad438c66fff5acafa710c328e5922cc086dbe65[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Fri Mar 29 21:52:39 2024 -0400

    Fix build when nvtools is missing (#3698)

[33mcommit 203d4f82ac137f04c0e487bbdbba86b3cf3ae7bf[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Mar 29 18:46:39 2024 -0700

    [Core][Bugfix] cache len of tokenizer (#3741)

[33mcommit 991143cfcdc57d658d312bc001dd6d6dffba9495[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Fri Mar 29 16:26:44 2024 -0700

    [BugFix] Use consistent logger everywhere (#3738)

[33mcommit 8b2d3cbc1bf4791329fdf400fb1b087b8b1a42f8[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Mar 29 15:57:08 2024 -0700

    usage lib get version another way (#3735)

[33mcommit 9765b5c4061b37c0db417aa6c638b0ca90183be1[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Fri Mar 29 17:52:36 2024 -0400

    [ROCm][Bugfix] Fixed several bugs related to rccl path and attention selector logic (#3699)

[33mcommit 430530fc18b7dc8076f7df4c3c6718ba8cc303f3[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Mar 29 12:28:33 2024 -0700

    bump version to v0.4.0 (#3712)

[33mcommit 97356f3c7e2fcaf1f8e17300eaf0b20b35eccb9d[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Mar 29 12:27:51 2024 -0700

    [Bugfix] Command-R Max Model Length (#3727)

[33mcommit f510395bbf4177dad55f53b85a671ba4e4aba60d[m
Author: Roy <jasonailu87@gmail.com>
Date:   Sat Mar 30 00:38:21 2024 +0800

    [BugFix][Frontend] Fix completion logprobs=0 error (#3731)

[33mcommit 6110c39dc8f7ab177a48d35a4426a0f6e811d538[m
Author: Roy <jasonailu87@gmail.com>
Date:   Fri Mar 29 23:18:59 2024 +0800

    [BugFix] Fix tokenizer out of vocab size (#3685)

[33mcommit d8658c8cc16d67e6690cb0f3f340e365652ce80b[m
Author: yhu422 <92338430+yhu422@users.noreply.github.com>
Date:   Thu Mar 28 22:16:12 2024 -0700

    Usage Stats Collection (#2852)

[33mcommit 7bc94a0fddcd62d20b40390a7efb69c7a221ae5b[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Mar 28 22:14:24 2024 -0700

    add ccache to docker build image (#3704)

[33mcommit 756b30a5f30ee08b97243e1077419d8d74442b02[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Mar 28 21:19:45 2024 -0700

    [Core][Test] move local_rank to the last arg with default value(#3711)
    
    [Core][Test] move local_rank to the last arg with default value to keep api compatible (#3711)

[33mcommit 395aa823ea456ef4f4677b7a43c37806307be2bc[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Mar 28 21:12:24 2024 -0700

    [Misc] Minor type annotation fix (#3716)

[33mcommit 26422e477b2c485b6dc05c6515ad4250404a3e53[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri Mar 29 13:06:40 2024 +0900

    [Test] Make model tests run again and remove --forked from pytest (#3631)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit f342153b4892789616a9bf58b6b9348dcb2329c3[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Mar 28 18:49:42 2024 -0700

    Revert "bump version to v0.4.0" (#3708)

[33mcommit 27a57cad52f2688fca024322b751a54f52b5e84f[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Mar 28 18:26:51 2024 -0700

    bump version to v0.4.0 (#3705)

[33mcommit 98a42e70782ec38c1f0f20d0226d0f71147d1ac2[m
Author: Yile (Michael) Gu <39850409+IKACE@users.noreply.github.com>
Date:   Thu Mar 28 17:33:52 2024 -0700

    [Benchmark] Change mii to use persistent deployment and support tensor parallel (#3628)

[33mcommit 0267fef52a7fade4bd5de05caea0bc8fc8418bf7[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Mar 28 17:24:58 2024 -0700

    [Core] fix del of communicator (#3702)

[33mcommit 4716a32dd4b413674c104b96882ea9965051c4ff[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Mar 28 16:29:55 2024 -0700

    fix logging msg for block manager (#3701)

[33mcommit c0935c96d3472fe153ec849311c78fd8728dbb3c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Mar 28 16:26:30 2024 -0700

    [Bugfix] Set enable_prefix_caching=True in prefix caching example (#3703)

[33mcommit cb40b3ab6bec6c26a0403b672b3679aabae3f683[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Mar 28 15:26:24 2024 -0700

    [Kernel] Add MoE Triton kernel configs for A100 40GB (#3700)

[33mcommit 515386ef3cacb44a2bcfab9d66eaee6143d94e95[m
Author: Roy <jasonailu87@gmail.com>
Date:   Fri Mar 29 06:01:55 2024 +0800

    [Core] Support multi-node inference(eager and cuda graph) (#3686)

[33mcommit a4075cba4de42470565737f668c8cf7512fbe935[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Mar 28 14:36:10 2024 -0700

    [CI] Add test case to run examples scripts (#3638)

[33mcommit 96aa014d1e299bede81b30d6bb7844739f68b849[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Mar 28 14:35:16 2024 -0700

    fix benchmark format reporting in buildkite (#3693)

[33mcommit 1715056fef0e8f047f71bfb864fe9773af47af41[m
Author: Adam Boeglin <adamrb@gmail.com>
Date:   Thu Mar 28 10:43:34 2024 -0700

    [Bugfix] Update neuron_executor.py to add optional vision_language_config (#3695)

[33mcommit b51c1cc9d2f223cfa3aef1426bced10dfde28dbb[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri Mar 29 02:06:01 2024 +0900

    [2/N] Chunked prefill data update (#3538)

[33mcommit ce567a292685f362852c7c5fc43658a2b6d7d576[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Thu Mar 28 10:05:34 2024 -0700

    [Kernel] DBRX Triton MoE kernel H100 (#3692)

[33mcommit d6ea427f04890014fa9b0ab8eb6d87e244ff1a48[m
Author: wenyujin333 <l.y.q.see@gmail.com>
Date:   Thu Mar 28 23:19:59 2024 +0800

    [Model] Add support for Qwen2MoeModel (#3346)

[33mcommit 14ccd94c89d0ffd9da283545d93ab1dfea5da340[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Wed Mar 27 23:59:28 2024 -0700

    [Core][Bugfix]Refactor block manager for better testability (#3492)

[33mcommit 8267b06c3026dd5e27578371886dd2571c5d6f59[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Mar 27 22:22:25 2024 -0700

    [Kernel] Add Triton MoE kernel configs for DBRX on A100 (#3679)

[33mcommit 3492859b687ba18db47720bcf6f07289999a2df5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Mar 27 21:18:54 2024 -0700

    [CI/Build] update default number of jobs and nvcc threads to avoid overloading the system (#3675)

[33mcommit 098e1776ba72805bbf8f68a44b10f499413e5189[m
Author: hxer7963 <hxer7963@gmail.com>
Date:   Thu Mar 28 09:12:54 2024 +0800

    [Model] Add support for xverse  (#3610)
    
    Co-authored-by: willhe <hexin@xverse.cn>
    Co-authored-by: root <root@localhost.localdomain>

[33mcommit 10e6322283a9149c23eb76db50e6da972ce4b99e[m
Author: Roy <jasonailu87@gmail.com>
Date:   Thu Mar 28 08:20:00 2024 +0800

    [Model] Fix and clean commandr (#3671)

[33mcommit 6d9aa00fc404f8877287d559fbdac4f7a05330de[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Mar 27 15:20:00 2024 -0700

    [Docs] Add Command-R to supported models (#3669)

[33mcommit 1182607e182f139e24a298ec3a3a5863f7ba0ace[m
Author: zeppombal <79043513+zeppombal@users.noreply.github.com>
Date:   Wed Mar 27 21:19:32 2024 +0000

    Add support for Cohere's Command-R model (#3433)
    
    Co-authored-by: Jos√© Maria Pombal <jose.pombal@unbabel.com>
    Co-authored-by: youkaichao <youkaichao@gmail.com>

[33mcommit 45b6ef651387100c24d671fb485e7a6e208216f6[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Wed Mar 27 13:39:26 2024 -0700

    feat(benchmarks): Add Prefix Caching Benchmark to Serving Benchmark (#3277)

[33mcommit 195693143634e7cf3841cc33cdbf0906f3b1af3d[m
Author: AmadeusChan <greenclouds@foxmail.com>
Date:   Wed Mar 27 16:39:05 2024 -0400

    [Misc] add the "download-dir" option to the latency/throughput benchmarks (#3621)

[33mcommit e24336b5a772ab3aa6ad83527b880f9e5050ea2a[m
Author: Megha Agarwal <16129366+megha95@users.noreply.github.com>
Date:   Wed Mar 27 13:01:46 2024 -0700

    [Model] Add support for DBRX (#3660)

[33mcommit d18f4e73f39a72bc2abe74bc6b02c61805e1c3d1[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Mar 27 10:23:54 2024 -0700

    [Bugfix] [Hotfix] fix nccl library name (#3661)

[33mcommit 82c540bebf599e3208683bebf87db56175145ebd[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Mar 27 09:37:18 2024 -0700

    [Bugfix] More faithful implementation of Gemma (#3653)

[33mcommit 8f44facdddcf3c704f7d6a2719b6e85efc393449[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Wed Mar 27 00:33:26 2024 -0700

    [Core] remove cupy dependency (#3625)

[33mcommit e66b629c04c38e2743ccac5f14c43bdde016cae1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Mar 26 23:14:06 2024 -0700

    [Misc] Minor fix in KVCache type (#3652)

[33mcommit 76879342a33352b4e7cd08de36a0474ad2e25453[m
Author: Jee Li <pandaleefree@163.com>
Date:   Wed Mar 27 10:06:46 2024 +0800

    [Doc]add lora support (#3649)

[33mcommit 566b57c5c48a7ba8bbed3e45a07fae9e0bb58cac[m
Author: Jee Li <pandaleefree@163.com>
Date:   Wed Mar 27 08:37:42 2024 +0800

    [Kernel] support non-zero cuda devices  in punica kernels (#3636)

[33mcommit 0dc72273b8421bbbc7ce1eec7c915a9e0799e250[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Mar 26 14:39:44 2024 -0700

    [BugFix] Fix ipv4 address parsing regression (#3645)

[33mcommit a979d9771e9bc728c57e98efb3cf94f430822d7d[m
Author: liiliiliil <781102525@qq.com>
Date:   Wed Mar 27 02:58:20 2024 +0800

    [Bugfix] Fix ipv6 address parsing bug (#3641)

[33mcommit 8af890a865bf9f744d7d9bd5515558b42224c744[m
Author: Jee Li <pandaleefree@163.com>
Date:   Tue Mar 26 09:09:31 2024 +0800

    Enable more models to  inference based on LoRA (#3382)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit dfeb2ecc3abe5c1d1a3161b39d8cead5484591e9[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Mar 25 17:31:32 2024 -0700

    [Misc] Include matched stop string/token in responses (#2976)
    
    Co-authored-by: Sahil Suneja <sahilsuneja@gmail.com>

[33mcommit 3a243095e5e7b655b63ab08fbd5936cb40850415[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Mar 25 16:03:02 2024 -0700

    Optimize `_get_ranks` in Sampler (#3623)

[33mcommit 64172a976c8d975b3aec946f1675716d2532d94f[m
Author: xwjiang2010 <87673679+xwjiang2010@users.noreply.github.com>
Date:   Mon Mar 25 14:16:30 2024 -0700

    [Feature] Add vision language model support. (#3042)

[33mcommit f408d05c523c25e2f638a13cb34a2dab3dcb2754[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Mar 25 11:55:46 2024 -0700

    hotfix isort on logprobs ranks pr (#3622)

[33mcommit 0b4997e05cf5aefcf648cae4d91c8e1d651008b9[m
Author: Dylan Hawk <51147702+dylanwhawk@users.noreply.github.com>
Date:   Mon Mar 25 10:14:34 2024 -0700

    [Bugfix] API stream returning two stops (#3450)
    
    Co-authored-by: Dylan Hawk <dylanwawk@gmail.com>

[33mcommit c13ad1b7bdf6fba5ab02225e6655bc26fae90192[m
Author: Travis Johnson <tjohnson31415@gmail.com>
Date:   Mon Mar 25 11:14:26 2024 -0600

    feat: implement the min_tokens sampling parameter (#3124)
    
    Signed-off-by: Travis Johnson <tsjohnso@us.ibm.com>
    Co-authored-by: Nick Hill <nickhill@us.ibm.com>

[33mcommit 819924e74947ba2ac4f2035df88bb4dac79ec6cf[m
Author: Swapnil Parekh <swapnilbp100@gmail.com>
Date:   Mon Mar 25 13:13:10 2024 -0400

    [Core] Adding token ranks along with logprobs (#3516)
    
    Co-authored-by: Swapnil Parekh <swapnilp@ibm.com>

[33mcommit 01bfb22b4112ee813185366ab26985d172661a61[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Mon Mar 25 23:59:47 2024 +0900

    [CI] Try introducing isort.  (#3495)

[33mcommit e67c295b0c812a4969d5bbc70818f6d87c87f9e4[m
Author: TianYu GUO <guoty9@mail2.sysu.edu.cn>
Date:   Mon Mar 25 20:35:22 2024 +0800

    [Bugfix] fix automatic prefix args and add log info (#3608)

[33mcommit 925f3332cac488e5ad2dbc8f5c6d5f42d2556816[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Mar 24 21:39:33 2024 -0700

    [Core] Refactor Attention Take 2 (#3462)

[33mcommit b0dfa91dd77e954be71e1e21ef8a4041a0e98cea[m
Author: Â∞ëÂπ¥ <48116214+shaonianyr@users.noreply.github.com>
Date:   Mon Mar 25 12:07:36 2024 +0800

    [Model] Add starcoder2 awq support (#3569)

[33mcommit 56a8652f33955bfb5bf6766106db78eb6ff37d55[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Mar 24 20:06:50 2024 -0700

    [Bugfix] store lock file in tmp directory (#3578)" (#3599)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 6d93d35308fc34bf76e2456c25be297b095ae902[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Mon Mar 25 10:01:13 2024 +0800

    [BugFix] tensor.get_device() -> tensor.device (#3604)

[33mcommit 837e1851428e8aae7fc91a837620ac6c889089b0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Mar 24 17:43:05 2024 -0700

    [CI/Build] fix flaky test (#3602)

[33mcommit 42bc386129f6890aa1654c31aa17a415f7642a5e[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Mar 24 17:04:00 2024 -0700

    [CI/Build] respect the common environment variable MAX_JOBS (#3600)

[33mcommit 8b268a46a7c955bb1f2b25bbed02f9b1e3a4ff05[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Sun Mar 24 16:03:06 2024 -0700

    [CI] typo fix: is_hip --> is_hip() (#3595)

[33mcommit 41deac4a3d785aa8d889acd3eebe534d060df117[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sun Mar 24 16:00:16 2024 -0700

    [BugFix] 1D query fix for MoE models (#3597)

[33mcommit af9e53496fc4dfc01b4680c1f16e38687cb3a91a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Mar 24 06:34:01 2024 -0700

    [BugFix] Fix Falcon tied embeddings (#3590)
    
    Co-authored-by: 44670 <44670@users.noreply.github.com>

[33mcommit f8a12ecc7f7ebcffe26e1ae405c6aa533fc400cd[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Sun Mar 24 06:32:45 2024 -0700

    [Misc] Bump transformers version (#3592)

[33mcommit 3c5ab9b811da7a72af6459bc0c344644ebdc1ef6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Mar 23 23:30:56 2024 -0700

    [Misc] Fix BLOOM copyright notice (#3591)

[33mcommit 743a0b74021b466088924d1a1228031bdedba896[m
Author: kota-iizuka <64062831+kota-iizuka@users.noreply.github.com>
Date:   Sun Mar 24 03:43:11 2024 +0900

    [Bugfix] use SoftLockFile instead of LockFile (#3578)

[33mcommit bfdb1ba5c3fb14387c69acb1f5067102d8028e56[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Mar 22 13:44:12 2024 -0700

    [Core] Improve detokenization performance for prefill (#3469)
    
    Co-authored-by: MeloYang <meloyang05@gmail.com>

[33mcommit cf2f084d56a1293cb08da2393984cdc7685ac019[m
Author: Thomas Parnell <tpa@zurich.ibm.com>
Date:   Fri Mar 22 20:28:14 2024 +0100

    Dynamic scheduler delay to improve ITL performance  (#3279)
    
    Co-authored-by: Jan van Lunteren <jvl@zurich.ibm.com>

[33mcommit f721096d48a7e3b98dffcb9b400bf58989cef64d[m
Author: Hanzhi Zhou <hanzhi713@gmail.com>
Date:   Thu Mar 21 23:02:58 2024 -0700

    [BugFix] Some fixes for custom allreduce kernels (#2760)

[33mcommit e90fc21f2eda7e53f692398ee2c0cb5a0ac19693[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Mar 21 18:22:17 2024 -0700

    [Hardware][Neuron] Refactor neuron support (#3471)

[33mcommit ea5f14e6ffafcb9c660a3eea5a935122aa9f84ae[m
Author: Roy <jasonailu87@gmail.com>
Date:   Fri Mar 22 08:18:58 2024 +0800

    [Bugfix][Model] Fix Qwen2 (#3554)

[33mcommit b7050ca7df640326f53e89f518f3ee045dfbbdef[m
Author: Taemin Lee <persuade@gmail.com>
Date:   Fri Mar 22 05:16:57 2024 +0900

    [BugFix] gemma loading after quantization or LoRA. (#3553)

[33mcommit c188ecb080501c5ccb34bbd6542978284c547122[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Mar 21 07:58:12 2024 -0700

    [Misc] Bump up transformers to v4.39.0 & Remove StarCoder2Config (#3551)
    
    Co-authored-by: Roy <jasonailu87@gmail.com>
    Co-authored-by: Roger Meier <r.meier@siemens.com>

[33mcommit 865732342b4e3b8a4ef38f28a2a5bdb87cf3f970[m
Author: Roy <jasonailu87@gmail.com>
Date:   Thu Mar 21 18:07:48 2024 +0800

    [Misc][Log] Add log for tokenizer length not equal to vocabulary size (#3500)

[33mcommit 4c07dd28c0ef8642735222e077935b55f4c98017[m
Author: Lalit Pradhan <136452006+grandiose-pizza@users.noreply.github.com>
Date:   Thu Mar 21 13:45:24 2024 +0400

    [üöÄ Ready to be merged] Added support for Jais models (#3183)

[33mcommit 3bbff9e5ab964cf04897cebfc5e886a1113fef01[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu Mar 21 17:49:06 2024 +0900

    Fix 1D query issue from `_prune_hidden_states` (#3539)

[33mcommit 6ebd02bdef1eb08f9a7a11253a26cd49b5fb6d2d[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Thu Mar 21 07:20:04 2024 +0100

    [PREFIX CACHING FOLLOW UP] OrderedDict-based evictor (#3431)
    
    Co-authored-by: rsnm2 <rshaw@neuralmagic.com>
    Co-authored-by: Luka <luka@paperspace>

[33mcommit 523e30ea0c5abcb447763dcd9a77b54d5c5f3239[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Mar 20 17:59:52 2024 -0700

    [BugFix] Hot fix in setup.py for neuron build (#3537)

[33mcommit f1c0fc391909e55fce5f109893f3c483f69a091f[m
Author: Roy <jasonailu87@gmail.com>
Date:   Thu Mar 21 07:25:01 2024 +0800

    Migrate `logits` computation and gather to `model_runner` (#3233)

[33mcommit 6e435de766c7749b214b637ac58570a221006c95[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Thu Mar 21 06:46:05 2024 +0900

    [1/n][Chunked Prefill] Refactor input query shapes (#3236)

[33mcommit 426ec4ec6711b4180538cd56b9f6b856e5276a1f[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Mar 20 14:45:08 2024 -0700

    [1/n] Triton sampling kernel (#3186)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit 80e254834de9c3c34eaca02d8880e952b3daf344[m
Author: James Whedbee <jamesw@telnyx.com>
Date:   Wed Mar 20 16:05:03 2024 -0500

    [Bugfix] Fix ROCm support in CMakeLists.txt (#3534)

[33mcommit ba8ae1d84f66dd804a97182350fee6ffcadf0faf[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Wed Mar 20 13:06:56 2024 -0400

    Check for _is_cuda() in compute_num_jobs (#3481)

[33mcommit 84eaa68425807a490f363d2e5ddf9bee3d362b0d[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Thu Mar 21 00:28:29 2024 +0800

    Abort when nvcc command is not found in the PATH (#3527)

[33mcommit 5ee14494e4c78769fa10af8b58c3e7808053da0d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Mar 20 00:38:53 2024 -0700

    [Misc] Remove cache stream and cache events (#3461)

[33mcommit 4ad521d8b51145a55c1be6b8e451f76423cc2d87[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Mar 20 00:36:09 2024 -0700

    [Core] Add generic typing to `LRUCache` (#3511)

[33mcommit 9474e89ba4ecae253b585eb6b3e1d85f4e108f01[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Wed Mar 20 08:11:11 2024 +0100

    [PREFIX CACHING FOLLOW UP] A bunch of fixes to block allocator performance when automatic prefix caching is disabled (#3357)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 20478c4d3abcd0aa8a1d9ace9c76ea3a2e04cb5e[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Mar 19 14:34:15 2024 -0700

    Use lru_cache for some environment detection utils (#3508)

[33mcommit 63e8b28a990ef1584975c642b1ee5ae8a65b3183[m
Author: Jim Burtoft <39492751+jimburtoft@users.noreply.github.com>
Date:   Tue Mar 19 16:32:30 2024 -0400

    [Doc] minor fix of spelling in amd-installation.rst (#3506)

[33mcommit cc63d03fbb93f2b984d38e1f5626f523c1f9f1a4[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Mar 19 13:22:58 2024 -0700

    Revert "[Core] Cache some utils" (#3507)

[33mcommit 2a60c9bd174c4eaba790ecb36d13fa4c145d99f4[m
Author: Jim Burtoft <39492751+jimburtoft@users.noreply.github.com>
Date:   Tue Mar 19 16:21:35 2024 -0400

    [Doc] minor fix to neuron-installation.rst (#3505)

[33mcommit c614cfee5861e5715a023fa501e432d4acf910fe[m
Author: ifsheldon <39153080+ifsheldon@users.noreply.github.com>
Date:   Wed Mar 20 01:54:59 2024 +0800

    Update dockerfile with ModelScope support (#3429)

[33mcommit 7341c77d693edcecf0a9f5a6e399c5137177dfba[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Mon Mar 18 23:05:20 2024 -0700

    [BugFix] Avoid initializing CUDA too early (#3487)

[33mcommit ef65dcfa6f5820ce9e4a2411e9be18586f6fd467[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Mar 18 22:05:34 2024 -0700

    [Doc] Add docs about OpenAI compatible server (#3288)

[33mcommit 6a9c583e73c75c8eab10a9c607cb096750b751a0[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Mon Mar 18 21:06:23 2024 -0700

    [Core] print error before deadlock (#3459)

[33mcommit b37cdce2b1125ac06829c2606be1e26d75b5a505[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Mar 18 17:14:26 2024 -0700

    [Core] Cache some utils (#3474)

[33mcommit b30880a7626cfd4b3f593c995118513674a98880[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Mar 18 15:58:38 2024 -0700

    [Misc] Update README for the Third vLLM Meetup (#3479)

[33mcommit 49eedea373043ee9d1b11b81b6c5b3bc24af5b77[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Mar 18 15:56:40 2024 -0700

    [Core] Zero-copy asdict for InputMetadata (#3475)

[33mcommit 9fdf3de346836e88b310e53b50e7947974fde1d3[m
Author: bnellnm <49004751+bnellnm@users.noreply.github.com>
Date:   Mon Mar 18 18:38:33 2024 -0400

    Cmake based build system (#2830)

[33mcommit c0c17d489628591363ef486fe840d9308ff13dc9[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Mar 18 15:00:31 2024 -0700

    [Misc] Fix PR Template (#3478)

[33mcommit 097aa0ea220b45d82440a8072e8e3a2ce4631fdf[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Mon Mar 18 15:28:00 2024 -0500

    [CI/Build] Fix Bad Import In Test (#3473)

[33mcommit 482b0adf1b689a3fb6cdd5374b57ac75f1591d6a[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Mon Mar 18 12:48:45 2024 -0700

    [Testing] Add test_config.py to CI (#3437)

[33mcommit 8c654c045f73198a517becd8b1b23a9b16eae284[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Mar 18 12:33:47 2024 -0700

    CI: Add ROCm Docker Build (#2886)

[33mcommit 9101d832e6fe3811db8faa739f4a7e6e2f32a240[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Mar 18 11:26:24 2024 -0700

    [Bugfix] Make moe_align_block_size AMD-compatible (#3470)

[33mcommit 93348d9458af7517bb8c114611d438a1b4a2c3be[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Mar 17 14:56:30 2024 -0700

    [CI] Shard tests for LoRA and Kernels to speed up (#3445)

[33mcommit abfc4f3387c436d46d6701e9ba916de8f9ed9329[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Mar 17 03:02:46 2024 -0700

    [Misc] Use dataclass for InputMetadata (#3452)
    
    Co-authored-by: youkaichao <youkaichao@126.com>

[33mcommit 6b78837b29b5045a71e6ecfa68442b1f4fd2d0a6[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat Mar 16 16:00:25 2024 -0700

    Fix setup.py neuron-ls issue (#2671)

[33mcommit 120157fd2a256faf9e4d9941aa580c195735b878[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat Mar 16 13:35:27 2024 -0700

    Support arbitrary json_object in OpenAI and Context Free Grammar (#3211)

[33mcommit 8e67598aa6ea6ce37c4c8cb470412db0ea523573[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat Mar 16 00:36:29 2024 -0700

    [Misc] fix line length for entire codebase (#3444)

[33mcommit ad50bf4b25ba4344a560a7919fdc6ddb57c3d808[m
Author: simon-mo <simon.mo@hey.com>
Date:   Fri Mar 15 22:23:38 2024 -0700

    fix lint

[33mcommit cf6ff18246194c1197ce85028036a462ea9f9269[m
Author: Dinghow Yang <DinghowYang@gmail.com>
Date:   Sat Mar 16 12:02:12 2024 +0800

    Fix Baichuan chat template (#3340)

[33mcommit 14e3f9a1b2711336ca2e68235eb53bf1b49880c5[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Sat Mar 16 06:01:30 2024 +0200

    Replace `lstrip()` with `removeprefix()` to fix Ruff linter warning (#2958)

[33mcommit 3123f151387d2afa49eaf3130bcee3556f2e87d2[m
Author: Tao He <sighingnow@gmail.com>
Date:   Sat Mar 16 11:58:10 2024 +0800

    Fixes the incorrect argument in the prefix-prefill test cases (#3246)

[33mcommit 413366e9a2e66adf9280e7a700c3b0017eab856c[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Fri Mar 15 18:25:51 2024 -0700

    [Misc] PR templates (#3413)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 10585e035ec564cd376146c3fe5ffe427a43c92c[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Mar 15 19:35:36 2024 -0500

    Removed Extraneous Print Message From OAI Server (#3440)

[33mcommit fb96c1e98c05ffa35dd48416f68e88edb2f9eb34[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Mar 15 16:37:01 2024 -0700

    Asynchronous tokenization (#2879)

[33mcommit 8fa7357f2d3171e3d373be865c8f9520e538c415[m
Author: laneeee <55518470+laneeeee@users.noreply.github.com>
Date:   Sat Mar 16 07:06:09 2024 +0800

    fix document error for value and v_vec illustration (#3421)

[33mcommit a7af4538ca92b53537f7869122f89d6a8ea44f7f[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Fri Mar 15 21:26:00 2024 +0000

    Fix issue templates (#3436)

[33mcommit 604f235937684aa173afec96cca5b02e3b0bc154[m
Author: youkaichao <youkaichao@126.com>
Date:   Fri Mar 15 14:21:37 2024 -0700

    [Misc] add error message in non linux platform (#3438)

[33mcommit 14b8ae02e74aa7223a25cf914b61e0a76e3cad87[m
Author: Tao He <sighingnow@gmail.com>
Date:   Sat Mar 16 02:25:43 2024 +0800

    Fixes the misuse/mixuse of time.time()/time.monotonic() (#3220)
    
    Signed-off-by: Tao He <sighingnow@gmail.com>
    Co-authored-by: simon-mo <simon.mo@hey.com>

[33mcommit 03d37f24413b13a4e42ee115f89f647c441d1fcd[m
Author: Dan Clark <44146800+declark1@users.noreply.github.com>
Date:   Fri Mar 15 09:56:13 2024 -0700

    [Fix] Add args for mTLS support (#3430)
    
    Co-authored-by: declark1 <daniel.clark@ibm.com>

[33mcommit a7c871680e622d998c9a4585404b0b88bad9ba92[m
Author: Yang Fan <suyang.fy@alibaba-inc.com>
Date:   Sat Mar 16 00:36:53 2024 +0800

    Fix tie_word_embeddings for Qwen2. (#3344)

[33mcommit 429284dc374bab79d4dfbb25053583901e6e5051[m
Author: Junda Chen <32371474+GindaChen@users.noreply.github.com>
Date:   Thu Mar 14 23:25:05 2024 -0700

    Fix `dist.broadcast` stall without group argument (#3408)

[33mcommit 253a98078a21a014c263bea9f99ae9234a263670[m
Author: Dinghow Yang <DinghowYang@gmail.com>
Date:   Fri Mar 15 14:19:22 2024 +0800

    Add chat templates for ChatGLM (#3418)

[33mcommit 21539e68563ae61d2be311d8b8e656fa039f5a5c[m
Author: Dinghow Yang <DinghowYang@gmail.com>
Date:   Fri Mar 15 14:19:02 2024 +0800

    Add chat templates for Falcon (#3420)

[33mcommit b522c4476fcdaee254fe40fefb354a4908fccac5[m
Author: youkaichao <youkaichao@126.com>
Date:   Thu Mar 14 21:32:52 2024 -0700

    [Misc] add HOST_IP env var (#3419)
    
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 78b6c4845ac9aa57ccf7e42cf4c7d3c4cdef14cf[m
Author: akhoroshev <arthoroshev@gmail.com>
Date:   Fri Mar 15 04:18:07 2024 +0300

    Dynamically configure shared memory size for moe_align_block_size_kernel (#3376)

[33mcommit b983ba35bd29f6d385efff8bedf80f7989c28d12[m
Author: Enrique Shockwave <33002121+qeternity@users.noreply.github.com>
Date:   Thu Mar 14 23:26:19 2024 +0000

    fix marlin config repr (#3414)

[33mcommit 54be8a0be2819340ce7c2d7993382559597f5665[m
Author: ÈôàÂ∫è <chenxu2048@gmail.com>
Date:   Fri Mar 15 04:56:57 2024 +0800

    Fix assertion failure in Qwen 1.5 with prefix caching enabled (#3373)
    
    Co-authored-by: Cade Daniel <edacih@gmail.com>

[33mcommit dfc77408bdca19308cbb28a54dfe697442fbf335[m
Author: youkaichao <youkaichao@126.com>
Date:   Thu Mar 14 13:16:00 2024 -0700

    [issue templates] add some issue templates (#3412)

[33mcommit c17ca8ef186b5e90a500d3e37724b220944450f7[m
Author: Dan Clark <44146800+declark1@users.noreply.github.com>
Date:   Thu Mar 14 13:11:45 2024 -0700

    Add args for mTLS support (#3410)
    
    Co-authored-by: Daniel Clark <daniel.clark@ibm.com>

[33mcommit 06ec486794f42db656c3cc16c8c5ed56ce4f696b[m
Author: Thomas Parnell <tom.parnell@gmail.com>
Date:   Thu Mar 14 18:55:54 2024 +0100

    Install `flash_attn` in Docker image (#3396)

[33mcommit 8fe838659164b415d7f3044ec6b7e5bc52c6b6a5[m
Author: youkaichao <youkaichao@gmail.com>
Date:   Thu Mar 14 01:11:48 2024 -0700

    [Kernel] change benchmark script so that result can be directly used; tune moe kernel in A100/H100 with tp=2,4,8 (#3389)

[33mcommit a37415c31b3b5c7ab40d2d897192025f0ca7be08[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Thu Mar 14 14:35:13 2024 +0800

    allow user to chose which vllm's merics to display in grafana (#3393)

[33mcommit 81653d968842d2ec51b2642b6b5d83786271f9af[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Mar 13 17:02:21 2024 -0700

    [Hotfix] [Debug] test_openai_server.py::test_guided_regex_completion (#3383)

[33mcommit eeab52a4ff02e15f970880a689df2861ad173770[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Mar 13 14:18:40 2024 -0700

    [FIX] Simpler fix for async engine running on ray (#3371)

[33mcommit c33afd89f56ba5c260275fdd6723c59642f82f22[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Mar 13 13:56:49 2024 -0700

    Fix lint (#3388)

[33mcommit 7e9bd08f60a4b18e3646ff986caeacde9ffffa53[m
Author: Terry <149540247+tterrysun@users.noreply.github.com>
Date:   Wed Mar 13 13:45:26 2024 -0700

    Add batched RoPE kernel (#3095)

[33mcommit ae0ccb40170d140ded8de99fc905fd8cb0bd409c[m
Author: Or Sharir <or+github@sharir.org>
Date:   Wed Mar 13 21:18:25 2024 +0200

    Add missing kernel for CodeLlama-34B on A/H100 (no tensor parallelism) when using Multi-LoRA. (#3350)

[33mcommit 739c350c1926682f435316294491aa54661849b6[m
Author: ÈôàÂ∫è <chenxu2048@gmail.com>
Date:   Thu Mar 14 00:43:24 2024 +0800

    [Minor Fix] Use cupy-cuda11x in CUDA 11.8 build (#3256)

[33mcommit ba8dc958a3d8533a6e5b7debda47e4d42a062b78[m
Author: Hui Liu <96135754+hliuca@users.noreply.github.com>
Date:   Wed Mar 13 09:16:55 2024 -0700

    [Minor] Fix bias in if to remove ambiguity (#3259)

[33mcommit e221910e77087743a50560e4ae69c3c2a12beb53[m
Author: Ronan McGovern <78278410+RonanKMcGovern@users.noreply.github.com>
Date:   Wed Mar 13 06:33:43 2024 +0000

    add hf_transfer to requirements.txt (#3031)

[33mcommit b167109ba12f18d028d2be8a61d3dce950eb2724[m
Author: Bo-Wen Wang <1849994161@qq.com>
Date:   Wed Mar 13 13:51:42 2024 +0800

    [Fix] Fix quantization="gptq" when using Marlin (#3319)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 602358f8a86ef9fc0ba882e083e19b44e00b9302[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Mar 12 22:06:17 2024 -0700

    Add kernel for GeGLU with approximate GELU (#3337)

[33mcommit 49a3c8662ba745503890ab8b3c502aad7e1a0a19[m
Author: Breno Faria <breno@veltefaria.de>
Date:   Wed Mar 13 01:30:08 2024 +0100

    Fixes #1556 double free (#3347)

[33mcommit b0925b38789bb3b20dcc39e229fcfe12a311e487[m
Author: Sherlock Xu <65327072+Sherlock113@users.noreply.github.com>
Date:   Wed Mar 13 01:34:30 2024 +0800

    docs: Add BentoML deployment doc (#3336)
    
    Signed-off-by: Sherlock113 <sherlockxu07@gmail.com>

[33mcommit 654865e21df8ac6fe95de926625306e5756c2c0d[m
Author: DAIZHENWEI <32122197+DAIZHENWEI@users.noreply.github.com>
Date:   Mon Mar 11 13:19:51 2024 -0700

    Support Mistral Model Inference with transformers-neuronx (#3153)

[33mcommit c9415c19d3df26d8ede611abefba35c6837cd934[m
Author: kliuae <17350011+kliuae@users.noreply.github.com>
Date:   Tue Mar 12 04:14:07 2024 +0800

    [ROCm] Fix warp and lane calculation in blockReduceSum (#3321)

[33mcommit 4c922709b65ff5c0652ae36b93047016bdeaace8[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Mar 11 11:03:45 2024 -0700

    Add distributed model executor abstraction (#3191)

[33mcommit 657061fdced8a33a60c1b09f5da2525de9da8f03[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Mon Mar 11 00:54:51 2024 -0700

    [docs] Add LoRA support information for models (#3299)

[33mcommit 2f8844ba08d77af8a64784317055b03a475f6051[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Mar 10 19:49:14 2024 -0700

    Re-enable the 80 char line width limit (#3305)

[33mcommit 4b59f00e917679337169c88c981f268e6ab96cd6[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sun Mar 10 19:17:46 2024 -0700

    [Fix] Fix best_of behavior when n=1 (#3298)

[33mcommit 9e8744a545f34ca636a5113ae98cec5851af56eb[m
Author: Roy <jasonailu87@gmail.com>
Date:   Mon Mar 11 10:17:16 2024 +0800

    [BugFix] Fix get tokenizer when using ray (#3301)

[33mcommit e4a28e53165902ffc5daf20977c70885d0c05768[m
Author: Douglas Lehr <91553416+dllehr-amd@users.noreply.github.com>
Date:   Sun Mar 10 17:27:45 2024 -0500

    [ROCM] Fix blockReduceSum to use correct warp counts for ROCm and CUDA (#3262)

[33mcommit 0bba88df03754c40bd9135fc2ff9554ffca59c87[m
Author: Terry <149540247+tterrysun@users.noreply.github.com>
Date:   Sat Mar 9 17:14:16 2024 -0800

    Enhance lora tests with more layer and rank variations (#3243)

[33mcommit 8437bae6ef47a690d18c72f0da02c7e5abe83866[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Fri Mar 8 23:32:46 2024 -0800

    [Speculative decoding 3/9] Worker which speculates, scores, and applies rejection sampling (#3103)

[33mcommit f48c6791b7bfc2579ad575d33ed83912f0bfb011[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Fri Mar 8 17:16:14 2024 -0800

    [FIX] Fix prefix test error on main (#3286)

[33mcommit c2c5e0909ad4457ad542117939c2629ebe2db609[m
Author: Michael Goin <mgoin64@gmail.com>
Date:   Fri Mar 8 13:33:10 2024 -0800

    Move model filelocks from `/tmp/` to `~/.cache/vllm/locks/` dir (#3241)

[33mcommit 1cb0cc2975d1c42c445c795f955b783e78919502[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Mar 8 10:52:20 2024 -0800

    [FIX] Make `flash_attn` optional (#3269)

[33mcommit 99c3cfb83c20d45899ab8cbfdddce98c7cffb7b1[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Fri Mar 8 09:58:01 2024 -0800

    [Docs] Fix Unmocked Imports (#3275)

[33mcommit 1ece1ae829dcbc4b1b19b3e2d3042457615e862f[m
Author: TianYu GUO <guoty9@mail2.sysu.edu.cn>
Date:   Fri Mar 8 14:22:59 2024 +0800

    [Minor Fix] Fix comments in benchmark_serving (#3252)

[33mcommit c59e120c557743b0fc8178ee1796c8a3def78bf4[m
Author: whyiug <whyiug@hotmail.com>
Date:   Fri Mar 8 13:58:24 2024 +0800

    Feature add lora support for Qwen2 (#3177)

[33mcommit d2339d6840498397f6e373489ed120cd2cce8eb4[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Mar 7 16:38:12 2024 -0800

    Connect engine healthcheck to openai server (#3260)

[33mcommit b35cc93420e37b72dc1c4bbedb06012fd294b743[m
Author: ElizaWszola <eliza@neuralmagic.com>
Date:   Fri Mar 8 01:37:28 2024 +0100

    Fix auto prefix bug (#3239)

[33mcommit 8cbba4622c8c526b207b17e3ba51e18e2c766419[m
Author: jacobthebanana <50071502+jacobthebanana@users.noreply.github.com>
Date:   Thu Mar 7 18:03:22 2024 -0500

    Possible fix for conflict between Automated Prefix Caching (#2762) and multi-LoRA support (#1804) (#3263)

[33mcommit 385da2dae2b90e5273da8dfce881727bd9c574a1[m
Author: Michael Goin <mgoin64@gmail.com>
Date:   Thu Mar 7 11:42:42 2024 -0800

    Measure model memory usage (#3120)

[33mcommit 2daf23ab0cf00da157b1255faddcf0a269283d36[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Mar 7 01:45:50 2024 -0800

    Separate attention backends (#3005)

[33mcommit cbf4c05b156c8705c6bb1a94b9edc0a5b4d26e20[m
Author: Chen Wang <Chen.Wang1@ibm.com>
Date:   Thu Mar 7 03:39:28 2024 -0500

    Update requirements-dev.txt to include package for benchmarking scripts. (#3181)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit d3c04b6a39df016504c28ec3fc27ea58ca802a28[m
Author: TechxGenus <jianghao0728@mail.ustc.edu.cn>
Date:   Thu Mar 7 08:19:14 2024 +0800

    Add GPTQ support for Gemma (#3200)

[33mcommit 4cb3b924cdeb6b809f0a0311f9833253d9162699[m
Author: Chujie Zheng <chujiezhengchn@gmail.com>
Date:   Wed Mar 6 14:41:42 2024 -0800

    Add tqdm `dynamic_ncols=True` (#3242)

[33mcommit a33ce60c6629e8c22aaf002ae8478a685e726e3e[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Wed Mar 6 01:04:23 2024 -0800

    [Testing] Fix core tests (#3224)

[33mcommit 24aecf421a4ad5989697010963074904fead9a1b[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Wed Mar 6 11:23:34 2024 +0900

    [Tests] Add block manager and scheduler tests (#3108)

[33mcommit 2efce05dc3c7c1e367617465f8f661a058499e37[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Mar 5 16:17:20 2024 -0800

    [Fix] Avoid pickling entire LLMEngine for Ray workers (#3207)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit 8999ec3c1632c91c194ab27df6bf274f5bcb0b5f[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Tue Mar 5 15:35:43 2024 -0800

    Store `eos_token_id` in `Sequence` for easy access (#3166)

[33mcommit 05af6da8d927f70d15ab1ed25b01df3c967ad961[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Mon Mar 4 21:14:53 2024 -0500

    [ROCm] enable cupy in order to enable  cudagraph mode for AMD GPUs (#3123)
    
    Co-authored-by: lcskrishna <lollachaitanya@gmail.com>

[33mcommit 9a4548bae73a8831f668116d8a6e88491d933a4e[m
Author: Chen Wang <Chen.Wang1@ibm.com>
Date:   Mon Mar 4 18:51:56 2024 -0500

    Fix the openai benchmarking requests to work with latest OpenAI apis (#2992)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit ff578cae54d23812b53b6c9b94b8bd0bb293a1fe[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Mar 4 14:01:40 2024 -0800

    Add health check, make async Engine more robust (#3015)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 22de45235c6dd14e901e089971635ec655d5fbe0[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Mar 4 11:54:06 2024 -0800

    Push logprob generation to LLMEngine (#3065)
    
    Co-authored-by: Avnish Narayan <avnish@anyscale.com>

[33mcommit 76e8a70476ef9daa970349c14c117fe91e8b4544[m
Author: ttbachyinsda <ttbachyinsda@outlook.com>
Date:   Tue Mar 5 03:17:12 2024 +0800

    [Minor fix] The domain dns.google may cause a socket.gaierror exception (#3176)
    
    Co-authored-by: guofangze <guofangze@kuaishou.com>

[33mcommit 9cbc7e5f3be72552d6041f81738921a9597643e8[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Tue Mar 5 02:37:58 2024 +0800

    enable --gpu-memory-utilization in benchmark_throughput.py (#3175)
    
    Co-authored-by: zixiao <shunli.dsl@alibaba-inc.com>

[33mcommit 27a7b070db526326ede3335fb07c1fa13ac008bb[m
Author: Jialun Lyu <43287111+pian13131@users.noreply.github.com>
Date:   Mon Mar 4 09:23:34 2024 -0800

    Add document for vllm paged attention kernel. (#2978)

[33mcommit 901cf4c52bf65472ca13aa4f996d631d00c2228d[m
Author: TianYu GUO <guoty9@mail2.sysu.edu.cn>
Date:   Mon Mar 4 14:48:27 2024 +0800

    [Minor Fix] Remove unused code in benchmark_prefix_caching.py (#3171)

[33mcommit d0fae881143f07a558ea72b2cae3c4c6dfa94937[m
Author: Liangfu Chen <liangfc@amazon.com>
Date:   Sun Mar 3 17:03:51 2024 -0800

    [DOC] add setup document to support neuron backend (#2777)

[33mcommit 17c3103c562e748686a3fa4bd9b43ebe98aae3d9[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Sun Mar 3 16:19:13 2024 -0800

    Make it easy to profile workers with nsight (#3162)
    
    Co-authored-by: Roger Wang <136131678+ywang96@users.noreply.github.com>

[33mcommit 996d095c541e1cd67f0a7ec2579bc3bb0a435494[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Mar 3 14:37:18 2024 -0800

    [FIX] Fix styles in automatic prefix caching & add a automatic prefix caching benchmark (#3158)

[33mcommit d65fac2738f0287a41955b45df76a2d5a919bff6[m
Author: Jason Cox <jason@jasonacox.com>
Date:   Sun Mar 3 00:00:29 2024 -0500

    Add vLLM version info to logs and openai API server (#3161)

[33mcommit ce4f5a29fb3e35041842518fefe999847b8326b9[m
Author: Sage Moore <sagemoore@utexas.edu>
Date:   Sat Mar 2 03:50:01 2024 -0500

    Add Automatic Prefix Caching (#2762)
    
    Co-authored-by: ElizaWszola <eliza@neuralmagic.com>
    Co-authored-by: Michael Goin <michael@neuralmagic.com>

[33mcommit baee28c46c242b72f90d6b1211ab9d7872ab05d3[m
Author: cloudhan <cloudhan@outlook.com>
Date:   Sat Mar 2 14:34:48 2024 +0800

    Reorder kv dtype check to avoid nvcc not found error on AMD platform (#3104)

[33mcommit 29e70e3e88698feca9509cf07fcf06b12163f1c3[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Sat Mar 2 07:28:41 2024 +0800

    allow user chose log level by --log-level instead of fixed 'info'. (#3109)
    
    Co-authored-by: zixiao <shunli.dsl@alibaba-inc.com>
    Co-authored-by: Simon Mo <simon.mo@hey.com>

[33mcommit 82091b864af105dbe373353655dc9d8c0a6ba66f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Mar 1 12:58:06 2024 -0800

    Bump up to v0.3.3 (#3129)

[33mcommit c0c2335ce027486d254c31f665ce00d7db427d22[m
Author: Robert Shaw <114415538+robertgshaw2-neuralmagic@users.noreply.github.com>
Date:   Fri Mar 1 14:47:51 2024 -0600

    Integrate Marlin Kernels for Int4 GPTQ inference (#2497)
    
    Co-authored-by: Robert Shaw <114415538+rib-2@users.noreply.github.com>
    Co-authored-by: alexm <alexm@neuralmagic.com>

[33mcommit 90fbf12540da089fcc7dc825ce2ceb7ea3a3df33[m
Author: Huarong <huohuarong@gmail.com>
Date:   Sat Mar 2 03:42:06 2024 +0800

    fix relative import path of protocol.py (#3134)
    
    Co-authored-by: huohuarong <huohuarong@zuoshouyisheng.com>

[33mcommit 49d849b3ab7aa6ae493ccde1d85d226833f73fbb[m
Author: Yuan Tang <terrytangyuan@gmail.com>
Date:   Fri Mar 1 14:04:14 2024 -0500

    docs: Add tutorial on deploying vLLM model with KServe (#2586)
    
    Signed-off-by: Yuan Tang <terrytangyuan@gmail.com>

[33mcommit 27ca23dc002e06eade014ac6b801dc2dcbea40f3[m
Author: Seonghyeon <seonghyeon.drew@gmail.com>
Date:   Sat Mar 2 02:59:06 2024 +0900

    Remove exclude_unset in streaming response (#3143)

[33mcommit 54d3544784ff20e7038abf72793eaf734e727269[m
Author: Sherry <503147114@qq.com>
Date:   Fri Mar 1 15:52:22 2024 +0800

    Fix: Output text is always truncated in some models (#3016)

[33mcommit 703e42ee4b3efed3c71e7ae7d15f0f96e05722d4[m
Author: felixzhu555 <79335195+felixzhu555@users.noreply.github.com>
Date:   Thu Feb 29 14:13:08 2024 -0800

    Add guided decoding for OpenAI API server (#2819)
    
    Co-authored-by: br3no <breno@veltefaria.de>
    Co-authored-by: simon-mo <simon.mo@hey.com>

[33mcommit 29a8d6a554a87292f05b62078976b43a899691e3[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Thu Feb 29 11:20:42 2024 -0800

    [Fix] Don't deep-copy LogitsProcessors when copying SamplingParams (#3099)

[33mcommit 2c08ff23c07f2f8d51da8e1783c5346dccc1fd12[m
Author: Billy Cao <aliencaocao@gmail.com>
Date:   Fri Mar 1 03:13:58 2024 +0800

    Fix building from source on WSL (#3112)

[33mcommit bfdcfa6a053c693800551bd1bd71acabbe1941e8[m
Author: Seonghyeon <seonghyeon.drew@gmail.com>
Date:   Thu Feb 29 17:51:48 2024 +0900

    Support starcoder2 architecture (#3089)

[33mcommit 9289e577ec185bd9feb2c03bb86b82f1bf9bb633[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Thu Feb 29 14:15:18 2024 +0800

    add cache_config's info to prometheus metrics. (#3100)

[33mcommit a6d471c75939b2f4708a4e1cb1aa3b7b993ee54b[m
Author: Jae-Won Chung <jwnchung@umich.edu>
Date:   Thu Feb 29 01:04:07 2024 -0500

    Fix: `AttributeError` in OpenAI-compatible server (#3018)

[33mcommit 01a5d18a537b65a156cfa1a77706693a24c869c1[m
Author: CHU Tianxiang <tianxiang.ctx@alibaba-inc.com>
Date:   Thu Feb 29 13:52:23 2024 +0800

    Add Support for 2/3/8-bit GPTQ Quantization Models (#2330)

[33mcommit 929b4f2973ec6a53ea4f0f03d21147ef8b8278be[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 28 13:03:28 2024 -0800

    Add LoRA support for Gemma (#3050)

[33mcommit 3b7178cfa4a317922d4aef9dd3b2647b8d950e7d[m
Author: Liangfu Chen <liangfc@amazon.com>
Date:   Wed Feb 28 09:34:34 2024 -0800

    [Neuron] Support inference with transformers-neuronx (#2569)

[33mcommit e46fa5d52e02ee48d5fdd12b35e39993008b4bd6[m
Author: Allen.Dou <allen.dou@hotmail.com>
Date:   Wed Feb 28 13:38:26 2024 +0800

    Restrict prometheus_client >= 0.18.0 to prevent errors when importing pkgs (#3070)

[33mcommit a8683102cc0ab9c1a0c3ae1ba2b7954f78eba1b3[m
Author: Ganesh Jagadeesan <ganesh.jcs@gmail.com>
Date:   Wed Feb 28 00:26:15 2024 -0500

    multi-lora documentation fix (#3064)

[33mcommit 71bcaf99e2cb2c677bf3a9addb9e8039cbcab22a[m
Author: Tao He <sighingnow@gmail.com>
Date:   Tue Feb 27 17:14:31 2024 +0800

    Enable GQA support in the prefix prefill kernels (#3007)
    
    Signed-off-by: Tao He <sighingnow@gmail.com>

[33mcommit 8b430d7dea5695324636fc458c1cce52213bd499[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 26 20:23:50 2024 -0800

    [Minor] Fix StableLMEpochForCausalLM -> StableLmForCausalLM (#3046)

[33mcommit e0ade06d6305cf84b41c1962cdd9dfdbfee16ac9[m
Author: Dylan Hawk <51147702+dylanwhawk@users.noreply.github.com>
Date:   Mon Feb 26 19:51:53 2024 -0800

    Support logit bias for OpenAI API (#3027)

[33mcommit 4bd18ec0c719d2910040e22fa60503fdbfce1332[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 26 19:44:29 2024 -0800

    [Minor] Fix type annotation in fused moe (#3045)

[33mcommit 2410e320b35cd704059b7c6ba8d8ba7643fe46ee[m
Author: Jingru <niejingru@hotmail.com>
Date:   Tue Feb 27 11:22:16 2024 +0800

    fix `get_ip` error in pure ipv6 environment (#2931)

[33mcommit 48a8f4a7fd18d516ffc0a304219ef722613ea792[m
Author: Âº†Â§ßÊàê <1345739055@qq.com>
Date:   Tue Feb 27 11:17:06 2024 +0800

    Support Orion model (#2539)
    
    Co-authored-by: zhangdacheng <zhangdacheng@ainirobot.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 4dd6416faf7cc3035ac3f5c8375eb27e6b0eee80[m
Author: Roy <jasonailu87@gmail.com>
Date:   Tue Feb 27 10:31:10 2024 +0800

    Fix stablelm (#3038)

[33mcommit c1c0d00b88320f97e00a3175fac235a232893da5[m
Author: Roy <jasonailu87@gmail.com>
Date:   Tue Feb 27 09:33:38 2024 +0800

    Don't use cupy when `enforce_eager=True` (#3037)

[33mcommit d9f726c4d0920e705069c005fb3b1042368961ae[m
Author: Roy <jasonailu87@gmail.com>
Date:   Tue Feb 27 09:25:22 2024 +0800

    [Minor] Remove unused config files (#3039)

[33mcommit d6e4a130b028f42a7f413d99eb91a4395fa7a04a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 26 15:00:54 2024 -0800

    [Minor] Remove gather_cached_kv kernel (#3043)

[33mcommit cfc15a1031ef0197a1b291d2ed93717a9bdad268[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Mon Feb 26 13:48:56 2024 -0800

    Optimize Triton MoE Kernel (#2979)
    
    Co-authored-by: Cade Daniel <edacih@gmail.com>

[33mcommit 70f3e8e3a1ed081003c0a2b70de151bb144f98e0[m
Author: Jared Moore <27744679+jlcmoore@users.noreply.github.com>
Date:   Sun Feb 25 18:39:34 2024 -0800

    Add LogProbs for Chat Completions in OpenAI (#2918)

[33mcommit ef978fe4111b0eb91c81eceba4d9791b94c7ffbf[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Sun Feb 25 19:54:00 2024 +0000

    Port metrics from `aioprometheus` to `prometheus_client` (#2730)

[33mcommit f7c1234990793008f3d44790fd274040f26c4ee4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 23 12:57:48 2024 -0800

    [Fix] Fissertion on YaRN model len (#2984)

[33mcommit 57f044945f25d90d1b434014b2719ba6b06fdc44[m
Author: zhaoyang-star <zhaoyangstar@foxmail.com>
Date:   Fri Feb 23 06:25:07 2024 +0800

    Fix nvcc not found in vlm-openai image (#2781)

[33mcommit 4caf7044e052399f07089aa8f586d5bd641f7d53[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Fri Feb 23 00:00:12 2024 +0200

    Include tokens from prompt phase in `counter_generation_tokens` (#2802)

[33mcommit 6f32cddf1c795e74a47e84620462431154718f49[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 22 09:58:29 2024 -0800

    Remove Flash Attention in test env (#2982)

[33mcommit c530e2cfe3b3d7e60130ff817cee7f3a395af232[m
Author: 44670 <44670@users.noreply.github.com>
Date:   Thu Feb 22 17:40:05 2024 +0800

    [FIX] Fix a bug in initializing Yarn RoPE (#2983)

[33mcommit fd5dcc5c816b7392821d3d4c02b13a7cf820d962[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 21 20:17:52 2024 -0800

    Optimize GeGLU layer in Gemma (#2975)

[33mcommit 93dc5a287086299a124e9f1f6fac75458ae0acbd[m
Author: Massimiliano Pronesti <massimiliano.pronesti@gmail.com>
Date:   Thu Feb 22 02:56:01 2024 +0000

    chore(vllm): codespell for spell checking  (#2820)

[33mcommit 95529e32537287831cddd800280a20d7c2417163[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 21 18:28:23 2024 -0800

    Use Llama RMSNorm custom op for Gemma (#2974)

[33mcommit 344020c926ad19d9d147f5ab6b8929669296edcb[m
Author: Roy <jasonailu87@gmail.com>
Date:   Thu Feb 22 10:25:05 2024 +0800

    Migrate MistralForCausalLM to LlamaForCausalLM (#2868)

[33mcommit 5574081c49c9a5ac51662981aff80250119a97bd[m
Author: Mustafa Eyceoz <maxusmusti@gmail.com>
Date:   Wed Feb 21 21:24:01 2024 -0500

    Added early stopping to completion APIs (#2939)

[33mcommit d7f396486e3e9b4dd31020c81c6eb446593b586d[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Thu Feb 22 04:18:37 2024 +0200

    Update comment (#2934)

[33mcommit 8fbd84bf7839d53e6dd26a1dd4473dd1a99aab6e[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Feb 21 11:47:25 2024 -0800

    Bump up version to v0.3.2 (#2968)
    
    This version is for more model support. Add support for Gemma models (#2964) and OLMo models (#2832).

[33mcommit 7d2dcce175cec00bc1d127d6b3a5f1ef73a6ba3c[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Wed Feb 21 11:47:00 2024 -0800

    Support per-request seed (#2514)

[33mcommit dc903e70acf9dba74d6afaa50e7b5650d6b9338a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 21 09:46:57 2024 -0800

    [ROCm] Upgrade transformers to v4.38.0 (#2967)

[33mcommit a9c821289582747c57f149017678a282f5e788e4[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Feb 21 09:46:15 2024 -0800

    [FIX] Add Gemma model to the doc (#2966)

[33mcommit c20ecb6a51cb58d408eb5ae7b03ac76c7b83e609[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 21 09:38:03 2024 -0800

    Upgrade transformers to v4.38.0 (#2965)

[33mcommit 5253edaacb3d023fad83d0549d525dd404ff1a26[m
Author: Xiang Xu <117880274+xiangxu-google@users.noreply.github.com>
Date:   Wed Feb 21 09:34:30 2024 -0800

    Add Gemma model (#2964)

[33mcommit 017d9f15151ce571a5f4fd381699c72a872636ec[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Feb 20 21:55:57 2024 -0800

    Add metrics to RequestOutput (#2876)

[33mcommit 181b27d8813e6a92de4f38cecfa24914e652588a[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Feb 20 14:38:55 2024 -0800

    Make vLLM logging formatting optional (#2877)

[33mcommit 63e2a6419dc5863311a11d1d2a95cda9fc8ef7e5[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Feb 20 14:37:39 2024 -0800

    [FIX] Fix beam search test (#2930)

[33mcommit 264017a2bf030f060ebad91eb9be9b4e0033edb9[m
Author: James Whedbee <jamestwhedbee@gmail.com>
Date:   Mon Feb 19 19:58:59 2024 -0600

    [ROCm] include gfx908 as supported (#2792)

[33mcommit e433c115bce2bf27f7b1abdde7029566007d9eee[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Mon Feb 19 09:55:41 2024 +0200

    Fix `vllm:prompt_tokens_total` metric calculation (#2869)

[33mcommit 86fd8bb0ac9a836e55b5075d8416bd067af9e7b2[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Feb 18 21:36:19 2024 -0800

    Add warning to prevent changes to benchmark api server (#2858)

[33mcommit ab3a5a8259922ce312d01be39d29e27666968039[m
Author: Isotr0py <41363108+Isotr0py@users.noreply.github.com>
Date:   Mon Feb 19 13:05:15 2024 +0800

    Support OLMo models. (#2832)

[33mcommit a61f0521b8d0d53a91951bb56789ead397d5cd83[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Feb 18 16:44:50 2024 -0800

    [Test] Add basic correctness test (#2908)

[33mcommit 537c9755a736b4e206107a99e1c8961448a3d63b[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Feb 18 14:39:00 2024 -0800

    [Minor] Small fix to make distributed init logic in worker looks cleaner (#2905)

[33mcommit 786b7f18a541a0460a9ee56154558ac7121601ac[m
Author: Mark Mozolewski <57800471+mbm-ai@users.noreply.github.com>
Date:   Sat Feb 17 22:36:53 2024 -0800

    Add code-revision config argument for Hugging Face Hub (#2892)

[33mcommit 8f36444c4f9a55669bcb64e20b5588c0dd72bd93[m
Author: jvmncs <jvmncs@gmail.com>
Date:   Sat Feb 17 15:00:48 2024 -0500

    multi-LoRA as extra models in OpenAI server (#2775)
    
    how to serve the loras (mimicking the [multilora inference example](https://github.com/vllm-project/vllm/blob/main/examples/multilora_inference.py)):
    ```terminal
    $ export LORA_PATH=~/.cache/huggingface/hub/models--yard1--llama-2-7b-sql-lora-test/
    $ python -m vllm.entrypoints.api_server \
     --model meta-llama/Llama-2-7b-hf \
     --enable-lora \
     --lora-modules sql-lora=$LORA_PATH sql-lora2=$LORA_PATH
    ```
    the above server will list 3 separate values if the user queries `/models`: one for the base served model, and one each for the specified lora modules. in this case sql-lora and sql-lora2 point to the same underlying lora, but this need not be the case. lora config values take the same values they do in EngineArgs
    
    no work has been done here to scope client permissions to specific models

[33mcommit 185b2c29e241c864c9660ef0b69b5076a370f55e[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sat Feb 17 11:18:04 2024 -0800

    Defensively copy `sampling_params` (#2881)
    
    If the SamplingParams object passed to LLMEngine.add_request() is mutated after it returns, it could affect the async sampling process for that request.
    
    Suggested by @Yard1 https://github.com/vllm-project/vllm/pull/2514#discussion_r1490106059

[33mcommit 5f08050d8d0bfcdaced0fe706cdfc9e311e0f263[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 16 15:05:18 2024 -0800

    Bump up to v0.3.1 (#2887)

[33mcommit 64da65b3225b7a2e6c2b161b726dc9751f973f33[m
Author: shiyi.c_98 <shicao@berkeley.edu>
Date:   Fri Feb 16 14:17:55 2024 -0800

    Prefix Caching- fix t4 triton error (#2517)

[33mcommit 5255d99dc595f9ae7647842242d6542aa4145a4f[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Thu Feb 15 13:22:39 2024 -0500

    [ROCm] Dockerfile fix for flash-attention build (#2885)

[33mcommit 4f2ad1113553211778640c648e11f5aa2e03dbd4[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Wed Feb 14 22:29:57 2024 -0800

    Fix DeciLM (#2883)

[33mcommit d7afab6d3af84c18ecb9cbc478842e3bf62af906[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 14 22:17:44 2024 -0800

    [BugFix] Fix GC bug for `LLM` class (#2882)

[33mcommit 31348dff03d638eb66abda9bec94b8992de9c7a1[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Wed Feb 14 16:00:43 2024 -0800

    Align LoRA code between Mistral and Mixtral (fixes #2875) (#2880)
    
    * Fix AttributeError: MixtralModel object has no attribute org_vocab_size.
    
    * Make LoRA logic for Mistral and Mixtral the same
    
    ---------
    
    Co-authored-by: Pernekhan Utemuratov <pernekhan@deepinfra.com>

[33mcommit 25e86b6a616638cea9ce121a6c28c7b1d69615e7[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 14 12:30:44 2024 -0800

    Don't use cupy NCCL for AMD backends (#2855)

[33mcommit 4efbac6d3593ed35fd5b6ccb3958bd96b2c9b4da[m
Author: Roy <jasonailu87@gmail.com>
Date:   Thu Feb 15 04:30:24 2024 +0800

    Migrate AquilaForCausalLM to LlamaForCausalLM (#2867)

[33mcommit 87069ccf68c1bd74aec5ff58db360977f0d9d757[m
Author: Nikola Borisov <nikola.borisof@gmail.com>
Date:   Wed Feb 14 10:17:57 2024 -0800

    Fix docker python version (#2845)

[33mcommit 7e45107f51bcb38c22dd9916c61226078e8eb26d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 13 19:52:34 2024 -0800

    [Fix] Fix memory profiling when GPU is used by multiple processes (#2863)

[33mcommit 0c48b37c310254e83cd2906230e87af97cb148ba[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Tue Feb 13 18:01:15 2024 -0800

    Fix internlm after https://github.com/vllm-project/vllm/pull/2860 (#2861)

[33mcommit 7eacffd9512c29bfcce0963b5a19da0cd66cc22f[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Tue Feb 13 17:12:05 2024 -0800

    Migrate InternLMForCausalLM to LlamaForCausalLM (#2860)
    
    Co-authored-by: Roy <jasonailu87@gmail.com>

[33mcommit 2a543d6efecc4e0fe391cbccb68d99ab42e37c33[m
Author: Terry <149540247+tterrysun@users.noreply.github.com>
Date:   Tue Feb 13 15:55:45 2024 -0800

    Add LoRA support for Mixtral (#2831)
    
    * add mixtral lora support
    
    * formatting
    
    * fix incorrectly ported logic
    
    * polish tests
    
    * minor fixes and refactoring
    
    * minor fixes
    
    * formatting
    
    * rename and remove redundant logic
    
    * refactoring
    
    * refactoring
    
    * minor fix
    
    * minor refactoring
    
    * fix code smell

[33mcommit 317b29de0f16428610e2e4d6a6953bee5a2d0ec2[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Tue Feb 13 14:22:22 2024 -0800

    Remove Yi model definition, please use `LlamaForCausalLM` instead (#2854)
    
    Co-authored-by: Roy <jasonailu87@gmail.com>

[33mcommit a463c333dd7905519141abe4f61b63ccc6b739a9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 13 11:32:06 2024 -0800

    Use CuPy for CUDA graphs (#2811)

[33mcommit ea356004d4749627bd1c65b7f71c76f51b5c45be[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Tue Feb 13 09:24:59 2024 -0800

    Revert "Refactor llama family models (#2637)" (#2851)
    
    This reverts commit 5c976a7e1a1bec875bf6474824b7dff39e38de18.

[33mcommit 5c976a7e1a1bec875bf6474824b7dff39e38de18[m
Author: Roy <jasonailu87@gmail.com>
Date:   Tue Feb 13 16:09:23 2024 +0800

    Refactor llama family models (#2637)

[33mcommit f964493274c3c839b2e27453cb70f179090cd027[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Feb 12 22:53:07 2024 -0800

    [CI] Ensure documentation build is checked in CI (#2842)

[33mcommit a4211a4dc3a83d9e58eb7ee2f015aa033159c267[m
Author: Roger Wang <136131678+ywang96@users.noreply.github.com>
Date:   Mon Feb 12 22:53:00 2024 -0800

    Serving Benchmark Refactoring (#2433)

[33mcommit 563836496abc0914c212b693130f80be25926564[m
Author: Rex <zcnrex@gmail.com>
Date:   Mon Feb 12 11:02:17 2024 -0800

    Refactor 2 awq gemm kernels into m16nXk32 (#2723)
    
    Co-authored-by: Chunan Zeng <chunanzeng@Chunans-Air.attlocal.net>

[33mcommit 4ca2c358b178d5e026db925a1ed9f8945010a98f[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Mon Feb 12 08:24:45 2024 -0800

    Add documentation section about LoRA (#2834)

[33mcommit 0580aab02ffe60fee50bddc80b787828eb233c44[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Sun Feb 11 02:14:37 2024 -0500

    [ROCm] support Radeon‚Ñ¢ 7900 series (gfx1100) without using flash-attention (#2768)

[33mcommit 3711811b1d2956e83e626c72f0e1607f2dfbc8fb[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 8 09:58:03 2024 -0800

    Disable custom all reduce by default (#2808)

[33mcommit 65b89d16ee54063d0737e3da1b15e2177916118d[m
Author: SangBin Cho <rkooo567@gmail.com>
Date:   Fri Feb 9 02:57:25 2024 +0900

    [Ray] Integration compiled DAG off by default (#2471)

[33mcommit 931746bc6d7c1c0ab40b2c4f58b51b855f0b2c94[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Wed Feb 7 14:42:02 2024 -0800

    Add documentation on how to do incremental builds (#2796)

[33mcommit c81dddb45c71e630b907f9d84686ecd73b4105c7[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Wed Feb 7 01:36:59 2024 -0500

    [ROCm] Fix build problem resulted from previous commit related to FP8 kv-cache support  (#2790)

[33mcommit fe6d09ae61f2281417e35f53a948b6fa898a4eba[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Tue Feb 6 11:38:38 2024 -0800

    [Minor] More fix of test_cache.py CI test failure (#2750)

[33mcommit ed70c70ea3569670499717f06d117ed25ec32af4[m
Author: liuyhwangyh <liuyhwangyh@163.com>
Date:   Wed Feb 7 01:57:15 2024 +0800

    modelscope: fix issue when model parameter is not a model id but path of the model. (#2489)

[33mcommit f0d4e145575bf6fb96c141d776ce92c9bfc79c49[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 5 17:38:02 2024 -0800

    Add fused top-K softmax kernel for MoE (#2769)

[33mcommit 2ccee3def6d8532afaf6fcd351b228ec1dfd6013[m
Author: Douglas Lehr <91553416+dllehr-amd@users.noreply.github.com>
Date:   Mon Feb 5 16:59:09 2024 -0600

    [ROCm] Fixup arch checks for ROCM (#2627)

[33mcommit b92adec8e88f5b69384189faae17b48b5980cba3[m
Author: Lukas <52111220+gardberg@users.noreply.github.com>
Date:   Mon Feb 5 23:26:50 2024 +0100

    Set local logging level via env variable (#2774)

[33mcommit 56f738ae9b631189e67795b397258afbed59b042[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Mon Feb 5 17:25:36 2024 -0500

    [ROCm] Fix some kernels failed unit tests (#2498)

[33mcommit 72d3a30c6327e70de3595d00f04e2d577fcbbb68[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 5 12:45:37 2024 -0800

    [Minor] Fix benchmark_latency script (#2765)

[33mcommit c9b45adeeb0e5b2f597d1687e0b8f24167602395[m
Author: whyiug <whyiug@hotmail.com>
Date:   Mon Feb 5 15:07:36 2024 +0800

    Require triton >= 2.1.0 (#2746)
    
    Co-authored-by: yangrui1 <yangrui@lanjingren.com>

[33mcommit 5a6c81b0511da333b1fabf5ad612eb7874d5e88e[m
Author: Rex <zcnrex@gmail.com>
Date:   Sun Feb 4 14:32:42 2024 -0800

    Remove eos tokens from output by default (#2611)

[33mcommit 51cd22ce56b93e74cca22eaca286ff4770e8157c[m
Author: dancingpipi <xxdyx110@126.com>
Date:   Mon Feb 5 06:25:36 2024 +0800

    set&get llm internal tokenizer instead of the TokenizerGroup (#2741)
    
    Co-authored-by: shujunhua1 <shujunhua1@jd.com>

[33mcommit 5ed704ec8c4e68f1bc846ab4e3c9e355585d62da[m
Author: Massimiliano Pronesti <massimiliano.pronesti@gmail.com>
Date:   Sun Feb 4 03:17:55 2024 +0100

    docs: fix langchain (#2736)

[33mcommit 4abf6336ec65c270343eb895e7b18786e9274176[m
Author: Cheng Su <chengsu@anyscale.com>
Date:   Fri Feb 2 15:41:42 2024 -0800

    Add one example to run batch inference distributed on Ray (#2696)

[33mcommit 0e163fce18594c7e29dc5a143dd6b33d213fcbf3[m
Author: zspo <songpo.zhang@foxmail.com>
Date:   Fri Feb 2 07:59:39 2024 +0800

    Fix default length_penalty to 1.0 (#2667)

[33mcommit 96b6f475dda40a0c7d557f73c36fe09c07be2e9c[m
Author: Kunshang Ji <kunshang.ji@intel.com>
Date:   Fri Feb 2 07:46:39 2024 +0800

    Remove hardcoded `device="cuda" ` to support more devices (#2503)
    
    Co-authored-by: Jiang Li <jiang1.li@intel.com>
    Co-authored-by: Kunshang Ji <kunshang.ji@intel.com>

[33mcommit c410f5d020216df2dfedde52bcae24ae7f0ac7ec[m
Author: Pernekhan Utemuratov <bestkhang@gmail.com>
Date:   Thu Feb 1 15:41:58 2024 -0800

    Use revision when downloading the quantization config file (#2697)
    
    Co-authored-by: Pernekhan Utemuratov <pernekhan@deepinfra.com>

[33mcommit bb8c697ee0f01aaeddce31bd5fba3e9f7f4488a1[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Feb 1 14:56:53 2024 -0800

    Update README for meetup slides (#2718)

[33mcommit b9e96b17de4c555e2249db9f6149b346232c000e[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Feb 1 14:00:58 2024 -0800

    fix python 3.8 syntax (#2716)

[33mcommit 923797fea4d80a4dac4409ece3c450b84d5ba001[m
Author: zhaoyang-star <zhaoyangstar@foxmail.com>
Date:   Fri Feb 2 01:35:09 2024 +0800

    Fix compile error when using rocm (#2648)

[33mcommit cd9e60c76c776c42431b7ae523fcfe7835546d74[m
Author: Fengzhe Zhou <zfz-960727@163.com>
Date:   Fri Feb 2 01:27:40 2024 +0800

    Add Internlm2 (#2666)

[33mcommit 93b38bea5dd03e1b140ca997dfaadef86f8f1855[m
Author: Robert Shaw <114415538+rib-2@users.noreply.github.com>
Date:   Wed Jan 31 14:58:07 2024 -0800

    Refactor Prometheus and Add Request Level Metrics (#2316)

[33mcommit d0d93b92b190f420e2628350ec69921bede691d4[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Wed Jan 31 14:34:17 2024 -0800

    Add unit test for Mixtral MoE layer (#2677)

[33mcommit 89efcf1ce53cd01c27384e3c3e1c6b0761978076[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Wed Jan 31 10:12:11 2024 -0800

    [Minor] Fix test_cache.py CI test failure (#2684)

[33mcommit c664b0e6838644c22839b6e9c88e61b4e9a540f6[m
Author: zspo <songpo.zhang@foxmail.com>
Date:   Thu Feb 1 02:09:23 2024 +0800

    fix some bugs (#2689)

[33mcommit d69ff0cbbbb07b571eeea62b4e2ce87b91cea387[m
Author: Tao He <sighingnow@gmail.com>
Date:   Thu Feb 1 01:00:13 2024 +0800

    Fixes assertion failure in prefix caching: the lora index mapping should respect prefix_len (#2688)
    
    Signed-off-by: Tao He <sighingnow@gmail.com>

[33mcommit 1af090b57d0e23d268e79941f8084bf0a8ad8621[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Jan 31 00:07:07 2024 -0800

    Bump up version to v0.3.0 (#2656)

[33mcommit 3dad94448583a835230ae68c726d4b67e46845f2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jan 30 16:34:10 2024 -0800

    Add quantized mixtral support (#2673)

[33mcommit 105a40f53a8001ce7f4282462a4636b31383f393[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jan 30 14:39:40 2024 -0800

    [Minor] Fix false warning when TP=1 (#2674)

[33mcommit bbe9bd9684218038cca9663ac79dfe7c4f28a351[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Tue Jan 30 13:40:37 2024 -0800

    [Minor] Fix a small typo (#2672)

[33mcommit 4f65af0e252066d961bf864d0862f442e497f619[m
Author: Vladimir <vladimir.ovsyannikov@gmail.com>
Date:   Tue Jan 30 18:30:50 2024 +0100

    Add swap_blocks unit tests (#2616)

[33mcommit d79ced3292445d8471b3c4e5ce2dbf311834ec1b[m
Author: Wen Sun <35923278+HermitSun@users.noreply.github.com>
Date:   Wed Jan 31 00:17:05 2024 +0800

    Fix 'Actor methods cannot be called directly' when using `--engine-use-ray` (#2664)
    
    * fix: engine-useray complain
    
    * fix: typo

[33mcommit ab406446691f289ef51d1abd8d1ff66760eda36f[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Mon Jan 29 22:43:37 2024 -0800

    Fused MOE for Mixtral (#2542)
    
    Co-authored-by: chen shen <scv119@gmail.com>

[33mcommit 5d60def02cb5a43fa5864fcb123909b101df9ec5[m
Author: wangding zeng <155410488+zwd003@users.noreply.github.com>
Date:   Tue Jan 30 13:19:48 2024 +0800

    DeepseekMoE support with Fused MoE kernel (#2453)
    
    Co-authored-by: roy <jasonailu87@gmail.com>

[33mcommit ea8489fce266d69f2fbe314c1385956b1a342e12[m
Author: Rasmus Larsen <rlarsen@pm.me>
Date:   Mon Jan 29 19:52:31 2024 +0100

    ROCm: Allow setting compilation target (#2581)

[33mcommit 1b20639a43e811f4469e3cfa543cf280d0d76265[m
Author: Hanzhi Zhou <hanzhi713@163.com>
Date:   Tue Jan 30 02:46:29 2024 +0800

    No repeated IPC open (#2642)

[33mcommit b72af8f1eded6f5838be29eb6093ab0e0e0c240c[m
Author: zhaoyang-star <zhaoyangstar@foxmail.com>
Date:   Mon Jan 29 14:47:39 2024 +0800

    Fix error when tp > 1 (#2644)
    
    Co-authored-by: zhaoyang-star <zhao.yang16@zte.com.cn>

[33mcommit 9090bf02e74334a8020b454814e0d00fa780fd79[m
Author: zhaoyang-star <zhaoyangstar@foxmail.com>
Date:   Mon Jan 29 08:43:54 2024 +0800

    Support FP8-E5M2 KV Cache (#2279)
    
    Co-authored-by: zhaoyang <zhao.yang16@zte.com.cn>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 7d648418b8b1aadb90489ef18cff1763ffc82ed5[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Jan 28 14:27:22 2024 -0800

    Update Ray version requirements (#2636)

[33mcommit 89be30fa7d51035cee96d1573ffbe8b8ba6db878[m
Author: Murali Andoorveedu <37849411+andoorve@users.noreply.github.com>
Date:   Sat Jan 27 23:28:37 2024 -0800

    Small async_llm_engine refactor (#2618)

[33mcommit f8ecb84c0283a7f1ba02ee732c9f044f8f9d36ee[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Jan 27 17:46:56 2024 -0800

    Speed up Punica compilation (#2632)

[33mcommit 5f036d2bcc5244ca431212167c94700e5ae7a8e0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Jan 27 15:43:40 2024 -0800

    [Minor] Fix warning on Ray dependencies (#2630)

[33mcommit 380170038e05cf81953c29d7e8ed789e048b6434[m
Author: Hanzhi Zhou <hanzhi713@163.com>
Date:   Sun Jan 28 04:46:35 2024 +0800

    Implement custom all reduce kernels (#2192)

[33mcommit 220a47627bf48c728ce0a2737be39c400bb6f653[m
Author: Xiang Xu <117880274+xiangxu-google@users.noreply.github.com>
Date:   Sat Jan 27 10:30:49 2024 -0800

    Use head_dim in config if exists (#2622)

[33mcommit beb89f68b448a43ac112b48e3834f80a2df626cb[m
Author: Casper <casperbh.96@gmail.com>
Date:   Sat Jan 27 08:53:17 2024 +0100

    AWQ: Up to 2.66x higher throughput (#2566)

[33mcommit 390b495ff327e8548c3f7cd701afce87870d9102[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Fri Jan 26 15:19:19 2024 -0800

    Don't build punica kernels by default (#2605)

[33mcommit 3a0e1fc070dc7482ab1c8fcdc961e5729a4cb0b3[m
Author: dakotamahan-stability <139925645+dakotamahan-stability@users.noreply.github.com>
Date:   Fri Jan 26 14:45:19 2024 -0600

    Support for Stable LM 2 (#2598)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 6b7de1a030e5bf8c32eb66a03a0fc70bb3c2da4a[m
Author: Hongxia Yang <62075498+hongxiayang@users.noreply.github.com>
Date:   Fri Jan 26 15:41:10 2024 -0500

    [ROCm] add support to ROCm 6.0 and MI300 (#2274)

[33mcommit 5265631d15d59735152c8b72b38d960110987f10[m
Author: Vladimir <vladimir.ovsyannikov@gmail.com>
Date:   Fri Jan 26 08:48:17 2024 +0100

    use a correct device when creating OptionalCUDAGuard (#2583)

[33mcommit 2832e7b9f92e2d1dd7dfe37951e5837c61d3db20[m
Author: Junyang Lin <justinlin930319@hotmail.com>
Date:   Thu Jan 25 14:37:51 2024 +0800

    fix names and license for Qwen2 (#2589)

[33mcommit 3a7dd7e367277c47472912e84375fa912df07328[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Jan 24 17:11:07 2024 -0800

    Support Batch Completion in Server (#2529)

[33mcommit 223c19224b917005c8ed9e614825b7940f9de84b[m
Author: LastWhisper <whuwkl@gmail.com>
Date:   Thu Jan 25 03:22:51 2024 +0800

    Fix the syntax error in the doc of supported_models (#2584)

[33mcommit f1f6cc10c77d6ee40b3ce769124cb2760428dc48[m
Author: Federico Galatolo <galatolo.federico@gmail.com>
Date:   Wed Jan 24 19:21:56 2024 +0100

    Added `include_stop_str_in_output` and `length_penalty` parameters to OpenAI API (#2562)

[33mcommit 3209b4903376fd723858b256dcfabb8420a0cc64[m
Author: Nikola Borisov <nikola.borisof@gmail.com>
Date:   Tue Jan 23 22:38:55 2024 -0800

    [Bugfix] fix crash if max_tokens=None (#2570)

[33mcommit 1e4277d2d1eceedbe0d00ba9e2c1bef88145df7b[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Jan 23 15:53:06 2024 -0800

    lint: format all python file instead of just source code (#2567)

[33mcommit 9b945daaf1ce03b8b02d68b37c59baf28566b535[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Jan 24 00:26:37 2024 +0100

    [Experimental] Add multi-LoRA support (#1804)
    
    Co-authored-by: Chen Shen <scv119@gmail.com>
    Co-authored-by: Shreyas Krishnaswamy <shrekris@anyscale.com>
    Co-authored-by: Avnish Narayan <avnish@anyscale.com>

[33mcommit 9c1352eb5736d9e71d37959db44b6a641e898772[m
Author: Erfan Al-Hossami <erfan.hossami@gmail.com>
Date:   Tue Jan 23 18:13:00 2024 -0500

    [Feature] Simple API token authentication and pluggable middlewares (#1106)

[33mcommit 7a0b011dd51e5c6b48e8f8f5424be0995b5cb8ee[m
Author: Jason Zhu <jasonchu13@outlook.com>
Date:   Mon Jan 22 14:47:25 2024 -0800

    Add a 1-line docstring to explain why calling context_attention_fwd twice in test_prefix_prefill.py (#2553)

[33mcommit 63e835cbccec62cc34ed27a6133d9a7f4af4a068[m
Author: Harry Mellor <19981378+hmellor@users.noreply.github.com>
Date:   Mon Jan 22 22:40:31 2024 +0000

    Fix progress bar and allow HTTPS in `benchmark_serving.py` (#2552)

[33mcommit 94b5edeb5384ea2a46533a11dd5938b2c859bf5c[m
Author: Junyang Lin <justinlin930319@hotmail.com>
Date:   Tue Jan 23 06:34:21 2024 +0800

    Add qwen2 (#2495)

[33mcommit ab7e6006d62d77dca72b29721b7b346eeb6563d4[m
Author: Philipp Moritz <pcmoritz@gmail.com>
Date:   Mon Jan 22 10:02:38 2024 -0800

    Fix https://github.com/vllm-project/vllm/issues/2540 (#2545)

[33mcommit 18bfcdd05c657e6997b132488e6f4e74307d6cee[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Sun Jan 21 16:31:47 2024 -0800

    [Speculative decoding 2/9] Multi-step worker for draft model (#2424)

[33mcommit 71d63ed72e8e528e3131af79b2c1ad853065ccb8[m
Author: Jannis Sch√∂nleber <joennlae@gmail.com>
Date:   Mon Jan 22 01:05:56 2024 +0100

     migrate pydantic from v1 to v2 (#2531)

[33mcommit d75c40734a96a10b30c7b2652d49f2a70030855b[m
Author: Nick Hill <nickhill@us.ibm.com>
Date:   Sat Jan 20 22:36:09 2024 -0800

    [Fix] Keep `scheduler.running` as deque (#2523)

[33mcommit 5b23c3f26fcf08fdbe2b7e6beecb4d970e632897[m
Author: Junda Chen <32371474+GindaChen@users.noreply.github.com>
Date:   Sat Jan 20 16:00:26 2024 -0800

    Add `group` as an argument in broadcast ops (#2522)

[33mcommit 00efdc84baf313cb775ca99a011b0e9a13539bdd[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Jan 19 20:20:19 2024 -0800

    Add benchmark serving to CI (#2505)

[33mcommit 91a61da9b12c483a6688841b8f860c1a32b8918c[m
Author: Roy <jasonailu87@gmail.com>
Date:   Sat Jan 20 08:26:16 2024 +0800

    [Bugfix] fix load local safetensors model (#2512)

[33mcommit ef9b636e2d427f588bf11242e312ba8954d9aff0[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Fri Jan 19 11:23:30 2024 -0800

    Simplify broadcast logic for control messages (#2501)

[33mcommit 2709c0009aa434fbf2ef0fe48ca3094a2268b190[m
Author: Harry Mellor <19981378+HMellor@users.noreply.github.com>
Date:   Fri Jan 19 04:34:08 2024 +0000

    Support OpenAI API server in `benchmark_serving.py` (#2172)

[33mcommit dd7e8f5f643167e3f13045cf75cbead54cb2ccfe[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Jan 18 16:45:14 2024 -0800

    refactor complemention api for readability (#2499)

[33mcommit d2a68364c473a3167a1c2b90f947bb611322a867[m
Author: ljss <31004720+beginlner@users.noreply.github.com>
Date:   Fri Jan 19 07:10:42 2024 +0800

    [BugFix] Fix abort_seq_group (#2463)

[33mcommit 7e1081139d65e941815234aa0e0e91e1ea5c0ff1[m
Author: Nikola Borisov <nikola.borisof@gmail.com>
Date:   Thu Jan 18 11:05:53 2024 -0800

    Don't download both safetensor and bin files. (#2480)

[33mcommit 18473cf498615a68b88a5b2c5202e221e1db87ad[m
Author: Liangfu Chen <liangfu@apache.org>
Date:   Thu Jan 18 10:58:50 2024 -0800

    [Neuron] Add an option to build with neuron (#2065)

[33mcommit 4df417d0593b56d189e8aed8b9c85a4476cfc630[m
Author: zspo <songpo.zhang@foxmail.com>
Date:   Fri Jan 19 01:41:44 2024 +0800

    fix: fix some args desc (#2487)

[33mcommit 5d80a9178b48f211a6fa02a7b5ddc0a0ae29aa44[m
Author: Jason Zhu <jasonchu13@outlook.com>
Date:   Thu Jan 18 09:40:34 2024 -0800

    Minor fix in prefill cache example (#2494)

[33mcommit 8a25d3a71ac8b0b06c37935ed67e7c35aa901bf5[m
Author: YingchaoX <xycxycxycxyc@gmail.com>
Date:   Fri Jan 19 01:39:46 2024 +0800

    fix stablelm.py tensor-parallel-size bug (#2482)

[33mcommit d10f8e1d43bfb0656b6848ad0c681ecbdec812d6[m
Author: shiyi.c_98 <shiyicao314@gmail.com>
Date:   Wed Jan 17 16:32:10 2024 -0800

    [Experimental] Prefix Caching Support (#1669)
    
    Co-authored-by: DouHappy <2278958187@qq.com>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 14cc317ba48229d93ee2417822d96ccb8db56abe[m
Author: FlorianJoncour <148003496+FlorianJoncour@users.noreply.github.com>
Date:   Wed Jan 17 05:33:14 2024 +0000

    OpenAI Server refactoring (#2360)

[33mcommit e1957c6ebdd4860f832c26ae4de4195d10803723[m
Author: Hyunsung Lee <ita9naiwa@gmail.com>
Date:   Wed Jan 17 13:32:40 2024 +0900

    Add StableLM3B model (#2372)

[33mcommit 8cd5a992bffff40434dac6c233767e4fa6359183[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Jan 16 12:51:04 2024 -0800

    ci: retry on build failure as well (#2457)

[33mcommit 947f0b23ccea1377a5f08900fe71d7de118e5042[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Jan 16 09:50:13 2024 -0800

    CI: make sure benchmark script exit on error (#2449)

[33mcommit f780504d1294cbe28221d9d030b040384fa53d5d[m
Author: Chenhui Zhang <zhang.chenhui@outlook.com>
Date:   Tue Jan 16 07:43:59 2024 +0800

    fix weigit loading for GQA with TP (#2379)

[33mcommit bfc072addfba28d9575c372801db840df80d8fb2[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Jan 15 15:43:15 2024 -0800

    Allow buildkite to retry build on agent lost (#2446)

[33mcommit 2a18da257ccd0d5beafcebe93246e4e220c88a12[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jan 15 14:11:59 2024 -0800

    Announce the second vLLM meetup (#2444)

[33mcommit 6e01e8c1c8ea323d30e3f57050469b2df66b56c6[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Jan 14 12:37:58 2024 -0800

    [CI] Add Buildkite (#2355)

[33mcommit 9f659bf07fa3aa0183f2d36b09abaa5ef7cbd77a[m
Author: Roy <jasonailu87@gmail.com>
Date:   Mon Jan 15 01:40:51 2024 +0800

    [Minor] Optimize cuda graph memory usage (#2437)

[33mcommit 35c4bc20d9d454f58506b561b6770d3ae4752bf9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jan 12 14:02:52 2024 -0800

    [Minor] Fix err msg (#2431)

[33mcommit 218dc2ccdab133ffb0faa86cca510730fb917449[m
Author: ÈôàÂ∫è <chenxu2048@gmail.com>
Date:   Sat Jan 13 05:51:03 2024 +0800

    Aligning `top_p` and `top_k` Sampling (#1885)
    
    * Align top_p and top_k with huggingface
    
    * remove _get_prompt_and_output_tokens
    
    * rename _apply_top_p_top_k
    
    * compare top_p top_k with hf
    
    * fix test errors

[33mcommit 827cbcd37c464452b79956fa4a564199e6c0ab6a[m
Author: Simon <ak.simonm@gmail.com>
Date:   Fri Jan 12 14:56:18 2024 -0600

    Update quickstart.rst (#2369)

[33mcommit cb7a1c1cbf7c07e072df29844fb7a51a01344392[m
Author: Ben <chuanzhubin@163.com>
Date:   Sat Jan 13 04:33:29 2024 +0800

    Suggest using dtype=half when OOM.

[33mcommit 7878958c0de9da8c372495dab7d4f25257894c4f[m
Author: Gary Hui <44025886+huiwy@users.noreply.github.com>
Date:   Sat Jan 13 04:16:49 2024 +0800

    Address Phi modeling update 2 (#2428)

[33mcommit ce036244c9999c90c8cf906bf21cc3f171213333[m
Author: Chirag Jain <jain.chirag925@gmail.com>
Date:   Sat Jan 13 00:29:59 2024 +0530

    Allow setting fastapi root_path argument (#2341)

[33mcommit 48cf1e413c42b29909077afe21c7b9e57996a1cf[m
Author: ÈôàÂ∫è <chenxu2048@gmail.com>
Date:   Sat Jan 13 00:44:18 2024 +0800

    fix: deque mutated during iteration in abort_seq_group (#2371)

[33mcommit 97460585d9ae2c79fb625d0e4ad48f17b753a2da[m
Author: arkohut <39525455+arkohut@users.noreply.github.com>
Date:   Fri Jan 12 11:45:56 2024 +0800

    Add gradio chatbot for openai webserver (#2307)

[33mcommit f745847ef7401744f25ca68681d6e0bc939a8a67[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Jan 11 19:44:01 2024 -0800

    [Minor] Fix the format in quick start guide related to Model Scope (#2425)

[33mcommit 6549aef24501d5cd1a0d22a19e9e0f8e04f8bd77[m
Author: Jiaxiang <56266729+litone01@users.noreply.github.com>
Date:   Fri Jan 12 11:26:49 2024 +0800

    [DOC] Add additional comments for LLMEngine and AsyncLLMEngine (#1011)

[33mcommit 50376faa7b7397f82f9b67d7b6e0770ab189b6c1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jan 11 16:23:43 2024 -0800

    Rename phi_1_5 -> phi (#2385)

[33mcommit 4b61c6b669e368c6850531815940d9a542b9f223[m
Author: Yunfeng Bai <83252681+yunfeng-scale@users.noreply.github.com>
Date:   Wed Jan 10 11:39:58 2024 -0800

    `get_ip()`: Fix ipv4 ipv6 dualstack (#2408)

[33mcommit 79d64c495463665cf80937a05226806785cfa583[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Jan 9 15:38:41 2024 -0800

    [Speculative decoding 1/9] Optimized rejection sampler (#2336)

[33mcommit 74cd5abdd14b8a7b24a6bf4929f64ae59a3bbd5c[m
Author: KKY <evilpsycho42@gmail.com>
Date:   Tue Jan 9 11:13:02 2024 -0600

    Add baichuan chat template jinjia file (#2390)

[33mcommit 28c3f121040dd80d3540fb7d36e0b7a4817da28c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jan 8 13:13:08 2024 -0800

    [Minor] Remove unused code in attention (#2384)

[33mcommit c88481913599daff6ca293bf778a620213e467c9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jan 8 10:11:06 2024 -0800

    Fix eager mode performance (#2377)

[33mcommit 05921a9a7ab2bd5694d28dd5a986b8aa00ddbbd1[m
Author: Nadav Shmayovits <45605409+NadavShmayo@users.noreply.github.com>
Date:   Sun Jan 7 19:48:07 2024 +0200

    Changed scheduler to use deques instead of lists (#2290)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit d0215a58e78572d91dadafe9d832a2db89b09a13[m
Author: Iskren Ivov Chernev <me@iskren.info>
Date:   Fri Jan 5 15:24:42 2024 +0200

    Ensure metrics are logged regardless of requests (#2347)

[33mcommit 937e7b7d7c460c00805ac358a4873ec0653ab2f5[m
Author: Alexandre Payot <18074599+payoto@users.noreply.github.com>
Date:   Thu Jan 4 18:35:18 2024 +0100

    Build docker image with shared objects from "build" step (#2237)

[33mcommit aee8ef661a227bfeb0c886b2b3892b0fc56bbd47[m
Author: ljss <31004720+beginlner@users.noreply.github.com>
Date:   Thu Jan 4 13:27:56 2024 +0800

    Miner fix of type hint (#2340)

[33mcommit 2e0b6e775756345aa1d39f772c186e00f8c29e92[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jan 3 17:35:56 2024 -0800

    Bump up to v0.2.7 (#2337)

[33mcommit 941767127c388ae5ed5e587286994c6061660a14[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jan 3 17:32:05 2024 -0800

    Revert the changes in test_cache (#2335)

[33mcommit 74d8d77626763bf7c4a2dd227231c69bb4638e29[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Thu Jan 4 01:49:07 2024 +0200

    Remove unused const TIMEOUT_TO_PREVENT_DEADLOCK (#2321)

[33mcommit fd4ea8ef5c17a8b991107402a414f6ed355d854d[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Jan 4 03:30:22 2024 +0800

    Use NCCL instead of ray for control-plane communication to remove serialization overhead (#2221)

[33mcommit 1066cbd152fb7c9a096e914a10ce675a14796b92[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Wed Jan 3 19:56:21 2024 +0200

    Remove deprecated parameter: concurrency_count (#2315)

[33mcommit 6ef00b03a2b6679d494530e9a98932c5a6cc8418[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jan 3 09:52:29 2024 -0800

    Enable CUDA graph for GPTQ & SqueezeLLM (#2318)

[33mcommit 9140561059904f133a3c146f04afe13d1cdd5a6c[m
Author: Roy <jasonailu87@gmail.com>
Date:   Wed Jan 3 11:23:15 2024 +0800

    [Minor] Fix typo and remove unused code (#2305)

[33mcommit 77af974b406f0947d5eb0b55f7ac4dd4516c38e3[m
Author: Jee Li <pandaleefree@163.com>
Date:   Wed Jan 3 11:09:59 2024 +0800

    [FIX] Support non-zero CUDA devices in custom kernels (#1959)

[33mcommit 4934d492744d14104353b8236ef8a0405edf1622[m
Author: Jong-hun Shin <20063100+dalgarak@users.noreply.github.com>
Date:   Sun Dec 31 01:42:04 2023 +0900

    Support GPT-NeoX Models without attention biases (#2301)

[33mcommit 358c328d69f62c1fdbd6deaf3b872809734c37b2[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Dec 28 06:18:11 2023 +0800

    [BUGFIX] Fix communication test (#2285)

[33mcommit 4aaafdd289f57a82513a7742155e4f1b796c8bdc[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Dec 27 02:37:21 2023 +0800

    [BUGFIX] Fix the path of test prompts (#2273)

[33mcommit 66b108d1428eaee089bf2a4cb41b1299d150fd93[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Dec 27 02:37:06 2023 +0800

    [BUGFIX] Fix API server test (#2270)

[33mcommit e0ff920001988f2240cf05551bef566898ed6e4b[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Dec 26 13:41:09 2023 +0800

    [BUGFIX] Do not return ignored sentences twice in async llm engine (#2258)

[33mcommit face83c7eccff05c5cd3ec3b6f114f71b7694e4e[m
Author: blueceiling <148506960+blueceiling@users.noreply.github.com>
Date:   Mon Dec 25 17:37:07 2023 -0700

    [Docs] Add "About" Heading to README.md (#2260)

[33mcommit 1db83e31a2468cae37f326a642c0a4c4edbb5e4f[m
Author: Shivam Thakkar <shivamthakkar5@gmail.com>
Date:   Sat Dec 23 12:50:02 2023 +0530

    [Docs] Update installation instructions to include CUDA 11.8 xFormers (#2246)

[33mcommit a1b9cb2a3469e4e682e741af9a0f91e16923205d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Dec 20 21:52:37 2023 -0800

    [BugFix] Fix recovery logic for sequence group (#2186)

[33mcommit 3a4fd5ca59ffaf880137914247bd3cac3c730292[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Dec 20 21:52:08 2023 -0800

    Disable Ray usage stats collection (#2206)

[33mcommit c17daa9f896f9c770962a0aa22fa770bac0d709a[m
Author: Ronen Schaffer <ronen.schaffer@ibm.com>
Date:   Wed Dec 20 22:43:42 2023 +0200

    [Docs] Fix broken links (#2222)

[33mcommit bd29cf3d3ad3dd06105f1a4bb9023bb23bdfd5ed[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Dec 20 00:04:33 2023 -0800

    Remove Sampler copy stream (#2209)

[33mcommit 31bff69151606220e9db7ed37603e41b3f2e3230[m
Author: Hanzhi Zhou <hanzhi713@163.com>
Date:   Tue Dec 19 16:52:46 2023 -0800

    Make _prepare_sample non-blocking and use pinned memory for input buffers (#2207)

[33mcommit ba4f82673884b644a516c2088087ef42688e202c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Dec 19 16:16:11 2023 -0800

    [BugFix] Fix weight loading for Mixtral with TP (#2208)

[33mcommit de60a3fb93957dce6b242299b5d163f02ef7f383[m
Author: avideci <61653911+avideci@users.noreply.github.com>
Date:   Tue Dec 19 12:29:33 2023 +0200

    Added DeciLM-7b and DeciLM-7b-instruct (#2062)

[33mcommit 21d5daa4aca6e16c0c42dbfdf704fdfd0006ba4c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 18 18:16:17 2023 -0800

    Add warning on CUDA graph memory usage (#2182)

[33mcommit 290e015c6c328d08d6074827c5c43371017b27ab[m
Author: Suhong Moon <46987248+SuhongMoon@users.noreply.github.com>
Date:   Mon Dec 18 14:33:24 2023 -0500

    Update Help Text for --gpu-memory-utilization Argument (#2183)

[33mcommit 1b7c791d60629453030de1600e756a8ba555455e[m
Author: kliuae <17350011+kliuae@users.noreply.github.com>
Date:   Tue Dec 19 02:41:04 2023 +0800

    [ROCm] Fixes for GPTQ on ROCm (#2180)

[33mcommit bbe4466fd98a27f918bd498c9e64a736202a133e[m
Author: JohnSaxon <39079736+oushu1zhangxiangxuan1@users.noreply.github.com>
Date:   Mon Dec 18 15:28:49 2023 +0800

    [Minor] Fix typo (#2166)
    
    Co-authored-by: John-Saxon <zhang.xiangxuan@oushu.com>

[33mcommit 08133c4d1a9e3c13aa42c3fb83aa7c987e79289f[m
Author: Harry Mellor <19981378+HMellor@users.noreply.github.com>
Date:   Mon Dec 18 02:56:23 2023 +0000

    Add SSL arguments to API servers (#2109)

[33mcommit 76a7983b23f55785005d361e20784f7d3d6e11ce[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 17:09:10 2023 -0800

    [BugFix] Fix RoPE kernel on long sequences(#2164)

[33mcommit 8041b7305e93a8626d85cb23b3fcb995882867c1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 17:08:23 2023 -0800

    [BugFix] Raise error when max_model_len is larger than KV cache (#2163)

[33mcommit 3ec8c25cd07c4a3d747b846ece8e305a7fb44349[m
Author: Suhong Moon <46987248+SuhongMoon@users.noreply.github.com>
Date:   Sun Dec 17 13:51:57 2023 -0500

    [Docs] Update documentation for gpu-memory-utilization option (#2162)

[33mcommit 671af2b1c0b3ed6d856d37c21a561cc429a10701[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 10:34:56 2023 -0800

    Bump up to v0.2.6 (#2157)

[33mcommit 6f41f0e377708f223871c888ce84bb575bae732f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 10:24:25 2023 -0800

    Disable CUDA graph for SqueezeLLM (#2161)

[33mcommit 2c9b638065ae8d69f8949e56f87990f1fcfe9255[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 10:12:44 2023 -0800

    [Minor] Fix a typo in .pt weight support (#2160)

[33mcommit a7347d9a6d2391734d838ab6a4f3a702e348d9fa[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Sun Dec 17 07:03:49 2023 -0800

    Make sampler less blocking (#1889)

[33mcommit f8c688d746b32a54c249c4faf6fc73b83f53952a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 02:54:57 2023 -0800

    [Minor] Add Phi 2 to supported models (#2159)

[33mcommit c9fadda54353f1b57c3dae9b7cbebda6f0767f8e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 02:28:02 2023 -0800

    [Minor] Fix xformers version (#2158)

[33mcommit 30fb0956dfee6113765ccb527f4f06703c75bf47[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 01:56:16 2023 -0800

    [Minor] Add more detailed explanation on `quantization` argument (#2145)

[33mcommit 3a765bd5e1891b8c6454e60b56c2405fbe35bb9e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 01:51:12 2023 -0800

    Temporarily enforce eager mode for GPTQ models (#2154)

[33mcommit 26c52a5ea6e9523b1c8bb8365b214ca29056c266[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 01:49:20 2023 -0800

    [Docs] Add CUDA graph support to docs (#2148)

[33mcommit c3372e87bed990510e4ae0b39f151a34dea24f8b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 01:49:07 2023 -0800

    Remove dependency on CuPy (#2152)

[33mcommit b0a1d667b04dcce8e54201cb429a57155bf9670c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 01:46:54 2023 -0800

    Pin PyTorch & xformers versions (#2155)

[33mcommit e1d54022385ac52a3c3c6c6a3359d93f5c2944d5[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 17 01:44:45 2023 -0800

    Fix all-reduce memory usage (#2151)

[33mcommit 3d1cfbfc745b8644661263071c341dfa3684dde2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Dec 16 22:05:18 2023 -0800

    [Minor] Delete Llama tokenizer warnings (#2146)

[33mcommit 37ca5581039271d4bf69e5cb1f1ec8e04775777c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Dec 16 21:12:08 2023 -0800

    Optimize model execution with CUDA graph (#1926)
    
    Co-authored-by: Chen Shen <scv119@gmail.com>
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit eed74a558ffacc9a456d440b5d2ec1ca869e80b5[m
Author: Roy <jasonailu87@gmail.com>
Date:   Sun Dec 17 04:41:23 2023 +0800

    Simplify weight loading logic (#2133)

[33mcommit 2acd76f346efcdff4f6ca1d92fe1575c448e4b70[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Dec 15 17:13:58 2023 -0800

    [ROCm] Temporarily remove GPTQ ROCm support (#2138)

[33mcommit b81a6a6bb342d7b9166a1c7a6b69507fb53ff33e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Dec 15 13:29:22 2023 -0800

    [Docs] Add supported quantization methods to docs (#2135)

[33mcommit 0fbfc4b81b9208f13ceb82d1ea92ff14a6e56088[m
Author: CHU Tianxiang <tianxiang.ctx@alibaba-inc.com>
Date:   Fri Dec 15 19:04:22 2023 +0800

    Add GPTQ support (#916)

[33mcommit c06170cc8e324f4fe6a0c26b57d09e8c958e11bc[m
Author: Yunfeng Bai <83252681+yunfeng-scale@users.noreply.github.com>
Date:   Fri Dec 15 00:45:58 2023 -0800

    Add a flag to include stop string in output text (#1976)

[33mcommit 614856da25fe59f633af865aefc874fad32d25a0[m
Author: Mingcan Xiang <mingcanxiang@umass.edu>
Date:   Thu Dec 14 12:35:58 2023 -0500

    Avoid multiple redefinition (#1817)

[33mcommit 05bdf4eaf3bd8c577d09a6556acc3688094d0f6b[m
Author: TJian <tunjian1996@gmail.com>
Date:   Thu Dec 14 16:45:58 2023 +0800

    Fix Dockerfile.rocm (#2101)
    
    Co-authored-by: miloice <jeffaw99@hotmail.com>

[33mcommit 6774bd50b0c19b3f33717d15763022df385a1b70[m
Author: mezuzza <mezuzza@live.com>
Date:   Thu Dec 14 03:19:41 2023 -0500

    Fix typing in AsyncLLMEngine & add toml to requirements-dev (#2100)

[33mcommit 31c1f3255ee9771538da138396e1a50e369f8723[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Dec 13 23:56:15 2023 -0800

    Bump up to v0.2.5 (#2095)

[33mcommit 21d93c140d0a97af5f0c59e660cf04bd417fd424[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Dec 13 23:55:07 2023 -0800

    Optimize Mixtral with expert parallelism (#2090)

[33mcommit f1c8520146031a650404a6ab120ee11e91c10bed[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Dec 13 12:28:13 2023 -0800

    [BugFix] Fix input positions for long context with sliding window (#2088)

[33mcommit 096827c2846e7a769cf20e34c46b8eada444cc1e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Dec 13 09:45:34 2023 -0800

    [Docs] Add notes on ROCm-supported models (#2087)

[33mcommit 6565d9e33eb6f0a49d9824bff7ccc3f4fa5e4110[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Dec 13 09:25:59 2023 -0800

    Update installation instruction for vLLM + CUDA 11.8 (#2086)

[33mcommit f375ec844036104cbae36477ce3541588d026829[m
Author: TJian <tunjian1996@gmail.com>
Date:   Wed Dec 13 16:56:05 2023 +0800

    [ROCm] Upgrade xformers version for ROCm & update doc (#2079)
    
    Co-authored-by: miloice <jeffaw99@hotmail.com>

[33mcommit 518369d78c1ec9ffef308131366e4bda745b5573[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Dec 12 22:21:45 2023 -0800

    Implement lazy model loader (#2044)

[33mcommit 30bad5c49278ec5c3836a7bf00faa1316e8827b8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Dec 12 22:01:53 2023 -0800

    Fix peak memory profiling (#2031)

[33mcommit 3fefe271ecd0bcd03afa8c19416a8f71a7ed40e7[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Tue Dec 12 17:34:17 2023 -0800

    Update Dockerfile to build Megablocks (#2042)

[33mcommit 6428f1d051d731a9eca192950591e7a5a2788cb2[m
Author: Megha Agarwal <16129366+megha95@users.noreply.github.com>
Date:   Tue Dec 12 10:16:05 2023 -0800

    Support MPT with GQA (#1938)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 7e1b21daacaedb18a7001a4f5990d992209c4f78[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Dec 12 09:34:09 2023 -0800

    Remove einops from requirements (#2049)

[33mcommit cb3f30c600169210f9715f084e34adf2afc4f7d7[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 18:39:14 2023 -0800

    Upgrade transformers version to 4.36.0 (#2046)

[33mcommit f3e024bece5c6a5efb855903db227e0d375ad481[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 17:48:11 2023 -0800

    [CI/CD] Upgrade PyTorch version to v2.1.1 (#2045)

[33mcommit 31d2ab4aff51c537dd4bc82451efbc194e0b8f2b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 12:26:42 2023 -0800

    Remove python 3.10 requirement (#2040)

[33mcommit eb17212858dce5c73b8fe3e8c548861ea18f1f43[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Dec 11 11:59:08 2023 -0800

    Update Dockerfile to support Mixtral (#2027)

[33mcommit 4dd4b5c538dabcf2c822bc91b4f760364520e5af[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 11:49:39 2023 -0800

    Bump up to v0.2.4 (#2034)

[33mcommit 6120e5aaeaa336a5603ff0a1e64c189624098e9a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 11:40:56 2023 -0800

    Fix import error msg for megablocks (#2038)

[33mcommit 2eaa81b23671c4f1936697c97d18c1636a8c495e[m
Author: Ram <9160496+0-hero@users.noreply.github.com>
Date:   Tue Dec 12 01:07:34 2023 +0530

    Update README.md to add megablocks requirement for mixtral (#2033)

[33mcommit 81ce2a4b26c7a76742039d7b96882e2e741ac5c8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 11:32:39 2023 -0800

    [Minor] Fix type annotation in Mixtral (#2036)

[33mcommit 5dd80d3777306e489cb17cb4df1ea4c902d32645[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 11:19:08 2023 -0800

    Fix latency benchmark script (#2035)

[33mcommit beeee69bc92980c0cf70f9a733522641da0d08ec[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 10:49:00 2023 -0800

    Revert adding Megablocks (#2030)

[33mcommit 9bf28d0b69c8a01627643305d7821dc42b21b38d[m
Author: Ram <9160496+0-hero@users.noreply.github.com>
Date:   Tue Dec 12 00:09:29 2023 +0530

    Update requirements.txt for mixtral (#2029)

[33mcommit c0ce15dfb2b4316d5a519adbbd7c5c04d7718b9f[m
Author: Ikko Eltociear Ashimine <eltociear@gmail.com>
Date:   Tue Dec 12 03:32:58 2023 +0900

    Update run_on_sky.rst (#2025)
    
    sharable -> shareable

[33mcommit b9bcdc715808c2ec110a6e98e98e4fbe0681f8bf[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 10:32:17 2023 -0800

    Change the load format to pt for Mixtral (#2028)

[33mcommit 4ff0203987ff100eaaad69f0a8abf7ed821e3a0a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Dec 11 09:16:15 2023 -0800

    Minor fixes for Mixtral (#2015)

[33mcommit b5f882cc98e2c9c6dde7357dbac2ec0c2c57d8cd[m
Author: Pierre Stock <pierrestock@users.noreply.github.com>
Date:   Mon Dec 11 10:09:15 2023 +0100

    Mixtral 8x7B support (#2011)
    
    Co-authored-by: Pierre Stock <p@mistral.ai>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 2e8fc0d4c3bf8374f1f55569069e59ef45d4bc98[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Dec 10 13:20:30 2023 -0800

    Fix completion API echo and logprob combo (#1992)

[33mcommit dacaf5a40056c40be4a84f0aec42278335f76dae[m
Author: wbn <66299196+wbn03@users.noreply.github.com>
Date:   Mon Dec 11 02:12:53 2023 +0800

    Replace head_mapping params with num_kv_heads to attention kernel. (#1997)
    
    Co-authored-by: wangguoya <wangguoya@baidu.com>
    Co-authored-by: Yang Zhao <zhaoyangstar@foxmail.com>

[33mcommit 24cde76a152fbffde30fa2be0d08dcbad490530e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 10 10:04:12 2023 -0800

    [Minor] Add comment on skipping rope caches (#2004)

[33mcommit 1aa13615103c2ea47e36710a9b2e17dfe1909143[m
Author: Jin Shang <shangjin1997@gmail.com>
Date:   Sun Dec 10 13:01:21 2023 +0800

    Fix OpenAI server completion_tokens referenced before assignment (#1996)

[33mcommit fe470ae5ade3d4b04ec5ee6f26ffb681d66a8ca1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Dec 9 19:24:29 2023 -0800

    [Minor] Fix code style for baichuan (#2003)

[33mcommit 3a8c2381f7d7933b01dd9ddbd4c3df2ce673cfc1[m
Author: Jun Gao <imgaojun@gmail.com>
Date:   Sun Dec 10 07:59:57 2023 +0800

    Fix for KeyError on Loading LLaMA (#1978)

[33mcommit c85b80c2b64d0f420aaca59679e5f38f71a8a53e[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Fri Dec 8 09:53:47 2023 -0800

    [Docker] Add cuda arch list as build option (#1950)

[33mcommit 2b981012a6eb27d566f03cf61c06b1ef7a522f27[m
Author: firebook <dzzf@163.com>
Date:   Sat Dec 9 01:38:36 2023 +0800

    Fix Baichuan2-7B-Chat (#1987)

[33mcommit 6ccc0bfffbcf1b7e927cc3dcf4159fc74ff94d40[m
Author: TJian <tunjian1996@gmail.com>
Date:   Fri Dec 8 15:16:52 2023 +0800

    Merge EmbeddedLLM/vllm-rocm into vLLM main (#1836)
    
    Co-authored-by: Philipp Moritz <pcmoritz@gmail.com>
    Co-authored-by: Amir Balwel <amoooori04@gmail.com>
    Co-authored-by: root <kuanfu.liu@akirakan.com>
    Co-authored-by: tjtanaa <tunjian.tan@embeddedllm.com>
    Co-authored-by: kuanfu <kuanfu.liu@embeddedllm.com>
    Co-authored-by: miloice <17350011+kliuae@users.noreply.github.com>

[33mcommit c8e7eb1eb3e3862cde4f7c27952d2eb9104ef416[m
Author: Daya Khudia <37562707+dskhudia@users.noreply.github.com>
Date:   Thu Dec 7 16:04:41 2023 -0800

    fix typo in getenv call (#1972)

[33mcommit 24f60a54f42076e0bfa49fde113756bf4e95f9ef[m
Author: AguirreNicolas <37890346+AguirreNicolas@users.noreply.github.com>
Date:   Thu Dec 7 16:00:32 2023 -0300

    [Docker] Adding number of nvcc_threads during build as envar (#1893)

[33mcommit 42c02f5892e984d308614f074f423a311aba8993[m
Author: gottlike <gottlike.one@gmail.com>
Date:   Thu Dec 7 17:34:44 2023 +0100

    Fix quickstart.rst typo jinja (#1964)

[33mcommit ebede26ebf9c142465e1bfa8930fc8d2cbf5d953[m
Author: Jie Li <theFool32@users.noreply.github.com>
Date:   Fri Dec 8 00:32:08 2023 +0800

    Make InternLM follow `rope_scaling` in `config.json` (#1956)
    
    Co-authored-by: lijie8 <lijie8@sensetime.com>

[33mcommit d940ce497e96bf86908248ea4b21417d0cf1c261[m
Author: Peter G√∂tz <peter.gtz@gmail.com>
Date:   Wed Dec 6 19:04:26 2023 +0100

    Fix typo in adding_model.rst (#1947)
    
    adpated -> adapted

[33mcommit 05ff90b692a6cdac4d8c06e7a4a4606d1b8fe1d6[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Dec 5 20:55:55 2023 -0800

    Save pytorch profiler output for latency benchmark (#1871)
    
    * Save profiler output
    
    * Apply feedback from code review

[33mcommit 1d9b737e054ecbbf6250e0541b74d4e8ca668406[m
Author: dancingpipi <xxdyx110@126.com>
Date:   Wed Dec 6 02:52:48 2023 +0800

    Support ChatGLMForConditionalGeneration (#1932)
    
    Co-authored-by: shujunhua1 <shujunhua1@jd.com>

[33mcommit 60dc62dc9e53428912953276e0d12a034b353fb6[m
Author: Roy <jasonailu87@gmail.com>
Date:   Mon Dec 4 04:59:18 2023 +0800

    add custom server params (#1868)

[33mcommit 0f90effc660317070b88b860eda76bfb3b596701[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 3 12:27:47 2023 -0800

    Bump up to v0.2.3 (#1903)

[33mcommit 464dd985e31a62cb7f87ab5b710a50db1912d177[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Dec 3 12:24:30 2023 -0800

    Fix num_gpus when TP > 1 (#1852)

[33mcommit c07a4428545c7708626ab04bb0033284e71d4ed7[m
Author: Massimiliano Pronesti <massimiliano.pronesti@gmail.com>
Date:   Sun Dec 3 10:11:22 2023 +0100

    chore(examples-docs): upgrade to OpenAI V1  (#1785)

[33mcommit cd3aa153a4e4974802385f209ad343149af02c07[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Dec 2 22:17:33 2023 -0800

    Fix broken worker test (#1900)

[33mcommit 9b294976a2373f6fda22c1b2e704c395c8bd0787[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Dec 2 21:18:40 2023 -0800

    Add PyTorch-native implementation of custom layers (#1898)

[33mcommit 5313c2cb8b3bcf7f71c0e6024c59d120efe94d88[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat Dec 2 16:37:44 2023 -0800

    Add Production Metrics in Prometheus format (#1890)

[33mcommit 5f09cbdb63a5821d365b72318bcd92b8ffd03fb4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Dec 2 16:06:17 2023 -0800

    Fix broken sampler tests (#1896)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit 4cefa9b49b6cb2be6d7eac88315df65e0f0d8c9a[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sat Dec 2 15:52:47 2023 -0800

    [Docs] Update the AWQ documentation to highlight performance issue (#1883)

[33mcommit f86bd6190ad300051fce5f0a13ba03b29e5e199a[m
Author: Jerry <71265541+xukp20@users.noreply.github.com>
Date:   Fri Dec 1 18:06:36 2023 +0800

    Fix the typo in SamplingParams' docstring (#1886)

[33mcommit e5452ddfd6e9a08d5e15bd81a010934550b9b507[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 30 20:03:58 2023 -0800

    Normalize head weights for Baichuan 2 (#1876)

[33mcommit d06980dfa7e8dcc1738656beb46d3735c86faa21[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 30 18:35:50 2023 -0800

    Fix Baichuan tokenizer error (#1874)

[33mcommit 66785cc05c05c7f19f319533c23d1998b9d80bf9[m
Author: Adam Brusselback <adambrusselback@gmail.com>
Date:   Thu Nov 30 19:43:13 2023 -0500

    Support chat template and `echo` for chat API (#1756)

[33mcommit 05a38612b0f2895e480f08dfd77d1b5697c3ed42[m
Author: Massimiliano Pronesti <massimiliano.pronesti@gmail.com>
Date:   Thu Nov 30 19:57:44 2023 +0100

    docs: add instruction for langchain (#1162)

[33mcommit d27f4bae393214b4e7715fc3cb5754d4bf801bce[m
Author: Roy <jasonailu87@gmail.com>
Date:   Fri Dec 1 00:29:28 2023 +0800

    Fix rope cache key error (#1867)

[33mcommit 8d8c2f6ffe305bc25725800827208e851649e2d3[m
Author: aisensiy <aisensiy@163.com>
Date:   Fri Dec 1 00:10:24 2023 +0800

    Support max-model-len argument for throughput benchmark (#1858)

[33mcommit 51d3cb951d5666b518a937f90477fe131d61c687[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 30 00:00:32 2023 -0800

    Remove max_num_seqs in latency benchmark script (#1855)

[33mcommit e74b1736a1f1673e7823a68442cbf574d4493390[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Nov 29 23:42:52 2023 -0800

    Add profile option to latency benchmark script (#1839)

[33mcommit f07c1ceaa5162e2ad3b127e06b162508dc57e4db[m
Author: Allen <allenhaozi@gmail.com>
Date:   Thu Nov 30 15:06:50 2023 +0800

    [FIX] Fix docker build error (#1831) (#1832)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit 63b2206ad01499921428ba50c85a18c92772f26c[m
Author: Jee Li <pandaleefree@163.com>
Date:   Thu Nov 30 15:06:27 2023 +0800

    Avoid multiple instantiations of the RoPE class (#1828)

[33mcommit 27feead2f80f906de88d64c6e69342451cf1d7f0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Nov 29 22:16:37 2023 -0800

    Refactor Worker & InputMetadata (#1843)

[33mcommit c782195662bd0beee20eef3f9d630379eff1415a[m
Author: Michael McCulloch <MichaelMcCulloch@users.noreply.github.com>
Date:   Wed Nov 29 22:50:02 2023 -0700

    Disable Logs Requests should Disable Logging of requests. (#1779)
    
    Co-authored-by: Michael McCulloch <mjm.gitlab@fastmail.com>

[33mcommit 0f621c2c7dfe409b6e24e8810dc039745b9a8a7a[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Wed Nov 29 18:33:56 2023 -0800

    [Docs] Add information about using shared memory in docker (#1845)

[33mcommit a9e4574261a20d4ada213d26671da7dc7633580b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Nov 29 15:37:31 2023 -0800

    Refactor Attention (#1840)

[33mcommit 0229c386c541a293f18a9ffe1a5cd7735d487158[m
Author: FlorianJoncour <148003496+FlorianJoncour@users.noreply.github.com>
Date:   Wed Nov 29 21:25:43 2023 +0000

    Better integration with Ray Serve (#1821)
    
    Co-authored-by: FlorianJoncour <florian@zetta-sys.com>

[33mcommit a7b3e33078469943d2a11b1c3d634e220b71bf76[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Nov 29 13:01:19 2023 -0800

    [Fix] Fix RoPE in ChatGLM-32K (#1841)

[33mcommit e19a64c7eff2085790dbf71851208fa2dd31ca4d[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Nov 28 16:56:43 2023 -0800

    [FIX] Fix formatting error in main branch (#1822)

[33mcommit 1cb4ad8de98b672873dbfc1f246fbceae29234a5[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Nov 29 00:40:19 2023 +0000

    [FIX] Fix formatting error

[33mcommit 6ed068a71a58110f41c9cba76035f4c086840eb1[m
Author: explainerauthors <152090505+explainerauthors@users.noreply.github.com>
Date:   Tue Nov 28 16:34:05 2023 -0800

    Use the type BlockTable (#1791)

[33mcommit 708e6c18b0eff37643458424391bcc68ef7f3467[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Nov 28 14:08:01 2023 -0800

    [FIX] Fix class naming (#1803)

[33mcommit b9438904842b729f622f286447fc22c94bd2735f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Nov 28 11:22:44 2023 -0800

    Fix OPT param names (#1819)

[33mcommit a1125ad4df7011e74bbbcf88d268e521278161fa[m
Author: explainerauthors <152090505+explainerauthors@users.noreply.github.com>
Date:   Tue Nov 28 10:19:35 2023 -0800

    Correct comments in parallel_state.py (#1818)

[33mcommit a8b150c5950a353d458b47ce319585698ef41e3f[m
Author: ljss <31004720+beginlner@users.noreply.github.com>
Date:   Tue Nov 28 03:18:26 2023 +0800

    Init model on GPU to reduce CPU memory footprint (#1796)

[33mcommit 665cbcec4b963f6ab7b696f3d7e3393a7909003d[m
Author: Yunmo Chen <16273544+wanmok@users.noreply.github.com>
Date:   Mon Nov 27 13:29:17 2023 +0800

    Added echo function to OpenAI API server. (#1504)

[33mcommit 7c600440f7560348e571f021f2b2d1469de5264d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 23 23:04:44 2023 -0800

    Fix model docstrings (#1764)

[33mcommit e0c6f556e85053059c74ab6b5cee396baf3b4316[m
Author: Yanming W <yanmwang@amazon.com>
Date:   Thu Nov 23 16:31:19 2023 -0800

    [Build] Avoid building too many extensions (#1624)

[33mcommit de23687d168ebeaa8872c27f05b8292bab0fac71[m
Author: ljss <31004720+beginlner@users.noreply.github.com>
Date:   Thu Nov 23 06:41:44 2023 +0800

    Fix repetition penalty aligned with huggingface (#1577)

[33mcommit 4cea74c73b2e0981aadfefb3a00e8186d065c897[m
Author: ljss <31004720+beginlner@users.noreply.github.com>
Date:   Thu Nov 23 04:51:09 2023 +0800

    Set top_p=0 and top_k=-1 in greedy sampling (#1748)

[33mcommit a921d8be9dd8b98795b4d8076f3af4f48dc3d24d[m
Author: Casper <casperbh.96@gmail.com>
Date:   Wed Nov 22 21:31:27 2023 +0100

    [DOCS]¬†Add engine args documentation (#1741)

[33mcommit 094f716bf2cdc213f2b812dbb489fbf6f4a4423c[m
Author: ÈôàÂ∫è <chenxu2048@gmail.com>
Date:   Wed Nov 22 12:13:53 2023 +0800

    Add stop_token_ids in SamplingParams.__repr__ (#1745)

[33mcommit 7d761fe3c12e87df37383467c43c97dec2bb8470[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Nov 20 23:56:48 2023 -0800

    [FIX] Fix the case when `input_is_parallel=False` for `ScaledActivation` (#1737)

[33mcommit cf35d8f3d7210c7cdf282e96d1bce10613db5279[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Nov 20 21:42:45 2023 -0800

    [BugFix] Fix TP support for AWQ (#1731)

[33mcommit 4bb6b67188f1073419555a2c214ca8d2b571467c[m
Author: boydfd <boydfd@163.com>
Date:   Tue Nov 21 11:02:42 2023 +0800

    fix RAM OOM when load large models in tensor parallel mode. (#1395)
    
    Co-authored-by: ran_lin <rlin@thoughtworks.com>

[33mcommit 819b18e7ba7f179ba90e44b2a846ddbdd1b0763d[m
Author: ljss <31004720+beginlner@users.noreply.github.com>
Date:   Tue Nov 21 09:46:32 2023 +0800

    Rewrite torch.repeat_interleave to remove cpu synchronization (#1599)

[33mcommit 19849db573466eff7a83a4c203948c761a6cda85[m
Author: Zhuofan <44121452+linotfan@users.noreply.github.com>
Date:   Tue Nov 21 08:10:50 2023 +0800

    [Fix] Fix bugs in scheduler (#1727)

[33mcommit 3d4ceb292c1c03863daf2316b8123b17307050c3[m
Author: ÈôàÂ∫è <chenxu2048@gmail.com>
Date:   Tue Nov 21 08:06:49 2023 +0800

    Fix hanging in the scheduler caused by long prompts (#1534)

[33mcommit f5a37c6c6c8204ec42187525ebdb8288cfc4b552[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Nov 20 15:51:18 2023 -0800

    [BugFix] Fix a bug in loading safetensors (#1732)

[33mcommit 32c927b53f59ef49d0489f493c66d20b16c0d2ec[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Nov 20 12:46:24 2023 -0800

    [FIX] Update the doc link in README.md (#1730)

[33mcommit 5ffc0d13a2d38050ba44c2efd848910d87ceb57e[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Mon Nov 20 11:58:01 2023 -0800

    Migrate linter from `pylint` to `ruff` (#1665)

[33mcommit 112627e8b26ccbbee19d894c2c4c4d953970a6fd[m
Author: Wen Sun <35923278+HermitSun@users.noreply.github.com>
Date:   Mon Nov 20 17:22:39 2023 +0800

    [Docs] Fix the code block's format in deploying_with_docker page (#1722)

[33mcommit 37c1e3c218ed9987cb6e1a52a2efdeed2e3c304a[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Sun Nov 19 20:56:26 2023 -0800

    Documentation about official docker image (#1709)

[33mcommit 06e9ebebd51c3db779dedec5556251c8ecc3a00a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Nov 18 23:48:58 2023 -0800

    Add instructions to install vLLM+cu118 (#1717)

[33mcommit c5f7740d89737744438e08c26da1d4fbadcb3893[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Nov 18 21:57:07 2023 -0800

    Bump up to v0.2.2 (#1689)

[33mcommit be66d9b1252bdc8aa198106a819583f104928d44[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Nov 18 21:49:55 2023 -0800

    Fix warning msg on quantization (#1715)

[33mcommit e1054247ba28aed104a1a26bbca86bac70d642af[m
Author: ljss <31004720+beginlner@users.noreply.github.com>
Date:   Sun Nov 19 10:18:02 2023 +0800

    [Optimization] Implement fused add rmsnorm (#1667)

[33mcommit 8d17774f924da6a3b730289f351205f3b17095c6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Nov 18 17:56:47 2023 -0800

    Add AWQ support for all models (#1714)

[33mcommit e946260cf3c7a9d5a463a1babae4cebb433f7ffd[m
Author: twaka <twaka@users.noreply.github.com>
Date:   Sun Nov 19 09:45:18 2023 +0900

    use get_tensor in safe_open (#1696)

[33mcommit edb305584bda536ee2b35db9c3e0615b43a5ee02[m
Author: liuyhwangyh <liuyhwangyh@163.com>
Date:   Sat Nov 18 12:38:31 2023 +0800

    Support download models from www.modelscope.cn (#1588)

[33mcommit bb00f66e19acdf6cb614683ab74f777ed3932eee[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Nov 17 16:23:49 2023 -0800

    Use `quantization_config` in hf config (#1695)

[33mcommit e87557b069db2b945563c5d7a27ddc27b8361105[m
Author: Roy <jasonailu87@gmail.com>
Date:   Sat Nov 18 08:20:49 2023 +0800

    Support Min P Sampler (#1642)

[33mcommit dcc543a298f0e3af670f329367ba13cd07f68342[m
Author: Zhuofan <44121452+linotfan@users.noreply.github.com>
Date:   Sat Nov 18 01:42:49 2023 +0800

    [Minor] Fix comment (#1704)

[33mcommit 0fc280b06cd0cc562281b55b0b70248b119f575b[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Nov 16 18:46:26 2023 -0800

    Update the adding-model doc according to the new refactor (#1692)

[33mcommit 20d0699d49a730661434f8374ba495714a92f953[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Nov 16 16:28:39 2023 -0800

    [Fix] Fix comm test (#1691)

[33mcommit 686f5e321096f3a843a23a89fa4a3f28e586c26f[m
Author: Iskren Ivov Chernev <me@iskren.info>
Date:   Fri Nov 17 01:28:36 2023 +0200

    Return usage for openai streaming requests (#1663)

[33mcommit 415d1095278d896135728a54b4307dde3bc83243[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Nov 16 14:47:26 2023 -0800

    [Fix] Update Supported Models List (#1690)

[33mcommit 521b35f799d8d7e22961a79e41256ff770ab2b95[m
Author: maximzubkov <47659865+maximzubkov@users.noreply.github.com>
Date:   Thu Nov 16 23:28:39 2023 +0100

    Support Microsoft Phi 1.5 (#1664)

[33mcommit cb08cd0d754f5ac352e31bf362062ba61403eb02[m
Author: Simon Mo <simon.mo@hey.com>
Date:   Thu Nov 16 13:11:41 2023 -0800

    [Minor] Fix duplication of ignored seq group in engine step (#1666)

[33mcommit 2a2c135b41e8894a8feb1a2b8a434bb23d3eb623[m
Author: twaka <twaka@users.noreply.github.com>
Date:   Fri Nov 17 03:38:10 2023 +0900

    Fix loading error when safetensors contains empty tensor (#1687)

[33mcommit 65ea2ddf172a7234017f11d161ce87141deff3a2[m
Author: Aaron Pham <29749331+aarnphm@users.noreply.github.com>
Date:   Thu Nov 16 04:31:06 2023 -0500

    feat(config): support parsing torch.dtype (#1641)
    
    Signed-off-by: Aaron <29749331+aarnphm@users.noreply.github.com>

[33mcommit b514d3c4960eb10c9963a6a582540e2aafafcfbb[m
Author: Megha Agarwal <16129366+megha95@users.noreply.github.com>
Date:   Thu Nov 16 01:19:39 2023 -0800

    Revert `MptConfig` to `MPTConfig`   (#1668)

[33mcommit 7076fa1c9f5769469bc2671afaca5af604a9bed3[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Nov 15 22:50:41 2023 -0800

    TP/quantization/weight loading refactor part 2 - Refactor quantized linear logic and extend quantization support to all models (#1622)
    
    Refactor the tensor parallelism, quantization, and weight-loading codes.
    
    Summary of the new features enabled by this PR:
    - **All models** are able to be quantized with AWQ and SqueezeLLM, and [soon GPTQ](https://github.com/vllm-project/vllm/pull/1580).
    - Model loading code became much simpler.
    - Support model parallelism for all MQA/GQA models when the number of key/value heads is smaller than the tensor parallel size.

[33mcommit 660a7fcfa40d62305ecba6bc6352c4026d56d680[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Nov 14 12:35:30 2023 -0800

    Add DeepSpeed MII backend to benchmark script (#1649)

[33mcommit 054072bee534faa9fae53dd9c14e91873d76204a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Nov 12 16:04:50 2023 -0800

    [Minor] Move RoPE selection logic to `get_rope` (#1633)

[33mcommit eb825c1e7401a6d9ebb2b3d8d693df0069b80ccb[m
Author: lirui <30922859+lihuahua123@users.noreply.github.com>
Date:   Mon Nov 13 07:53:12 2023 +0800

    Fix #1474 - AssertionError:assert param_slice.shape == loaded_weight.shape (#1631)

[33mcommit 1b290ace4f0c6b74d7536b1acc831e43e9771527[m
Author: Dominik Schwabe <schwabedominik@gmail.com>
Date:   Sat Nov 11 23:50:44 2023 +0100

    Run default _AsyncLLMEngine._run_workers_async in threadpool (#1628)

[33mcommit 0d578228ca220c120bb73316c1d35d078a5bd7b1[m
Author: Sin <edad811@gmail.com>
Date:   Fri Nov 10 11:29:51 2023 +0800

    config parser: add ChatGLM2 seq_length to `_get_and_verify_max_len` (#1617)

[33mcommit aebfcb262a2c6a66f96d8a82efc4ac4c35092222[m
Author: GhaziSyed <115798228+GhaziSyed@users.noreply.github.com>
Date:   Thu Nov 9 20:49:02 2023 +0100

    Dockerfile: Upgrade Cuda to 12.1 (#1609)

[33mcommit ab9e8488d57687d1144e7b4802d195f35882ecdc[m
Author: forpanyang <138085590+forpanyang@users.noreply.github.com>
Date:   Fri Nov 10 03:47:14 2023 +0800

    Add Yi model to quantization support (#1600)

[33mcommit fd58b73a40d937ea6d2c55e5a8147cc0a605efe2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Nov 9 03:52:29 2023 -0800

    Build CUDA11.8 wheels for release (#1596)

[33mcommit 8efe23f15087222540ec076ed00785544442c02f[m
Author: Yanming W <yanmingwang01@gmail.com>
Date:   Thu Nov 9 06:19:12 2023 +0800

    Fix input_metadata.selected_token_indices in worker prepare_inputs (#1546)

[33mcommit 06458a0b42449398aa2ba001d9dbaff256159448[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Nov 8 14:17:49 2023 -0800

    Upgrade to CUDA 12 (#1527)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 1a2bbc930135cd3b94fbff2aafbdf5c568acc8bd[m
Author: GoHomeToMacDonal <143197337+GoHomeToMacDonal@users.noreply.github.com>
Date:   Tue Nov 7 08:09:33 2023 +0800

    ChatGLM Support (#1261)

[33mcommit e7f579eb97f8129acec28804fb74d61f4f9b1ddf[m
Author: Roy <jasonailu87@gmail.com>
Date:   Tue Nov 7 07:26:03 2023 +0800

    Support Yi model (#1567)

[33mcommit 8516999495114926c9838c2d6e0feb580d4d983f[m
Author: Casper <casperbh.96@gmail.com>
Date:   Sun Nov 5 06:43:39 2023 +0100

    Add Quantization and AutoAWQ to docs (#1235)

[33mcommit 9f669a9a7c2b2d0a7963a6e29253280e57680adb[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Nov 3 14:12:48 2023 -0700

    Support YaRN models (#1264)
    
    Signed-off-by: Antoni Baum <antoni.baum@protonmail.com>
    Co-authored-by: Viktor Ferenczi <viktor@ferenczi.eu>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 555bdcc5a3c67779ec80c9fc89323ce8cb05913f[m
Author: Noam Gat <noamgat@gmail.com>
Date:   Fri Nov 3 23:12:15 2023 +0200

    Added logits processor API to sampling params (#1469)

[33mcommit 54ca1ba71deda7eb54f6c9d5002db43039e9edf3[m
Author: lots-o <39071632+lots-o@users.noreply.github.com>
Date:   Sat Nov 4 01:14:52 2023 +0900

    docs: add description (#1553)

[33mcommit 9738b84a08957eb828669e8af27337ee722e8fdc[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Nov 1 16:24:32 2023 -0700

    Force paged attention v2 for long contexts (#1510)

[33mcommit 1fe09900238870a0477fa638dbd2d2bd2f251e1d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Nov 1 15:29:05 2023 -0700

    Remove `MPTConfig` (#1529)

[33mcommit 7e90a2d11785b4cba5172f13178adb6d194a867f[m
Author: Fluder-Paradyne <121793617+Fluder-Paradyne@users.noreply.github.com>
Date:   Wed Nov 1 22:59:44 2023 +0530

    Add `/health` Endpoint for both Servers  (#1540)

[33mcommit 5687d584fe4825d59a6fd9ecc5840e1df04e380f[m
Author: ljss <31004720+beginlner@users.noreply.github.com>
Date:   Wed Nov 1 17:14:18 2023 +0800

    [BugFix] Set engine_use_ray=True when TP>1 (#1531)

[33mcommit cf8849f2d6ea0a6ab76c94d2f585e02aea9e1512[m
Author: Wenfei Yan <87323464+wenfeiy-db@users.noreply.github.com>
Date:   Tue Oct 31 15:46:53 2023 -0700

    Add `MptForCausalLM` key in model_loader (#1526)

[33mcommit e575df33b1963212f79b2efddd45d53225fa5c45[m
Author: Cade Daniel <edacih@gmail.com>
Date:   Tue Oct 31 15:39:38 2023 -0700

    [Small] Formatter only checks lints in changed files (#1528)

[33mcommit 0ce8647dc5bc89074541447d8d410aae0d912173[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Oct 31 15:19:30 2023 -0700

    Fix integer overflows in attention & cache ops (#1514)

[33mcommit 9cabcb76453e7d8384d1858663f1841cef174c2c[m
Author: Stephen Krider <72541272+skrider@users.noreply.github.com>
Date:   Tue Oct 31 12:36:47 2023 -0700

    Add Dockerfile (#1350)

[33mcommit 7b895c5976a81cb1428b24b56fcc4d3716b53710[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Oct 31 09:04:47 2023 -0700

    [Fix] Fix duplicated logging messages (#1524)

[33mcommit 7013a80170146ca4f7fd9539e4d7fd852d4718b6[m
Author: Dan Lord <blahblahasdf@gmail.com>
Date:   Mon Oct 30 16:52:56 2023 -0700

    Add support for `spaces_between_special_tokens`

[33mcommit 79a30912b8d6e9867e56a579cf93d56bf30c955e[m
Author: Jared Roesch <roeschinc@gmail.com>
Date:   Mon Oct 30 14:50:47 2023 -0700

    Add py.typed so consumers of vLLM can get type checking (#1509)
    
    * Add py.typed so consumers of vLLM can get type checking
    
    * Update py.typed
    
    ---------
    Co-authored-by: aarnphm <29749331+aarnphm@users.noreply.github.com>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 2f3d36a8a1485ae372071eb93f822ef9f592d957[m
Author: Adam Brusselback <adambrusselback@gmail.com>
Date:   Mon Oct 30 13:02:21 2023 -0400

    Fix logging so we actually get info level entries in the log. (#1494)

[33mcommit ac8d36f3e5776e020eb32a08eb3a2f9c60a49344[m
Author: iongpt <135581102+iongpt@users.noreply.github.com>
Date:   Mon Oct 30 18:14:37 2023 +0200

    Refactor LLMEngine demo script for clarity and modularity (#1413)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 15f5632365a98fd43ea42e4948a995aa399e99b5[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Oct 30 09:01:34 2023 -0700

    Delay GPU->CPU sync in sampling (#1337)

[33mcommit aa9af07cac7b681d7195dbd5de621fc5a2acde99[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Oct 30 00:24:18 2023 +0100

    Fix bias in InternLM (#1501)

[33mcommit 69be658bba3fcd97fbe23246406c64bd3f1cbe93[m
Author: ljss <31004720+beginlner@users.noreply.github.com>
Date:   Mon Oct 30 01:02:41 2023 +0800

    Support repetition_penalty (#1424)

[33mcommit beac8dd4615566f153d2d8e8b74e703a4df18ce4[m
Author: Ricardo Lu <37237570+gesanqiu@users.noreply.github.com>
Date:   Sun Oct 29 19:26:36 2023 +0800

    fix: don't skip first special token. (#1497)

[33mcommit 28b47d1e490b2b13ec282ac1cbe0eb51f908bfbd[m
Author: Qing <cwq1913@gmail.com>
Date:   Sun Oct 29 19:25:21 2023 +0800

    Add rope_scaling to Aquila model (#1457)

[33mcommit 1f24755bf802a2061bd46f3dd1191b7898f13f45[m
Author: chooper1 <54963573+chooper1@users.noreply.github.com>
Date:   Sun Oct 22 03:14:59 2023 -0300

    Support SqueezeLLM (#1326)
    
    Co-authored-by: squeeze-ai-lab <squeezeailab.bair@gmail.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit bf31d3606a075fe836f4992a37a2052f568de541[m
Author: Thiago Salvatore <thiago.salvatore@gmail.com>
Date:   Sat Oct 21 15:18:58 2023 -0300

    Pin pydantic dependency versions (#1429)

[33mcommit d189170b6c5a143e493c3f5cb7e8c976e8da62c7[m
Author: Wang Ran (Ê±™ÁÑ∂) <wrran@outlook.com>
Date:   Fri Oct 20 23:52:07 2023 +0800

    remove useless statements (#1408)

[33mcommit f61dc8072fbbef76430291ef62d79b7dd265b0e3[m
Author: Light Lin <lxrite@gmail.com>
Date:   Fri Oct 20 23:50:47 2023 +0800

    Fix type hints (#1427)

[33mcommit f8a1e39fae05ca610be8d5a78be9d40f5274e5fc[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Oct 17 01:09:44 2023 -0700

    [BugFix] Define `__eq__` in SequenceGroupOutputs (#1389)

[33mcommit a132435204aac8506e41813f90d08ddf7eca43b2[m
Author: Wang Ran (Ê±™ÁÑ∂) <wrran@outlook.com>
Date:   Tue Oct 17 12:53:37 2023 +0800

    Fix typo (#1383)

[33mcommit 95248677014cb10a9dbaa2e72f688e1a6e6cf566[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Oct 16 17:49:54 2023 -0700

    Add Mistral 7B to `test_models` (#1366)

[33mcommit c1376e0f825e88e32b5aca85c676fe547bcb03c9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Oct 16 17:48:42 2023 -0700

    Change scheduler & input tensor shape (#1381)

[33mcommit 651c614aa43e497a2e2aab473493ba295201ab20[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Oct 16 12:58:57 2023 -0700

    Bump up the version to v0.2.1 (#1355)

[33mcommit d3a5bd9fb7d778c2f2f74bcf8d5343f185f69b61[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Oct 16 12:57:26 2023 -0700

    Fix sampler test (#1379)

[33mcommit e8ef4c0820ff6457f32c17e1470fe47976b35e21[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Oct 16 12:37:56 2023 -0700

    Fix PyTorch index URL in workflow (#1378)

[33mcommit 348897af3112c4e9f6fdc3cd1a7093c98b10e705[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Oct 16 11:27:17 2023 -0700

    Fix PyTorch version to 2.0.1 in workflow (#1377)

[33mcommit 9d9072a069202e7892a40ef94e9085019e73f370[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Oct 16 10:56:50 2023 -0700

    Implement prompt logprobs & Batched topk for computing logprobs (#1328)
    
    Co-authored-by: Yunmo Chen <16273544+wanmok@users.noreply.github.com>

[33mcommit 928de46888b9b257dfa491047a7d9cd199ca585b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Oct 16 00:59:57 2023 -0700

    Implement PagedAttention V2 (#1348)

[33mcommit 29678cd21322f041518541e62992557d293c8597[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Oct 15 21:53:56 2023 -0700

    Minor fix on AWQ kernel launch (#1356)

[33mcommit d0740dff1b3ab06860316d98c937a3d4e143f25f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Oct 14 14:47:43 2023 -0700

    Fix error message on `TORCH_CUDA_ARCH_LIST` (#1239)
    
    Co-authored-by: Yunfeng Bai <yunfeng.bai@scale.com>

[33mcommit de894728979411bc88ecc00ca6bb928c9a8f0231[m
Author: Lu Wang <38018689+lu-wang-dl@users.noreply.github.com>
Date:   Fri Oct 13 11:51:29 2023 -0700

    Fix the issue for AquilaChat2-* models (#1339)

[33mcommit e7c8555d0652e5213353411dd40b99408b1b1b28[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Oct 13 10:05:26 2023 -0700

    Bump up transformers version & Remove MistralConfig (#1254)

[33mcommit ec3b5ce9ccb4262194a16a8b1c31ffd6b3b824b9[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Oct 13 09:59:07 2023 -0700

    Improve detokenization performance (#1338)

[33mcommit 6368e777a8ead7fb62054d3779c6237361ec0d86[m
Author: ldwang <ftgreat@163.com>
Date:   Fri Oct 13 03:11:16 2023 +0800

    Add Aquila2 to README (#1331)
    
    Signed-off-by: ldwang <ftgreat@gmail.com>
    Co-authored-by: ldwang <ftgreat@gmail.com>

[33mcommit 875afe38ab3b622ea2e84162799d5368cfb05257[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Oct 12 01:05:37 2023 -0700

    Add blacklist in model checkpoint (#1325)

[33mcommit ee8217e5bee5860469204ee57077a91138c9af02[m
Author: amaleshvemula <vemulaamalesh1997@gmail.com>
Date:   Wed Oct 11 09:26:24 2023 +0200

    Add Mistral to quantization model list (#1278)

[33mcommit 980dd4a2c4ca965e4b10483258a006b812a1991f[m
Author: CHU Tianxiang <chutianxiang@gmail.com>
Date:   Wed Oct 11 15:19:53 2023 +0800

    Fix overflow in awq kernel (#1295)
    
    Co-authored-by: Ê•öÂ§©Áøî <tianxiang.ctx@alibaba-inc.com>

[33mcommit 82857368400bcf6a12a3d42a3ccdc5f585153404[m
Author: twaka <twaka@users.noreply.github.com>
Date:   Wed Oct 11 11:48:16 2023 +0900

    workaround of AWQ for Turing GPUs (#1252)

[33mcommit 91fce82c6f3e3efd705faa0edd3aa64d328c3c77[m
Author: yhlskt23 <146050887+yhlskt23@users.noreply.github.com>
Date:   Wed Oct 11 11:37:42 2023 +0900

    change the timing of sorting logits (#1309)

[33mcommit ac5cf86aa6aebbf9e42df51f7e377fbee85bc703[m
Author: Wang Ran (Ê±™ÁÑ∂) <wrran@outlook.com>
Date:   Wed Oct 11 00:58:28 2023 +0800

    Fix `__repr__` of `SequenceOutputs` (#1311)

[33mcommit 6a6119554cee13bb4ef5018155be5530d6aaca26[m
Author: yanxiyue <alex.yueye@gmail.com>
Date:   Wed Oct 11 00:21:57 2023 +0800

    lock torch version to 2.0.1 (#1290)

[33mcommit b95ee898fe1ccb77632ed96fba7c517f6e6be931[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Oct 9 19:44:37 2023 -0700

    [Minor] Fix comment in mistral.py (#1303)

[33mcommit 9eed4d1f3e012d52059ae28a956b38f34890376a[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Oct 8 23:15:50 2023 -0700

    Update README.md (#1292)

[33mcommit 6b5296aa3ae632b8f2dcbc78579eb41b28e41068[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Oct 8 15:22:38 2023 -0700

    [FIX] Explain why the finished_reason of ignored sequences are length (#1289)

[33mcommit ee92b58b3ae28a52c2500674de721e7a718432d8[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Sat Oct 7 22:10:44 2023 -0700

    Move bfloat16 check to worker (#1259)

[33mcommit 09ff7f106a1e5ad77f6c2941382d5ba4fd5a0879[m
Author: Yunfeng Bai <83252681+yunfeng-scale@users.noreply.github.com>
Date:   Sat Oct 7 15:15:54 2023 -0700

    API server support ipv4 / ipv6 dualstack (#1288)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit acbed3ef40f015fcf64460e629813922fab90380[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Oct 2 19:22:05 2023 -0700

    Use monotonic time where appropriate (#1249)

[33mcommit 66d18a7fb07d3a9d6e6e46352aea05355a51cfed[m
Author: Federico Cassano <federico.cassano@federico.codes>
Date:   Mon Oct 2 22:19:46 2023 -0400

    add support for tokenizer revision (#1163)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit ba0bfd40e21cacfd5da6a1e43028a37258a29cb4[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Oct 2 15:36:09 2023 -0700

    TP/quantization/weight loading refactor part 1 - Simplify parallel linear logic (#1181)

[33mcommit 84e4e37d1427bd254bea6ff366026773d36f3982[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Oct 2 15:28:31 2023 -0700

    [Minor] Fix type annotations (#1238)

[33mcommit a60b35300553448cb35c6356bab16d8a4b437d7d[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Oct 2 15:26:33 2023 -0700

    support sharding llama2-70b on more than 8 GPUs (#1209)
    
    Co-authored-by: JiCheng <247153481@qq.com>

[33mcommit ebe4d1db3a42096cebcc2b2d289143bc0ef02d3d[m
Author: Liang <44948473+soundOfDestiny@users.noreply.github.com>
Date:   Mon Oct 2 02:35:06 2023 +0800

    Fix boundary check in paged attention kernel (#1241)

[33mcommit b5a10eb0ef68f45c7dbdef2917e02bebca780d1a[m
Author: kg6-sleipnir <45186108+kg6-sleipnir@users.noreply.github.com>
Date:   Sun Oct 1 00:04:03 2023 -0400

    Added `dtype` arg to benchmarks (#1228)

[33mcommit 0967102c6de874902d973f0bcb98d48149a8eb49[m
Author: Usama Ahmed <53372259+0ssamaak0@users.noreply.github.com>
Date:   Fri Sep 29 23:40:25 2023 +0300

    fixing typo in `tiiuae/falcon-rw-7b` model name (#1226)

[33mcommit e2fb71ec9f2c3168ba8614408fa807a5f65707c5[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 28 15:30:38 2023 -0700

    Bump up the version to v0.2.0 (#1212)

[33mcommit f936657eb67671ac594f285ebd5c90c3f8a6dee2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 28 14:44:02 2023 -0700

    Provide default max model length (#1224)

[33mcommit 6f88f762bf907bccdadc52948001b21ccb616a01[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 28 14:33:24 2023 -0700

    Fix OOM in attention kernel test (#1223)

[33mcommit 202351d5bf7a625852316516c0e1d00745bf88ab[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 28 14:33:04 2023 -0700

    Add Mistral to supported model list (#1221)

[33mcommit 2e8e49fce3775e7704d413b2f02da6d7c99525c9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 28 10:52:38 2023 -0700

    [Fix] Remove false assertion (#1222)

[33mcommit a8e98aee0c1625312b5477aa15a7cf1dd58aa576[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 28 10:44:05 2023 -0700

    Fix Mistral model (#1220)

[33mcommit bb1ba58f064731b179d586ae32fdaaaea439098d[m
Author: Chris Bamford <chrisbam4d@gmail.com>
Date:   Thu Sep 28 19:41:03 2023 +0200

    [Mistral] Mistral-7B-v0.1 support (#1196)
    
    Co-authored-by: timlacroix <t@mistral.ai>

[33mcommit 7bedab574891ccdefb02a438b8a28bedd75a3b97[m
Author: Qing <cwq1913@gmail.com>
Date:   Thu Sep 28 15:49:23 2023 +0800

    Add rope_scaling to Qwen (#1210)

[33mcommit 20f7cc4cdebcbcad788fbe1b06e5e07f8d145b77[m
Author: Dan Lord <blahblahasdf@gmail.com>
Date:   Wed Sep 27 19:21:42 2023 -0700

    Add `skip_special_tokens` sampling params (#1186)

[33mcommit 649aa730c5f8c2aefc4a6ead7d50a49c3355ce5a[m
Author: Danilo Peixoto <danilopeixoto@outlook.com>
Date:   Wed Sep 27 21:41:36 2023 -0300

    Use standard extras for uvicorn (#1166)

[33mcommit a19bc5c6281cb1d539043acb06699bf8438bb254[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Sep 27 16:34:00 2023 -0700

    Automatically configure `max_num_batched_tokens` (#1198)

[33mcommit 28e616c4e3ef24d3763de5c5210f2ee20be56f5e[m
Author: Qing <cwq1913@gmail.com>
Date:   Thu Sep 28 07:33:16 2023 +0800

    fix qwen-14b model (#1173)

[33mcommit 30e775281d0ba983e0e2e9904fc9e0fb1a055c20[m
Author: Wang Ran (Ê±™ÁÑ∂) <wangr@smail.nju.edu.cn>
Date:   Thu Sep 28 07:22:45 2023 +0800

    fix typo (#1184)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 21877b0d7523a1202ed279c046d9268baaee3d5c[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Wed Sep 27 03:36:02 2023 -0700

    Support Longchat and RoPE scaling (#555)
    
    Co-authored-by: Wing Lian <wing.lian@gmail.com>
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit cf5cb1e33eed16b2f0d5fe6268bf5705a4d0ea5a[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Sep 26 22:27:13 2023 -0700

    Allocate more shared memory to attention kernel (#1154)

[33mcommit 03ffd0a02251e10c1aa14fca8cb0ab1e4e40b886[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Sep 26 10:48:33 2023 -0700

    Add comments on RoPE initialization (#1176)

[33mcommit a425bd9a9af6b32e0e93b2787d6682a1a5133983[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Sep 26 10:21:08 2023 -0700

    [Setup] Enable `TORCH_CUDA_ARCH_LIST` for selecting target GPUs (#1074)

[33mcommit bbbf86565f2fb2bab0cf6675f9ebefcd449390bd[m
Author: Wen Sun <35923278+HermitSun@users.noreply.github.com>
Date:   Sun Sep 24 09:10:13 2023 +0800

    Align `max_tokens` behavior with openai (#852)

[33mcommit 9f6be8692e09b0ea706ecbb6693c54e210a967f9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Sep 23 17:38:43 2023 -0700

    Fix config for Falcon (#1164)

[33mcommit f187877945ea88fff281b0818443b303681eba7d[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sat Sep 23 17:21:56 2023 -0700

    [FIX] Simplify sampler logic (#1156)

[33mcommit 947b794146aeae41ea17cbbe8bf9e53abc9c3f53[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Fri Sep 22 17:48:04 2023 -0700

    [Sampler] Vectorized sampling (simplified) (#1048)
    
    Co-authored-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit 8d926e91f183a73b92aa3e254e894ecd02018dd5[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Sep 22 11:37:14 2023 -0700

    Announce the First vLLM Meetup (#1148)

[33mcommit 4ee52bb169d64691c3bfe7b1b2fff91300d49095[m
Author: Nick Perez <nickjperez@gmail.com>
Date:   Fri Sep 22 14:36:09 2023 -0400

    Docs: Fix broken link to openai example (#1145)
    
    Link to `openai_client.py` is no longer valid - updated to `openai_completion_client.py`

[33mcommit 7d7e3b78a3c265ab3c57eeff43af56f509907998[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 21 18:26:47 2023 -0700

    Use `--ipc=host` in docker run for distributed inference (#1125)

[33mcommit f98b745a81df1613a9c5f1d5986456663f86c457[m
Author: Ricardo Lu <37237570+gesanqiu@users.noreply.github.com>
Date:   Fri Sep 22 06:34:02 2023 +0800

    feat: support stop_token_ids parameter. (#1097)

[33mcommit 2d1e86f1b15396119321cfb3a77acde72b0c08ee[m
Author: Roy <jasonailu87@hotmail.com>
Date:   Fri Sep 22 04:25:05 2023 +0800

    clean api code, remove redundant background task. (#1102)

[33mcommit 1ac4ccf73c91370f1fcb4f60c1117646cd7a7502[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 21 00:52:47 2023 -0700

    Add float16 and float32 (#1115)

[33mcommit 2ac4d5e2bf033306fdb9b5002b2adbaafb864a3a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 21 00:51:47 2023 -0700

    Replace DtypeTensor (#1123)

[33mcommit 3302f0aef39c392321567ac1400101155e365a29[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Sep 20 13:35:11 2023 -0700

    rope_theta and max_position_embeddings from config (#1096)
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: wnma3mz <wnma3mz@gmail.com>

[33mcommit 6f2dd6c37e984dd254d263007b4be0b60964630c[m
Author: Tanmay Verma <tanmay2592@gmail.com>
Date:   Wed Sep 20 10:32:40 2023 -0700

    Add documentation to Triton server tutorial (#983)

[33mcommit bc0644574ca12d754a031596bdcfe8e1f0e6ab39[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Sep 19 22:16:04 2023 -0700

    Add gpu_memory_utilization and swap_space to LLM (#1090)

[33mcommit 400b8289f744c4b8cdaa2c35268192c23e90d26c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Sep 18 22:36:17 2023 -0700

    Add pyarrow to dependencies & Print warning on Ray import error (#1094)

[33mcommit c1026311b59446d1ada5f950ddbdbe0bb21943b0[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Sep 18 12:23:35 2023 -0700

    [Community] Add vLLM Discord server (#1086)

[33mcommit 2b1c116b5acdf3b738e310f98617875132214c37[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Sep 18 12:02:01 2023 -0700

    Add minimum capability requirement for AWQ (#1064)

[33mcommit cc796b13584419afc741d747c02cb715adb9c019[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Sep 18 11:51:48 2023 -0700

    Convert before transpose (#1073)

[33mcommit f029ef94d72528aaccd7d48f973031e9dff23447[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Sep 18 11:49:40 2023 -0700

    Fix get_max_num_running_seqs for waiting and swapped seq groups (#1068)

[33mcommit 95592fa00a01c1e779137f72814c8091736e1c86[m
Author: Roy <jasonailu87@hotmail.com>
Date:   Tue Sep 19 02:49:10 2023 +0800

    align llm_engine and async_engine. (#1081)

[33mcommit fbe66e1d0b8d1445cb3204150afac74ab075e559[m
Author: orellavie1212 <126397224+orellavie1212@users.noreply.github.com>
Date:   Mon Sep 18 21:04:21 2023 +0300

    added support for quantize on LLM module (#1080)

[33mcommit 90979c38f87c17d53a7cd0eb430373ecb0b64b9a[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Sep 17 17:15:38 2023 -0700

    [FIX] Don't initialize parameter by default (#1067)

[33mcommit e21d7687a9528ce6c1a7123b6223c53e65f37d8a[m
Author: ÈôàÂ∫è <chenxu2048@gmail.com>
Date:   Sun Sep 17 16:48:56 2023 +0800

    Fix hanging when prompt exceeds limit (#1029)

[33mcommit ff36139ffc66294c19b503c1e52dc42c2cd265f6[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Sun Sep 17 00:29:08 2023 -0700

    Remove AsyncLLMEngine busy loop, shield background task (#1059)

[33mcommit e3e79e9e8a2224e03a711c3d1ef7a35daa447083[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Sep 16 00:03:37 2023 -0700

    Implement AWQ quantization support for LLaMA (#1032)
    
    Co-authored-by: Robert Irvine <robert@seamlessml.com>
    Co-authored-by: root <rirv938@gmail.com>
    Co-authored-by: Casper <casperbh.96@gmail.com>
    Co-authored-by: julian-q <julianhquevedo@gmail.com>

[33mcommit b9fe4616f98b77b4b9458bce203aa6544cb31ef2[m
Author: Jerry Yang <rucyang@hotmail.com>
Date:   Fri Sep 15 08:40:18 2023 +0800

    Abort when coroutine is cancelled (#1020)

[33mcommit 64ca424e7518d1176fff032b76d85e49a4fc936a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 14 17:33:32 2023 -0700

    Fix warning message on LLaMA FastTokenizer (#1037)

[33mcommit b5f93d063126dd94518a7773fed74c5b07823719[m
Author: Lukas Kreussel <65088241+LLukas22@users.noreply.github.com>
Date:   Fri Sep 15 02:33:01 2023 +0200

    Only fail if logit_bias has actual values (#1045)

[33mcommit a58936966f5c3fa0d2f2454cc18c3feac8fa056e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Sep 14 17:31:38 2023 -0700

    Add pandas to requirements.txt (#1047)
    
    * Add pandas to requirements.txt
    
    * Minor

[33mcommit dd54a4b026455f728f9d5945eca369b2be7b12f9[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Thu Sep 14 16:37:03 2023 -0700

    Fix detokenization leaving special tokens (#1044)
    
    Signed-off-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit eda1a7cad3b58d33353ce8f4145c66237a65c238[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Sep 13 17:38:13 2023 -0700

    Announce paper release (#1036)

[33mcommit f04908cae782e1a2404eb3e4f331718d311d1e0d[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Sep 13 16:38:12 2023 -0700

    [FIX] Minor bug fixes (#1035)
    
    * [FIX] Minor bug fixes
    
    * Address review comments

[33mcommit ab019eea7513eb1e26ead79cf162863f3f19e971[m
Author: Jasmond L <100826484+JasLoh564@users.noreply.github.com>
Date:   Thu Sep 14 06:20:02 2023 +0800

    Add Model Revision Support (#1014)
    
    Co-authored-by: Jasmond Loh <Jasmond.Loh@hotmail.com>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 9841d48a108b0e14da6572de6be0b47d70bbb641[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Sep 13 13:38:01 2023 -0700

    Use TGI-like incremental detokenization (#984)

[33mcommit 3272d7a0b715a79059ebfcf8959d1ac0488ad18c[m
Author: Ikko Eltociear Ashimine <eltociear@gmail.com>
Date:   Thu Sep 14 04:55:23 2023 +0900

    Fix typo in README.md (#1033)

[33mcommit 0bb1e885a08df59beec7149b1d0d646e24ab1a42[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Sep 12 16:29:19 2023 -0700

    Make `max_model_len` configurable (#972)

[33mcommit d6545ad22ee89c8b6e3eb6cfcf8ff914a06ccee1[m
Author: leiwen83 <leiwen83@users.noreply.github.com>
Date:   Wed Sep 13 06:10:14 2023 +0800

    add option to shorten prompt print in log (#991)
    
    Signed-off-by: Lei Wen <wenlei03@qiyi.com>
    Co-authored-by: Lei Wen <wenlei03@qiyi.com>
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 90eb3f43ca5228647c834243d98881d53c7745d0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Sep 11 00:54:30 2023 -0700

    Bump up the version to v0.1.7 (#1013)

[33mcommit e67b4f2c2a216ff12d4f607caa3ba3409ae3f572[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Sep 11 00:26:35 2023 -0700

    Use FP32 in RoPE initialization (#1004)
    
    Co-authored-by: One <imone@tuta.io>

[33mcommit d6770d1f23b642289a2f1462f2851a7be9d3cc83[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Sep 10 23:42:45 2023 -0700

    Update setup.py (#1006)

[33mcommit b9cecc26359794af863b3484a3464108b7d5ee5f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Sep 10 14:23:31 2023 -0700

    [Docs] Update installation page (#1005)

[33mcommit 898285c9bf306e32c7f161b75bf0bf7fd483f265[m
Author: Kyujin Cho <thy2134@me.com>
Date:   Sun Sep 10 17:39:02 2023 +0900

    fix: CUDA error when inferencing with Falcon-40B base model (#992)

[33mcommit a62de9ecfdc6bfc80db3d0d1136124c74c94ea04[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Sat Sep 9 14:58:35 2023 -0700

    Fix wrong dtype in PagedAttentionWithALiBi bias (#996)
    
    
    ---------
    
    Signed-off-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit 4042d192f5fbad6c95563f2880cd30dac8caf8f2[m
Author: Jingru <niejingru@hotmail.com>
Date:   Sat Sep 9 08:21:30 2023 +0800

    fix "tansformers_module" ModuleNotFoundError when load model with `trust_remote_code=True` (#871)

[33mcommit 1117aa1411d9858ea5eef8a81e044379432e6d0e[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Fri Sep 8 00:07:46 2023 -0700

    Bump up the version to v0.1.6 (#989)

[33mcommit 080438477f319149db4f09f3a8835dde23609f7a[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Sep 8 00:03:39 2023 -0700

    Start background task in `AsyncLLMEngine.generate` (#988)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 4b5bcf89065e0d9247cb1e12635b0d57f67a3a6a[m
Author: Robert Irvine <rirv938@gmail.com>
Date:   Fri Sep 8 06:48:54 2023 +0100

    faster startup of vLLM  (#982)
    
    * update
    
    ---------
    
    Co-authored-by: Robert Irvine <robert@seamlessml.com>

[33mcommit 852ef5b4f5481ce526c804ea234d1de0df91f48d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Sep 8 08:15:31 2023 +0900

    Bump up the version to v0.1.5 (#944)

[33mcommit db09d4ad833b1d8911f14852a484790c53818a5d[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Sep 7 15:53:14 2023 -0700

    [FIX] Fix Alibi implementation in PagedAttention kernel (#945)
    
    * [FIX] Fix Alibi implementation in PagedAttention kernel
    
    * Fix test_attention
    
    * Fix
    
    ---------
    
    Co-authored-by: Woosuk Kwon <woosuk.kwon@berkeley.edu>
    Co-authored-by: Oliver-ss <yuansongwx@outlook.com>

[33mcommit c957c741d9da4bb07a303663e82d826fb5f8c6c4[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Sep 7 15:49:52 2023 -0700

    Enable safetensors loading for all models (#974)

[33mcommit c07ece5ca490a90b2b19c33ab7da2d21e015d7bd[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Thu Sep 7 13:43:45 2023 -0700

    Make `AsyncLLMEngine` more robust & fix batched abort (#969)
    
    Signed-off-by: Antoni Baum <antoni.baum@protonmail.com>
    Co-authored-by: Avnish Narayan <38871737+avnishn@users.noreply.github.com>

[33mcommit 7a9c20c71521f9bfce5bb88fda5a1308b7351c82[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Sep 8 05:15:53 2023 +0900

    Bum up transformers version (#976)

[33mcommit 005ba458b52fe2cf9837201d05644eadcdf10ca0[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Sep 6 23:39:37 2023 -0700

    Set torch default dtype in a context manager (#971)
    
    Signed-off-by: Antoni Baum <antoni.baum@protonmail.com>

[33mcommit 320a622ec4d098f2da5d097930f4031517e7327b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Sep 6 11:54:33 2023 +0900

    [BugFix] Implement RoPE for GPT-J (#941)

[33mcommit c9927c1a6aca1b74d9868397e7b711ea38242e99[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Tue Sep 5 19:27:23 2023 -0700

    Use queue for finished requests (#957)

[33mcommit fbd80ad4092c4bc48ce672f0435c1d1362aee052[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Sep 6 08:57:38 2023 +0900

    Clean up kernel unit tests (#938)

[33mcommit 22379d55130cb3c8d8c2130eedc0eaedf5e209e1[m
Author: Wen Sun <35923278+HermitSun@users.noreply.github.com>
Date:   Tue Sep 5 14:22:30 2023 +0800

    fix: typo (#948)

[33mcommit 1696725879f25de03ca36cde764102bba60ff681[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Mon Sep 4 17:41:22 2023 -0700

    Initialize AsyncLLMEngine bg loop correctly (#943)

[33mcommit 002800f08142574aeafed7c33982503d28d53cdc[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Sep 4 17:29:42 2023 -0700

    Align vLLM's beam search implementation with HF generate (#857)

[33mcommit e15932bb60e645e533a4b2f999bec9c60328e6d3[m
Author: Nelson Liu <nelson-liu@users.noreply.github.com>
Date:   Mon Sep 4 08:50:55 2023 -0700

    Only emit warning about internal tokenizer if it isn't being used (#939)

[33mcommit ce741ba3e4fea00bacd2e1c609ca587ec35eb161[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Sun Sep 3 21:43:43 2023 -0700

    Refactor AsyncLLMEngine (#880)

[33mcommit bf87484efac9812b5854266025f86bbb21894e4b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Sep 4 09:20:06 2023 +0900

    [BugFix] Fix NaN errors in paged attention kernel (#936)

[33mcommit 8ce9c50d4034de3c557b520935fac1d6dac585a0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Sep 2 14:59:47 2023 +0900

    Avoid compiling kernels for double data type (#933)

[33mcommit 32b6816e556f69f1672085a6267e8516bcb8e622[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Sep 1 11:19:43 2023 +0900

    Add tests for models (#922)

[33mcommit c128d69856200543e6bff40956f95858a826d63c[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Aug 31 17:18:34 2023 -0700

    Fix README.md Link (#927)

[33mcommit 55b28b1eee3a94a8b1c812d461f68ff8f150d38e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Sep 1 08:28:39 2023 +0900

    [Docs] Minor fixes in supported models (#920)
    
    * Minor fix in supported models
    
    * Add another small fix for Aquila model
    
    ---------
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit e11222333f43c8466c57d0223380dcf297b02bac[m
Author: Dong-Yong Lee <pfldy2850@gmail.com>
Date:   Fri Sep 1 00:37:17 2023 +0900

    fix: bug fix when penalties are negative (#913)
    
    Co-authored-by: dongyong-lee <dongyong.lee@navercorp.com>

[33mcommit 28873a2799ddfdd0624edd4619e6fbeeb49cd02c[m
Author: Aman Gupta Karmani <aman@tmm1.net>
Date:   Thu Aug 31 00:28:43 2023 -0400

    Improve _prune_hidden_states micro-benchmark (#707)

[33mcommit 0080d8329d272f06627286984be8038b0ca9d590[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Aug 30 02:17:27 2023 -0700

    Add acknowledgement to a16z grant

[33mcommit 0d93f15694273417372561e9e5c191ed9ce4d77a[m
Author: JFDuan <30710061+JF-D@users.noreply.github.com>
Date:   Wed Aug 30 16:00:13 2023 +0800

    Accelerate LLaMA model loading (#234)

[33mcommit becd7a56f115f425e8ca99c785b12d545ac30042[m
Author: lplcor <11920339+Peilun-Li@users.noreply.github.com>
Date:   Tue Aug 29 21:54:08 2023 -0700

    Enable request body OpenAPI spec for OpenAI endpoints (#865)

[33mcommit 75471386de62eef044568bf4425b63d410fde11f[m
Author: Aman Gupta Karmani <aman@tmm1.net>
Date:   Wed Aug 30 00:52:13 2023 -0400

    use flash-attn via xformers (#877)

[33mcommit d2b2eed67c49cdda3c1d6fa09ee2ec128b318138[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Aug 27 23:00:56 2023 -0700

    [Fix] Fix a condition for ignored sequences (#867)

[33mcommit 4b6f069b6fbb4f2ef7d4c6a62140229be61c5dd3[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Fri Aug 25 12:44:07 2023 -0700

    Add support for CodeLlama (#854)

[33mcommit 791d79de3261402fae1b9d0b1650655071a68095[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Aug 25 12:28:00 2023 +0900

    Bump up the version to v0.1.4 (#846)

[33mcommit 94d2f598956dbd5ab8a6097d6eaa8176035d3220[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Aug 25 12:22:01 2023 +0900

    Set replacement=True in torch.multinomial (#858)

[33mcommit 75c0ca9d432199d336e0bc6ae854aa1d35ba35ce[m
Author: wenjun93 <gwj1235@yeah.net>
Date:   Thu Aug 24 07:44:15 2023 +0800

    Clean up code (#844)

[33mcommit 2a4ec90854ae3ad08a3593cb4896dfce601974c3[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Aug 23 17:44:21 2023 +0900

    Fix for breaking changes in xformers 0.0.21 (#834)

[33mcommit 85ebcda94d6031761938ac8551d7a467ec77699a[m
Author: ldwang <ftgreat@163.com>
Date:   Wed Aug 23 11:48:36 2023 +0800

    Fix typo of Aquila in README.md (#836)

[33mcommit d64bf1646c19123bf236d5ba1c02b75ee3d68306[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Aug 23 07:43:21 2023 +0900

    Implement approximate GELU kernels (#828)

[33mcommit a41c20435eab2abf3584144a056deed9ebe9f18e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Aug 23 07:28:38 2023 +0900

    Add compute capability 8.9 to default targets (#829)

[33mcommit eedac9dba0e586820a797685dab26807439a3c2c[m
Author: Wen Sun <35923278+HermitSun@users.noreply.github.com>
Date:   Wed Aug 23 02:55:16 2023 +0800

    fix: revert code to avoid no attribute problem (#827)

[33mcommit 14f9c72bfdd6c90cbcb52bcfa34f33f56cbe323f[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Aug 22 11:51:44 2023 -0700

    Update Supported Model List (#825)

[33mcommit ad5f2fe34cf2b3564a2d71500a7a096e25065734[m
Author: shunxing1234 <33774367+shunxing1234@users.noreply.github.com>
Date:   Tue Aug 22 15:13:36 2023 +0800

    Add support for aquila (#663)
    
    * add aquila
    
    Signed-off-by: ftgreat <ftgreat@163.com>
    
    * fix some bug
    
    Signed-off-by: shunxing1234 <xw747777271@gmail.com>
    
    * delete pdb
    
    Signed-off-by: shunxing1234 <xw747777271@gmail.com>
    
    * fix bugs
    
    Signed-off-by: shunxing1234 <xw747777271@gmail.com>
    
    * fix bugs
    
    Signed-off-by: shunxing1234 <xw747777271@gmail.com>
    
    * delete whitespace
    
    Signed-off-by: shunxing1234 <xw747777271@gmail.com>
    
    * format
    
    * fix order
    
    ---------
    
    Signed-off-by: ftgreat <ftgreat@163.com>
    Signed-off-by: shunxing1234 <xw747777271@gmail.com>
    Co-authored-by: ftgreat <ftgreat@163.com>

[33mcommit 4f8584756d79234bd8207201273490907340b4bb[m
Author: zhaoyang-star <zhaoyangstar@foxmail.com>
Date:   Tue Aug 22 13:22:06 2023 +0800

    Fix mqa is false case in gpt_bigcode (#806)

[33mcommit 65fc1c3127f4df8a99a0a5db4a205dbfcc673713[m
Author: Xudong Zhang <zxdvd_zhang@163.com>
Date:   Tue Aug 22 07:05:44 2023 +0800

    set default coompute capability according to cuda version (#773)

[33mcommit c393af6cd70373ab88b22dbbe59e14bb80ea343d[m
Author: Daniel <Danielphone221299@gmail.com>
Date:   Mon Aug 21 10:59:15 2023 +0300

    [Feature | CI] Added a github action to build wheels (#746)

[33mcommit 0c04ce323448af8cb576f9698f907ef2e6a8c1d0[m
Author: wangcx18 <wangcx18@hotmail.com>
Date:   Fri Aug 18 09:12:46 2023 +0800

    Fix typo in sampling_params.py (#788)

[33mcommit 73b3de79eae5dec7459d54888083e5068890799b[m
Author: Xinyu Yang <cauyxy@163.com>
Date:   Fri Aug 18 03:56:04 2023 +0800

    explicitly del state (#784)

[33mcommit d1744376ae9fdbfa6a2dc763e1c67309e138fa3d[m
Author: Abraham-Xu <35354142+Abraham-Xu@users.noreply.github.com>
Date:   Wed Aug 16 07:44:33 2023 +0800

    Align with huggingface Top K sampling (#753)

[33mcommit 805de738f618f8b47ab0d450423d23db1e636fa2[m
Author: Ikko Eltociear Ashimine <eltociear@gmail.com>
Date:   Tue Aug 15 14:26:36 2023 +0900

    Fix typo in tokenizer.py (#750)
    
    conjuction -> conjunction

[33mcommit 1b151ed181f5ef0d267c1cf6d15d6f6f43e302ed[m
Author: Uranus <109661872+UranusSeven@users.noreply.github.com>
Date:   Mon Aug 14 11:57:31 2023 +0800

    Fix baichuan doc style (#748)

[33mcommit e06f504a761aba85ba34472d6c2544b626c311a8[m
Author: WanMok <16273544+wanmok@users.noreply.github.com>
Date:   Fri Aug 11 12:14:34 2023 -0700

    Supports tokens and arrays of tokens as inputs to the OpenAI completion API (#715)

[33mcommit 462ae5220aeeb2135b841107d2c841f85fc348bd[m
Author: WRH <12756472+wangruohui@users.noreply.github.com>
Date:   Sat Aug 12 02:40:37 2023 +0800

    [Fix] unwantted bias in InternLM Model (#740)

[33mcommit 66c54aa9c33555a6b41421d57d3ad6c1bf004ec9[m
Author: Nicolas Basile <nbasile@usc.edu>
Date:   Tue Aug 8 17:43:49 2023 -0700

    Check the max prompt length for the OpenAI completions API (#472)

[33mcommit 735ecfff61f62b78bd1455c65e8e27dc36febce1[m
Author: Jia Guoqing <jiaguoqing12138@gmail.com>
Date:   Wed Aug 9 07:35:06 2023 +0800

    add internlm model (#528)

[33mcommit a57d13cc967d04478cebcfa2c3440fb167b21c6d[m
Author: Qing <cwq1913@gmail.com>
Date:   Wed Aug 9 04:50:38 2023 +0800

    add QWen-7b (#685)
    
    Co-authored-by: wq.chu <wq.chu@tianrang-inc.com>

[33mcommit 79af7e96a0e2fc9f340d1939192122c3ae38ff17[m
Author: Dean Leitersdorf <dean.leitersdorf@gmail.com>
Date:   Fri Aug 4 20:57:29 2023 +0300

    [OPTIMIZATION] Optimizes the single_query_cached_kv_attention kernel (#420)

[33mcommit 621980bdc0d5a41e224febf962a6e0474e2b14ef[m
Author: Wen Sun <35923278+HermitSun@users.noreply.github.com>
Date:   Sat Aug 5 01:35:22 2023 +0800

    fix: incorrect bigcode attention heads num (#676)

[33mcommit aa84c92ef636e689b506b9842c712e5c615cc73a[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Aug 2 16:46:53 2023 -0700

    Bump up version to 0.1.3 (#657)

[33mcommit f7389f4763c37579d249d0f9d80917e2ecfc4ead[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Aug 2 16:45:12 2023 -0700

    [Doc] Add Baichuan 13B to supported models (#656)

[33mcommit 55fe8a81ec5deab319c7c6b02913c21273b764ca[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Aug 2 16:42:01 2023 -0700

    Refactor scheduler (#658)

[33mcommit e8ddc08ec85495e5faca31bdf9129e0bf59a4fac[m
Author: YHPeter <44126839+YHPeter@users.noreply.github.com>
Date:   Wed Aug 2 17:05:59 2023 -0400

    [BUG FIX] upgrade fschat version to 0.2.23 (#650)
    
    Co-authored-by: hao.yu <hao.yu@cn-c017.server.mila.quebec>

[33mcommit 1b0bd0fe8a4a9de749b9d4618758ff20c8658d86[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Aug 2 14:04:39 2023 -0700

    Add Falcon support (new) (#592)

[33mcommit 20044cab7aa6e884e13460506b0e0b6a12722b5d[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Wed Aug 2 13:35:10 2023 -0700

    Fix log message in scheduler (#652)

[33mcommit 64f23c29000ca832f50d3470a83d7a9bdbe95a0c[m
Author: Song <44120206+Oliver-ss@users.noreply.github.com>
Date:   Wed Aug 2 13:22:51 2023 +0800

    fix baichuan for different position embedding for 7b and 13b models (#643)

[33mcommit d4c7755ca88aefe749346f510be1b919186be0b6[m
Author: Qing <cwq1913@gmail.com>
Date:   Wed Aug 2 06:41:36 2023 +0800

    fix biachuan-7b tp (#598)
    
    Co-authored-by: wq.chu <wq.chu@tianrang-inc.com>

[33mcommit aa39e42c5a8a2359363529571cb553cc30e26d58[m
Author: Chaofan Lin <siriusneo@sjtu.edu.cn>
Date:   Tue Aug 1 04:11:57 2023 +0800

    fix doc (#622)

[33mcommit 953f28cf9a8440f3b61bb99013c12638368581ec[m
Author: Fang li <mklf@users.noreply.github.com>
Date:   Sun Jul 30 11:52:41 2023 +0800

    fix ModuleNotFoundError (#599)
    
    Co-authored-by: fangli <fangli@tencent.com>

[33mcommit c0d00f5be6d3ed390534dd909c82b639baf2d359[m
Author: Xudong Zhang <zxdvd_zhang@163.com>
Date:   Fri Jul 28 14:37:40 2023 +0800

    [Fix] fix import error of RayWorker (#604) (#605)

[33mcommit 58a072be15a4e36bee006d1c9a962e527819cf18[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Jul 25 23:46:30 2023 -0700

    [Fix] Add model sequence length into model config (#575)

[33mcommit 82ad323deed0d4f5fbdb6592f14314ca5b1118ad[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Jul 25 23:45:48 2023 -0700

    [Fix] Add chat completion Example and simplify dependencies (#576)

[33mcommit df5dd3c68ec7007e4b3a27907f4d954f1c7d511d[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Jul 25 15:25:12 2023 -0700

    Add Baichuan-7B to README (#494)

[33mcommit 2d867b55fa17840b50709fa12106e9fd6b2f527d[m
Author: MoeedDar <moeed.dar@gmail.com>
Date:   Tue Jul 25 22:16:51 2023 +0100

    fixed tensor parallel is not defined (#564)

[33mcommit d7a1c6d614756b3072df3e8b52c0998035fb453f[m
Author: Tao Peng <dev.pengtao@gmail.com>
Date:   Tue Jul 25 12:01:56 2023 +0800

    Fix paged attention testing. (#495)
    
    Signed-off-by: Tao Peng <jiankeng.pt@alibaba-inc.com>

[33mcommit 7d5a155e4aa258b0db1649bdcbf29477bf490ac2[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jul 24 18:36:33 2023 -0700

    [Fix] Fix GPTBigcoder for distributed execution (#503)

[33mcommit 1dde34e0f8f1021103e62fdf81ae7e89cce5aaf2[m
Author: leegohi04517 <58016551+leegohi04517@users.noreply.github.com>
Date:   Tue Jul 25 02:29:30 2023 +0800

    GPTJConfig has no attribute rotary.  (#532)

[33mcommit 6fc2a38b110f9ba6037b31ee016f20df32426877[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Jul 20 11:38:27 2023 -0700

    Add support for LLaMA-2 (#505)

[33mcommit c487a221ee27141170592d440cc973905a42fd97[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Jul 19 23:17:12 2023 -0700

    Fix bad assert in initialize_cluster if PG already exists (#526)

[33mcommit 9925c179409f7b14aef55bcfde47b320bd1a263c[m
Author: Antoni Baum <antoni.baum@protonmail.com>
Date:   Wed Jul 19 22:49:31 2023 -0700

    Ray placement group support (#397)

[33mcommit 8c4b2592fb953d1a8f880d42ebb1b28eaa94d0a6[m
Author: Ricardo Lu <37237570+gesanqiu@users.noreply.github.com>
Date:   Thu Jul 20 08:06:15 2023 +0800

    fix: enable trust-remote-code in api server & benchmark. (#509)

[33mcommit cf21a9bd5cd29b8b52a8dfceac22798ef648e6bc[m
Author: WRH <12756472+wangruohui@users.noreply.github.com>
Date:   Thu Jul 20 08:02:40 2023 +0800

    support trust_remote_code in benchmark (#518)

[33mcommit 16c3e295a877580867c8b90ace86acf3d1841455[m
Author: Massimiliano Pronesti <massimiliano.pronesti@gmail.com>
Date:   Thu Jul 20 02:01:19 2023 +0200

    fix(ray_utils): ignore re-init error (#465)

[33mcommit bda41c70ddb124134935a90a0d51304d2ac035e8[m
Author: Song <44120206+Oliver-ss@users.noreply.github.com>
Date:   Wed Jul 19 02:31:48 2023 +0800

    hotfix attn alibi wo head mapping (#496)
    
    Co-authored-by: oliveryuan <oliveryuan@basemind.com>

[33mcommit 453bafb96f48dfa1423bcec0a8cdc6e75f04fe1c[m
Merge: b4b195b3 328d231c
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Tue Jul 18 09:22:56 2023 -0700

    Merge pull request #498 from MoeedDar/main
    
    Fixed old name reference for max_seq_len

[33mcommit 328d231c17a6c414a40d6abf31c4deb410a750f8[m
Author: MoeedDar <moeed.dar@gmail.com>
Date:   Tue Jul 18 16:47:59 2023 +0100

    Fixed old name reference for max_seq_len

[33mcommit b4b195b3608610533e9d2c6c0168be71a8436355[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Mon Jul 17 23:20:20 2023 -0700

    fix max seq len (#489)

[33mcommit 20b0d88d1630aec3a18a80590080b0ab1d16969f[m
Author: codethazine <41583025+codethazine@users.noreply.github.com>
Date:   Mon Jul 17 21:50:55 2023 +0100

    Add support for baichuan (#365)

[33mcommit 2bdea7ac110d3090d6a3c582aed36577ca480473[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jul 17 00:33:48 2023 -0400

    [Fix] Fix the condition of max_seq_len (#477)

[33mcommit 58df2883cb3d3813e1d09ba691744773d9dcae58[m
Author: Zhanghao Wu <zhanghao.wu@outlook.com>
Date:   Sun Jul 16 13:37:14 2023 -0700

    [Doc] Add doc for running vLLM on the cloud (#426)
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 6d7d95a70a4308699ad60fb5bcc08904135086f2[m
Author: Zhangir Azerbayev <59542043+zhangir-azerbayev@users.noreply.github.com>
Date:   Sun Jul 16 02:11:02 2023 -0400

    Offload port selection to OS (#467)

[33mcommit 96853af5a830d42496aa6cfd5c670d073d6a0209[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Fri Jul 14 20:06:40 2023 -0400

    Optimize MQA Kernel (#452)

[33mcommit dbed69058c88ddf42914e6ab3a9b6ea12e15b12a[m
Author: Wen Sun <35923278+HermitSun@users.noreply.github.com>
Date:   Fri Jul 14 12:58:09 2023 +0800

    Fix the `KeyError` when loading bloom-based models (#441)

[33mcommit 7b6ae94059a7c7f097f32987489fb03b02cbf613[m
Author: panda <jasonailu87@hotmail.com>
Date:   Fri Jul 14 11:56:22 2023 +0800

    add vocab padding for LLama(Support WizardLM) (#411)

[33mcommit c6dfc3cdbeb4687a8313b82d399177e293fee196[m
Author: xcnick <xcnick0412@gmail.com>
Date:   Wed Jul 12 23:14:56 2023 +0800

    Fix handling of special tokens in decoding. (#418)

[33mcommit 51be365143382515a4be5f44d7ed9a900d5740b7[m
Author: Keming <kemingy94@gmail.com>
Date:   Wed Jul 12 23:10:55 2023 +0800

    fix: freeze pydantic to v1 (#429)

[33mcommit c894836108732d0cbb6fce15aeda8de1218a380d[m
Author: Andre Slavescu <51034490+AndreSlavescu@users.noreply.github.com>
Date:   Sat Jul 8 20:55:16 2023 -0400

    [Model] Add support for GPT-J (#226)
    
    Co-authored-by: woWoosuk Kwon <woosuk.kwon@berkeley.edu>

[33mcommit 75beba29b5c7316a9ebde9b0886f609dd5bf05bd[m
Author: Fazlul Shahriar <97305712+lpfhs@users.noreply.github.com>
Date:   Sat Jul 8 18:26:28 2023 -0400

    Don't try to load training_args.bin (#373)

[33mcommit ddfdf470ae721d5be668af97d5a2b5d40ce4c15c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Jul 8 15:24:17 2023 -0700

    Add trust_remote_code arg to get_config (#405)

[33mcommit b6fbb9a565a7e27d26e91a064dc83d13b36fa2b6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Jul 8 14:48:18 2023 -0700

    Sort the outputs before return (#402)

[33mcommit 2179e4f4c5c40d852044fddbcae80996c2feb092[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Sat Jul 8 12:42:08 2023 -0700

    avoid python list copy in sequence initialization (#401)

[33mcommit a945fcc2aec97d5fd85f5a7264814de04bbf5154[m
Author: codethazine <41583025+codethazine@users.noreply.github.com>
Date:   Fri Jul 7 20:04:58 2023 +0200

    Add trust-remote-code flag to handle remote tokenizers (#364)

[33mcommit be54f8e5c4083831aeaa4a1da9e248ddafcef54b[m
Author: Nicolas Frenay <nicolas.frenay@gmail.com>
Date:   Thu Jul 6 20:15:17 2023 -0500

    [Fix] Change /generate response-type to json for non-streaming (#374)

[33mcommit b396cb49982e740276b5dbd8c99b2f5a5d07aab0[m
Author: Ricardo Lu <37237570+gesanqiu@users.noreply.github.com>
Date:   Fri Jul 7 09:08:40 2023 +0800

    fix: only response [DONE] once when streaming response. (#378)

[33mcommit 1c395b4eaa805fc7cacf2f591e658ce395761537[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Jul 4 21:41:53 2023 -0700

    Bump up the version (#300)

[33mcommit 3d64cf019e85385e33b522f65ad9e1e7c665c3e3[m
Author: akxxsb <akxxsb@users.noreply.github.com>
Date:   Wed Jul 5 12:39:59 2023 +0800

    [Server] use fastchat.model.model_adapter.get_conversation_template method to get model template (#357)

[33mcommit 98fe8cb5420c28fa8dcc3110b6c898848dd57e45[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jul 3 23:01:56 2023 -0700

    [Server] Add option to specify chat template for chat endpoint (#345)

[33mcommit ffa6d2f9f9cc8d016f7d0bfb6247933bda028a73[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jul 3 16:51:47 2023 -0700

    [Docs] Fix typo (#346)

[33mcommit 404422f42ed9c59ee816dacd9b54196a59ae65b2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jul 3 16:47:53 2023 -0700

    [Model] Add support for MPT (#334)

[33mcommit 7717d0838b2b74313184a462bb6e08711a5950c6[m
Author: coolcloudcol <131243218+coolcloudcol@users.noreply.github.com>
Date:   Tue Jul 4 06:22:28 2023 +0800

    Fix an endless loop issue when engine_step throws a RuntimeError (#339)

[33mcommit 42e0c1df789a2079eeb219fa790cbf5678af662f[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jul 3 14:50:56 2023 -0700

    [Quality] Add CI for formatting (#343)

[33mcommit e41f06702cb6d6787ac4474832264108a6e28780[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jul 3 13:12:35 2023 -0700

    Add support for BLOOM (#331)

[33mcommit d6fa1be3a8ef71fa16f74afdc5d07d27cbf725b1[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jul 3 11:31:55 2023 -0700

    [Quality] Add code formatter and linter (#326)

[33mcommit 0ffded812aa9193838c3daae87981b46b2c6068c[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jul 3 09:27:31 2023 -0700

    [Fix] Better error message for batched prompts (#342)

[33mcommit 0bd2a573a5a88b6e6135145c5ef5abe3ac942f83[m
Author: Michele Catalano <michele.catalano@mayflower.de>
Date:   Mon Jul 3 18:17:50 2023 +0200

    Allow send list of str for the Prompt on openai demo endpoint /v1/completions (#323)
    
    * allow str or List[str] for prompt
    
    * Update vllm/entrypoints/openai/api_server.py
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>
    
    ---------
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit 49b26e2cec8c56594668905e853fe4af34336b05[m
Author: Ricardo Lu <37237570+gesanqiu@users.noreply.github.com>
Date:   Mon Jul 3 13:54:33 2023 +0800

    feat: add ChatCompletion endpoint in OpenAI demo server. (#330)

[33mcommit dafd924c1f165b4478a9d7a3c915d2ecc2e148e2[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Fri Jun 30 18:48:49 2023 -0700

    Raise error for long prompt (#273)

[33mcommit 598dc4b79a0078fe14e0c134d0b53b4842a8b227[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Jun 29 22:14:17 2023 -0700

    [Fix] Weight loading for GPTBigCode (#313)

[33mcommit 85de0934727dc2c7b740b1d4a90d1a2e3c2d0585[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Jun 29 15:00:21 2023 -0700

    [Fix] Do not pin memory when in WSL (#312)

[33mcommit f72297562f0afb13d762eec4dfd76af90f4c6fe2[m
Author: Zhanghao Wu <zhanghao.wu@outlook.com>
Date:   Thu Jun 29 12:32:37 2023 -0700

    Add news for the vllm+skypilot example (#314)

[33mcommit 9d27b09d12767de775a92d765e177a61f8477189[m
Author: Bayang <bayangp0@gmail.com>
Date:   Thu Jun 29 14:52:15 2023 +0100

    Update README.md (#306)

[33mcommit 998d9d15095e7a69629f9e131c8b59bfdd1c6314[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 28 14:19:22 2023 -0700

    [Tokenizer] Add tokenizer mode (#298)

[33mcommit 425040d4c15464a3185c5a6010ce58d1919591ae[m
Author: Lily Liu <lilyliupku@gmail.com>
Date:   Wed Jun 28 14:11:51 2023 -0700

    remove floats == 0 comparison  (#285)

[33mcommit 4338cc475029dcd37a291a867d52419122648e72[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 28 09:46:58 2023 -0700

    [Tokenizer] Add an option to specify tokenizer (#284)

[33mcommit bdd6b4c8bc3e5ac93553436514171ffad5926f0c[m
Author: Jishnu Ray Chowdhury <jishnu.ray.c@gmail.com>
Date:   Wed Jun 28 02:28:29 2023 -0500

    Add LLM.set_tokenizer (#283)

[33mcommit 2b7d3aca2e1dd25fe26424f57c051af3b823cd71[m
Author: Cody Yu <hao.yu.cody@gmail.com>
Date:   Tue Jun 27 14:34:23 2023 -0700

    Update setup.py (#282)
    
    Co-authored-by: neubig <neubig@gmail.com>

[33mcommit 4026a049d3ad510bea8e177bf71722bd510fbb46[m
Author: twaka <twaka@users.noreply.github.com>
Date:   Tue Jun 27 22:27:41 2023 +0900

    expand coverage of gpt2 model loading (#271)

[33mcommit 43710e8d0965d616db51639ced76605dee1bde93[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jun 26 13:15:35 2023 -0700

    [Fix] Fix default port number in benchmark scripts (#265)

[33mcommit 526df28fb250c90970cd3db0f68a21797dbe555f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 26 13:09:02 2023 -0700

    [BugFix] Fix a bug in counting running sequences (#266)

[33mcommit 2cf1a333b63a303fd4b65dd499f2e9b606e6525a[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jun 26 11:34:23 2023 -0700

    [Doc] Documentation for distributed inference  (#261)

[33mcommit 0b7db411b5af4bf8a3a0cf989daa024ba5401ac1[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jun 26 11:16:13 2023 -0700

    [Bug] Fix the OOM condition for CPU cache (#260)

[33mcommit 471a7a456667971721a1ce589029fc82be6ab193[m
Author: BasicCoder <abasiccoder@gmail.com>
Date:   Tue Jun 27 00:23:57 2023 +0800

    Compatible with Decapoda Research llama hf version (#251)

[33mcommit 6214dd6ce95cc2d00daa14b0db6ca0661cd83853[m
Author: Lianmin Zheng <lianminzheng@gmail.com>
Date:   Sun Jun 25 16:58:06 2023 -0700

    Update README.md (#236)

[33mcommit 0603379863cd98aac0b56a32eed49c6f0c8bff46[m
Author: metacryptom <98044045+metacryptom@users.noreply.github.com>
Date:   Sun Jun 25 13:00:24 2023 +0800

    fix wrong using getattr to get dict value (#232)

[33mcommit 665c48963be11b2e5cb7209cd25f884129e5c284[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jun 22 15:05:11 2023 -0700

    [Docs] Add GPTBigCode to supported models (#213)

[33mcommit 298695b76691867ecd320ea6a2c6d0c6a843d5ae[m
Author: Michael Feil <63565275+michaelfeil@users.noreply.github.com>
Date:   Thu Jun 22 19:49:27 2023 +0200

    GPTBigCode (StarCoder, SantaCoder Support) (#209)

[33mcommit 83658c8ace771617460f9e2d5f1cf6f811d6d6fb[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Jun 22 15:33:32 2023 +0800

    Bump up version to 0.1.1 (#204)

[33mcommit 1d24ccb96cdfbb42fc2b0f0591df82727d9537c6[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Jun 22 15:30:06 2023 +0800

    [Fix] Better error message when there is OOM during cache initialization (#203)

[33mcommit 14f0b39cda15b948e0d5e7c87c4cef09e8db240a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Jun 22 00:17:24 2023 -0700

    [Bugfix] Fix a bug in RequestOutput.finished (#202)

[33mcommit 2e0d3143844303136c8aefa4c7e7bac30fd26850[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Jun 22 00:21:41 2023 +0800

    fix-ray (#193)

[33mcommit 67d96c29fba9b72cb4c4edbc26211c208a00ebdd[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 19 23:19:47 2023 -0700

    Use slow tokenizer for open llama models (#168)

[33mcommit 033f5c78f5bd0b6a16ad7e5e973ce765fbe19374[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Jun 20 14:00:28 2023 +0800

    Remove e.g. in README (#167)

[33mcommit 794e578de0f9657e169c713908a5fb8d25046b13[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 19 22:57:14 2023 -0700

    [Minor] Fix URLs (#166)

[33mcommit caddfc14c1bbd357a039144efa44604be4ea5e5d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 19 20:35:38 2023 -0700

    [Minor] Fix icons in doc (#165)

[33mcommit fc72e39de33ed854360cd4ada18f97b236f2de85[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Jun 20 11:15:15 2023 +0800

    Change image urls (#164)

[33mcommit b7e62d3454afc807ddcc2fe3a56ce075461f1bc4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 19 20:03:40 2023 -0700

    Fix repo & documentation URLs (#163)

[33mcommit 364536acd1477ce3aa3158d7e15dbe1a9563e9ec[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 19 19:58:23 2023 -0700

    [Docs] Minor fix (#162)

[33mcommit 0b32a987ddb0d73dbf366c51eb5a0b7daf0d3ec0[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue Jun 20 10:57:46 2023 +0800

    Add and list supported models in README (#161)

[33mcommit 570fb2e9cc3e128a3d9f996859ee6ff6590efed6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 19 18:05:01 2023 -0700

    [PyPI] Fix package info in setup.py (#158)

[33mcommit a255885f83b8d302fa684d4c972b2c69c44d47eb[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jun 19 16:31:13 2023 +0800

    Add logo and polish readme (#156)

[33mcommit 5822ede66ee834f406d475ce28a1d8f666458a48[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Jun 18 23:46:24 2023 -0700

    Add performance figures for dark mode (#160)

[33mcommit 0370afa2e55c4934e8d38fa1dfe22e7a8e64345a[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jun 19 11:12:37 2023 +0800

    Remove benchmark_async_llm_server.py (#155)

[33mcommit 7e2a913c64bae56e1835e061d3b23c490508ec52[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Jun 18 19:58:25 2023 -0700

    [Minor] Fix CompletionOutput.__repr__ (#157)

[33mcommit 3f92038b990b26fdb9e6a9bccab0e3ec0cdc6aea[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Jun 18 11:39:35 2023 -0700

    Add comments on swap space (#154)

[33mcommit dcda03b4cb2c757682abe0faf14a6379dcde1cb2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Jun 18 03:19:38 2023 -0700

    Write README and front page of doc (#147)

[33mcommit bf5f121c0284a2a06483b585f0d49e8508c69573[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Jun 18 17:33:50 2023 +0800

    Reduce GPU memory utilization to make sure OOM doesn't happen (#153)

[33mcommit bec7b2dc26c332563e9c0e53474a47c6c69b2a96[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Jun 18 01:26:12 2023 +0800

    Add quickstart guide (#148)

[33mcommit 0b98ba15c744f1dfb0ea4f2135e85ca23d572ae1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Jun 17 03:07:40 2023 -0700

    Change the name to vLLM (#150)

[33mcommit e5464ee484450c2671dd0226516c99c60ce70d9d[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sat Jun 17 17:25:21 2023 +0800

    Rename servers to engines (#152)

[33mcommit bab8f3dd0ddf18ed0e28f77de57f0e55c7097aff[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jun 16 21:00:52 2023 -0700

    [Minor] Fix benchmark_throughput.py (#151)

[33mcommit eedb46bf03818796536358f3767ee2b6a619b4f5[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sat Jun 17 00:13:02 2023 +0800

    Rename servers and change port numbers to reduce confusion (#149)

[33mcommit 311490a720951f322977d811eacea685a623b5a1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 14 19:55:38 2023 -0700

    Add script for benchmarking serving throughput (#145)

[33mcommit da5ddcd544ac5ce6bc4f522af9cbdc315f94620e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Jun 10 21:25:11 2023 -0700

    Remove redundant code in ColumnParallelLinear (#146)

[33mcommit 5020e1e80c33e57ec9d4f7e17f35bc87b1a7cb01[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Jun 11 01:43:07 2023 +0800

    Non-streaming simple fastapi server (#144)

[33mcommit 4298374265a4379a2bd378373c7252b7a7b2b34f[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Jun 7 18:25:20 2023 +0800

    Add docstrings for LLMServer and related classes and examples (#142)

[33mcommit e38074b1e6ad0975acbfa15d858c4bd7cd005e99[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Jun 7 00:40:21 2023 -0700

    Support FP32 (#141)

[33mcommit 376725ce74d2d75490eed1840b41de00c0e4acd6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 5 20:03:14 2023 -0700

    [PyPI] Packaging for PyPI distribution (#140)

[33mcommit 456941cfe4313f5b89390e55fa4ed0b9771731ce[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Jun 5 20:01:26 2023 -0700

    [Docs] Write the `Adding a New Model` section (#138)

[33mcommit 1a956e136beae057746af6257ffa8da601730f10[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Mon Jun 5 23:44:50 2023 +0800

    Fix various issues of async servers (#135)

[33mcommit 8274ca23ac9f2ea0ccf758d1883794643aecb2e0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Jun 4 12:52:41 2023 -0700

    Add docstrings for LLM (#137)

[33mcommit 62ec38ea4148bb8147f346f7e01cab6b8a2ec7b6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jun 2 22:35:17 2023 -0700

    Document supported models (#127)

[33mcommit 0eda2e0953080467eb98f2730341acea0287cdc0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Jun 2 22:27:44 2023 -0700

    Add .readthedocs.yaml (#136)

[33mcommit 211318d44ad3225eaba488150f797efceab6cc32[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 28 03:20:05 2023 -0700

    Add throughput benchmarking script (#133)

[33mcommit 337871c6fd581b74949849ad645064318896801b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 28 02:51:42 2023 -0700

    Enable LLaMA fast tokenizer (#132)

[33mcommit 56b7f0efa4d83865afc2da38b40b2f337d778dda[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat May 27 01:13:06 2023 -0700

    Add a doc for installation (#128)

[33mcommit d721168449281a5f5a299bba8d94523ad4e833cb[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat May 27 00:59:32 2023 -0700

    Improve setup script & Add a guard for bfloat16 kernels (#130)

[33mcommit 4a151dd45308f812d125b6ea239b1730b7f647c4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu May 25 00:09:07 2023 -0700

    Add activation registry (#126)

[33mcommit 057daef778ec4e951841f44afda1cd0b1eb50ee4[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Tue May 23 21:39:50 2023 -0700

    OpenAI Compatible Frontend (#116)

[33mcommit e86717833da1216222cf0d490c2e3ba198610b13[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue May 23 20:46:32 2023 -0700

    Incrementally decode output tokens (#121)

[33mcommit aedba6d5ec4e1eaad10745f71970c10b601f9dc1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue May 23 18:22:26 2023 -0700

    Print warnings/errors for large swap space (#123)

[33mcommit a283ec2eece57454ec9301e5542cffa1201e175f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue May 23 17:58:51 2023 -0700

    Add contributing guideline and mypy config (#122)

[33mcommit 3f942acfe15de367931a63aa96c1931eb74799c0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon May 22 17:03:40 2023 -0700

    Fix latency benchmark script (#118)

[33mcommit 19d289943978d72fa6b96eeaae154a418e82097c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon May 22 17:02:44 2023 -0700

    Add initial sphinx docs (#120)

[33mcommit 655a5e48df3937bf793add53aa95ce0c992a24c6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 21 17:04:18 2023 -0700

    Introduce LLM class for offline inference (#115)

[33mcommit f746ced08d224113110adfc5526d952e51972515[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 21 11:18:00 2023 -0700

    Implement stop strings and best_of (#114)

[33mcommit c3442c1f6fabe54adb82d2d676920c5f31b9834e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat May 20 13:06:59 2023 -0700

    Refactor system architecture (#109)

[33mcommit 7297fa6f7c4ce6413ee005025b312c4c9d4f5f0b[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sat May 20 09:11:34 2023 -0600

    Remove unused parts in Megatron-LM code and add copyright notice (#110)

[33mcommit b7955ef17b8d899327b25564f20665ec3ffa71cb[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Fri May 19 14:00:46 2023 -0600

    Fix timeout error in the FastAPI frontend (#34)

[33mcommit f756799b84f5558c82c7a049069f845b31573e9e[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Fri May 19 11:35:44 2023 -0600

    Use runtime profiling to replace manual memory analyzers (#81)

[33mcommit 825d8892b54af80516ce98a89b595018f756a6d3[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 17 17:11:23 2023 -0700

    Use pytest format for unit tests (#107)

[33mcommit b322fd1607597930993dfd005343c4f04c6545d4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 14 22:32:38 2023 -0700

    Add docstrings to some modules and classes (#100)

[33mcommit 667ba3995c013df060657a4cdf3931176c6c5259[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 14 22:19:19 2023 -0700

    Add copyright headers to source files adapted from FT (#104)

[33mcommit 707ec647bb3a5018e5d8cdded409d6244bbb9ea5[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 14 21:54:32 2023 -0700

    Add copyright headers for HF models (#103)

[33mcommit 89988ec8c2a0c3e18e63767d9df5ca8f6b8ff21c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 14 18:05:19 2023 -0700

    Add Apache-2.0 license (#102)

[33mcommit 6208d622ca74789f329fb4e9041a600e1f96659b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri May 12 18:07:09 2023 -0700

    Minor code cleaning for SamplingParams (#99)

[33mcommit 42f1042e1c71f89b7875a292d1adf3a8d01c6d49[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu May 11 15:45:30 2023 -0700

    Enhance SamplingParams (#96)

[33mcommit 55f8b0a5def22ed6b85d3b91b726a7573d54313b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 10 23:39:12 2023 -0700

    Implement presence and frequency penalties (#95)

[33mcommit 9f88db35da012544a9cd9450c68b8df2e6509b92[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 10 12:51:36 2023 -0700

    Support top-k sampling (#94)

[33mcommit ae356774ab60af7ffa665a7b80e28bd73a9a7f48[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 10 01:57:07 2023 -0700

    Avoid sorting waiting queue & Minor code cleaning (#93)

[33mcommit e331957784339ec1ca225b4752ea93fbdc34d851[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 10 01:06:53 2023 -0700

    Log system stats (#90)

[33mcommit 8d66a7b6d747dd28fb29b998473f159ec08be2da[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 10 00:58:31 2023 -0700

    Rename variables and methods (#91)

[33mcommit ce26e57fd3ff4d6f92e5bb48b5e55b23ab5d2171[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue May 9 16:47:39 2023 -0700

    Update sample prompts in `simple_server.py` (#89)

[33mcommit 85eb6318391fc25d708af6109480498b45f56c77[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue May 9 16:03:44 2023 -0700

    Use slow tokenizer for LLaMA (#84)

[33mcommit add055e151f32f89dab5932d25e5285b2fc823f1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue May 9 15:46:42 2023 -0700

    Enhance model loader (#83)

[33mcommit 7c041ab5784760416f85d68eb8925a1d1f981932[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue May 9 15:30:12 2023 -0700

    Refactor system architecture (#82)

[33mcommit 8917782af6a5892a0afb697badbe761dc8558619[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon May 8 23:03:35 2023 -0700

    Add a system logger (#85)

[33mcommit 7addca5935c83806429d7ec557999a505e6f6a35[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun May 7 16:30:43 2023 -0700

    Specify python package dependencies in requirements.txt (#78)

[33mcommit c84e924287fbaf923994865806e7ebc93b4070e6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat May 6 02:12:12 2023 -0700

    [Minor] Fix a dtype bug (#79)

[33mcommit c9d5b6d4a8b3f51ff6c9eee7eb52bb5149d89b6a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri May 5 02:01:08 2023 -0700

    Replace FlashAttention with xformers (#70)

[33mcommit 189ae231336857bcc4c6f6157bf7868cdf56fb5f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu May 4 03:05:37 2023 -0700

    Use dtype from model config & Add Dolly V2 (#63)

[33mcommit e548c1488ae1e93b5ca60359f4b292d2bee0b60d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu May 4 02:59:56 2023 -0700

    Add support for GPT-2 (#60)

[33mcommit 130d5fd8c7902a5a2e54feb25249168151e3bc2f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu May 4 02:56:09 2023 -0700

    Fix a bug in attention kernel (#68)

[33mcommit e070829ae81dc59cb660cf462a55fb703cd997e7[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 3 14:09:44 2023 -0700

    Support bfloat16 data type (#54)

[33mcommit 436e523bf1616bea22a1df78d93d7522311dccc8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed May 3 13:40:13 2023 -0700

    Refactor attention kernels (#53)

[33mcommit 27f1410d065ceca53a07abd2518082eb25228e4f[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed May 3 15:32:04 2023 +0800

    New weight loader without np copy (#52)

[33mcommit 4858f3bb45ec62fab1fc32dc26eb1e2a8e1df14b[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Apr 30 15:42:17 2023 +0800

    Add an option to launch cacheflow without ray (#51)

[33mcommit a96d63c21d18ad6610adfcabd3aae02c6357334e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Apr 28 00:32:10 2023 -0700

    Add support for GPT-NeoX (Pythia) (#50)

[33mcommit aa50b17ca776f8c69a793787d0ce06dfa4671884[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Apr 17 04:49:14 2023 +0000

    Change plotting script

[33mcommit 0f4b32199ec6c5d16bc03767e36fff2d54559ff8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Apr 15 09:03:24 2023 -0700

    Support various block sizes & Change default block size to 16 (#38)

[33mcommit 84eee24e20ff4c0fc1b126289265f560089efa47[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Apr 12 15:03:49 2023 -0700

    Collect system stats in scheduler & Add scripts for experiments (#30)

[33mcommit e3cec88aa5b7ac391e4aa6dc9b6388100d59d8f9[m
Author: Siyuan (Ryans) Zhuang <suquark@gmail.com>
Date:   Mon Apr 10 18:22:49 2023 -0700

    Memcpy kernel for flash attention (#29)
    
    * optimize
    
    * add benchmark
    
    * add assert
    
    * add test

[33mcommit b9926f7f663b953c886a42b691cd7ba3e4325239[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Apr 9 23:07:18 2023 -0700

    Support block size 32 (#35)

[33mcommit ee88a7e5f3acc1f81c52dfc45d2bdd542b4cd9ed[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Apr 8 23:36:12 2023 -0700

    Add an option to use dummy model weights (#33)

[33mcommit c267b1a02c952b68a897c96201f32ad57e0b955e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Apr 8 13:36:09 2023 -0700

    Add query stride to multi_query_cached_kv_attention & Add kernel benchmark script (#27)
    
    * Add query stride to multi_query_cached_kv_attention
    
    * Add kernel benchmark script

[33mcommit 0f40557af6141ced118b81f2a04e651a0c6c9dbd[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Apr 7 17:45:07 2023 -0700

    Implement block copy kernel to optimize beam search (#32)

[33mcommit a490aafa3671da1b6b2be6cff4568913fcb1732c[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Thu Apr 6 13:44:24 2023 +0800

    Fix potential bugs in FastAPI frontend and add comments (#28)

[33mcommit 12659a0bd7e442d1e3dcbff4a4d5909a02c76c60[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Apr 5 11:16:57 2023 -0700

    Add CUDA graph-based all reduce launcher (#26)

[33mcommit 21b3671bbc508662561ae95a418a26dbe71db356[m
Author: Siyuan (Ryans) Zhuang <suquark@gmail.com>
Date:   Tue Apr 4 20:34:46 2023 -0700

    Basic attention kernel that supports cached KV + (multi-)prompts (#24)

[33mcommit 897cb2ae28e93de1b22ecfbffcccfb9493f8f4d9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Apr 2 00:30:17 2023 -0700

    Optimize data movement (#20)

[33mcommit 1f01a18d39b7fc873b79024b5799597cb6fc88bc[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sun Apr 2 15:23:29 2023 +0800

    Merge QKV into one linear layer (#15)

[33mcommit 2c5cd0defe110cb1a5c699852f4b38284a2b86b4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Apr 1 19:00:20 2023 -0700

    Add ninja to dependency (#21)

[33mcommit a90c97d72705f57b589062a2e09917dd9d27e389[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Mar 31 23:33:43 2023 -0700

    Use FP32 for log probabilities (#19)

[33mcommit e3f00d191e1c1fa1aae0a895ef74a2ed8edd1b30[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sat Apr 1 01:07:57 2023 +0800

    Modify README to include info on loading LLaMA (#18)

[33mcommit 09e9245478a44faec3c9bc888edea4089085e222[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Mar 31 09:51:22 2023 -0700

    Add custom kernel for RMS normalization (#16)

[33mcommit c45f3c3ab60f4bf4eaab791a76028b8b07ffe9bd[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Sat Apr 1 00:51:08 2023 +0800

    Optimize tensor parallel execution speed (#17)

[33mcommit 7a7929abe8e2fd6a4688487c471a1ee1fde0edd2[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Mar 30 14:51:46 2023 -0700

    Implement preemption via recomputation & Refactor scheduling logic (#12)

[33mcommit 88c0268a18f1c724d59a624364635d5c7ac39408[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Mar 30 11:04:21 2023 -0700

    Implement custom kernel for LLaMA rotary embedding (#14)

[33mcommit 80a2f812f17add5838f84288054fbe0b915622cc[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Mar 29 21:25:32 2023 -0700

    Implement LLaMA (#9)
    
    
    Co-authored-by: Zhuohan Li <zhuohan123@gmail.com>

[33mcommit a1b3de86cd6f27aeb299d45296a7409b8d2b7c0c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Mar 29 18:59:27 2023 -0700

    Refactor the test code for attention kernels (#13)

[33mcommit 64e0e383148a613c327d4bf9e866b7a185df8277[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Mar 29 16:38:48 2023 -0700

    Add cache watermark to avoid frequent cache eviction (#11)

[33mcommit 721fa3df155e5649bbe2188517594f24f4e63523[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Mar 29 14:48:56 2023 +0800

    FastAPI-based working frontend (#10)

[33mcommit d359cda5fae1c9a6fe54ba12b940572edfbf87ac[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Mar 26 08:00:39 2023 +0000

    Minor

[33mcommit 2f49f155858faaf82bfd076a821497e41e961658[m
Author: Zhuohan Li <zhuohan123@gmail.com>
Date:   Wed Mar 22 04:45:42 2023 +0800

    Support tensor parallel (#2)

[33mcommit cfae35b861c5fc0c9f3689f99c7aba2e4501beb8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Mar 13 13:48:38 2023 -0700

    Add miscellaneous updates (#8)

[33mcommit e9d3f2ff7772c8efe41dc805cec71c223ec18ec8[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Mar 11 23:23:14 2023 -0800

    Add memory analyzer & utomatically configure KV cache size (#6)

[33mcommit 1a7eb7da6157541ed7867c9aff94231695f2cee9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Mar 10 09:58:21 2023 -0800

    Support beam search & parallel generation (#7)

[33mcommit 04e5acc08ed5b878225491bf62540ea10274fb29[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Mar 6 10:05:27 2023 -0800

    Fix a bug in 1D input shape (#5)

[33mcommit 3e9f991d6acd7efd90f04f1f530b837a40c93442[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Mar 1 21:13:08 2023 -0800

    Use FlashAttention for `multi_query_kv_attention` (#4)

[33mcommit 0deacbce6e96a1af5885babc4e470ce2a0cecf95[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Mar 1 15:02:19 2023 -0800

    Implement `single_query_cached_kv_attention` kernel (#3)

[33mcommit cbf8779afafdaba2ddc6e2212d67c40f1b6e11fd[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 16:29:36 2023 -0800

    Fix a bug in tying OPT embeddings (#1)

[33mcommit c84c708a1d13e5815376c2640cafeefaaf801827[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 12:04:49 2023 +0000

    Add README

[33mcommit fa16389a2e2fa8207f2489e64657897eec17662c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 11:56:21 2023 +0000

    Clean up the server script

[33mcommit 6aef2278f457e564c17a84465b8b4e74986ccd3c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 11:56:06 2023 +0000

    [Minor] Fix printing format

[33mcommit 1132fae0ca7f6103b0dd7b96932c75f5ed780288[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 11:46:43 2023 +0000

    Add Frontend

[33mcommit 46ce1356f7108f27af9ebb153ddbe02d1a3fa97d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 11:44:40 2023 +0000

    Add max_num_steps to SamplingParams

[33mcommit b39f149a0853c6b6d48716f21fbb7b97828d17f4[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 11:44:21 2023 +0000

    Add is_finished

[33mcommit ef6098ec51fcd07da3b93704e2c48e1f861ff00b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 10:36:08 2023 +0000

    Merge pre_step and step

[33mcommit 53f70e73344a67f61b80feab03834a770bfb671b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 10:22:39 2023 +0000

    Reduce the number of states in scheduler

[33mcommit 762fd1c3faf17001b943cb68e5d08e7d7fe59119[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 08:58:46 2023 +0000

    Refactor and annotate types for attention

[33mcommit 7f22f90e8cb423fdaa35203d41badd734d9c2e86[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 08:36:16 2023 +0000

    Remove xformers

[33mcommit afdbe5d3736f156e2a2c0afd13891f47a416baf5[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Fri Feb 24 01:33:37 2023 +0000

    [WIP] Add server script

[33mcommit 932844f1cd781aa926439ee2394edfb2f9e696f7[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 23:02:25 2023 +0000

    Fix attention

[33mcommit ba84b8728a8d0a766a636b30661836c30b17fbe6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 22:29:46 2023 +0000

    Fix attention

[33mcommit 87e0bcd426c746a17229e8e292cc2997d0719e9b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 21:32:02 2023 +0000

    Fix attention

[33mcommit 1ce13335732c8b28d4a76118821b391f6b219b7c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 21:31:39 2023 +0000

    Set default dtype to half

[33mcommit de0fabbc5c84e6771d70b92014ae06fe82654ff0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 20:30:12 2023 +0000

    Fix sampler

[33mcommit fdd0f2f4723afd8c45edacf9357c5a8973767da6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 20:23:47 2023 +0000

    Minor

[33mcommit 7f985166f727159424ae8ede07d8030c3fd36413[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 20:20:33 2023 +0000

    Consider pempty tensor

[33mcommit 86f9eb6d39f12372c7349809485d743241f58907[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 20:19:24 2023 +0000

    Fix typo

[33mcommit 1f6c7ef437b7b3ce5b83ca1b5a1de54183331bdd[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 09:32:19 2023 +0000

    Add controller

[33mcommit d4bc1a4d248a5d23e1f731ecb53511a9a54f5dfc[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 09:31:55 2023 +0000

    Add unoptimized OPT Attention

[33mcommit b56b6ca0d650c653c80ec113e27d6a8e640a4b2f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 09:26:09 2023 +0000

    Add greedy sampler

[33mcommit 343cea3dbcc5d3ee44654fa6289262c2553486c5[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 09:25:01 2023 +0000

    Add seq_ids to input metadata

[33mcommit 4f6f4967f6af78534f460d75a9391f9a42b564b0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 07:55:14 2023 +0000

    Add get_block_table

[33mcommit 331fa0b042b5cbcdadb03f25dc8592aba9c12b53[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 07:54:20 2023 +0000

    Implement scheduler.step & Add a threshold for batch size

[33mcommit 501c4bd0cd8896df92c49f3eeda06b1ddd52d736[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 07:39:20 2023 +0000

    decoding.py -> sampling_params.py

[33mcommit 86c682cd32efe8a3322ab47ed0d7bed06809f43d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 07:38:43 2023 +0000

    DecodingParams -> SamplingParams

[33mcommit af16c050742979475fa8fe842e9916eb389d872a[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 05:58:04 2023 +0000

    Add get_len

[33mcommit d094512296ad18968efffd925c372533e9dd12e3[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 04:57:46 2023 +0000

    Move max_context_len

[33mcommit 4b1ac23f53d0e714a4a48d2c8058438405c0fd07[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 23 00:10:07 2023 +0000

    Fix slot mapping

[33mcommit 8290fce47d0d5efa02edc52d4c6961bea6043a31[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 22 19:01:38 2023 +0000

    Add Worker class

[33mcommit 7b6844e59044309b1c4014b02b95428018bfd8a5[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 22 19:01:20 2023 +0000

    Add input metadata

[33mcommit 608f74ffe5635cd8ac7fc78a13e3d67a4f59b9e0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 22 18:08:25 2023 +0000

    Minor

[33mcommit 709a69176ea86f60786acb87ede52e62d9efb036[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Wed Feb 22 18:03:48 2023 +0000

    Move worker/models -> models

[33mcommit af68ec1c5c5eabb12865d8468391fe2c8df8d3b6[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Feb 18 19:23:07 2023 +0000

    Add tests for kernels

[33mcommit c413c41cda0f9359e7a12bb674c0f87bf41798c5[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sat Feb 18 19:22:57 2023 +0000

    Add reshape_and_cache op

[33mcommit ffad4e1e031a9facda4cab5b9fff31b47157aebc[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 16 20:05:45 2023 +0000

    cache_kernel -> cache_kernels

[33mcommit 6d2f74efb34566edc11477a651749173cac4c25d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 16 09:24:42 2023 +0000

    Remove redundant fn

[33mcommit 3b41f16596e9981dac8df85b4eff00311abcfec3[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 16 07:47:21 2023 +0000

    Add gitignore

[33mcommit 6f058c7ba88e657457ad5db9226d5b194e5aaabe[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 16 07:47:03 2023 +0000

    Implement cache ops

[33mcommit a1c67e6db8d59c05b8785c48c1c189e6e708a2a0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 16 01:42:53 2023 +0000

    Minor

[33mcommit 9e68a6827ef7e08c71b9c4a92cf3c2be7b60fc84[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 16 01:33:03 2023 +0000

    Fix return type error

[33mcommit 8edcabc737c867cf237289134583c2bbc852f11e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 16 01:28:17 2023 +0000

    Add warning

[33mcommit 2f4887de77fc36ec27f6b2e8d4cd52c9cf02efed[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 16 01:24:45 2023 +0000

    Fix KVCache shape

[33mcommit 3363c27d1954fd63741020dbf5e48bc9b9735cd7[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 09:34:07 2023 +0000

    Add __repr__

[33mcommit 2729087efe1f3e75383eceee09273168da1b8809[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 09:20:12 2023 +0000

    Fix a ref count bug in swapping

[33mcommit c128c2ed0309dd1ff684ac0da2f8fc7ea5994b77[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 09:14:05 2023 +0000

    Fix double free

[33mcommit c80ed212a19ae124e6e926ead1ee17200fc91646[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 09:06:27 2023 +0000

    Minor

[33mcommit 263e91b3864060393b1945c0536005cc0c5afced[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 09:05:39 2023 +0000

    Minor

[33mcommit be1e2163c9f9519310abe2519caa36b0a6966a1b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 08:45:59 2023 +0000

    Fix memory leak in swapping

[33mcommit 7e5f604e68fb3eb69c62297984a4da355b7f8eba[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 02:25:32 2023 +0000

    Fix bugs in scheduler

[33mcommit 1f739f9b03663206d5c9c4648d9d5674e695652e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 02:12:58 2023 +0000

    Fix a bug in swap_in and swap_out

[33mcommit b1644f764f8111e34872fa871745c97ee08a3226[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 01:57:40 2023 +0000

    Fix can_swap_in

[33mcommit c574f1950642ea835ede31d5458975ab4bc6e80f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 01:19:27 2023 +0000

    Fix typo

[33mcommit e40fa136aad5fde3d77e43e21b078e972be743fd[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Tue Feb 14 01:19:05 2023 +0000

    Fix typo

[33mcommit ee9442518d88925e96c36f1a039d61893d224e78[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 13 22:51:03 2023 +0000

    Fix get_model

[33mcommit 531e1c74e81075de85070dae84938e597756684b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 13 18:51:33 2023 +0000

    Fix typo

[33mcommit d3d317665b594e752422039f925ff8a0770723f1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 13 09:37:00 2023 +0000

    Fix scheduler

[33mcommit fffa2e1f4b7534d5f86e900838d9a24dfba307c9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 13 09:36:12 2023 +0000

    Add model_utils

[33mcommit bb59a3e7302ad6892e097eee4040e3f516e9f4ea[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 13 09:35:48 2023 +0000

    Fix cache engine

[33mcommit 5a309bb5887eeba8d47f07854c476870f3b40f03[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 13 02:39:53 2023 +0000

    Add scheduler

[33mcommit 0961f5a49a7f826a8b8be08451b308b374868c51[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 13 02:39:12 2023 +0000

    Add find method to sequence group

[33mcommit eb52db1bea23cdad8c5dc55d32e9eb69b20591d9[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Mon Feb 13 02:38:50 2023 +0000

    Fix can_swap_in

[33mcommit a2a9869cb7e11a46c215e0cd55401509395c035d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Feb 12 08:25:05 2023 +0000

    SERVING -> RUNNING

[33mcommit 46958cf941997264ff36c23c42a71d30674b61f0[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Sun Feb 12 08:15:18 2023 +0000

    BlockAllocator -> BlockManager

[33mcommit 3be29a1104e15c3bb30ed1d42eda476d2bf9f04e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:37:06 2023 +0000

    Add blank setup file

[33mcommit 38ed06a846511e5e048da800a28671519457511c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:30:55 2023 +0000

    Minor

[33mcommit 0a11a2e5ca764af37254fc962e5e6d35295d499b[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:28:12 2023 +0000

    Add gitignore

[33mcommit e7bee2aa811963b8c5ce352a427595749f6bfca1[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:28:02 2023 +0000

    Add cache engine

[33mcommit aa78aeaa0f4fee0ccb0184914266d6170cfc848f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:27:33 2023 +0000

    Add block manager

[33mcommit 3c2b47fcae9cd60c03d599462380e27c8195b15e[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:27:06 2023 +0000

    Add decoding params

[33mcommit 5e644b912ec10ec0fac02ccdc0f9a4d8342d8f4c[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:26:50 2023 +0000

    Add utils

[33mcommit d904350a2c9a9fb2e476b45a486cc72fa6c2bd8f[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:26:35 2023 +0000

    Add sequence

[33mcommit 6680129ba2d9c779050a18a97aeb57930a0b2f35[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:26:21 2023 +0000

    Add blocks

[33mcommit 39161c98a054756cb39edb9f634c6a466410c92d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:25:37 2023 +0000

    Add OPT

[33mcommit e7d9d9c08c79b386f6d0477e87b77a572390317d[m
Author: Woosuk Kwon <woosuk.kwon@berkeley.edu>
Date:   Thu Feb 9 11:24:15 2023 +0000

    Initial commit
